{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5OeTiryEcoX"
   },
   "source": [
    "# Fine-tuning Gemma2 2B model on Roadrunner with JAX, Flax.\n",
    "\n",
    "We have adopted the Gemma2 notebook from Google Deepmind to use HuggingFace's libraries and and simplified the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m81VQOqEcoX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade kagglehub -q\n",
    "!pip install ipywidgets -q\n",
    "!pip install tensorflow-cpu -q\n",
    "!pip install tensorflow_datasets -q\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu -q\n",
    "!pip install git+https://github.com/felafax/gemma.git -q\n",
    "!pip install qax -q\n",
    "!pip install jax-lorax -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HUB_CACHE'] = '/mnt/persistent-disk/hf/'\n",
    "os.environ['HF_HOME'] = '/mnt/persistent-disk/hf/'\n",
    "!export HF_HUB_CACHE=\"/mnt/persistent-disk/hf/\"\n",
    "!export HF_HOME=\"/mnt/persistent-disk/hf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yWaP_LPoEcoY"
   },
   "outputs": [],
   "source": [
    "# @title Python imports\n",
    "\n",
    "import enum\n",
    "import re\n",
    "import string\n",
    "\n",
    "# We import JAX and some related packages.\n",
    "import chex\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from functools import partial\n",
    "\n",
    "# For LoRA\n",
    "import lorax\n",
    "\n",
    "# We will use HuggingFace's dataset, tokenizer, and model classes.\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer, default_data_collator\n",
    "from datasets import Dataset, load_dataset, concatenate_datasets\n",
    "import torch\n",
    "\n",
    "# Finally, we import Gemma.\n",
    "from gemma import params as params_lib\n",
    "from gemma import sampler as sampler_lib\n",
    "from gemma import transformer as transformer_lib\n",
    "import sentencepiece as spm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "INPUT: Please provide your HUGGINGFACE_USERNAME:  felarof01\n",
      "INPUT: Please provide your HUGGINGFACE_TOKEN:  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\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace username and token to use when downloading.\n",
    "MODEL_NAME=\"felafax/gemma-2-2b-it-Flax\"\n",
    "HUGGINGFACE_USERNAME = input(\"INPUT: Please provide your HUGGINGFACE_USERNAME: \")\n",
    "HUGGINGFACE_TOKEN = input(\"INPUT: Please provide your HUGGINGFACE_TOKEN: \")\n",
    "\n",
    "model_name=MODEL_NAME\n",
    "hugging_face_token=HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "ckpt_path = snapshot_download(repo_id=MODEL_NAME, token=HUGGINGFACE_TOKEN)\n",
    "vocab_path = os.path.join(ckpt_path, 'tokenizer.model')\n",
    "\n",
    "print(ckpt_path)\n",
    "print()\n",
    "print(vocab_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VsT2o6JEcoZ"
   },
   "source": [
    "## Fine tuning the Gemma model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters.\n",
    "params = params_lib.load_and_format_params(os.path.join(ckpt_path, 'gemma2-2b-it'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model config.\n",
    "config = transformer_lib.TransformerConfig.gemma2_2b(cache_size=30)\n",
    "model = transformer_lib.Transformer(config=config)\n",
    "\n",
    "# You can also infer the model config by using the number of layers in the params.\n",
    "# config_2b = transformer_lib.TransformerConfig.from_params(params, cache_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import flax\n",
    "from flax.traverse_util import flatten_dict\n",
    "\n",
    "def print_params(params):\n",
    "    flat_params = flatten_dict(params)    \n",
    "    for path, param in flat_params.items():\n",
    "        # Join the path components to create a string name\n",
    "        name = \"/\".join(str(x) for x in path)\n",
    "        print(f\"Name: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        print(f\"dtype: {param.dtype}\")\n",
    "        # print(f\"Value: {param}\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print params before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformer/embedder/input_embedding\n",
      "Shape: (256128, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/final_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lorax.constants import LORA_FULL, LORA_FREEZE\n",
    "\n",
    "def decision_fn(path, param):\n",
    "    if 'embedding' in path:\n",
    "        print(f'Fully finetuning param {path}')\n",
    "        return LORA_FULL\n",
    "    dim = 2\n",
    "    print(f'Using LoRA with dim={dim} for param {path}')\n",
    "    return dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='embedder'), DictKey(key='input_embedding'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_0'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_0'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_0'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_0'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_0'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_1'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_1'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_1'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_1'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_1'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_10'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_10'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_10'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_10'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_10'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_11'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_11'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_11'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_11'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_11'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_12'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_12'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_12'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_12'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_12'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_13'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_13'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_13'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_13'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_13'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_14'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_14'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_14'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_14'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_14'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_15'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_15'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_15'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_15'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_15'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_16'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_16'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_16'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_16'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_16'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_17'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_17'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_17'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_17'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_17'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_18'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_18'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_18'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_18'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_18'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_19'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_19'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_19'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_19'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_19'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_2'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_2'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_2'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_2'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_2'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_20'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_20'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_20'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_20'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_20'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_21'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_21'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_21'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_21'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_21'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_22'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_22'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_22'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_22'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_22'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_23'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_23'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_23'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_23'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_23'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_24'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_24'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_24'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_24'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_24'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_25'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_25'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_25'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_25'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_25'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_3'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_3'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_3'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_3'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_3'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_4'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_4'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_4'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_4'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_4'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_5'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_5'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_5'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_5'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_5'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_6'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_6'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_6'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_6'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_6'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_7'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_7'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_7'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_7'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_7'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_8'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_8'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_8'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_8'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_8'), DictKey(key='mlp'), DictKey(key='linear'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_9'), DictKey(key='attn'), DictKey(key='attn_vec_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_9'), DictKey(key='attn'), DictKey(key='kv_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_9'), DictKey(key='attn'), DictKey(key='q_einsum'), DictKey(key='w'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_9'), DictKey(key='mlp'), DictKey(key='gating_einsum'))\n",
      "Using LoRA with dim=2 for param (DictKey(key='transformer'), DictKey(key='layer_9'), DictKey(key='mlp'), DictKey(key='linear'))\n"
     ]
    }
   ],
   "source": [
    "lora_spec = lorax.simple_spec(params, decision_fn=decision_fn, tune_vectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer': {'embedder': {'input_embedding': 2},\n",
       "  'final_norm': {'scale': -1},\n",
       "  'layer_0': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_1': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_10': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_11': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_12': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_13': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_14': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_15': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_16': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_17': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_18': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_19': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_2': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_20': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_21': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_22': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_23': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_24': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_25': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_3': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_4': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_5': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_6': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_7': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_8': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_9': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}}}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_params = lorax.init_lora(params, lora_spec, jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformer/embedder/input_embedding\n",
      "Shape: (256128, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/final_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_0/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_1/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_10/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_11/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_12/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_13/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_14/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_15/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_16/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_17/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_18/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_19/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_2/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_20/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_21/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_22/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_23/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_24/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_25/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_3/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_4/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_5/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_6/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_7/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_8/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/attn/attn_vec_einsum/w\n",
      "Shape: (8, 256, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/attn/kv_einsum/w\n",
      "Shape: (2, 4, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/attn/q_einsum/w\n",
      "Shape: (8, 2304, 256)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/mlp/gating_einsum\n",
      "Shape: (2, 2304, 9216)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/mlp/linear\n",
      "Shape: (9216, 2304)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/post_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/post_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/pre_attention_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n",
      "Name: transformer/layer_9/pre_ffw_norm/scale\n",
      "Shape: (2304,)\n",
      "dtype: bfloat16\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_params(lora_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transformer': {'embedder': {'input_embedding': LoraWeight(shape=(256128, 2304), dtype=dtype(bfloat16), w=Array([[0.0351562, -0.0229492, 0.081543, ..., 0.0211182, 0.0527344,\n",
      "        -0.0351562],\n",
      "       [-0.0200195, 0.0522461, -0.0302734, ..., 0.0027771, -0.0240479,\n",
      "        -0.017334],\n",
      "       [-0.000164032, -0.00592041, 0.0222168, ..., 0.0151978,\n",
      "        -0.00735474, -0.0119019],\n",
      "       ...,\n",
      "       [0.0227051, -0.0375977, 0.0356445, ..., 0.0402832, 0.0117798,\n",
      "        -0.0308838],\n",
      "       [0.0319824, -0.0368652, 0.0410156, ..., 0.0385742, 0.0196533,\n",
      "        -0.0270996],\n",
      "       [0.0203857, -0.0405273, 0.0368652, ..., 0.0400391, 0.0180664,\n",
      "        -0.0306396]], dtype=bfloat16), a=Array([[ 0.02199156,  0.0049439 , -0.01322838, ..., -0.01093095,\n",
      "         0.01156266,  0.01847863],\n",
      "       [ 0.01022545, -0.01507886, -0.0023296 , ...,  0.00661303,\n",
      "         0.02698121,  0.00401224]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'final_norm': {'scale': Array([2.32812, 2.34375, 2.28125, ..., 4.65625, 2.53125, 2.4375],      dtype=bfloat16)}, 'layer_0': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0090332, 0.0100708, 0.0155029, ..., 0.00256348, -0.00537109,\n",
      "         0.00848389],\n",
      "        [0.0114136, 0.0202637, 0.00952148, ..., -0.000166893, 0.0108032,\n",
      "         0.0124512],\n",
      "        [0.00543213, -0.000261307, 0.000991821, ..., 0.0150146,\n",
      "         0.0119019, 0.00424194],\n",
      "        ...,\n",
      "        [0.00188446, 0.00346375, -0.00598145, ..., 0.0195312,\n",
      "         -0.00405884, -0.00738525],\n",
      "        [-0.0111694, 0.00515747, 0.00306702, ..., -0.00750732,\n",
      "         0.00389099, -0.0107422],\n",
      "        [-0.00230408, 0.0202637, 0.00167084, ..., -0.0123901,\n",
      "         0.00787354, 0.00236511]],\n",
      "\n",
      "       [[0.012207, -0.00169373, -0.0222168, ..., -0.0055542,\n",
      "         -0.00891113, -0.0150146],\n",
      "        [0.00546265, -0.00872803, -0.00112915, ..., 0.00854492,\n",
      "         -0.0110474, 0.0131836],\n",
      "        [0.00294495, 0.00230408, 0.00650024, ..., 0.0011673,\n",
      "         -0.00598145, 0.0131226],\n",
      "        ...,\n",
      "        [-0.00714111, -0.00848389, -0.00340271, ..., -0.000105381,\n",
      "         0.0118408, 0.00469971],\n",
      "        [0.00231934, -0.00115967, 0.0078125, ..., -0.00512695,\n",
      "         -0.00579834, 0.000249863],\n",
      "        [0.0045166, 0.00982666, 0.0105591, ..., 0.00479126, -0.00915527,\n",
      "         -0.00872803]],\n",
      "\n",
      "       [[-0.0114136, -0.0194092, 0.00334167, ..., 0.0055542,\n",
      "         -0.00952148, 0.0133057],\n",
      "        [-0.00958252, 0.00224304, 0.000499725, ..., 0.0216064,\n",
      "         0.00268555, -0.000448227],\n",
      "        [0.00195312, -0.0214844, -0.00341797, ..., 0.00265503,\n",
      "         -0.00430298, 0.0169678],\n",
      "        ...,\n",
      "        [0.00320435, -0.00222778, 0.0111694, ..., -0.0151367,\n",
      "         -0.00994873, -0.0116577],\n",
      "        [-0.00187683, 0.00616455, 0.000991821, ..., 0.0168457,\n",
      "         0.00299072, -0.00149536],\n",
      "        [-0.00836182, 0.00772095, -0.00671387, ..., 0.00860596,\n",
      "         -0.000370026, -0.0116577]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00738525, -0.00878906, -0.0100708, ..., 0.00848389,\n",
      "         0.0108032, -0.0223389],\n",
      "        [0.0126343, -0.0055542, 0.0020752, ..., 0.0151367, 0.00741577,\n",
      "         0.00564575],\n",
      "        [0.0179443, -0.006073, 0.0152588, ..., -0.00552368, -0.0151978,\n",
      "         -0.0184326],\n",
      "        ...,\n",
      "        [-0.00364685, -0.0162354, 0.00897217, ..., -0.0114136,\n",
      "         -0.0234375, -0.0178223],\n",
      "        [0.0129395, -0.0134888, -0.0109253, ..., -0.0233154, 0.00335693,\n",
      "         -0.0144043],\n",
      "        [0.00482178, -0.0142822, 0.00370789, ..., 0.00473022,\n",
      "         0.00946045, 0.0132446]],\n",
      "\n",
      "       [[0.0140381, 0.00576782, -0.0126953, ..., 0.00215149, -0.0015564,\n",
      "         -0.0118408],\n",
      "        [0.00335693, -0.0055542, 0.00872803, ..., 0.0145874, 0.0238037,\n",
      "         -0.0159912],\n",
      "        [-0.00601196, 0.0214844, -0.0140991, ..., 0.00460815, 0.0155029,\n",
      "         -0.00231934],\n",
      "        ...,\n",
      "        [-0.0127563, 0.0090332, -0.0126953, ..., -0.00842285,\n",
      "         -0.000185013, -0.00897217],\n",
      "        [-0.000663757, 4.91738e-06, -0.000220299, ..., -0.006073,\n",
      "         -0.00402832, 0.00114441],\n",
      "        [0.00634766, -0.0201416, -0.000180244, ..., -0.00494385,\n",
      "         -0.0183105, -0.00375366]],\n",
      "\n",
      "       [[0.0167236, -0.00463867, 0.00646973, ..., 0.00082016,\n",
      "         0.00811768, -0.00338745],\n",
      "        [-0.0125732, -0.00860596, -0.00811768, ..., -0.00769043,\n",
      "         0.00473022, -0.00335693],\n",
      "        [-0.00105286, 0.0231934, 0.00216675, ..., 0.00646973,\n",
      "         -0.00331116, -0.0201416],\n",
      "        ...,\n",
      "        [0.00442505, 0.00927734, -0.0037384, ..., 0.00588989,\n",
      "         -0.0039978, -0.00131989],\n",
      "        [-0.00268555, -0.0032196, 0.00640869, ..., -0.00756836,\n",
      "         0.000105858, -0.00227356],\n",
      "        [-0.00102234, 0.00927734, 0.0174561, ..., 0.013855, -0.0142822,\n",
      "         0.0163574]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0055542, -0.00469971, 0.00686646, ..., -0.00312805,\n",
      "          -0.0183105, 0.0264893],\n",
      "         [0.00479126, -0.0022583, 0.00549316, ..., -0.00119781,\n",
      "          0.00958252, -0.00558472],\n",
      "         [-0.0192871, 0.00210571, 0.00720215, ..., 0.00128174,\n",
      "          0.00799561, 0.0136108],\n",
      "         ...,\n",
      "         [0.0120239, -0.00173187, -0.0088501, ..., 0.00296021,\n",
      "          0.0136719, -0.0144653],\n",
      "         [-0.00518799, 0.00744629, 0.00014019, ..., -0.000934601,\n",
      "          0.0106812, 0.010437],\n",
      "         [0.0126953, -0.00698853, -0.0113525, ..., 0.027832,\n",
      "          0.00921631, 0.00994873]],\n",
      "\n",
      "        [[-0.00110626, -0.00497437, 0.0147095, ..., 0.0172119,\n",
      "          0.00714111, -0.00354004],\n",
      "         [0.0163574, -0.00386047, 0.0189209, ..., 0.0136108, 0.0192871,\n",
      "          -0.0257568],\n",
      "         [-0.0105591, -0.0100708, 0.0134277, ..., 0.0112915, 0.0152588,\n",
      "          -0.00302124],\n",
      "         ...,\n",
      "         [-0.0152588, -0.00537109, -0.00148773, ..., -0.0306396,\n",
      "          -0.0019455, 0.0206299],\n",
      "         [0.00714111, 0.00549316, 0.00396729, ..., -0.00122833,\n",
      "          0.00500488, 0.0157471],\n",
      "         [0.0101318, 0.00173187, -0.0100708, ..., -0.00604248,\n",
      "          0.00506592, 0.00830078]],\n",
      "\n",
      "        [[0.00509644, 0.0194092, 0.00094223, ..., 0.0159912, 0.0120239,\n",
      "          0.00244141],\n",
      "         [0.0035553, -0.00753784, -0.0128174, ..., -0.0038147,\n",
      "          -0.00958252, -0.0162354],\n",
      "         [0.00352478, -0.00842285, -0.00564575, ..., 0.046875,\n",
      "          0.00286865, 0.0126343],\n",
      "         ...,\n",
      "         [-0.00927734, -0.0088501, -0.0114136, ..., 0.00933838,\n",
      "          0.0220947, -0.0124512],\n",
      "         [0.000629425, -0.0067749, 0.000930786, ..., 0.00720215,\n",
      "          -0.0228271, -0.0025177],\n",
      "         [0.00534058, 0.0152588, 0.00427246, ..., -0.0275879,\n",
      "          -0.0123901, 0.00145721]],\n",
      "\n",
      "        [[0.000911713, 0.0195312, -0.00546265, ..., 0.0136108,\n",
      "          0.0017395, 0.0038147],\n",
      "         [0.00509644, 0.000364304, 0.000488281, ..., 0.00552368,\n",
      "          -0.00872803, 0.013855],\n",
      "         [0.00337219, -0.00216675, -0.00150299, ..., -0.020752,\n",
      "          0.0153198, -0.00183868],\n",
      "         ...,\n",
      "         [0.00494385, -0.00686646, -0.0014801, ..., -0.00830078,\n",
      "          0.00817871, 0.015625],\n",
      "         [-0.0211182, -0.00860596, 0.0180664, ..., -0.0133667,\n",
      "          0.00537109, -0.00257874],\n",
      "         [0.00500488, 0.00811768, -0.00765991, ..., -0.0120239,\n",
      "          -0.00778198, -0.00346375]]],\n",
      "\n",
      "\n",
      "       [[[0.00735474, 0.00170135, -0.00234985, ..., -0.0192871,\n",
      "          -0.0101929, -0.00209045],\n",
      "         [0.0105591, 0.0145874, 0.0067749, ..., -0.0050354, 0.00613403,\n",
      "          0.00531006],\n",
      "         [0.0213623, -0.00442505, -0.00418091, ..., 0.00396729,\n",
      "          0.00479126, -0.00543213],\n",
      "         ...,\n",
      "         [-0.00268555, -0.0088501, -0.0108032, ..., -0.0108643,\n",
      "          -0.0184326, -0.0157471],\n",
      "         [-0.00376892, 0.000387192, 0.00732422, ..., 0.00172424,\n",
      "          -0.00619507, 0.000286102],\n",
      "         [0.00260925, 0.00927734, -0.0218506, ..., -0.0102539,\n",
      "          -0.00183105, -0.00424194]],\n",
      "\n",
      "        [[-0.00115204, 0.024292, 0.0072937, ..., -0.0122681,\n",
      "          -0.0241699, 0.00653076],\n",
      "         [-0.00689697, -0.0240479, -0.00196838, ..., -0.0032196,\n",
      "          -0.00570679, -0.00315857],\n",
      "         [0.00866699, -0.000195503, 0.00408936, ..., -0.000595093,\n",
      "          -0.00111389, 0.00349426],\n",
      "         ...,\n",
      "         [-0.0162354, 0.00325012, 0.000671387, ..., -0.0105591,\n",
      "          0.0106201, -0.0189209],\n",
      "         [0.0140381, -0.0145874, 0.0019455, ..., 0.0062561,\n",
      "          7.24792e-05, -0.0124512],\n",
      "         [0.00692749, 0.0108032, -0.00308228, ..., -0.00628662,\n",
      "          -0.00166321, 0.00358582]],\n",
      "\n",
      "        [[0.00154114, 0.0030365, -0.00567627, ..., -0.00430298,\n",
      "          0.0120239, -0.00106049],\n",
      "         [0.0266113, -0.00588989, -0.00124359, ..., -0.00128937,\n",
      "          -0.00491333, -0.00104523],\n",
      "         [0.0141602, -0.00463867, 0.00402832, ..., -0.00744629,\n",
      "          0.00585938, 0.00680542],\n",
      "         ...,\n",
      "         [-0.00732422, 0.0172119, 0.0112915, ..., -0.0088501,\n",
      "          -0.010376, 0.0022583],\n",
      "         [0.00445557, 0.0032196, 0.00970459, ..., 0.0116577,\n",
      "          -0.0112915, 0.0106812],\n",
      "         [-0.00344849, -0.00640869, -0.00241089, ..., 0.0184326,\n",
      "          -0.00314331, 0.0129395]],\n",
      "\n",
      "        [[0.0126953, 0.0267334, 0.00668335, ..., -0.00268555,\n",
      "          -0.00897217, -0.00176239],\n",
      "         [-0.0116577, -0.0045166, -0.0181885, ..., 0.0189209,\n",
      "          -0.00811768, 0.00439453],\n",
      "         [-0.00772095, -0.0078125, 0.0146484, ..., -0.0105591,\n",
      "          -0.00263977, -0.0118408],\n",
      "         ...,\n",
      "         [0.0153198, -0.0114746, -0.0217285, ..., 0.00357056,\n",
      "          0.0117798, 0.000226974],\n",
      "         [-0.00274658, -0.00306702, 0.010376, ..., -0.00305176,\n",
      "          0.0128784, -0.0088501],\n",
      "         [0.00613403, -0.00866699, 0.00491333, ..., -0.00848389,\n",
      "          -0.00512695, -0.00350952]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00701904, -0.00222778, 0.00172424, ..., 0.00131989,\n",
      "         0.00759888, 0.00173187],\n",
      "        [0.0148926, 0.015564, 0.00344849, ..., -0.00527954, 0.00524902,\n",
      "         -0.000448227],\n",
      "        [-0.0192871, -0.0253906, 0.00622559, ..., -0.00582886,\n",
      "         0.000656128, -0.013855],\n",
      "        ...,\n",
      "        [0.0147705, 0.0205078, -0.000892639, ..., 0.00747681,\n",
      "         0.00512695, -0.000797272],\n",
      "        [-0.027832, -0.0100098, 0.0136108, ..., -0.000249863,\n",
      "         -0.0112915, -0.0116577],\n",
      "        [0.00866699, 0.00494385, -0.00124359, ..., -0.0127563,\n",
      "         -0.000556946, 0.00515747]],\n",
      "\n",
      "       [[-0.00497437, 0.00296021, 0.00723267, ..., -0.0065918,\n",
      "         -0.0189209, 0.0212402],\n",
      "        [-0.0038147, 0.00357056, 0.00236511, ..., 0.0100708, 0.00360107,\n",
      "         0.0153198],\n",
      "        [-0.00137329, -2.94447e-05, -0.00198364, ..., 0.0055542,\n",
      "         0.000164986, 0.00799561],\n",
      "        ...,\n",
      "        [0.0065918, -0.00180817, -0.00494385, ..., 0.00561523,\n",
      "         0.0314941, -0.0133057],\n",
      "        [0.00909424, 0.000522614, -0.00247192, ..., 9.58443e-05,\n",
      "         0.0228271, 0.0136108],\n",
      "        [0.00704956, -0.00379944, -0.00320435, ..., 0.0283203,\n",
      "         0.0143433, 0.0267334]],\n",
      "\n",
      "       [[-0.00817871, 0.00317383, 0.010376, ..., -0.0124512, -0.0161133,\n",
      "         0.00695801],\n",
      "        [0.0177002, 0.00689697, -0.00662231, ..., -0.00830078,\n",
      "         0.0153198, -4.55379e-05],\n",
      "        [0.00500488, 0.00282288, -0.00592041, ..., 0.00379944,\n",
      "         0.0170898, -0.0043335],\n",
      "        ...,\n",
      "        [-0.00552368, -0.0050354, 0.012146, ..., 0.00708008,\n",
      "         -0.00219727, 0.020874],\n",
      "        [-0.000272751, -0.00393677, 0.000801086, ..., 0.010437,\n",
      "         -0.00817871, 0.0267334],\n",
      "        [-0.0197754, 6.4373e-05, -0.00927734, ..., 0.0039978,\n",
      "         -0.0169678, -0.00762939]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00176239, 0.0280762, 0.00958252, ..., 0.0253906, 0.00405884,\n",
      "         -0.0103149],\n",
      "        [-0.00830078, 0.0157471, 0.00405884, ..., -0.00753784,\n",
      "         0.0157471, 0.00364685],\n",
      "        [0.000482559, -0.0168457, -0.0189209, ..., 0.00564575,\n",
      "         0.00273132, -0.0219727],\n",
      "        ...,\n",
      "        [-0.0147095, 0.0137939, 0.000431061, ..., 0.0134888, 0.00195312,\n",
      "         0.0134888],\n",
      "        [-0.0035553, -0.0163574, 0.015564, ..., -0.00177002, -0.020752,\n",
      "         -0.00830078],\n",
      "        [-0.00221252, -0.00111389, 0.00866699, ..., -0.00123596,\n",
      "         -0.0220947, 0.0164795]],\n",
      "\n",
      "       [[-0.000701904, 0.000305176, -0.00564575, ..., 0.0170898,\n",
      "         -0.00769043, 0.00793457],\n",
      "        [-0.00604248, -0.0133057, -0.00014782, ..., -0.013855,\n",
      "         0.0216064, 0.013916],\n",
      "        [0.00141907, -0.00622559, -0.00521851, ..., -0.00811768,\n",
      "         -0.00317383, 0.0133667],\n",
      "        ...,\n",
      "        [0.00466919, -0.0133667, 0.0220947, ..., -0.0198975,\n",
      "         -0.00909424, -0.00628662],\n",
      "        [-0.00263977, -0.00227356, -0.00592041, ..., -0.00518799,\n",
      "         -0.00720215, -0.00964355],\n",
      "        [-0.00704956, -0.010498, -0.0105591, ..., 0.00318909,\n",
      "         0.00306702, -0.00108337]],\n",
      "\n",
      "       [[-0.000785828, -0.00302124, -0.00518799, ..., 0.0030365,\n",
      "         0.00415039, -0.0100098],\n",
      "        [0.00115967, 0.0045166, 0.0268555, ..., 0.0275879, -0.00248718,\n",
      "         -0.0110474],\n",
      "        [-0.000383377, 0.00564575, -0.00389099, ..., 0.00872803,\n",
      "         0.00549316, 0.0213623],\n",
      "        ...,\n",
      "        [0.00379944, 0.012085, -0.0219727, ..., 0.0174561, 0.00698853,\n",
      "         -0.0152588],\n",
      "        [0.0144653, -0.00476074, -0.0035553, ..., -0.0113525,\n",
      "         0.000263214, 0.0339355],\n",
      "        [0.0141602, 0.0151367, -0.0126953, ..., -0.00133514, 0.00598145,\n",
      "         -0.0184326]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.0027771, -0.00335693, -0.00897217, ..., 0.0078125,\n",
      "         -0.00592041, 0.0115356],\n",
      "        [-0.0178223, -0.00717163, 0.0169678, ..., -0.000892639,\n",
      "         -0.00102234, 0.00619507],\n",
      "        [-0.00344849, -0.0055542, 0.00110626, ..., 0.00692749,\n",
      "         -0.00527954, -0.010376],\n",
      "        ...,\n",
      "        [0.00698853, -0.000255585, -0.006073, ..., -0.00726318,\n",
      "         -0.00897217, -0.0106812],\n",
      "        [0.00543213, -0.00732422, 0.00288391, ..., -0.0098877,\n",
      "         0.0101929, -0.00909424],\n",
      "        [0.00698853, -0.0126953, 0.0032196, ..., -0.00772095,\n",
      "         -0.00714111, 0.0125122]],\n",
      "\n",
      "       [[0.00817871, 0.0162354, 0.00274658, ..., -0.0105591,\n",
      "         -0.00811768, 0.00230408],\n",
      "        [-0.013855, -0.00346375, -0.00506592, ..., -0.00732422,\n",
      "         -0.00167847, 0.00552368],\n",
      "        [-0.00662231, 0.0125732, -0.0037384, ..., 0.00241089,\n",
      "         -0.00927734, -0.00946045],\n",
      "        ...,\n",
      "        [0.00674438, -0.0100098, -0.000713348, ..., -0.0116577,\n",
      "         -0.00037384, 0.00720215],\n",
      "        [-0.00622559, -0.00299072, -0.000191689, ..., 0.00576782,\n",
      "         -0.00424194, 0.00393677],\n",
      "        [0.000265121, -0.0195312, 0.00735474, ..., 0.00653076,\n",
      "         0.000455856, 0.0102539]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.000249863, 0.00778198, 0.0151978, ..., -0.00805664,\n",
      "        -0.00162506, -0.0137329],\n",
      "       [0.0143433, 0.00692749, 0.0136108, ..., -0.0235596, 0.00010252,\n",
      "        -0.00921631],\n",
      "       [0.00221252, 0.00842285, -0.00308228, ..., 0.000200272,\n",
      "        -0.00546265, -0.00994873],\n",
      "       ...,\n",
      "       [-0.000102043, -0.00230408, 0.00367737, ..., 0.0244141, 0.0109863,\n",
      "        -0.00683594],\n",
      "       [-0.00860596, 0.00357056, -0.006073, ..., -0.00616455,\n",
      "        -0.00698853, 0.00454712],\n",
      "       [-0.00708008, 0.00341797, 0.00242615, ..., 0.00189209,\n",
      "        -0.00402832, 0.00933838]], dtype=bfloat16), a=Array([[ 1.3663782e-02, -6.0665291e-03,  1.4391938e-02, ...,\n",
      "        -7.4021826e-03, -2.7578839e-03, -8.8478941e-03],\n",
      "       [ 1.8342493e-02,  3.5765569e-03,  2.9392069e-05, ...,\n",
      "        -1.2318562e-02,  2.7163564e-03,  2.3088796e-02]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.53125, -0.515625, -0.490234, ..., -0.53125, 1.42188, -0.519531],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([-0.229492, -0.189453, -0.194336, ..., -0.361328, 0.441406,\n",
      "       -0.162109], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.116699, 0.134766, 0.192383, ..., 0.636719, 0.0402832, 0.243164],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.227539, 0.208008, 0.208008, ..., 0.992188, 2.15625, 0.197266],      dtype=bfloat16)}}, 'layer_1': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00360107, 0.00775146, 0.0117798, ..., 0.00494385, -0.0147705,\n",
      "         -0.020752],\n",
      "        [0.00273132, -0.00309753, -0.00151825, ..., 0.00239563,\n",
      "         -0.00279236, -0.00411987],\n",
      "        [-0.0223389, -0.00183868, -0.0153198, ..., 0.00276184,\n",
      "         0.0239258, -0.0167236],\n",
      "        ...,\n",
      "        [0.0015564, 0.000617981, 0.00854492, ..., -0.00494385,\n",
      "         0.00331116, 0.00113678],\n",
      "        [-0.00389099, -0.00576782, -0.0159912, ..., 0.0119019,\n",
      "         -0.0410156, -0.0134277],\n",
      "        [-0.00018692, -0.0219727, 0.000747681, ..., -0.00274658,\n",
      "         -0.0114136, 0.00145721]],\n",
      "\n",
      "       [[-0.00946045, -0.0118408, -0.00891113, ..., 0.00927734,\n",
      "         0.019165, -0.0142212],\n",
      "        [-0.00169373, -0.00482178, 0.00134277, ..., 0.00476074,\n",
      "         -0.00153351, -0.000442505],\n",
      "        [0.00204468, -0.0224609, 0.00595093, ..., -0.00866699,\n",
      "         -0.0163574, -0.00964355],\n",
      "        ...,\n",
      "        [0.003479, -0.00109863, -0.00860596, ..., 0.0037384, 0.0163574,\n",
      "         0.034668],\n",
      "        [0.0181885, -0.00104523, -0.00454712, ..., 0.0168457,\n",
      "         -0.0200195, 0.00787354],\n",
      "        [-0.00262451, 0.0161133, -0.00662231, ..., -0.00970459,\n",
      "         0.00695801, -0.00106812]],\n",
      "\n",
      "       [[-0.0119019, -0.00598145, 0.00897217, ..., 0.00909424,\n",
      "         -0.0134277, 0.0162354],\n",
      "        [-0.00518799, 0.0168457, -0.00312805, ..., -0.00126648,\n",
      "         -0.00366211, -0.0149536],\n",
      "        [-0.00050354, 0.00125885, -0.0118408, ..., 0.00595093,\n",
      "         0.00637817, -0.00842285],\n",
      "        ...,\n",
      "        [-0.00714111, 0.0140991, -0.00479126, ..., -0.00165558,\n",
      "         -0.00273132, 0.019043],\n",
      "        [-0.00408936, -0.00144196, -0.0090332, ..., -0.0119019,\n",
      "         -0.00811768, 0.00524902],\n",
      "        [-0.00115204, -0.0230713, 0.00357056, ..., 0.0123901,\n",
      "         -0.00695801, 0.00860596]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00775146, 0.00799561, 0.0120239, ..., 0.0107422, -0.00811768,\n",
      "         -0.00952148],\n",
      "        [0.00744629, 0.0088501, 0.00567627, ..., 0.0126343, 0.0078125,\n",
      "         -0.0205078],\n",
      "        [0.0195312, -0.0112305, -0.0112915, ..., 0.0159912, -0.00799561,\n",
      "         0.0307617],\n",
      "        ...,\n",
      "        [0.0174561, 0.00405884, -0.00698853, ..., 0.000484467,\n",
      "         -0.0140381, 0.00830078],\n",
      "        [-0.00346375, -0.0141602, -0.0113525, ..., 0.00689697,\n",
      "         0.0272217, 0.00418091],\n",
      "        [-0.00927734, 0.0118408, -0.013855, ..., -0.00125122,\n",
      "         0.00952148, 0.000349045]],\n",
      "\n",
      "       [[-0.0157471, -0.00564575, 0.0019989, ..., 0.00296021,\n",
      "         -0.00230408, -0.00279236],\n",
      "        [-0.00576782, 0.013855, -0.0115967, ..., -0.00842285, 0.010376,\n",
      "         -0.00476074],\n",
      "        [-0.0137939, -0.0108032, 0.00717163, ..., 0.00958252,\n",
      "         -0.00897217, -0.00662231],\n",
      "        ...,\n",
      "        [0.0209961, 0.0177002, -0.00592041, ..., -0.0131226, 0.00732422,\n",
      "         -0.012085],\n",
      "        [-0.0109863, 0.00830078, -0.000545502, ..., -0.00759888,\n",
      "         -0.00811768, -0.00787354],\n",
      "        [0.0187988, -0.00921631, 0.0148926, ..., 0.0043335, 0.00854492,\n",
      "         0.0159912]],\n",
      "\n",
      "       [[-0.0100098, 0.00213623, 0.00836182, ..., 0.0043335, -0.0129395,\n",
      "         -0.00393677],\n",
      "        [0.00793457, 0.00579834, 0.00665283, ..., -0.00148773,\n",
      "         0.0110474, -0.0133667],\n",
      "        [0.00488281, -0.00466919, -0.0100708, ..., 0.0013504,\n",
      "         -0.00163269, -0.0123291],\n",
      "        ...,\n",
      "        [-0.0032959, -0.00415039, -0.0169678, ..., 0.00328064,\n",
      "         -0.00421143, -0.00109863],\n",
      "        [-0.0143433, -0.00247192, -0.00527954, ..., -0.00582886,\n",
      "         0.00162506, -0.00744629],\n",
      "        [0.0110474, -0.0263672, -0.00964355, ..., 0.00466919,\n",
      "         -0.0111084, -0.00909424]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0013504, -0.00108337, -0.00610352, ..., -0.0088501,\n",
      "          0.0020752, 0.0113525],\n",
      "         [0.00227356, 0.00799561, 0.00518799, ..., -0.00836182,\n",
      "          -0.00282288, -0.00564575],\n",
      "         [-0.00631714, 0.000492096, 7.92742e-06, ..., 0.0202637,\n",
      "          -0.0100098, 0.0124512],\n",
      "         ...,\n",
      "         [0.00245667, 0.00239563, 0.00082016, ..., 0.00178528,\n",
      "          0.0198975, 0.0238037],\n",
      "         [-0.00247192, 0.0206299, 0.00112152, ..., 0.043457,\n",
      "          1.43051e-05, 0.0150757],\n",
      "         [0.00112915, -0.0016098, 0.0025177, ..., 0.00720215,\n",
      "          0.0196533, -0.00775146]],\n",
      "\n",
      "        [[-0.00701904, 0.00878906, -0.00842285, ..., -0.00320435,\n",
      "          0.0175781, -0.0111694],\n",
      "         [-0.00145721, -0.00389099, -0.0128174, ..., 0.00704956,\n",
      "          -0.0158691, -0.0162354],\n",
      "         [-0.00695801, -0.00616455, -0.0109253, ..., -0.0341797,\n",
      "          0.000155449, 0.0110474],\n",
      "         ...,\n",
      "         [-0.019165, 0.0258789, 0.000396729, ..., 0.0159912, 0.0131226,\n",
      "          0.013855],\n",
      "         [0.00020504, 0.00756836, -0.00708008, ..., 0.00891113,\n",
      "          -0.00933838, 0.00384521],\n",
      "         [-0.00723267, -0.00297546, -0.00063324, ..., 0.00228882,\n",
      "          0.0212402, 0.0148926]],\n",
      "\n",
      "        [[-0.0118408, 0.00110626, 0.00177765, ..., 0.0019455,\n",
      "          -0.00379944, -0.0135498],\n",
      "         [-0.00137329, 0.00180054, -0.0117188, ..., 0.00160217,\n",
      "          0.027832, 0.000109673],\n",
      "         [-0.0155029, -0.00299072, 0.0103149, ..., 0.000865936,\n",
      "          -0.0172119, -0.0102539],\n",
      "         ...,\n",
      "         [-0.0168457, 0.00312805, 0.0361328, ..., -0.00427246,\n",
      "          0.0189209, 0.00952148],\n",
      "         [0.0125122, -0.0017395, 0.00531006, ..., -0.00817871,\n",
      "          -0.00402832, 0.00704956],\n",
      "         [0.00106812, -0.00457764, -0.0258789, ..., -0.00165558,\n",
      "          -0.0200195, -0.0131226]],\n",
      "\n",
      "        [[-0.00497437, 0.00726318, -0.012085, ..., -0.0112305,\n",
      "          -0.0184326, -0.00811768],\n",
      "         [0.00460815, 0.0123291, 0.0043335, ..., -0.0103149,\n",
      "          -0.0280762, -0.032959],\n",
      "         [0.00296021, 0.00366211, -0.0134888, ..., -0.0108032,\n",
      "          0.00154877, 0.00622559],\n",
      "         ...,\n",
      "         [-0.00158691, 0.0100708, -0.0118408, ..., -0.0124512,\n",
      "          -0.0101929, 0.0432129],\n",
      "         [-0.003479, -0.015625, -0.00473022, ..., -0.010437, -0.027832,\n",
      "          -0.0270996],\n",
      "         [-0.00119781, -0.00282288, 0.0090332, ..., 0.0174561,\n",
      "          -0.00473022, -0.00102234]]],\n",
      "\n",
      "\n",
      "       [[[-0.00271606, -0.0164795, -0.00101471, ..., 0.0108032,\n",
      "          0.0334473, 0.00101471],\n",
      "         [-0.0249023, -0.000164032, -0.00582886, ..., -0.0050354,\n",
      "          0.00939941, -0.00479126],\n",
      "         [-0.00427246, 0.0088501, 0.00866699, ..., -0.0106201,\n",
      "          0.0126343, -0.00994873],\n",
      "         ...,\n",
      "         [-0.017334, 0.00393677, -0.00161743, ..., 0.00537109,\n",
      "          0.0116577, 0.00952148],\n",
      "         [0.0152588, -0.000926971, -0.00747681, ..., 0.00363159,\n",
      "          0.00369263, 0.00354004],\n",
      "         [-0.00842285, 0.000244141, -0.0166016, ..., 0.0045166,\n",
      "          -0.00273132, -0.00848389]],\n",
      "\n",
      "        [[-0.0213623, -0.00268555, -0.00157928, ..., -0.00337219,\n",
      "          -0.0132446, -0.00509644],\n",
      "         [-0.000679016, 0.0117188, 0.00842285, ..., -0.0102539,\n",
      "          0.00485229, -0.00552368],\n",
      "         [-0.00262451, 0.00842285, 0.00364685, ..., -0.00552368,\n",
      "          0.0139771, -0.000999451],\n",
      "         ...,\n",
      "         [0.0105591, -0.00927734, 0.0286865, ..., 0.00370789,\n",
      "          -0.0179443, 0.00466919],\n",
      "         [0.012085, -0.00386047, 0.00756836, ..., 0.00300598,\n",
      "          -0.0020752, 0.00133514],\n",
      "         [0.015564, -0.0108032, -0.0209961, ..., 0.0151367, 0.00793457,\n",
      "          0.00372314]],\n",
      "\n",
      "        [[-0.00379944, -0.00933838, 0.00805664, ..., 0.00848389,\n",
      "          -0.00209045, 0.00891113],\n",
      "         [-0.0170898, -0.0102539, -0.0111084, ..., -0.00488281,\n",
      "          0.00787354, 0.0134888],\n",
      "         [-0.0106201, -0.000972748, -0.0137939, ..., -0.00759888,\n",
      "          -0.00512695, -0.0100098],\n",
      "         ...,\n",
      "         [-0.001297, 0.00188446, 0.00897217, ..., 0.0170898,\n",
      "          -0.00151825, -0.00994873],\n",
      "         [-0.00921631, 0.00582886, 0.00363159, ..., -0.00337219,\n",
      "          -0.010376, -0.00909424],\n",
      "         [0.00445557, 0.00192261, 0.00604248, ..., 0.00131226,\n",
      "          0.00442505, 0.00497437]],\n",
      "\n",
      "        [[0.0050354, 0.0136108, 0.00230408, ..., -0.0202637,\n",
      "          0.00674438, 0.0108032],\n",
      "         [-0.00854492, 0.0172119, -0.00848389, ..., 0.00460815,\n",
      "          0.00753784, 0.00378418],\n",
      "         [-0.013916, -0.00540161, -0.0113525, ..., 0.00210571,\n",
      "          0.00537109, 0.00224304],\n",
      "         ...,\n",
      "         [0.00787354, -0.000789642, -0.00671387, ..., -0.00726318,\n",
      "          0.00402832, 0.00125122],\n",
      "         [0.0169678, -0.00531006, -0.00509644, ..., 0.0155029,\n",
      "          0.00631714, 0.0100098],\n",
      "         [0.0088501, 0.0098877, -0.015625, ..., -0.0334473, -0.0201416,\n",
      "          0.0137329]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.000261307, -0.000207901, 0.0110474, ..., -0.0218506,\n",
      "         -0.0184326, -0.00034523],\n",
      "        [0.00430298, -0.00628662, -0.00927734, ..., 0.0112305,\n",
      "         0.00518799, 0.0131836],\n",
      "        [0.0112305, -0.00312805, -0.0062561, ..., -0.00334167,\n",
      "         0.00405884, 0.00576782],\n",
      "        ...,\n",
      "        [-0.00111389, 0.000934601, -0.010498, ..., 0.0136719,\n",
      "         -0.00805664, 0.00714111],\n",
      "        [0.0050354, -0.0147095, -0.00219727, ..., 0.0273438, 0.024292,\n",
      "         -0.0187988],\n",
      "        [-0.00326538, 0.0119629, 0.00909424, ..., 0.00717163,\n",
      "         -0.0153198, -0.00216675]],\n",
      "\n",
      "       [[-0.00340271, -0.00613403, 0.0067749, ..., -0.0206299,\n",
      "         -0.00463867, 0.00546265],\n",
      "        [0.00382996, -0.00231934, -0.00714111, ..., -0.010376,\n",
      "         -0.00094986, -0.00354004],\n",
      "        [-0.00104523, -4.43459e-05, -0.003479, ..., -0.00765991,\n",
      "         0.0175781, -0.00595093],\n",
      "        ...,\n",
      "        [-0.00604248, -0.00735474, -0.00723267, ..., 0.0310059,\n",
      "         -0.00854492, 0.026123],\n",
      "        [0.0196533, -0.00601196, -0.00872803, ..., 0.00250244,\n",
      "         -0.00509644, 0.0111694],\n",
      "        [0.00231934, -0.00762939, -0.00343323, ..., 0.0112305,\n",
      "         0.00616455, -0.0108643]],\n",
      "\n",
      "       [[0.0088501, 0.0118408, 0.00823975, ..., 0.00386047, 0.006073,\n",
      "         -0.0119629],\n",
      "        [0.00805664, -0.0114746, -0.0127563, ..., 0.00765991, 0.0136108,\n",
      "         0.00558472],\n",
      "        [-0.00338745, -0.0132446, 0.00836182, ..., 0.0133667,\n",
      "         -0.00601196, 0.00872803],\n",
      "        ...,\n",
      "        [-0.00283813, -0.00297546, 0.0130005, ..., -0.0213623,\n",
      "         -0.0117798, 0.00325012],\n",
      "        [0.0180664, -0.00158691, -0.00201416, ..., -0.0101318,\n",
      "         -0.00463867, 0.0037384],\n",
      "        [-0.00337219, -0.00744629, -0.0187988, ..., -0.00872803,\n",
      "         0.00288391, -0.0012207]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.0185547, -0.0125122, -0.012085, ..., 0.00185394, -0.00714111,\n",
      "         -0.0159912],\n",
      "        [-0.00613403, -0.00582886, 0.00601196, ..., 0.00331116,\n",
      "         -0.0112305, -0.0161133],\n",
      "        [0.00689697, 0.0098877, -0.0107422, ..., 0.00285339, -0.0090332,\n",
      "         0.00350952],\n",
      "        ...,\n",
      "        [0.00741577, -0.0178223, 0.00427246, ..., -0.00662231,\n",
      "         0.00753784, -0.012146],\n",
      "        [-0.0197754, -0.00982666, 0.0065918, ..., 0.0163574,\n",
      "         -0.00576782, 0.00723267],\n",
      "        [-0.00582886, 0.019165, -0.000728607, ..., 0.00227356,\n",
      "         0.0113525, 0.0272217]],\n",
      "\n",
      "       [[0.000717163, -0.00512695, 0.000724792, ..., -0.0159912,\n",
      "         -0.0155029, -0.00958252],\n",
      "        [0.00445557, -0.00250244, -0.00159454, ..., 0.00311279,\n",
      "         -0.00543213, -0.0180664],\n",
      "        [0.000235558, 0.00363159, 0.000339508, ..., 0.0106201,\n",
      "         0.00952148, 0.001091],\n",
      "        ...,\n",
      "        [-0.00244141, -0.00704956, 0.00476074, ..., -0.0534668,\n",
      "         -0.00582886, -0.0228271],\n",
      "        [0.0020752, 0.0124512, -0.00921631, ..., -0.0351562, -0.0495605,\n",
      "         -0.0103149],\n",
      "        [0.00215149, 0.00215149, 0.000904083, ..., 0.0133667,\n",
      "         0.00335693, -0.00108337]],\n",
      "\n",
      "       [[0.00271606, -0.0090332, 0.0240479, ..., 0.019043, -0.00230408,\n",
      "         -0.0123901],\n",
      "        [-0.00286865, 0.00680542, -0.00144958, ..., 0.0197754,\n",
      "         -0.00276184, -0.00717163],\n",
      "        [0.00769043, 0.00227356, -0.00915527, ..., 0.000222206,\n",
      "         0.000717163, -0.012085],\n",
      "        ...,\n",
      "        [-0.00164795, 0.000495911, 0.0119629, ..., -0.0281982,\n",
      "         -0.0137939, -0.0159912],\n",
      "        [-0.00357056, 0.0178223, -0.00442505, ..., -0.00056076,\n",
      "         -0.00878906, -0.0184326],\n",
      "        [-0.00411987, 0.00123596, -0.00259399, ..., -0.000724792,\n",
      "         0.00958252, 0.0164795]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.0139771, 0.0163574, 0.0174561, ..., -0.00169373, 0.00854492,\n",
      "         -0.0071106],\n",
      "        [-0.00231934, -0.0141602, 0.00576782, ..., -0.00494385,\n",
      "         -0.010437, 0.00291443],\n",
      "        [-0.00075531, 0.00628662, 0.0078125, ..., 0.000728607,\n",
      "         0.00117493, 0.0101318],\n",
      "        ...,\n",
      "        [0.0114746, -0.00521851, 0.000671387, ..., -0.00726318,\n",
      "         -0.00830078, -0.0019455],\n",
      "        [-0.00778198, 0.00527954, 0.0174561, ..., 0.00139618,\n",
      "         -0.0166016, -0.00897217],\n",
      "        [-0.00543213, -0.0240479, -0.00119781, ..., -0.00897217,\n",
      "         -0.0136719, -0.00482178]],\n",
      "\n",
      "       [[1.57356e-05, -0.0124512, 0.010498, ..., 0.00263977, 0.00396729,\n",
      "         -0.0078125],\n",
      "        [-0.00610352, -0.00257874, -0.00267029, ..., 0.00823975,\n",
      "         0.00732422, 0.00619507],\n",
      "        [-0.00122833, -0.00509644, -0.00726318, ..., -0.0112305,\n",
      "         0.00332642, 0.013916],\n",
      "        ...,\n",
      "        [-0.0098877, -0.00463867, -0.000675201, ..., -0.0055542,\n",
      "         -0.015564, 0.00616455],\n",
      "        [0.000265121, -0.00506592, -0.00549316, ..., 0.00738525,\n",
      "         -0.00300598, 0.000930786],\n",
      "        [4.12464e-05, -0.000762939, -0.00276184, ..., -0.0153198,\n",
      "         0.00215149, 0.00515747]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00463867, 0.00128174, 0.00817871, ..., 0.00216675, 0.0055542,\n",
      "        0.00386047],\n",
      "       [-0.00854492, -0.00830078, -0.00212097, ..., -0.00860596,\n",
      "        -0.00668335, 0.00466919],\n",
      "       [0.0016861, -0.0114136, 0.00842285, ..., -0.00976562, -0.00537109,\n",
      "        0.00144958],\n",
      "       ...,\n",
      "       [-0.00927734, 0.0125732, -0.0014267, ..., -0.00454712, 0.00576782,\n",
      "        -0.00405884],\n",
      "       [-0.00521851, 0.0011673, -0.00460815, ..., 0.00318909, 0.00248718,\n",
      "        -0.00146484],\n",
      "       [-0.0196533, 0.00497437, 0.00393677, ..., -0.00262451,\n",
      "        -0.00927734, 0.00732422]], dtype=bfloat16), a=Array([[ 0.01047093,  0.01922145, -0.01181239, ...,  0.0187807 ,\n",
      "        -0.002852  ,  0.01409159],\n",
      "       [-0.01944142,  0.00886716, -0.00052842, ..., -0.02301286,\n",
      "         0.00416193, -0.00264629]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.507812, -0.46875, -0.466797, ..., -0.503906, 0.102539,\n",
      "       -0.498047], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([-0.0354004, 0.0598145, 0.043457, ..., -0.202148, 0.308594,\n",
      "       0.113281], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.648438, 0.589844, 0.640625, ..., 1.27344, 0.229492, 0.5625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.498047, 0.570312, 0.535156, ..., 1.22656, 0.361328, 0.462891],      dtype=bfloat16)}}, 'layer_10': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00695801, -0.00424194, 0.000801086, ..., 0.015625,\n",
      "         0.00854492, 0.0179443],\n",
      "        [-0.0110474, -0.00460815, 0.00842285, ..., -0.00708008,\n",
      "         0.0187988, -0.0118408],\n",
      "        [0.0228271, 0.0130005, 0.0062561, ..., 0.000766754, 0.0027771,\n",
      "         -0.00372314],\n",
      "        ...,\n",
      "        [0.00772095, 0.0185547, -0.00872803, ..., 0.0100098, 0.00860596,\n",
      "         0.00500488],\n",
      "        [0.0100708, 0.00439453, 0.0123291, ..., 0.00958252, 0.00656128,\n",
      "         -0.0133057],\n",
      "        [0.00732422, 0.0090332, 0.0167236, ..., 0.00343323, 0.0111694,\n",
      "         -0.00653076]],\n",
      "\n",
      "       [[-0.000923157, -0.00344849, -0.00476074, ..., 0.0111694,\n",
      "         -0.0140381, -0.0224609],\n",
      "        [0.0256348, 0.0132446, 0.00668335, ..., 0.00488281, 0.0103149,\n",
      "         -0.0144653],\n",
      "        [0.00337219, -0.0115967, -0.029541, ..., -0.00634766,\n",
      "         -0.00418091, 0.00292969],\n",
      "        ...,\n",
      "        [-0.0143433, -0.00698853, -0.00872803, ..., -0.0098877,\n",
      "         -0.0327148, 0.0142212],\n",
      "        [-0.00364685, 0.00585938, 0.00686646, ..., 0.00221252,\n",
      "         0.00842285, 0.00897217],\n",
      "        [-0.0262451, -0.0274658, 0.00500488, ..., -0.00872803,\n",
      "         -0.015625, 0.000396729]],\n",
      "\n",
      "       [[-0.0245361, -0.00127411, -0.00680542, ..., -0.00424194,\n",
      "         0.000900269, -0.00370789],\n",
      "        [-0.0057373, -0.00273132, -0.00178528, ..., 0.0106812,\n",
      "         0.0137939, 0.00860596],\n",
      "        [0.0124512, 0.00610352, 0.0090332, ..., -0.00257874, 0.00390625,\n",
      "         -0.00393677],\n",
      "        ...,\n",
      "        [-0.00463867, -0.0180664, -0.0108643, ..., 0.0162354,\n",
      "         -0.0130615, 0.00952148],\n",
      "        [0.00482178, 0.0245361, -0.0180664, ..., 0.027832, -0.0217285,\n",
      "         -0.0202637],\n",
      "        [0.00118256, -0.000305176, 0.00315857, ..., -0.00442505,\n",
      "         0.0170898, 0.00164795]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00622559, 0.00775146, 0.0043335, ..., -0.0152588, 0.0032196,\n",
      "         0.00643921],\n",
      "        [-0.00224304, 0.0122681, 0.00650024, ..., -0.0212402,\n",
      "         -0.00488281, -0.0078125],\n",
      "        [0.0114746, -0.0148315, -0.00909424, ..., 0.00805664,\n",
      "         0.000831604, -0.00909424],\n",
      "        ...,\n",
      "        [-0.00582886, 0.00213623, 0.0090332, ..., -0.00143433,\n",
      "         0.00241089, 0.00288391],\n",
      "        [0.00448608, -0.000545502, -0.00312805, ..., 0.00424194,\n",
      "         -0.00460815, 0.0142212],\n",
      "        [-0.000389099, 0.0195312, -0.00518799, ..., 0.00390625,\n",
      "         -0.00823975, 0.0306396]],\n",
      "\n",
      "       [[-0.00646973, -0.000934601, -0.000629425, ..., -0.00427246,\n",
      "         -0.00576782, -0.0170898],\n",
      "        [-0.00107574, -0.00518799, 0.00242615, ..., -0.0161133,\n",
      "         0.0126953, -0.000610352],\n",
      "        [-0.019165, -0.0169678, -7.82013e-05, ..., -0.00396729,\n",
      "         -0.00379944, 0.00485229],\n",
      "        ...,\n",
      "        [0.0174561, 0.00695801, 0.00500488, ..., 0.00276184, -0.0137939,\n",
      "         -0.00982666],\n",
      "        [-0.0030365, -0.000789642, 0.00180817, ..., 0.0177002,\n",
      "         0.00897217, -0.00958252],\n",
      "        [0.00701904, 0.00521851, 0.0136108, ..., 0.0106812, -0.00830078,\n",
      "         -0.00665283]],\n",
      "\n",
      "       [[-0.00595093, -0.00294495, -0.00613403, ..., -0.00448608,\n",
      "         -0.00250244, -0.0112915],\n",
      "        [-0.00231934, -0.010376, -0.0111084, ..., -0.00430298,\n",
      "         0.0194092, 0.00309753],\n",
      "        [-0.00769043, 0.00540161, 0.00370789, ..., -0.0134277,\n",
      "         0.0132446, 0.0108032],\n",
      "        ...,\n",
      "        [0.0106812, -0.00124359, -0.00564575, ..., 0.0145874,\n",
      "         -0.0172119, -0.0229492],\n",
      "        [-0.0167236, -0.00326538, -0.0106812, ..., 0.00488281,\n",
      "         0.0078125, 0.0201416],\n",
      "        [-0.0142212, -0.00488281, -0.0128174, ..., -0.0122681,\n",
      "         0.0134888, 0.0109253]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.000888824, -0.00115204, -0.000119209, ..., -0.00598145,\n",
      "          -0.00704956, 0.0197754],\n",
      "         [-0.00139618, 0.0198975, -0.00424194, ..., -0.00946045,\n",
      "          -0.00634766, 0.00515747],\n",
      "         [0.00215149, -0.000652313, 0.00964355, ..., 0.0142822,\n",
      "          -0.000282288, 0.00376892],\n",
      "         ...,\n",
      "         [0.00561523, -0.00582886, 0.00585938, ..., -0.00387573,\n",
      "          0.00805664, 0.00720215],\n",
      "         [-3.3617e-05, -0.00149536, -0.0098877, ..., 0.00952148,\n",
      "          0.00982666, -0.0148315],\n",
      "         [0.00927734, 0.0018692, -0.00598145, ..., -0.00402832,\n",
      "          -0.00405884, 0.00306702]],\n",
      "\n",
      "        [[-0.00250244, 0.00183868, 0.000999451, ..., 0.0185547,\n",
      "          -0.0132446, 0.00564575],\n",
      "         [-0.00579834, 0.0150146, -0.0102539, ..., 0.0148926,\n",
      "          0.0184326, 0.0109863],\n",
      "         [-0.00346375, -0.00491333, -0.0148315, ..., 0.00216675,\n",
      "          0.0159912, 0.0118408],\n",
      "         ...,\n",
      "         [0.0106812, -0.00173187, -0.0045166, ..., 0.0114746,\n",
      "          -0.0281982, 0.00622559],\n",
      "         [0.00215149, -0.0157471, 0.0111084, ..., 0.000747681,\n",
      "          -0.000208855, 0.0183105],\n",
      "         [0.012207, -0.000537872, -0.0122681, ..., -0.019043,\n",
      "          -0.0088501, 0.00274658]],\n",
      "\n",
      "        [[-0.00680542, -0.000667572, 0.00147247, ..., 0.0233154,\n",
      "          -0.0105591, -0.0136108],\n",
      "         [0.00102997, -0.000371933, -0.000156403, ..., -0.00671387,\n",
      "          -0.012207, -0.00579834],\n",
      "         [-0.00174713, 0.00285339, -0.0109863, ..., 0.00173187,\n",
      "          -0.0030365, -0.00588989],\n",
      "         ...,\n",
      "         [0.00588989, 0.00421143, -0.00695801, ..., -0.0220947,\n",
      "          0.00692749, -0.00209045],\n",
      "         [-0.00148773, -0.00680542, 0.00331116, ..., -0.0174561,\n",
      "          -0.0128174, 0.00595093],\n",
      "         [-0.00497437, 0.00405884, -0.00349426, ..., 0.00958252,\n",
      "          0.000218391, -2.31266e-05]],\n",
      "\n",
      "        [[-0.00592041, -0.00367737, -0.00209045, ..., 0.0373535,\n",
      "          -0.0126953, 0.0240479],\n",
      "         [-0.00389099, -0.0015564, 0.00177765, ..., -0.006073,\n",
      "          0.00102234, 0.0222168],\n",
      "         [0.00753784, 0.00314331, -0.00708008, ..., 0.0163574,\n",
      "          -0.0129395, -0.00823975],\n",
      "         ...,\n",
      "         [-0.0108643, 0.00601196, 0.00283813, ..., 0.0120239,\n",
      "          -0.0228271, 0.0361328],\n",
      "         [0.00291443, -0.00253296, 0.00561523, ..., 0.0279541,\n",
      "          0.0147095, -0.022583],\n",
      "         [-0.0102539, -0.00582886, -0.0172119, ..., 0.00393677,\n",
      "          0.00463867, 0.0118408]]],\n",
      "\n",
      "\n",
      "       [[[-0.00241089, -0.0262451, -0.00878906, ..., 0.00750732,\n",
      "          -0.00376892, 0.0220947],\n",
      "         [-0.00102997, 0.00338745, 0.00891113, ..., 0.000117302,\n",
      "          -0.00540161, 0.0185547],\n",
      "         [0.00708008, -0.00567627, 0.0354004, ..., -0.00588989,\n",
      "          -0.00830078, -0.0214844],\n",
      "         ...,\n",
      "         [-0.00848389, 0.000541687, 0.0332031, ..., 0.00982666,\n",
      "          -0.00376892, 0.0187988],\n",
      "         [0.0133057, 0.00769043, -0.0214844, ..., 0.0184326, 0.0019989,\n",
      "          0.00854492],\n",
      "         [0.0272217, 0.0114746, -0.00708008, ..., -0.0219727,\n",
      "          0.0090332, -0.00872803]],\n",
      "\n",
      "        [[0.00775146, -0.00241089, -0.00799561, ..., 0.0116577,\n",
      "          0.00442505, -0.0209961],\n",
      "         [-0.0224609, 0.00732422, 1.50204e-05, ..., -0.0170898,\n",
      "          0.0184326, 0.0247803],\n",
      "         [0.00610352, 0.0100098, 0.0297852, ..., 0.0178223, 0.00811768,\n",
      "          0.00976562],\n",
      "         ...,\n",
      "         [0.0159912, -0.00683594, -0.00909424, ..., 0.00454712,\n",
      "          0.00817871, 0.0078125],\n",
      "         [-0.00361633, 0.00576782, -0.00159454, ..., -0.0222168,\n",
      "          -0.0212402, -0.0147705],\n",
      "         [-0.000720978, -0.00509644, -0.00283813, ..., -0.00500488,\n",
      "          -0.00263977, 0.00726318]],\n",
      "\n",
      "        [[0.00732422, -0.00195312, 0.00349426, ..., 0.0140381,\n",
      "          0.000766754, -0.0158691],\n",
      "         [0.00854492, 0.00396729, 0.00689697, ..., 0.00228882,\n",
      "          -0.00309753, -0.00178528],\n",
      "         [0.0168457, 0.02771, -0.00346375, ..., -0.00171661,\n",
      "          -0.0211182, -0.00805664],\n",
      "         ...,\n",
      "         [0.0272217, -0.0118408, 0.010498, ..., 0.000434875,\n",
      "          0.00190735, 0.00564575],\n",
      "         [-0.0039978, 0.0106812, -0.00402832, ..., 0.00209045,\n",
      "          -0.0168457, -0.00178528],\n",
      "         [-0.0098877, -0.0246582, -0.0354004, ..., -0.0206299,\n",
      "          0.00897217, 0.0172119]],\n",
      "\n",
      "        [[-0.0136108, 0.00723267, -0.0159912, ..., -4.43459e-05,\n",
      "          -1.2219e-05, 0.00527954],\n",
      "         [-0.0134277, 0.0050354, 0.0151367, ..., 0.0212402,\n",
      "          -0.00320435, -0.0170898],\n",
      "         [0.0114746, -0.00674438, 0.00457764, ..., -0.00137329,\n",
      "          -0.00848389, -0.00170135],\n",
      "         ...,\n",
      "         [-0.00038147, -0.00759888, -0.00570679, ..., 0.00288391,\n",
      "          -0.010498, 0.00247192],\n",
      "         [0.00836182, 0.0119019, 0.012207, ..., -0.00982666,\n",
      "          0.00107574, -0.00738525],\n",
      "         [0.00234985, 0.00878906, 0.000202179, ..., 0.00540161,\n",
      "          0.00753784, -0.0129395]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.0137329, 0.0100708, -0.00680542, ..., -0.0101929, 0.00154114,\n",
      "         -0.00592041],\n",
      "        [-0.000583649, 0.0131836, -0.00335693, ..., 0.0147705,\n",
      "         0.00411987, 0.00376892],\n",
      "        [0.00830078, -0.0103149, -0.00598145, ..., -0.0155029,\n",
      "         -0.00616455, -0.00817871],\n",
      "        ...,\n",
      "        [0.0109253, -0.000679016, -0.0152588, ..., -0.000354767,\n",
      "         -0.0145874, 0.00390625],\n",
      "        [-0.00387573, -0.00141907, 0.00161743, ..., -0.001091,\n",
      "         -0.015625, 0.0100098],\n",
      "        [-0.00259399, 0.00230408, 0.00427246, ..., -0.000469208,\n",
      "         -0.00866699, -0.00439453]],\n",
      "\n",
      "       [[0.00933838, 0.00170898, 9.05991e-05, ..., 0.0100098,\n",
      "         0.00747681, 0.0116577],\n",
      "        [0.00848389, 0.00732422, -0.00720215, ..., 0.00262451,\n",
      "         -0.0186768, 0.0067749],\n",
      "        [-0.00254822, 0.00527954, 0.00218201, ..., 0.020874, 0.00265503,\n",
      "         0.0065918],\n",
      "        ...,\n",
      "        [-0.0043335, -0.000183105, 0.00759888, ..., -0.00405884,\n",
      "         -3.30806e-06, -0.00448608],\n",
      "        [0.013916, -0.00209045, -0.00448608, ..., 0.00927734,\n",
      "         0.00241089, 0.0113525],\n",
      "        [-0.00393677, -0.00376892, 0.00576782, ..., -0.000740051,\n",
      "         0.00817871, 0.00823975]],\n",
      "\n",
      "       [[0.0057373, 0.0240479, 0.0174561, ..., -0.0125732, -0.00302124,\n",
      "         -0.0115356],\n",
      "        [-0.0100708, -0.000305176, 0.00518799, ..., 0.00585938,\n",
      "         -0.00662231, 0.00221252],\n",
      "        [-0.00248718, 0.0161133, 0.000222206, ..., 0.000610352,\n",
      "         0.000530243, -0.00131989],\n",
      "        ...,\n",
      "        [0.00138855, -0.00291443, -0.00546265, ..., 0.00250244,\n",
      "         0.017334, -0.0032196],\n",
      "        [0.032959, -0.00692749, -0.0022583, ..., 0.0218506, -0.00692749,\n",
      "         -0.00154114],\n",
      "        [-0.0163574, 0.00408936, -0.00811768, ..., -0.0136719,\n",
      "         0.000583649, -0.0114746]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00723267, 0.000976562, -0.00463867, ..., 0.00610352,\n",
      "         -0.00259399, -0.024292],\n",
      "        [0.0030365, 0.00405884, -0.0112305, ..., 0.00610352, -0.0336914,\n",
      "         -0.0354004],\n",
      "        [-0.00231934, 0.000267029, -0.00344849, ..., 0.00946045,\n",
      "         -0.0120239, -0.00300598],\n",
      "        ...,\n",
      "        [-0.00128174, -0.00604248, -0.00579834, ..., 0.0020752,\n",
      "         -0.00056839, -0.0344238],\n",
      "        [-0.0057373, 0.00221252, -0.00408936, ..., 0.0180664, -0.032959,\n",
      "         0.000202179],\n",
      "        [0.00915527, -0.00769043, -0.00149536, ..., -0.0111084,\n",
      "         -0.00196838, -0.0110474]],\n",
      "\n",
      "       [[0.0106201, -0.000976562, 0.00958252, ..., 0.00732422,\n",
      "         -0.00848389, 0.0103149],\n",
      "        [-0.00744629, 0.000915527, -0.00775146, ..., 0.0154419,\n",
      "         0.00759888, 0.0395508],\n",
      "        [-0.000602722, -0.00506592, 0.00427246, ..., -0.000242233,\n",
      "         0.0162354, 0.0245361],\n",
      "        ...,\n",
      "        [-0.00421143, 0.00750732, 0.00616455, ..., 0.03125, -0.00515747,\n",
      "         0.00121307],\n",
      "        [-0.00128174, 0.00643921, 0.00157928, ..., 0.00811768,\n",
      "         0.0123291, -0.0332031],\n",
      "        [0.00138092, -0.00387573, -0.00262451, ..., 0.00341797,\n",
      "         0.034668, -0.0349121]],\n",
      "\n",
      "       [[0.00314331, -0.00454712, 0.00147247, ..., 0.0120239, -0.020752,\n",
      "         -0.0111694],\n",
      "        [0.0258789, -0.0181885, -0.0090332, ..., 0.0123291, -0.017334,\n",
      "         0.0214844],\n",
      "        [0.00439453, -0.00408936, -0.00291443, ..., 0.0103149,\n",
      "         -0.0101929, -0.00178528],\n",
      "        ...,\n",
      "        [0.00469971, 0.00753784, 0.0175781, ..., 0.0202637, 0.00421143,\n",
      "         0.0230713],\n",
      "        [-0.0235596, 0.00141907, 0.0131226, ..., 0.0137939, -0.00153351,\n",
      "         -0.0167236],\n",
      "        [0.00616455, 0.0177002, 0.0111084, ..., -0.0219727, -0.00354004,\n",
      "         -0.0117798]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00218201, 0.00506592, -0.00318909, ..., 0.0202637,\n",
      "         0.00619507, 0.010376],\n",
      "        [-0.00244141, 0.00582886, 0.00346375, ..., -0.000448227,\n",
      "         0.00137329, -0.0037384],\n",
      "        [-0.0022583, -0.00604248, -0.00805664, ..., 0.0140991,\n",
      "         0.000572205, -0.0071106],\n",
      "        ...,\n",
      "        [-0.0155029, -0.0098877, -1.42306e-06, ..., -0.00787354,\n",
      "         -0.00848389, -0.00393677],\n",
      "        [0.00248718, -0.00512695, 0.0114136, ..., 0.00592041,\n",
      "         -0.00283813, -0.00646973],\n",
      "        [-0.00364685, 0.0101318, 0.0057373, ..., 0.00601196,\n",
      "         -0.00062561, -0.00466919]],\n",
      "\n",
      "       [[0.0136108, -0.00836182, 0.00720215, ..., -0.00811768,\n",
      "         0.0100708, -0.00167084],\n",
      "        [-0.00643921, -0.00262451, -0.00138855, ..., -0.00260925,\n",
      "         -0.0019455, 0.0130615],\n",
      "        [0.00735474, 0.00454712, 0.00595093, ..., 0.00579834,\n",
      "         0.00527954, -0.00491333],\n",
      "        ...,\n",
      "        [-0.00454712, 0.0144043, 0.00221252, ..., -0.0020752, 0.0105591,\n",
      "         -0.00592041],\n",
      "        [-0.0100708, -0.00717163, 0.010376, ..., 0.00112152, 0.0032196,\n",
      "         0.00270081],\n",
      "        [0.00445557, 0.00842285, -0.0100098, ..., -0.0090332,\n",
      "         0.00744629, 0.0139771]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.0102539, 0.0057373, -0.00534058, ..., 0.0134277, 0.00075531,\n",
      "        0.00314331],\n",
      "       [1.01924e-05, 0.0125732, -0.00222778, ..., -0.00314331,\n",
      "        -0.00213623, 0.0057373],\n",
      "       [0.00482178, -0.0131836, 0.000274658, ..., 0.00952148, 0.00640869,\n",
      "        -0.00909424],\n",
      "       ...,\n",
      "       [-0.00463867, -0.0183105, 0.00750732, ..., 0.00221252, 0.0090332,\n",
      "        -0.0150146],\n",
      "       [0.00631714, -0.00842285, 0.00151825, ..., 0.0027771, 0.000957489,\n",
      "        -0.00196838],\n",
      "       [-0.0111694, 0.0111084, 0.00415039, ..., -0.00241089, -2.2769e-05,\n",
      "        0.00497437]], dtype=bfloat16), a=Array([[ 0.00627691, -0.01385751, -0.00372067, ..., -0.01245145,\n",
      "        -0.01636037,  0.00584008],\n",
      "       [-0.01115024, -0.00439675,  0.00728602, ..., -0.01480319,\n",
      "         0.01306054,  0.00127973]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.244141, 0.330078, 0.421875, ..., 0.183594, 0.165039, 0.129883],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.496094, 0.535156, 0.570312, ..., 0.429688, 0.511719, 0.371094],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.699219, 0.773438, 0.65625, ..., 0.820312, 0.0186768, 0.671875],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.12793, 0.229492, 0.152344, ..., 0.227539, -0.212891, 0.125977],      dtype=bfloat16)}}, 'layer_11': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0011673, -0.0067749, -0.00610352, ..., 0.0169678, -0.0100098,\n",
      "         0.0117188],\n",
      "        [0.0145874, -0.00564575, -0.0162354, ..., -0.0152588,\n",
      "         0.00692749, 0.0102539],\n",
      "        [-0.0109863, -0.00247192, -0.0133057, ..., 0.00268555,\n",
      "         0.00598145, -0.00787354],\n",
      "        ...,\n",
      "        [0.0275879, -0.000671387, -0.0110474, ..., -0.0108643,\n",
      "         -0.0098877, 0.0137939],\n",
      "        [0.0100708, 0.0010376, -0.00230408, ..., 0.00267029, 0.00460815,\n",
      "         -0.00653076],\n",
      "        [0.00588989, 0.0012207, 0.010376, ..., 0.00439453, 0.00613403,\n",
      "         0.0114746]],\n",
      "\n",
      "       [[-0.0151367, 0.00233459, -0.0105591, ..., 0.000762939,\n",
      "         -0.00720215, 0.0201416],\n",
      "        [-0.0126343, 0.0133667, -0.0169678, ..., 0.00436401, 0.00325012,\n",
      "         0.00848389],\n",
      "        [0.00509644, -0.0043335, 0.0269775, ..., 0.00509644, 0.00540161,\n",
      "         0.00164795],\n",
      "        ...,\n",
      "        [0.00756836, 0.012207, -0.0133057, ..., -0.000736237,\n",
      "         -0.00976562, -0.00750732],\n",
      "        [-0.0101318, 0.00363159, -0.0219727, ..., -0.0179443,\n",
      "         0.00946045, 0.0238037],\n",
      "        [-0.00872803, 0.0186768, 0.0114136, ..., -0.0354004,\n",
      "         -0.000720978, 0.00338745]],\n",
      "\n",
      "       [[-0.00063324, -0.0170898, 0.00616455, ..., -0.0142822,\n",
      "         0.0004673, -0.00335693],\n",
      "        [0.0149536, 0.00564575, -0.00375366, ..., 0.0144653, 0.00546265,\n",
      "         -0.00772095],\n",
      "        [-0.00476074, -0.00933838, 0.0157471, ..., 0.0103149, 0.0107422,\n",
      "         0.0169678],\n",
      "        ...,\n",
      "        [-0.00357056, 0.00354004, -0.000579834, ..., 0.00631714,\n",
      "         0.00952148, 0.0098877],\n",
      "        [-0.00552368, -0.00212097, 0.00466919, ..., 0.00289917,\n",
      "         0.00138855, 0.000522614],\n",
      "        [0.0111084, 0.000406265, 0.00370789, ..., 0.00265503,\n",
      "         0.00173187, 0.00653076]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00708008, 0.0113525, -0.0205078, ..., 0.000201225,\n",
      "         0.0201416, -0.00540161],\n",
      "        [0.0037384, 0.00094986, 0.0131836, ..., -0.00424194, 0.015625,\n",
      "         -0.00848389],\n",
      "        [-0.00897217, -0.00297546, 0.00421143, ..., -0.00704956,\n",
      "         0.00254822, -0.00769043],\n",
      "        ...,\n",
      "        [0.0014801, -0.0170898, -0.00411987, ..., 0.00933838,\n",
      "         0.00726318, 0.00043869],\n",
      "        [0.0116577, 0.00224304, 0.0151978, ..., 0.00209045, 0.0161133,\n",
      "         -0.00970459],\n",
      "        [-0.00315857, 0.0124512, -0.00515747, ..., 0.00227356,\n",
      "         -0.0146484, 0.00201416]],\n",
      "\n",
      "       [[-0.0128784, 0.000854492, 0.00188446, ..., -0.0045166,\n",
      "         -0.00288391, 0.0115356],\n",
      "        [-0.0101929, -0.00521851, -0.00167847, ..., 0.00714111,\n",
      "         0.0115356, -0.0164795],\n",
      "        [0.00866699, -0.00424194, -0.00314331, ..., -0.00117493,\n",
      "         0.00549316, -0.0107422],\n",
      "        ...,\n",
      "        [-0.015625, 0.00772095, 9.25064e-05, ..., -0.00854492,\n",
      "         0.000720978, -0.00668335],\n",
      "        [-0.0213623, -0.00352478, 0.0129395, ..., -0.00964355,\n",
      "         -0.00793457, -0.00787354],\n",
      "        [-0.0198975, 0.00830078, -0.00245667, ..., -0.00646973,\n",
      "         0.00015831, -0.0164795]],\n",
      "\n",
      "       [[0.000434875, -0.000946045, -0.00209045, ..., -0.0114746,\n",
      "         -0.0113525, -0.00698853],\n",
      "        [0.0108032, -0.0169678, 0.006073, ..., 0.0129395, 0.00297546,\n",
      "         0.00897217],\n",
      "        [0.00202942, 0.0112305, -0.000598907, ..., -0.00601196,\n",
      "         -0.0195312, -0.00253296],\n",
      "        ...,\n",
      "        [0.0145874, 0.000534058, 0.0178223, ..., 0.0107422, 0.0100708,\n",
      "         0.0192871],\n",
      "        [-0.00762939, 0.00430298, 0.00756836, ..., -0.00241089,\n",
      "         -0.0268555, 0.0142212],\n",
      "        [0.0071106, 0.00140381, 0.000144958, ..., -0.00668335,\n",
      "         0.00643921, 0.000705719]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00527954, -0.0098877, -0.0153809, ..., 0.00271606,\n",
      "          0.00152588, -0.00772095],\n",
      "         [0.00215149, -0.00830078, 0.00683594, ..., -0.00527954,\n",
      "          0.0202637, 0.00567627],\n",
      "         [-0.00964355, 0.00689697, 0.00286865, ..., 0.012146,\n",
      "          -0.0157471, -0.00769043],\n",
      "         ...,\n",
      "         [0.00318909, 0.000247955, 0.00897217, ..., -0.0429688,\n",
      "          0.00564575, -7.53403e-05],\n",
      "         [-0.0071106, -0.00253296, 0.00515747, ..., -0.0134277,\n",
      "          0.0196533, 0.0109253],\n",
      "         [0.00521851, -0.0159912, 0.00112152, ..., -0.000356674,\n",
      "          -0.0142822, 0.000455856]],\n",
      "\n",
      "        [[0.00296021, 0.000417709, 0.00402832, ..., -0.00427246,\n",
      "          -0.0088501, 0.00297546],\n",
      "         [0.00247192, -0.00302124, 0.000368118, ..., -0.00393677,\n",
      "          -0.00485229, 0.00811768],\n",
      "         [0.00157166, -0.00799561, 0.00408936, ..., -0.00141144,\n",
      "          -0.00442505, 0.0279541],\n",
      "         ...,\n",
      "         [0.00087738, -0.00370789, 0.00640869, ..., 0.00479126,\n",
      "          0.000518799, -0.019165],\n",
      "         [-0.00218201, -0.00405884, -0.0133057, ..., 0.00521851,\n",
      "          -0.00445557, -0.00634766],\n",
      "         [-0.00634766, 0.000486374, -0.00213623, ..., -0.0098877,\n",
      "          -0.0224609, -0.0130005]],\n",
      "\n",
      "        [[-0.0014267, 0.00744629, 0.00389099, ..., -0.00976562,\n",
      "          0.0105591, -0.0132446],\n",
      "         [0.000169754, 0.00245667, 0.00312805, ..., 0.00331116,\n",
      "          0.000366211, -0.00854492],\n",
      "         [-0.0130005, -0.00769043, -0.00340271, ..., -0.000606537,\n",
      "          -0.0131226, 0.0133667],\n",
      "         ...,\n",
      "         [-0.013855, 0.00158691, -0.00376892, ..., 0.00970459,\n",
      "          -0.00326538, -0.00402832],\n",
      "         [-0.0166016, -0.00375366, -0.013855, ..., -0.00683594,\n",
      "          -0.00704956, -0.00640869],\n",
      "         [0.00958252, -0.00830078, 0.0230713, ..., -0.0108643,\n",
      "          -0.0147705, -0.0194092]],\n",
      "\n",
      "        [[-0.00352478, -0.000984192, -0.000356674, ..., 0.0108643,\n",
      "          -0.0230713, 0.00756836],\n",
      "         [0.000827789, 0.00561523, 0.00393677, ..., -0.0549316,\n",
      "          -0.00315857, 0.00439453],\n",
      "         [-0.00131226, 0.00567627, -0.00653076, ..., -0.0170898,\n",
      "          0.015625, -0.0170898],\n",
      "         ...,\n",
      "         [0.00289917, -0.0115967, -0.00352478, ..., 0.0166016,\n",
      "          0.0137329, 0.00396729],\n",
      "         [-0.0137329, 0.00263977, 0.0043335, ..., -0.0349121,\n",
      "          -0.0373535, 0.0201416],\n",
      "         [-0.00170898, -0.000427246, -0.0013504, ..., -0.0236816,\n",
      "          0.00282288, 0.0055542]]],\n",
      "\n",
      "\n",
      "       [[[-0.00897217, -0.0170898, -0.000888824, ..., 0.00170898,\n",
      "          -0.0119019, 0.0174561],\n",
      "         [0.0101929, -0.00174713, 0.0114746, ..., 0.00674438,\n",
      "          0.00445557, 0.0128784],\n",
      "         [-0.0038147, 0.0189209, 0.019043, ..., 0.00588989,\n",
      "          -0.00485229, -0.000919342],\n",
      "         ...,\n",
      "         [-0.000175476, -0.00646973, 0.00726318, ..., -0.00248718,\n",
      "          0.00506592, -0.0249023],\n",
      "         [-0.00582886, -0.00860596, -0.00854492, ..., 0.00375366,\n",
      "          -0.0144653, 0.00382996],\n",
      "         [0.0203857, -0.0299072, 0.0322266, ..., -0.00382996,\n",
      "          -0.00473022, 0.0213623]],\n",
      "\n",
      "        [[0.0115356, 0.0151978, 0.0035553, ..., -0.00628662, 0.0150146,\n",
      "          0.00613403],\n",
      "         [0.00909424, -0.00221252, 0.0101929, ..., -0.010376,\n",
      "          0.00230408, -0.00628662],\n",
      "         [0.0108032, 0.0227051, 0.00592041, ..., 0.00120544,\n",
      "          -0.0181885, -0.000579834],\n",
      "         ...,\n",
      "         [-0.00537109, -0.00540161, 0.0105591, ..., 0.00582886,\n",
      "          0.0118408, 0.00114441],\n",
      "         [-0.000705719, 0.00185394, 0.0222168, ..., -0.00592041,\n",
      "          -0.00421143, -0.0136108],\n",
      "         [-0.00497437, -0.0098877, 0.00946045, ..., -0.00271606,\n",
      "          0.0105591, 0.0108643]],\n",
      "\n",
      "        [[0.00650024, 0.0139771, -0.0115967, ..., 0.012146, 0.0213623,\n",
      "          -0.0159912],\n",
      "         [0.0270996, -0.0106812, -0.00762939, ..., -0.0262451,\n",
      "          -0.00994873, 0.00735474],\n",
      "         [-0.0239258, 0.00686646, 0.0238037, ..., -0.015564, 0.0209961,\n",
      "          -0.0140991],\n",
      "         ...,\n",
      "         [-0.00285339, -0.0122681, -0.00604248, ..., -0.000541687,\n",
      "          -0.0098877, 0.00430298],\n",
      "         [0.00430298, 0.0220947, -0.000368118, ..., -0.0296631,\n",
      "          0.00683594, -0.0039978],\n",
      "         [0.0120239, -0.020874, -0.0129395, ..., -0.00878906,\n",
      "          -0.0217285, -0.0131836]],\n",
      "\n",
      "        [[-0.000991821, -0.00872803, 0.0133057, ..., -0.00698853,\n",
      "          -0.0306396, -0.0124512],\n",
      "         [0.0090332, -0.00276184, 0.0110474, ..., 0.010376,\n",
      "          -0.00224304, 0.000134468],\n",
      "         [-0.000968933, -0.0071106, -0.000621796, ..., -0.00138855,\n",
      "          0.00671387, 0.00628662],\n",
      "         ...,\n",
      "         [-0.0157471, 0.0183105, 0.012207, ..., -0.0219727, 0.00241089,\n",
      "          -0.00448608],\n",
      "         [0.00270081, -0.0213623, 0.00297546, ..., -0.0168457,\n",
      "          -0.013916, 0.00854492],\n",
      "         [-0.00102234, 0.00164795, 0.000843048, ..., 0.0264893,\n",
      "          -0.0255127, 0.0130615]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00720215, 0.00402832, -0.00344849, ..., -0.0120239,\n",
      "         0.00436401, 0.0136108],\n",
      "        [-0.00476074, -0.00328064, -0.0050354, ..., -0.0107422,\n",
      "         0.0122681, -0.00233459],\n",
      "        [-0.00735474, -0.00799561, -0.00482178, ..., 0.00741577,\n",
      "         -0.00701904, 0.00236511],\n",
      "        ...,\n",
      "        [-0.0030365, -0.000530243, 0.0043335, ..., -0.0252686,\n",
      "         -0.019165, -0.017334],\n",
      "        [-0.00262451, 0.00909424, 0.00317383, ..., -0.00927734,\n",
      "         -0.0227051, 0.00738525],\n",
      "        [-0.010498, 0.00358582, -0.00227356, ..., -0.0240479, 0.0205078,\n",
      "         0.000444412]],\n",
      "\n",
      "       [[0.00491333, -0.00405884, 0.00692749, ..., -0.0038147,\n",
      "         0.00138092, 0.00372314],\n",
      "        [0.00430298, -0.00909424, -0.0149536, ..., 0.00184631, 0.020874,\n",
      "         0.00585938],\n",
      "        [-0.0101318, 0.00107574, -0.00662231, ..., 0.0186768,\n",
      "         -0.00497437, -0.00509644],\n",
      "        ...,\n",
      "        [0.00482178, 0.0140991, -0.0113525, ..., -0.00279236,\n",
      "         -0.00270081, -0.0045166],\n",
      "        [-0.0113525, -0.00842285, -0.0216064, ..., 0.0155029,\n",
      "         -0.00927734, 0.0256348],\n",
      "        [-0.00415039, 0.00196838, -0.00210571, ..., 0.00469971,\n",
      "         0.019043, 0.0294189]],\n",
      "\n",
      "       [[-0.000709534, 0.00524902, 0.00442505, ..., -0.0189209,\n",
      "         -0.00683594, 0.000387192],\n",
      "        [0.00933838, 0.0088501, 0.0072937, ..., -0.00619507, 0.00726318,\n",
      "         -0.00169373],\n",
      "        [0.00408936, -0.00518799, 0.00442505, ..., -0.0137329,\n",
      "         0.0146484, 0.00653076],\n",
      "        ...,\n",
      "        [0.00952148, 0.00167847, 0.0192871, ..., -0.00915527,\n",
      "         0.00909424, -0.00309753],\n",
      "        [-0.00601196, -0.0153198, -0.00221252, ..., 0.015564,\n",
      "         0.00418091, 0.00318909],\n",
      "        [0.00430298, 0.010498, 0.00198364, ..., -0.000534058,\n",
      "         0.00604248, 0.00227356]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00346375, -0.0105591, 0.00256348, ..., -0.00457764,\n",
      "         -0.00424194, -0.00683594],\n",
      "        [0.0142212, 0.00823975, -0.000892639, ..., -0.00747681,\n",
      "         -0.0112915, 0.0001688],\n",
      "        [0.00162506, -0.0119629, -0.00239563, ..., 0.0067749,\n",
      "         -0.0153809, -0.00384521],\n",
      "        ...,\n",
      "        [0.000417709, -0.00692749, 0.000587463, ..., -0.0129395,\n",
      "         -0.00570679, 0.0222168],\n",
      "        [-0.000117779, -0.0158691, 0.00408936, ..., 0.00488281,\n",
      "         0.00552368, -0.00799561],\n",
      "        [-0.00326538, 0.0125732, 0.0233154, ..., -0.0228271, 0.00714111,\n",
      "         0.0202637]],\n",
      "\n",
      "       [[-0.0100708, 0.00125885, -0.00248718, ..., 0.0233154,\n",
      "         -0.0463867, 0.0162354],\n",
      "        [-0.0100708, -0.00349426, -0.00769043, ..., -0.0127563,\n",
      "         0.0196533, 0.00497437],\n",
      "        [-0.000843048, -5.29289e-05, -0.00631714, ..., -0.0177002,\n",
      "         -0.00312805, -0.00741577],\n",
      "        ...,\n",
      "        [0.00982666, 0.00346375, 0.00830078, ..., -0.0366211, 0.0112305,\n",
      "         -0.00817871],\n",
      "        [0.0144653, -0.00357056, 0.00106812, ..., -0.0134277,\n",
      "         -0.0297852, -0.00909424],\n",
      "        [0.006073, 0.00964355, 0.0108032, ..., 0.0228271, 0.00442505,\n",
      "         -0.0291748]],\n",
      "\n",
      "       [[0.0123901, 0.00723267, -0.00393677, ..., -0.000968933,\n",
      "         -0.00964355, 0.0253906],\n",
      "        [0.00946045, -0.00646973, 0.00506592, ..., -0.0281982,\n",
      "         0.00701904, 0.0111694],\n",
      "        [0.00448608, -0.012085, 0.00518799, ..., -0.0532227, -0.0258789,\n",
      "         -0.00268555],\n",
      "        ...,\n",
      "        [0.00156403, 0.00732422, 0.000583649, ..., 0.00546265, 0.020752,\n",
      "         0.0169678],\n",
      "        [0.013916, -0.000276566, 0.000934601, ..., 0.0219727,\n",
      "         -0.0246582, 0.00762939],\n",
      "        [0.00343323, -0.00337219, -0.00695801, ..., -0.00262451,\n",
      "         0.0179443, -0.0286865]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.0114746, -0.0014267, -0.00331116, ..., -0.00162506,\n",
      "         -0.0117188, 0.00370789],\n",
      "        [0.00326538, 0.00159454, -0.000766754, ..., -0.00460815,\n",
      "         -0.00561523, -9.77516e-06],\n",
      "        [-0.0123291, 0.0072937, -0.00274658, ..., -0.000173569,\n",
      "         0.00113678, -0.00646973],\n",
      "        ...,\n",
      "        [-0.000463486, 0.00427246, -0.0148315, ..., -0.00793457,\n",
      "         0.0151367, -0.0132446],\n",
      "        [-0.00549316, 0.00357056, -0.00915527, ..., 0.00372314,\n",
      "         -0.0471191, -0.001091],\n",
      "        [-0.00357056, -0.00219727, -0.0103149, ..., 9.39369e-05,\n",
      "         -0.00439453, -0.00125885]],\n",
      "\n",
      "       [[0.0163574, 0.0035553, 0.00442505, ..., -0.0231934, -0.00723267,\n",
      "         0.0136108],\n",
      "        [0.00131989, 0.00976562, -0.00257874, ..., 0.013916,\n",
      "         -0.00271606, -0.0203857],\n",
      "        [-0.00732422, -0.00279236, -0.00860596, ..., -0.00479126,\n",
      "         -0.00473022, 0.00352478],\n",
      "        ...,\n",
      "        [0.0142822, -0.0112305, 0.00653076, ..., -0.00300598,\n",
      "         -0.00613403, 0.00280762],\n",
      "        [-0.0090332, 0.00312805, -0.00524902, ..., 0.00328064,\n",
      "         0.0130615, 0.0111694],\n",
      "        [0.000770569, 0.00646973, 0.0128174, ..., 4.8399e-05,\n",
      "         0.00592041, 0.0154419]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.0050354, 0.000976562, -0.00619507, ..., 0.0118408, -0.00799561,\n",
      "        -0.00179291],\n",
      "       [-0.0106812, -0.0114136, -0.00436401, ..., 0.00364685,\n",
      "        -0.00361633, -0.00372314],\n",
      "       [-0.00674438, 0.00170135, 0.00136566, ..., 0.000915527,\n",
      "        -0.00927734, 0.00415039],\n",
      "       ...,\n",
      "       [0.00335693, -0.00331116, 0.00463867, ..., 0.0010376, 0.0016861,\n",
      "        -0.00564575],\n",
      "       [0.0025177, -0.000295639, 0.000284195, ..., 0.00075531,\n",
      "        -0.00854492, -0.00244141],\n",
      "       [0.000148773, -0.0090332, -0.00650024, ..., -0.00686646,\n",
      "        0.0159912, 0.0155029]], dtype=bfloat16), a=Array([[ 0.01029943, -0.01047805,  0.00627802, ...,  0.00658243,\n",
      "         0.00416735, -0.00188006],\n",
      "       [-0.00780879, -0.00588758,  0.00545886, ...,  0.00931677,\n",
      "        -0.00922768,  0.00010113]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.417969, 0.449219, 0.496094, ..., 0.236328, 0.0996094, 0.226562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.570312, 0.636719, 0.699219, ..., 0.523438, 0.554688, 0.421875],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.648438, 0.875, 0.738281, ..., 0.773438, -0.0170898, 0.667969],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.074707, 0.15625, 0.0830078, ..., 0.185547, -0.205078, 0.0991211],      dtype=bfloat16)}}, 'layer_12': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0123291, 0.00909424, -0.001091, ..., 0.0146484, -0.000839233,\n",
      "         0.0090332],\n",
      "        [-0.00273132, 0.000862122, -0.00531006, ..., 0.0108032,\n",
      "         0.00160217, -0.00114441],\n",
      "        [0.00561523, 0.00665283, 0.00364685, ..., -0.0120239, 0.013855,\n",
      "         -0.00842285],\n",
      "        ...,\n",
      "        [-0.0336914, -0.0148315, -0.0022583, ..., -0.00204468,\n",
      "         0.00497437, 0.00309753],\n",
      "        [-0.0137939, -0.00276184, 0.000127792, ..., 0.0212402,\n",
      "         0.00488281, -0.00469971],\n",
      "        [-0.00239563, 0.00128174, 0.00592041, ..., -0.0129395,\n",
      "         -0.00262451, -0.00311279]],\n",
      "\n",
      "       [[0.00799561, -0.0144653, 0.00285339, ..., -0.00302124,\n",
      "         -0.000644684, 0.012146],\n",
      "        [0.00424194, -0.0019455, 0.00787354, ..., -0.00741577,\n",
      "         -0.00695801, -0.00335693],\n",
      "        [-0.0125732, -0.00976562, -0.00561523, ..., -0.00210571,\n",
      "         -0.00958252, 0.0134888],\n",
      "        ...,\n",
      "        [0.0245361, 0.00579834, 0.00344849, ..., 0.00726318,\n",
      "         -0.00775146, 0.00379944],\n",
      "        [0.00430298, 0.00866699, -0.00349426, ..., 0.00308228,\n",
      "         -0.00793457, 0.0018692],\n",
      "        [-0.00124359, -0.000320435, 0.00640869, ..., 0.00411987,\n",
      "         0.0117798, 0.00891113]],\n",
      "\n",
      "       [[-0.0200195, 0.00230408, 0.0246582, ..., -0.0205078, 0.0128174,\n",
      "         0.00762939],\n",
      "        [0.0189209, 0.00933838, -0.00708008, ..., 0.00418091, 0.0175781,\n",
      "         0.0136719],\n",
      "        [-0.012146, -0.00915527, 0.0164795, ..., 0.00564575, 0.00756836,\n",
      "         0.0174561],\n",
      "        ...,\n",
      "        [0.0133057, -0.0240479, -0.00891113, ..., 0.019165, 0.00494385,\n",
      "         0.0220947],\n",
      "        [0.00497437, 0.00744629, 0.010437, ..., 0.000926971, -0.0247803,\n",
      "         0.0169678],\n",
      "        [0.0249023, -0.00708008, -0.00546265, ..., 0.0166016,\n",
      "         -0.0202637, 0.00866699]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00153351, 0.0118408, -0.0019989, ..., -0.0102539,\n",
      "         -0.00169373, 0.00897217],\n",
      "        [-0.00872803, -0.0119019, 0.00656128, ..., -0.00297546,\n",
      "         -0.0205078, -0.000659943],\n",
      "        [-0.0106201, 0.000210762, 0.0133057, ..., -0.00442505,\n",
      "         -0.00738525, 0.0125122],\n",
      "        ...,\n",
      "        [-0.0111084, 0.000452042, -0.00915527, ..., -0.00387573,\n",
      "         -0.0117798, 0.000762939],\n",
      "        [-0.00723267, -0.00126648, -0.00169373, ..., -0.00872803,\n",
      "         1.32918e-05, 0.0148315],\n",
      "        [-0.00273132, 0.00109863, -0.00720215, ..., 0.0231934,\n",
      "         0.00390625, -0.0115967]],\n",
      "\n",
      "       [[0.0164795, -0.00162506, -0.00219727, ..., -0.00933838,\n",
      "         0.0011673, 0.00069809],\n",
      "        [0.0181885, -0.00576782, 0.00466919, ..., 0.000514984,\n",
      "         0.00260925, 0.00376892],\n",
      "        [0.0098877, 0.00337219, -0.0043335, ..., 0.00909424, 0.00469971,\n",
      "         -0.00964355],\n",
      "        ...,\n",
      "        [-0.00637817, 0.00759888, -0.000324249, ..., -0.000352859,\n",
      "         -0.000770569, 0.0145264],\n",
      "        [0.00411987, 0.0181885, 0.000854492, ..., -0.00558472,\n",
      "         -0.00102997, -0.0101318],\n",
      "        [0.0101929, -0.00662231, 0.0206299, ..., -0.010498, 0.0108643,\n",
      "         -0.0136108]],\n",
      "\n",
      "       [[-0.0115356, -0.000915527, 0.00341797, ..., -0.00150299,\n",
      "         -0.00717163, 0.00598145],\n",
      "        [-0.0157471, -0.0109253, -0.0117188, ..., 0.0109253, 0.00408936,\n",
      "         -0.00271606],\n",
      "        [-0.00793457, -0.00337219, -0.0037384, ..., 0.00234985,\n",
      "         0.00769043, 0.0112305],\n",
      "        ...,\n",
      "        [0.000957489, 0.000873566, -0.0117798, ..., 0.00164032,\n",
      "         -0.00500488, -0.0032196],\n",
      "        [0.000694275, -0.0185547, 0.00723267, ..., -0.00170135,\n",
      "         -0.00741577, 0.0109253],\n",
      "        [-0.00402832, 0.000999451, -0.0231934, ..., 0.00848389,\n",
      "         -0.00177765, 0.0130615]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00343323, 0.00543213, 0.0010376, ..., 0.0194092,\n",
      "          -0.0289307, 0.00854492],\n",
      "         [0.00335693, -0.000406265, -0.000614166, ..., -0.0223389,\n",
      "          -0.0181885, -0.0213623],\n",
      "         [0.0110474, -0.00549316, 0.000406265, ..., -0.0035553,\n",
      "          -0.00457764, 0.0284424],\n",
      "         ...,\n",
      "         [-0.0126343, 0.00759888, -0.00273132, ..., -0.00799561,\n",
      "          -0.00756836, -0.00378418],\n",
      "         [0.00364685, 0.00156403, 0.00567627, ..., 0.00558472,\n",
      "          -0.00909424, 0.00915527],\n",
      "         [0.00970459, -0.00213623, -0.000476837, ..., -0.0334473,\n",
      "          -0.00958252, -0.0162354]],\n",
      "\n",
      "        [[-0.000766754, -0.00704956, 0.00424194, ..., -0.010498,\n",
      "          -0.019165, -0.00775146],\n",
      "         [0.00595093, 0.0111084, -0.00457764, ..., -0.0145874,\n",
      "          -0.0019455, 0.000892639],\n",
      "         [0.000255585, -0.00408936, 0.00312805, ..., 0.0244141,\n",
      "          -0.0106201, -0.017334],\n",
      "         ...,\n",
      "         [-0.00585938, -0.00366211, -0.00265503, ..., -0.00897217,\n",
      "          -0.0114746, -0.00328064],\n",
      "         [1.2517e-05, 0.00592041, 0.000459671, ..., 0.00408936,\n",
      "          -0.0147705, 0.00244141],\n",
      "         [0.00094223, 0.0018158, -0.0010376, ..., 0.010437, 0.0280762,\n",
      "          0.0088501]],\n",
      "\n",
      "        [[0.00897217, 0.0078125, -0.00196838, ..., 0.00179291,\n",
      "          0.00156403, 0.00357056],\n",
      "         [-0.00173187, -0.00153351, -0.00598145, ..., -0.00982666,\n",
      "          0.00263977, -0.0120239],\n",
      "         [-0.00201416, -0.00494385, 0.00224304, ..., -0.00823975,\n",
      "          -0.00442505, -0.0273438],\n",
      "         ...,\n",
      "         [-0.00218201, 0.00111389, -0.00216675, ..., -0.00939941,\n",
      "          -0.00466919, -0.00946045],\n",
      "         [0.0039978, -0.00427246, -0.00747681, ..., -0.0159912,\n",
      "          -0.0322266, 0.0419922],\n",
      "         [0.00231934, -0.000358582, 0.00567627, ..., 0.00476074,\n",
      "          0.00448608, 0.00595093]],\n",
      "\n",
      "        [[-0.00274658, 0.0132446, -0.00205994, ..., -0.00848389,\n",
      "          -0.00430298, -0.00245667],\n",
      "         [0.00726318, 0.00111389, 0.00267029, ..., 0.000595093,\n",
      "          -0.0157471, -0.00408936],\n",
      "         [-0.00897217, -8.86917e-05, 0.0072937, ..., -0.00396729,\n",
      "          0.000717163, 0.00279236],\n",
      "         ...,\n",
      "         [-0.00364685, -0.00671387, 0.00024128, ..., -0.0050354,\n",
      "          0.00735474, -0.00640869],\n",
      "         [0.00408936, 8.58307e-05, 0.00897217, ..., 0.000915527,\n",
      "          0.0112915, -0.0122681],\n",
      "         [-0.00592041, -0.00241089, -0.00872803, ..., 0.0205078,\n",
      "          -0.00337219, -8.82149e-05]]],\n",
      "\n",
      "\n",
      "       [[[-0.00527954, 0.00213623, -0.00387573, ..., 0.000329971,\n",
      "          0.00113678, 0.00315857],\n",
      "         [-0.00689697, 0.00610352, -0.0174561, ..., -0.0117798,\n",
      "          0.00141907, -0.00634766],\n",
      "         [0.0169678, -0.019165, -0.0185547, ..., 0.00915527,\n",
      "          0.00909424, -0.00958252],\n",
      "         ...,\n",
      "         [-0.0150757, -0.00270081, 0.0181885, ..., 3.19481e-05,\n",
      "          -0.00842285, 0.0146484],\n",
      "         [-0.00750732, -0.0216064, -0.003479, ..., -0.00723267,\n",
      "          0.0114746, 0.000545502],\n",
      "         [0.00346375, -0.0334473, 0.00361633, ..., 0.000919342,\n",
      "          -0.0116577, -0.00570679]],\n",
      "\n",
      "        [[0.0135498, -0.0057373, 0.0128784, ..., -0.00674438,\n",
      "          0.000232697, -0.015564],\n",
      "         [-0.0194092, -0.000595093, 0.0117798, ..., 0.0212402,\n",
      "          -0.0177002, 0.0164795],\n",
      "         [-0.0247803, 0.00408936, -0.0153809, ..., 0.00765991,\n",
      "          -0.00376892, 0.00653076],\n",
      "         ...,\n",
      "         [0.00765991, -0.00457764, 0.0168457, ..., -0.0234375,\n",
      "          -0.0179443, -0.012085],\n",
      "         [-0.000953674, 0.00595093, 0.0119019, ..., -0.00588989,\n",
      "          0.0167236, 0.000192642],\n",
      "         [0.00506592, -0.00402832, 0.00328064, ..., -0.0195312,\n",
      "          -0.00175476, -0.0167236]],\n",
      "\n",
      "        [[0.0240479, 0.0250244, -0.00466919, ..., -0.00140381,\n",
      "          0.00387573, 0.00479126],\n",
      "         [-0.0216064, 0.00366211, -0.00744629, ..., 0.0145874,\n",
      "          -0.00364685, -0.0181885],\n",
      "         [0.0144043, -0.00561523, -0.00616455, ..., -0.00534058,\n",
      "          -0.00312805, -0.00167847],\n",
      "         ...,\n",
      "         [0.00158691, 0.00265503, -0.00231934, ..., 0.00552368,\n",
      "          -0.00506592, 0.000976562],\n",
      "         [-0.0125732, 0.0162354, -0.00119019, ..., -0.00315857,\n",
      "          0.0145874, -0.00147247],\n",
      "         [-0.0123901, -0.0218506, 0.00500488, ..., 0.00531006,\n",
      "          -0.0101929, -0.00540161]],\n",
      "\n",
      "        [[-0.00909424, -0.0184326, 0.00262451, ..., -0.00352478,\n",
      "          -0.0166016, -0.00500488],\n",
      "         [0.0022583, 0.00558472, -0.00296021, ..., -0.0137329,\n",
      "          -0.0294189, -0.0020752],\n",
      "         [0.0113525, -0.00549316, 0.0157471, ..., -0.00378418,\n",
      "          -0.00512695, -0.0119629],\n",
      "         ...,\n",
      "         [0.00640869, -0.00158691, -0.0055542, ..., -0.00137329,\n",
      "          0.0128784, 0.0090332],\n",
      "         [9.44138e-05, -0.00787354, -0.000178337, ..., -0.00128937,\n",
      "          0.0164795, -0.00854492],\n",
      "         [-0.000364304, 0.00056839, 0.00326538, ..., -0.0167236,\n",
      "          0.00123596, 0.0122681]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00866699, -0.000282288, -0.00335693, ..., 0.00732422,\n",
      "         -0.0071106, -0.0164795],\n",
      "        [0.00315857, -0.00297546, -0.00753784, ..., -0.00527954,\n",
      "         -0.00927734, -0.00349426],\n",
      "        [-0.010498, -0.0107422, -0.0129395, ..., -0.0223389, 0.0057373,\n",
      "         -0.00747681],\n",
      "        ...,\n",
      "        [0.00588989, -0.00308228, -0.00318909, ..., 0.000679016,\n",
      "         -0.000337601, -0.00515747],\n",
      "        [-0.00585938, -0.00592041, 0.0222168, ..., -0.00273132,\n",
      "         0.00320435, -0.0110474],\n",
      "        [0.000331879, 0.00167847, -0.00515747, ..., 0.0098877,\n",
      "         0.0016861, 0.0200195]],\n",
      "\n",
      "       [[0.000492096, -0.00396729, -0.000984192, ..., 0.0222168,\n",
      "         0.0202637, -0.00585938],\n",
      "        [-0.00564575, -0.0119629, -0.0131836, ..., -0.032959,\n",
      "         -0.0169678, 0.0153809],\n",
      "        [-0.0155029, -0.00921631, 0.000724792, ..., -0.0177002,\n",
      "         -0.00430298, 0.000751495],\n",
      "        ...,\n",
      "        [0.0016098, -0.00674438, 0.00488281, ..., 0.00367737,\n",
      "         0.00106049, -0.0157471],\n",
      "        [0.0116577, -0.000326157, -0.0211182, ..., 0.0115356, 0.0101318,\n",
      "         0.000812531],\n",
      "        [0.00323486, 0.0157471, -0.00418091, ..., 0.00231934, 0.0257568,\n",
      "         0.0339355]],\n",
      "\n",
      "       [[0.00823975, -0.00424194, -0.00317383, ..., 0.00534058,\n",
      "         0.0105591, -0.00267029],\n",
      "        [-0.00531006, 0.000789642, -0.00515747, ..., 0.010437,\n",
      "         -0.00817871, -0.00389099],\n",
      "        [-0.00668335, -0.000461578, -0.00631714, ..., 0.0158691,\n",
      "         0.0012207, 0.00668335],\n",
      "        ...,\n",
      "        [0.00418091, -0.000274658, 0.000398636, ..., -0.0252686,\n",
      "         -0.00866699, 0.00958252],\n",
      "        [-0.00933838, -0.000934601, 0.026001, ..., -0.0067749,\n",
      "         -0.00219727, -0.00909424],\n",
      "        [0.00212097, -2.75671e-06, -0.00460815, ..., 0.00668335,\n",
      "         -0.00186157, 0.0136719]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00488281, -0.00262451, 0.00250244, ..., 0.00897217,\n",
      "         0.00778198, 0.0332031],\n",
      "        [0.000770569, -0.00088501, 0.00830078, ..., -0.0067749,\n",
      "         -0.0169678, -0.00982666],\n",
      "        [-0.00320435, 0.00518799, -0.00506592, ..., -0.0180664,\n",
      "         0.00897217, -0.0119019],\n",
      "        ...,\n",
      "        [0.00540161, 0.00485229, 0.00288391, ..., -0.00735474,\n",
      "         0.0119629, -0.013855],\n",
      "        [-0.00497437, 0.0035553, -0.000398636, ..., -0.019165,\n",
      "         -0.00823975, -0.0111694],\n",
      "        [-0.00402832, -0.00242615, -0.00108337, ..., -0.00933838,\n",
      "         -0.00119019, -0.0240479]],\n",
      "\n",
      "       [[-0.000526428, -0.0107422, 0.000923157, ..., -0.0088501,\n",
      "         -0.00970459, -0.0088501],\n",
      "        [-0.00878906, -0.0109253, -0.00860596, ..., -0.0143433,\n",
      "         0.00466919, -4.62532e-05],\n",
      "        [0.0071106, -0.00346375, -0.00741577, ..., 0.00540161,\n",
      "         -0.00964355, -0.00152588],\n",
      "        ...,\n",
      "        [-0.0039978, -0.00976562, 0.00976562, ..., -0.0107422,\n",
      "         0.0174561, -0.00897217],\n",
      "        [0.00671387, -0.00830078, 0.00156403, ..., -0.0150146,\n",
      "         -0.00805664, 0.00250244],\n",
      "        [0.00160217, -0.0120239, -0.00817871, ..., 0.00564575,\n",
      "         -0.00309753, 0.00393677]],\n",
      "\n",
      "       [[-0.00848389, 0.00222778, 0.00360107, ..., 0.00405884,\n",
      "         -0.00708008, -0.00769043],\n",
      "        [-0.00136566, -6.7234e-05, -0.00384521, ..., -0.0062561,\n",
      "         -0.00463867, -0.00631714],\n",
      "        [0.00112915, 0.0045166, 0.00726318, ..., -0.0108032,\n",
      "         -0.00183868, -0.00344849],\n",
      "        ...,\n",
      "        [-0.00482178, -0.00497437, 0.00161743, ..., 0.00534058,\n",
      "         -0.00415039, 0.010376],\n",
      "        [0.00424194, 0.0181885, 0.00485229, ..., -0.00344849,\n",
      "         -0.00457764, 0.00665283],\n",
      "        [0.00680542, 0.00482178, -0.0065918, ..., 0.00190735,\n",
      "         0.00302124, 0.010498]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00946045, 0.00714111, 0.0112305, ..., -0.00205994,\n",
      "         -0.0202637, 0.000368118],\n",
      "        [-0.000888824, 0.0150757, -0.00897217, ..., -0.00485229,\n",
      "         0.0143433, -0.0109863],\n",
      "        [0.00260925, 0.0198975, 0.0281982, ..., -0.012146, -0.00842285,\n",
      "         -0.00115967],\n",
      "        ...,\n",
      "        [-0.00616455, -0.03125, 0.00933838, ..., -0.00448608,\n",
      "         -0.0126953, 0.010437],\n",
      "        [0.00056076, -0.00312805, -0.00305176, ..., -0.00210571,\n",
      "         0.0131226, 0.010376],\n",
      "        [0.006073, -0.0106201, -0.000105858, ..., 0.00952148,\n",
      "         -0.00579834, -0.00756836]],\n",
      "\n",
      "       [[-0.00775146, -0.00375366, -0.00421143, ..., -0.00224304,\n",
      "         -0.00344849, -0.00537109],\n",
      "        [-0.00125122, 0.000541687, -0.00369263, ..., 0.00982666,\n",
      "         0.0120239, -0.00367737],\n",
      "        [-0.00131989, -0.00866699, 0.0114136, ..., -0.0194092,\n",
      "         0.00183868, 0.00650024],\n",
      "        ...,\n",
      "        [-0.0140991, -0.00665283, -0.00604248, ..., 0.00267029,\n",
      "         0.00279236, -0.00396729],\n",
      "        [-0.00454712, -0.00331116, 0.0132446, ..., 0.00564575,\n",
      "         -0.00726318, 0.000785828],\n",
      "        [0.00643921, 0.0039978, 0.010376, ..., -0.000938416,\n",
      "         -0.00112152, 0.000827789]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.012085, 0.00479126, -0.00488281, ..., -0.00848389, -0.010376,\n",
      "        0.0062561],\n",
      "       [0.00113678, -0.00708008, -0.00592041, ..., 0.0145264, 0.00271606,\n",
      "        0.00308228],\n",
      "       [0.00156403, -0.00921631, 0.019043, ..., 0.00686646, -0.00364685,\n",
      "        -0.00259399],\n",
      "       ...,\n",
      "       [-0.00331116, 0.00233459, -0.00970459, ..., 0.00915527,\n",
      "        0.00689697, 0.00241089],\n",
      "       [-0.0181885, 0.00753784, 0.00424194, ..., 0.00253296, -0.0117188,\n",
      "        0.00289917],\n",
      "       [-0.00418091, -0.00244141, 0.00854492, ..., 0.00213623,\n",
      "        -0.00506592, 0.00424194]], dtype=bfloat16), a=Array([[-0.00788363,  0.00197184,  0.00437608, ...,  0.01334583,\n",
      "         0.00926806,  0.01390658],\n",
      "       [ 0.00132567, -0.00222159, -0.00384167, ..., -0.02493023,\n",
      "         0.00545663, -0.00319182]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.416016, 0.648438, 0.589844, ..., 0.335938, 0.133789, 0.298828],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.644531, 0.695312, 0.757812, ..., 0.589844, 0.589844, 0.507812],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.933594, 1.07812, 0.972656, ..., 0.863281, 0.0952148, 0.957031],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.0192871, 0.0976562, 0.0195312, ..., 0.10498, -0.239258,\n",
      "       0.0118408], dtype=bfloat16)}}, 'layer_13': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0135498, 0.00506592, -0.00741577, ..., 0.00358582,\n",
      "         -0.00222778, -0.00854492],\n",
      "        [-0.0125122, -0.00457764, 0.00662231, ..., -0.0090332,\n",
      "         0.00787354, -0.00112152],\n",
      "        [0.00087738, 0.0088501, 0.0039978, ..., -0.00241089, 0.00187683,\n",
      "         -0.0103149],\n",
      "        ...,\n",
      "        [0.0050354, 0.00866699, -0.00946045, ..., 0.0150146, 0.00311279,\n",
      "         0.00274658],\n",
      "        [0.00558472, 0.00158691, 0.000904083, ..., 0.00537109,\n",
      "         -0.0224609, -0.00247192],\n",
      "        [-9.67979e-05, 0.00213623, 0.00337219, ..., -0.00640869,\n",
      "         0.0162354, -0.0246582]],\n",
      "\n",
      "       [[-0.00378418, 0.0144043, -0.00680542, ..., 0.00817871,\n",
      "         -0.00357056, 0.00750732],\n",
      "        [0.00772095, 0.00296021, 0.00344849, ..., -0.0137939,\n",
      "         -0.00349426, 0.00549316],\n",
      "        [0.00897217, 0.00585938, -0.00300598, ..., -0.0206299,\n",
      "         0.000231743, -0.00361633],\n",
      "        ...,\n",
      "        [0.0129395, -0.00741577, 0.00631714, ..., 0.00762939, 0.0122681,\n",
      "         0.00485229],\n",
      "        [0.00637817, -0.00454712, -0.00193024, ..., 0.00268555,\n",
      "         -0.00952148, -0.000486374],\n",
      "        [-0.0050354, -0.00982666, 0.00376892, ..., 0.0045166,\n",
      "         0.00263977, -0.0025177]],\n",
      "\n",
      "       [[0.0201416, 0.00872803, -0.00201416, ..., 0.0151367,\n",
      "         -0.00094223, -0.00415039],\n",
      "        [0.00598145, -0.0187988, 0.0112915, ..., 0.0117798, 0.0071106,\n",
      "         0.00148773],\n",
      "        [-0.00205994, 0.00933838, 0.00878906, ..., 0.0090332,\n",
      "         0.00564575, 0.00120544],\n",
      "        ...,\n",
      "        [0.00683594, -0.00793457, -0.012085, ..., 0.0168457,\n",
      "         -0.00150299, 0.0078125],\n",
      "        [-0.00349426, 0.0112915, 0.00361633, ..., -0.0115356,\n",
      "         0.00897217, -0.0252686],\n",
      "        [0.00512695, -0.00585938, -0.0128174, ..., -0.000459671,\n",
      "         0.020752, 0.0170898]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.0141602, 0.0146484, -0.0205078, ..., 0.00265503, 0.00933838,\n",
      "         0.0299072],\n",
      "        [-0.0235596, 0.0172119, -0.00349426, ..., -0.00576782,\n",
      "         -0.00799561, 0.00314331],\n",
      "        [-0.013916, 0.0200195, -0.00860596, ..., -0.0269775,\n",
      "         0.000448227, -0.0107422],\n",
      "        ...,\n",
      "        [-0.0128174, -0.00921631, -0.00842285, ..., -0.000125885,\n",
      "         -0.00131226, -0.00250244],\n",
      "        [0.00482178, 0.0181885, 0.0189209, ..., -0.00239563, 0.0322266,\n",
      "         -0.0016098],\n",
      "        [0.00138855, -0.00328064, -0.0222168, ..., -0.0102539, 0.022583,\n",
      "         0.019043]],\n",
      "\n",
      "       [[-0.0235596, 0.0108643, -0.0132446, ..., 0.00491333, 0.00982666,\n",
      "         -0.0244141],\n",
      "        [-0.00531006, -0.017334, -0.00579834, ..., -0.0166016,\n",
      "         -0.00643921, -0.0102539],\n",
      "        [0.00836182, 0.00537109, 0.00180054, ..., 0.0115967, 0.0239258,\n",
      "         -0.00543213],\n",
      "        ...,\n",
      "        [0.00485229, -0.00860596, 0.00160217, ..., 0.00222778,\n",
      "         -0.000507355, -0.0150146],\n",
      "        [0.00561523, -0.0143433, 0.00460815, ..., -0.00156403,\n",
      "         0.000846863, 0.010376],\n",
      "        [0.00909424, -0.00218201, -0.0162354, ..., 0.0140381,\n",
      "         -0.00668335, -0.0175781]],\n",
      "\n",
      "       [[-0.017334, -0.00854492, 0.0183105, ..., 0.0088501, -0.00518799,\n",
      "         0.00598145],\n",
      "        [-0.00692749, -0.0130005, 0.00692749, ..., 0.0103149, 0.0157471,\n",
      "         -0.00387573],\n",
      "        [0.0122681, -0.0114746, -0.012207, ..., -0.0136719, -0.00494385,\n",
      "         0.00424194],\n",
      "        ...,\n",
      "        [0.000333786, 0.00247192, 0.0090332, ..., 0.000265121,\n",
      "         -0.0202637, 0.0263672],\n",
      "        [-0.00534058, 0.00958252, -0.00662231, ..., -0.0152588,\n",
      "         -0.0103149, 0.00579834],\n",
      "        [-0.00686646, 0.0045166, 0.0183105, ..., -0.00683594, 0.0128784,\n",
      "         0.0045166]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.000892639, 0.00201416, -0.00775146, ..., 0.000904083,\n",
      "          0.0071106, 0.00558472],\n",
      "         [-0.00891113, -0.00157166, 8.4877e-05, ..., -0.00939941,\n",
      "          0.0145264, -0.0100098],\n",
      "         [-0.00177765, -0.00106812, 0.00613403, ..., 0.0136108,\n",
      "          0.019043, -0.00375366],\n",
      "         ...,\n",
      "         [0.0067749, -0.000537872, -0.00546265, ..., 0.0090332,\n",
      "          -0.00445557, 0.0101318],\n",
      "         [-0.0218506, -0.0145874, 0.00244141, ..., -0.010498,\n",
      "          0.00127411, 0.00476074],\n",
      "         [-0.00364685, -0.000553131, 0.00390625, ..., -0.0184326,\n",
      "          0.0163574, -0.0163574]],\n",
      "\n",
      "        [[-0.00619507, 0.000919342, -0.0022583, ..., -0.027832,\n",
      "          0.0132446, 0.0241699],\n",
      "         [0.00164032, -0.000831604, -0.000235558, ..., 0.00958252,\n",
      "          0.0118408, 0.0107422],\n",
      "         [-0.00430298, 0.00650024, -0.00656128, ..., -0.0118408,\n",
      "          -0.00280762, 0.0140991],\n",
      "         ...,\n",
      "         [0.00245667, -0.00169373, 0.00198364, ..., -0.00701904,\n",
      "          -0.0117188, -0.00082016],\n",
      "         [0.00335693, 0.0164795, 0.00104523, ..., -0.0147705,\n",
      "          0.0148926, -0.00328064],\n",
      "         [0.000257492, 0.000400543, -0.00280762, ..., -0.0120239,\n",
      "          0.0196533, -0.0158691]],\n",
      "\n",
      "        [[0.00540161, -0.00411987, -8.82149e-05, ..., 0.0109253,\n",
      "          -0.0117798, 0.0201416],\n",
      "         [0.000103474, 0.00405884, 0.0098877, ..., 0.0106201, 0.017334,\n",
      "          0.0186768],\n",
      "         [-0.00830078, 0.00595093, 0.0071106, ..., -0.0118408,\n",
      "          0.00491333, 0.00543213],\n",
      "         ...,\n",
      "         [0.00665283, -0.00787354, 0.00170898, ..., -0.0258789,\n",
      "          0.00616455, 0.0111694],\n",
      "         [2.76566e-05, 0.00482178, 0.00234985, ..., 0.0112305,\n",
      "          0.00159454, 0.0145264],\n",
      "         [-0.00436401, 0.00343323, 0.00305176, ..., 0.0180664,\n",
      "          0.0181885, -0.0234375]],\n",
      "\n",
      "        [[0.00549316, -0.00238037, 0.00151062, ..., 0.0177002,\n",
      "          0.000762939, 0.00270081],\n",
      "         [-0.00424194, -0.00306702, 0.00543213, ..., 0.00436401,\n",
      "          0.00500488, -0.00698853],\n",
      "         [0.00494385, 0.00775146, 0.00147247, ..., 0.00744629,\n",
      "          -0.0249023, 0.0043335],\n",
      "         ...,\n",
      "         [0.00653076, 0.00325012, -0.00701904, ..., -0.00872803,\n",
      "          -0.0088501, -0.00915527],\n",
      "         [0.00430298, 0.000637054, -0.00282288, ..., 0.0218506,\n",
      "          0.0241699, -0.0209961],\n",
      "         [-0.00604248, 0.00378418, -0.00469971, ..., 0.00726318,\n",
      "          -1.44839e-05, 0.00897217]]],\n",
      "\n",
      "\n",
      "       [[[-0.00866699, -0.00228882, 0.00964355, ..., 0.00418091,\n",
      "          0.00592041, 0.00341797],\n",
      "         [0.000333786, -0.00811768, 0.0100098, ..., 0.00372314,\n",
      "          0.00592041, 0.0114136],\n",
      "         [0.00701904, 0.00463867, 0.00756836, ..., 0.00854492,\n",
      "          -0.0088501, -0.00325012],\n",
      "         ...,\n",
      "         [0.0108643, -0.00854492, -0.0222168, ..., 0.00418091,\n",
      "          0.00173187, 0.00799561],\n",
      "         [-0.00534058, 0.00616455, 0.0251465, ..., -0.0100098,\n",
      "          -0.0111084, 0.0102539],\n",
      "         [0.000507355, 0.00289917, -0.00421143, ..., -0.00805664,\n",
      "          -0.0018158, 0.00259399]],\n",
      "\n",
      "        [[0.000793457, -0.00221252, -0.00119019, ..., 0.00848389,\n",
      "          0.0105591, -0.00769043],\n",
      "         [0.00650024, 0.00982666, 0.00279236, ..., -0.00643921,\n",
      "          0.00628662, 0.00173187],\n",
      "         [-0.0252686, -0.00367737, 0.0100708, ..., 0.00125122,\n",
      "          0.019043, 0.0107422],\n",
      "         ...,\n",
      "         [-0.00230408, 0.00604248, 0.00848389, ..., 0.00909424,\n",
      "          -0.0185547, 0.00256348],\n",
      "         [-0.00872803, -0.00897217, -0.00509644, ..., -0.0101929,\n",
      "          0.0174561, 0.00506592],\n",
      "         [0.00387573, 0.0109863, -0.0224609, ..., 0.00805664,\n",
      "          -0.0090332, -0.0141602]],\n",
      "\n",
      "        [[0.0283203, -0.0112305, -0.00714111, ..., 0.0222168,\n",
      "          -0.00183868, 0.0115967],\n",
      "         [0.0109253, 0.0289307, 0.015564, ..., -0.0130005, -0.00326538,\n",
      "          -0.00561523],\n",
      "         [0.00842285, 0.0109863, 0.000160217, ..., 0.00169373,\n",
      "          -0.0139771, 0.00518799],\n",
      "         ...,\n",
      "         [-0.00494385, -0.00244141, 0.0105591, ..., 0.00180054,\n",
      "          0.00405884, -0.0264893],\n",
      "         [0.0038147, -0.00927734, -0.00537109, ..., -0.0142822,\n",
      "          0.0110474, 0.0230713],\n",
      "         [0.00558472, -0.00198364, 0.0202637, ..., -0.00270081,\n",
      "          -0.0169678, 0.00494385]],\n",
      "\n",
      "        [[-0.0109253, -0.00689697, 0.012085, ..., -0.0180664,\n",
      "          0.00125122, -0.0158691],\n",
      "         [-0.00534058, -0.0131226, -0.00665283, ..., -0.00325012,\n",
      "          0.020874, 0.00637817],\n",
      "         [-0.00564575, -0.017334, 0.0268555, ..., -0.00367737,\n",
      "          -0.000583649, -0.0107422],\n",
      "         ...,\n",
      "         [0.0111084, -0.00701904, 0.00836182, ..., -0.0147095,\n",
      "          -0.000888824, 0.00176239],\n",
      "         [0.0505371, -0.0151367, 0.0128784, ..., 0.00695801,\n",
      "          -0.00256348, 0.00445557],\n",
      "         [0.00842285, -0.0065918, -0.00540161, ..., -0.0127563,\n",
      "          0.00588989, -0.0247803]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.000207901, -0.00448608, -0.00363159, ..., 0.00964355,\n",
      "         0.00598145, -0.000116825],\n",
      "        [0.0103149, 0.0078125, -0.0137329, ..., -0.000747681,\n",
      "         0.00915527, -0.0141602],\n",
      "        [-0.00411987, 8.15392e-05, 0.000804901, ..., 0.000675201,\n",
      "         0.00567627, 0.0043335],\n",
      "        ...,\n",
      "        [0.00231934, -0.00101471, 0.000232697, ..., 0.00772095,\n",
      "         0.00171661, -0.0129395],\n",
      "        [0.000103951, -0.0269775, 0.00613403, ..., 0.00668335,\n",
      "         0.00370789, -0.0128784],\n",
      "        [-0.00454712, -0.00842285, -0.00704956, ..., -0.000341415,\n",
      "         -0.00726318, -0.0119629]],\n",
      "\n",
      "       [[-0.00186157, 0.00299072, -0.0030365, ..., 0.000368118,\n",
      "         -0.00588989, 0.0192871],\n",
      "        [0.00497437, 0.000667572, -0.00622559, ..., -0.0400391,\n",
      "         0.0128174, 0.0118408],\n",
      "        [-0.00151062, -0.00234985, -0.00318909, ..., -0.00604248,\n",
      "         0.0205078, 0.00256348],\n",
      "        ...,\n",
      "        [0.000450134, 0.00138855, -0.00302124, ..., 0.0262451,\n",
      "         0.0018158, 0.0131226],\n",
      "        [0.00854492, -0.0143433, -0.00506592, ..., -0.000518799,\n",
      "         0.0123291, 0.0133057],\n",
      "        [4.98295e-05, 0.00156403, -0.0101318, ..., -0.0236816,\n",
      "         -0.0014801, -0.00166321]],\n",
      "\n",
      "       [[0.00738525, 0.0181885, 0.00473022, ..., 0.000499725,\n",
      "         -0.00964355, -0.00570679],\n",
      "        [0.0123291, 0.00390625, 0.00213623, ..., 0.0263672, 0.0228271,\n",
      "         -0.000892639],\n",
      "        [-0.00619507, -0.00439453, -0.00138855, ..., 0.0194092,\n",
      "         -0.0137329, -0.000541687],\n",
      "        ...,\n",
      "        [-0.00175476, -0.00915527, 0.00561523, ..., 0.00231934,\n",
      "         -0.015625, 0.00674438],\n",
      "        [0.0030365, -0.00927734, 0.00778198, ..., -0.00640869,\n",
      "         -0.0130615, 0.029541],\n",
      "        [-0.0072937, -0.00306702, -0.00537109, ..., 0.0122681,\n",
      "         0.00787354, -0.0358887]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.0124512, -0.000469208, -0.00135803, ..., 0.0184326,\n",
      "         -0.0187988, -0.0162354],\n",
      "        [0.00183105, 0.00527954, -0.0202637, ..., 0.0236816,\n",
      "         -0.000782013, -0.00158691],\n",
      "        [-0.00509644, -0.019165, 0.0100708, ..., -0.0130615, 0.0161133,\n",
      "         0.00787354],\n",
      "        ...,\n",
      "        [-0.0124512, 0.00163269, -0.00588989, ..., -0.0334473,\n",
      "         -0.0114746, 0.000595093],\n",
      "        [0.00848389, -0.00515747, 0.0147095, ..., 0.00340271,\n",
      "         -0.00939941, 0.0267334],\n",
      "        [0.00215149, 0.000640869, 0.00976562, ..., -0.0152588, 0.015564,\n",
      "         -0.00723267]],\n",
      "\n",
      "       [[0.00367737, -0.0001688, 0.00402832, ..., -0.00982666,\n",
      "         0.0153198, 0.00267029],\n",
      "        [0.0122681, 0.00344849, -0.00671387, ..., -0.000534058,\n",
      "         0.0134888, -0.0180664],\n",
      "        [0.00439453, 0.00927734, -0.00137329, ..., 0.0332031, 0.0115967,\n",
      "         0.00585938],\n",
      "        ...,\n",
      "        [-0.000640869, -8.49366e-07, -0.0100098, ..., -0.00512695,\n",
      "         0.0181885, 0.0141602],\n",
      "        [0.00107574, -0.00204468, 0.00360107, ..., 0.0108643,\n",
      "         0.00338745, 0.0168457],\n",
      "        [0.010376, -0.00518799, 0.00153351, ..., -0.0140991, -0.0168457,\n",
      "         0.000663757]],\n",
      "\n",
      "       [[-0.00595093, -0.00396729, 0.00445557, ..., 0.00192261,\n",
      "         -0.0106201, -0.0015564],\n",
      "        [-0.0055542, 0.00830078, 0.00488281, ..., 0.0078125, 0.00145721,\n",
      "         0.000461578],\n",
      "        [-0.00128937, 0.00738525, 0.00215149, ..., 0.00805664,\n",
      "         0.00153351, -0.00172424],\n",
      "        ...,\n",
      "        [0.00537109, -0.00622559, -0.00817871, ..., -0.000184059,\n",
      "         0.000843048, -0.0088501],\n",
      "        [-0.0022583, -0.00325012, -0.00306702, ..., 0.00239563,\n",
      "         0.0149536, 0.0300293],\n",
      "        [-0.00193787, 0.00534058, 0.00524902, ..., 0.000556946,\n",
      "         0.0159912, 0.00866699]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00717163, -0.00282288, -0.00683594, ..., -0.00196838,\n",
      "         -0.0148315, 0.0126343],\n",
      "        [0.00964355, -0.00750732, -0.0146484, ..., -0.00218201,\n",
      "         0.0102539, 0.000999451],\n",
      "        [-0.000774384, 0.00622559, 0.0106812, ..., -0.00842285,\n",
      "         -0.00631714, -0.00234985],\n",
      "        ...,\n",
      "        [0.00210571, -0.00141144, -0.00491333, ..., -0.00683594,\n",
      "         -0.0120239, 0.00891113],\n",
      "        [0.00224304, 0.00177765, -0.00637817, ..., -0.00189209,\n",
      "         -0.00171661, -0.0112915],\n",
      "        [-0.00276184, -0.00543213, -0.00415039, ..., -0.00741577,\n",
      "         0.00473022, -0.00759888]],\n",
      "\n",
      "       [[-0.00823975, -0.00427246, 0.00817871, ..., -0.00088501,\n",
      "         0.0149536, 0.00375366],\n",
      "        [0.00747681, -0.0131836, 0.00421143, ..., -0.00183105,\n",
      "         -0.00958252, -0.00704956],\n",
      "        [-0.00126648, 0.00159454, -0.00836182, ..., 0.00439453,\n",
      "         -0.00288391, 0.0032196],\n",
      "        ...,\n",
      "        [-0.0101318, 0.017334, 0.000652313, ..., 0.00396729,\n",
      "         -0.000402451, 0.0117798],\n",
      "        [-0.0100708, -0.00674438, 0.0045166, ..., 0.00958252,\n",
      "         -0.0115356, -0.0011673],\n",
      "        [0.000629425, 0.00153351, -0.00119781, ..., 0.00653076,\n",
      "         0.00738525, -0.00463867]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00756836, -0.00531006, 0.00567627, ..., 0.00282288,\n",
      "        -0.0016098, -0.00387573],\n",
      "       [-0.00376892, -0.00121307, -0.00210571, ..., -0.00518799,\n",
      "        -0.00102997, 0.00302124],\n",
      "       [0.0157471, 0.0133667, -0.00637817, ..., 0.00382996, 0.00543213,\n",
      "        0.012085],\n",
      "       ...,\n",
      "       [-0.000934601, -0.00527954, -0.0100098, ..., -0.00309753,\n",
      "        0.0010376, -0.0126953],\n",
      "       [0.0169678, -0.0200195, -0.00241089, ..., -0.0050354, -0.00270081,\n",
      "        0.00854492],\n",
      "       [0.0103149, 0.00836182, 0.00531006, ..., 0.00616455, -1.87159e-05,\n",
      "        -0.00134277]], dtype=bfloat16), a=Array([[ 0.01005734,  0.01642189,  0.01510733, ...,  0.01328816,\n",
      "         0.00516436,  0.00271901],\n",
      "       [ 0.01016035, -0.00417797, -0.00903327, ..., -0.00616623,\n",
      "        -0.00244164, -0.01308654]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.742188, 0.71875, 0.671875, ..., 0.597656, 0.515625, 0.494141],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.875, 0.867188, 0.953125, ..., 0.859375, 0.839844, 0.679688],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.722656, 0.894531, 0.761719, ..., 0.726562, 0.0529785, 0.789062],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.126953, -0.0751953, -0.126953, ..., -0.0358887, -0.269531,\n",
      "       -0.0932617], dtype=bfloat16)}}, 'layer_14': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00366211, 0.00842285, -0.0114746, ..., 0.0151367,\n",
      "         0.000350952, -0.00479126],\n",
      "        [-0.00025177, 0.0019455, 0.000900269, ..., 0.00250244, 0.010376,\n",
      "         -0.00442505],\n",
      "        [-0.0155029, -0.010437, 0.00148773, ..., -0.00286865,\n",
      "         0.00579834, -0.0035553],\n",
      "        ...,\n",
      "        [0.0098877, -0.00233459, -0.00723267, ..., -0.00830078,\n",
      "         0.0147095, -0.000432968],\n",
      "        [0.00473022, 0.000396729, 0.00927734, ..., -0.0137939,\n",
      "         -0.00331116, 0.0177002],\n",
      "        [0.0133667, -0.0142822, 0.00595093, ..., -0.00692749,\n",
      "         0.00747681, 0.00799561]],\n",
      "\n",
      "       [[0.0071106, -0.00479126, -0.00182343, ..., -0.00114441,\n",
      "         0.00430298, -0.012085],\n",
      "        [-0.00154114, 0.0109253, -0.00927734, ..., -0.0103149,\n",
      "         -0.00823975, -0.00115204],\n",
      "        [-0.0147705, 0.000961304, 0.000155449, ..., 0.00631714,\n",
      "         0.00318909, 0.00276184],\n",
      "        ...,\n",
      "        [-0.00242615, -0.00198364, 0.0145264, ..., 0.0194092,\n",
      "         -0.00285339, -0.00457764],\n",
      "        [-0.00190735, 0.0130615, -0.00445557, ..., 0.0163574,\n",
      "         -0.0103149, -0.00491333],\n",
      "        [-0.00436401, 0.00588989, -0.0113525, ..., 0.0163574,\n",
      "         -0.0103149, -0.00585938]],\n",
      "\n",
      "       [[-0.00570679, 0.00227356, -0.00128174, ..., -0.0108032,\n",
      "         -0.0154419, 0.00921631],\n",
      "        [-0.00866699, 0.00509644, -0.0129395, ..., -0.00248718,\n",
      "         -0.00402832, 0.00970459],\n",
      "        [-0.0158691, 0.00156403, 0.00665283, ..., -0.00442505,\n",
      "         -0.0115356, 0.000518799],\n",
      "        ...,\n",
      "        [-0.00352478, 0.00595093, 9.53674e-05, ..., 0.000263214,\n",
      "         0.0101318, -0.000320435],\n",
      "        [-0.00866699, 0.000682831, 0.0133667, ..., 0.0101318,\n",
      "         -0.00210571, 0.00396729],\n",
      "        [-0.012207, 0.00747681, -0.019165, ..., 0.0194092, -0.0103149,\n",
      "         0.000305176]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.0106201, 0.00228882, 0.00714111, ..., 0.00579834,\n",
      "         0.00897217, -0.00518799],\n",
      "        [0.0130005, 0.010376, 0.0286865, ..., 0.00320435, 0.0161133,\n",
      "         0.0139771],\n",
      "        [0.00306702, 0.0103149, -0.0109863, ..., 0.0189209, 0.010498,\n",
      "         -0.0200195],\n",
      "        ...,\n",
      "        [0.00147247, -0.0238037, -0.00527954, ..., -0.00315857,\n",
      "         -0.00212097, -0.00915527],\n",
      "        [-0.000865936, 0.00741577, 0.00430298, ..., 0.00120544,\n",
      "         -0.00897217, -0.00823975],\n",
      "        [0.00775146, -0.00463867, -0.00964355, ..., 0.00294495,\n",
      "         -0.00022316, 0.00145721]],\n",
      "\n",
      "       [[-0.0174561, -0.0239258, 0.00315857, ..., -0.0101318,\n",
      "         -0.0137329, -0.00216675],\n",
      "        [-0.00653076, 0.00222778, 0.00108337, ..., -0.00805664,\n",
      "         -0.00872803, -0.0125122],\n",
      "        [0.00285339, -0.0038147, -0.00909424, ..., -0.000785828,\n",
      "         0.00325012, 7.00951e-05],\n",
      "        ...,\n",
      "        [-0.0101929, 0.0150146, -0.0043335, ..., 0.00340271, 0.0090332,\n",
      "         0.00738525],\n",
      "        [0.019165, -0.026123, 0.00921631, ..., -0.0134277, -0.0180664,\n",
      "         0.0039978],\n",
      "        [0.0014267, 0.00170135, 0.00738525, ..., 0.00823975, 0.0107422,\n",
      "         0.00120544]],\n",
      "\n",
      "       [[0.00671387, 0.00854492, -0.00279236, ..., 0.0159912,\n",
      "         0.00927734, 0.00765991],\n",
      "        [0.00994873, 0.00811768, -0.00101471, ..., 0.0114136,\n",
      "         0.000606537, -0.0108643],\n",
      "        [-0.00285339, -0.00891113, 0.00653076, ..., 0.0148926,\n",
      "         -0.00242615, -0.0108643],\n",
      "        ...,\n",
      "        [0.0126343, -0.00921631, 0.0067749, ..., 0.0072937, -0.0164795,\n",
      "         -0.00753784],\n",
      "        [-0.0128784, 0.00656128, -0.010498, ..., -0.00585938, 0.0144653,\n",
      "         -0.0128784],\n",
      "        [0.000198364, -0.0186768, -0.0108643, ..., 0.00247192,\n",
      "         -0.00592041, 0.00262451]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00674438, -0.00939941, 0.00112915, ..., 0.0203857,\n",
      "          0.0305176, -0.0172119],\n",
      "         [-0.00524902, -0.00127411, -0.000530243, ..., 0.0108643,\n",
      "          -0.00466919, -0.0246582],\n",
      "         [0.010376, 0.00631714, -0.0027771, ..., -0.00674438,\n",
      "          -0.00799561, -0.0102539],\n",
      "         ...,\n",
      "         [0.00122833, -0.00402832, -0.00463867, ..., -0.0218506,\n",
      "          -0.00674438, -0.0169678],\n",
      "         [-0.00430298, 0.0158691, 0.000427246, ..., -0.0294189,\n",
      "          -0.0150757, 0.00604248],\n",
      "         [-0.0109863, 0.00442505, -0.00222778, ..., -0.0107422,\n",
      "          -0.0148926, 0.0186768]],\n",
      "\n",
      "        [[0.00337219, -0.000486374, -0.0088501, ..., 0.00762939,\n",
      "          -0.00402832, 0.0108643],\n",
      "         [-0.00244141, 0.00387573, 0.0030365, ..., -0.00344849,\n",
      "          -0.00680542, -0.0130615],\n",
      "         [0.00643921, 0.00616455, 0.00161743, ..., 0.0100708,\n",
      "          0.0103149, -0.00454712],\n",
      "         ...,\n",
      "         [-0.00386047, 0.0114746, -0.00744629, ..., -0.0088501,\n",
      "          0.00631714, -0.0159912],\n",
      "         [0.00177002, -0.00726318, -0.00494385, ..., 0.0281982,\n",
      "          -0.0115967, -0.00805664],\n",
      "         [0.000930786, 0.00125885, 0.00133514, ..., 0.00167847,\n",
      "          -0.00552368, 0.00396729]],\n",
      "\n",
      "        [[-0.00102234, -0.00332642, -0.00708008, ..., 0.00823975,\n",
      "          0.0114136, -0.0198975],\n",
      "         [-0.00662231, -0.000305176, 0.00457764, ..., -0.0126953,\n",
      "          -0.000295639, -0.00274658],\n",
      "         [-0.00124359, -0.00379944, -0.0115967, ..., -0.00933838,\n",
      "          0.00291443, 0.0119019],\n",
      "         ...,\n",
      "         [-0.00244141, -0.00201416, -0.00436401, ..., 0.000804901,\n",
      "          -0.000679016, -0.000991821],\n",
      "         [-0.00778198, 0.00509644, -0.000511169, ..., -0.00164795,\n",
      "          0.0292969, -0.00363159],\n",
      "         [0.00439453, 0.00628662, 0.0012207, ..., 0.0239258,\n",
      "          -0.00927734, 0.0150757]],\n",
      "\n",
      "        [[0.00778198, 0.00231934, 0.000440598, ..., -0.00187683,\n",
      "          0.00970459, -0.00708008],\n",
      "         [-0.000854492, -0.00570679, -0.00144958, ..., -0.0157471,\n",
      "          0.00242615, 0.00732422],\n",
      "         [7.18236e-06, 0.00305176, -0.000663757, ..., -0.00698853,\n",
      "          -0.00668335, 0.00396729],\n",
      "         ...,\n",
      "         [-0.00340271, -0.00296021, -0.00180054, ..., -0.00202942,\n",
      "          0.00219727, 0.0062561],\n",
      "         [0.00114441, 0.013855, -0.00430298, ..., 0.00982666,\n",
      "          0.0102539, -0.00127411],\n",
      "         [-0.00297546, 0.0055542, -0.000511169, ..., -0.0126953,\n",
      "          0.0126953, 0.000762939]]],\n",
      "\n",
      "\n",
      "       [[[0.0123291, -0.019043, -0.000938416, ..., -0.012085,\n",
      "          -0.00598145, -0.0270996],\n",
      "         [-0.00466919, 0.00361633, -0.0106201, ..., -0.00704956,\n",
      "          0.00216675, 0.00595093],\n",
      "         [-0.00830078, -0.0166016, 0.00970459, ..., -0.00958252,\n",
      "          0.00500488, 0.00222778],\n",
      "         ...,\n",
      "         [0.00283813, 0.00418091, -0.013855, ..., 0.00769043,\n",
      "          -0.00460815, 0.0140991],\n",
      "         [0.0249023, 0.00836182, 0.0174561, ..., 0.00897217,\n",
      "          0.00994873, 0.00585938],\n",
      "         [-0.00350952, -0.00653076, 0.00184631, ..., -0.00119019,\n",
      "          -0.000522614, 0.000268936]],\n",
      "\n",
      "        [[-0.0356445, -0.00549316, 0.00640869, ..., -0.00897217,\n",
      "          0.0236816, -0.0217285],\n",
      "         [0.00805664, 0.0100098, -0.00952148, ..., 0.00213623,\n",
      "          -0.00436401, 0.00759888],\n",
      "         [0.010498, 0.00735474, 0.0197754, ..., 0.00665283, 0.00543213,\n",
      "          0.0150146],\n",
      "         ...,\n",
      "         [-0.0111694, 0.00759888, -0.006073, ..., -0.0078125,\n",
      "          0.0131836, 0.00732422],\n",
      "         [0.0140991, -0.00793457, -0.000534058, ..., 0.000839233,\n",
      "          -0.000360489, 0.0101929],\n",
      "         [-0.00946045, 0.00323486, 0.00561523, ..., 0.00189209,\n",
      "          -0.00799561, 0.0134277]],\n",
      "\n",
      "        [[0.00364685, -0.00891113, -0.0019989, ..., -0.0065918,\n",
      "          -0.00793457, -0.013916],\n",
      "         [-0.0114136, -0.00267029, -0.00186157, ..., 0.0175781,\n",
      "          -0.017334, -0.0195312],\n",
      "         [-0.00340271, -0.0125732, 0.00405884, ..., 0.0187988,\n",
      "          -0.00415039, 0.0107422],\n",
      "         ...,\n",
      "         [-0.00759888, -0.00188446, -0.013855, ..., 0.00241089,\n",
      "          0.000835419, 0.010498],\n",
      "         [-0.00610352, -0.0108032, -0.00122833, ..., -0.00110626,\n",
      "          0.0130005, 0.00259399],\n",
      "         [0.00866699, -0.00695801, 0.00643921, ..., -0.00262451,\n",
      "          0.0197754, -0.000831604]],\n",
      "\n",
      "        [[0.00537109, -0.000865936, 0.0159912, ..., 0.00854492,\n",
      "          -0.00567627, 0.00119781],\n",
      "         [8.67844e-05, -0.0153198, 0.00169373, ..., 0.00759888,\n",
      "          0.00921631, -0.0244141],\n",
      "         [-0.0195312, -0.00909424, 0.0108643, ..., 0.0220947,\n",
      "          -0.00631714, 0.00352478],\n",
      "         ...,\n",
      "         [0.00927734, 0.0202637, 0.0117798, ..., -0.000455856,\n",
      "          0.00113678, 0.0098877],\n",
      "         [-0.00274658, -0.0112915, -0.000400543, ..., -0.0116577,\n",
      "          0.0201416, 0.000113487],\n",
      "         [0.00161743, -0.0112915, -0.0184326, ..., -0.0039978,\n",
      "          -0.00665283, 0.013916]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00778198, -0.00485229, 0.003479, ..., 0.0324707, 0.0151367,\n",
      "         0.0219727],\n",
      "        [-0.00166321, -0.00233459, 0.00817871, ..., 0.00318909,\n",
      "         0.0375977, 0.0115356],\n",
      "        [-0.00616455, 0.00466919, 0.00662231, ..., -0.00631714,\n",
      "         0.00361633, -0.00369263],\n",
      "        ...,\n",
      "        [-0.000177383, -0.00402832, 0.00665283, ..., -0.0227051,\n",
      "         0.0105591, -0.0251465],\n",
      "        [0.00994873, -0.0038147, -0.00872803, ..., -0.017334,\n",
      "         -0.00138092, 0.0163574],\n",
      "        [-0.00598145, -0.0020752, 0.00296021, ..., -0.024292,\n",
      "         -0.00387573, 0.010498]],\n",
      "\n",
      "       [[-0.00799561, 0.00952148, -0.0043335, ..., 0.019165,\n",
      "         -0.00558472, 0.0039978],\n",
      "        [0.00189972, -0.00110626, -0.00457764, ..., 0.00221252,\n",
      "         0.020752, 0.0088501],\n",
      "        [-0.0163574, 0.00946045, 0.00289917, ..., 0.00289917,\n",
      "         0.00105286, 0.00106049],\n",
      "        ...,\n",
      "        [-0.000778198, -0.00294495, 0.00958252, ..., 0.00056076,\n",
      "         0.00637817, -0.0463867],\n",
      "        [0.0239258, -0.0043335, -0.0150757, ..., -0.0127563,\n",
      "         -6.96182e-05, -0.0140381],\n",
      "        [-0.00500488, 0.00250244, -0.00390625, ..., -0.0327148,\n",
      "         0.000206947, 0.0088501]],\n",
      "\n",
      "       [[-0.00488281, 0.00671387, 0.00118256, ..., 0.0175781, 0.0300293,\n",
      "         -0.0106812],\n",
      "        [-0.00157166, -0.0126343, 0.00273132, ..., 0.000253677,\n",
      "         0.000637054, 0.00062561],\n",
      "        [-0.00101471, -0.00619507, -0.000482559, ..., -0.0341797,\n",
      "         -0.00878906, 0.0272217],\n",
      "        ...,\n",
      "        [0.0057373, 0.00389099, -0.00674438, ..., -0.0127563,\n",
      "         0.00346375, 0.0198975],\n",
      "        [0.0128174, 0.00836182, 0.0103149, ..., -0.00121307,\n",
      "         -0.00106049, 0.0158691],\n",
      "        [0.00271606, 0.000720978, 0.0016098, ..., -0.00366211,\n",
      "         -0.0395508, 0.0167236]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00671387, -0.000911713, -0.0136108, ..., -0.0098877,\n",
      "         0.0032196, -0.000701904],\n",
      "        [-0.00234985, -0.00231934, -0.010437, ..., -0.00469971,\n",
      "         -0.0120239, -0.00267029],\n",
      "        [-0.00717163, 0.00139618, -0.00640869, ..., -0.00119781,\n",
      "         0.00384521, -0.00158691],\n",
      "        ...,\n",
      "        [0.00756836, 0.0133057, -0.00592041, ..., -0.00634766,\n",
      "         0.00117493, 0.00216675],\n",
      "        [-0.00402832, 0.00775146, -0.00872803, ..., -0.00634766,\n",
      "         0.00352478, -0.00811768],\n",
      "        [-0.0022583, -0.0055542, -0.0203857, ..., 0.00473022,\n",
      "         0.00479126, 0.0180664]],\n",
      "\n",
      "       [[-0.00173187, -0.0186768, -0.0128784, ..., -0.00250244,\n",
      "         -0.0202637, -0.0175781],\n",
      "        [-0.00848389, 0.00680542, 0.00460815, ..., -0.0262451,\n",
      "         0.0153198, -0.0071106],\n",
      "        [-0.00294495, 0.00176239, 0.00219727, ..., 0.000984192,\n",
      "         -0.0147705, -0.00854492],\n",
      "        ...,\n",
      "        [-0.00370789, 0.00656128, 0.00346375, ..., 0.0030365,\n",
      "         -0.0012207, 0.0101929],\n",
      "        [-0.00216675, -0.00531006, -9.65595e-06, ..., 0.0144653,\n",
      "         -0.00386047, -0.0120239],\n",
      "        [-0.00958252, 0.00279236, 0.00854492, ..., -0.00445557,\n",
      "         0.0270996, -0.00257874]],\n",
      "\n",
      "       [[0.00133514, 0.00344849, 0.00378418, ..., 0.00921631, 0.0231934,\n",
      "         0.000178337],\n",
      "        [0.0137939, 0.00402832, -0.00288391, ..., -0.0119629, 0.0141602,\n",
      "         0.00787354],\n",
      "        [-0.000329971, 0.00411987, -0.00567627, ..., 0.0175781,\n",
      "         -0.00378418, 0.00300598],\n",
      "        ...,\n",
      "        [0.00576782, -0.00112152, -0.0088501, ..., -0.00698853,\n",
      "         0.0164795, 0.00506592],\n",
      "        [0.00564575, -0.00286865, 0.010376, ..., 0.0314941, -0.0150146,\n",
      "         -0.00866699],\n",
      "        [0.000617981, 7.77245e-05, 0.0101318, ..., 0.0169678,\n",
      "         0.00308228, 0.00891113]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.0110474, -0.00537109, 0.00787354, ..., 0.00279236,\n",
      "         -0.00376892, -0.00744629],\n",
      "        [0.012085, 0.000492096, 0.0119629, ..., -0.00466919, 0.012146,\n",
      "         -0.00171661],\n",
      "        [-0.00149536, -0.00811768, -0.000320435, ..., -0.0163574,\n",
      "         -0.00117493, 0.00952148],\n",
      "        ...,\n",
      "        [0.0105591, -0.00221252, 0.00518799, ..., -0.00506592,\n",
      "         -0.0078125, 0.00292969],\n",
      "        [-0.00994873, -0.00805664, 0.00418091, ..., -0.000709534,\n",
      "         -0.00823975, 0.000770569],\n",
      "        [-0.00421143, 0.00585938, 0.010437, ..., -0.000850677,\n",
      "         -0.00915527, -0.00823975]],\n",
      "\n",
      "       [[0.00183868, -0.00198364, -0.00527954, ..., 0.00866699,\n",
      "         -0.00148773, -0.00239563],\n",
      "        [-0.00152588, 0.00976562, 0.00631714, ..., -0.000274658,\n",
      "         -0.0139771, -0.0090332],\n",
      "        [0.00512695, -0.00448608, -0.00224304, ..., -0.00793457,\n",
      "         0.00280762, -0.00411987],\n",
      "        ...,\n",
      "        [0.013916, -0.00714111, -0.00141144, ..., -0.0118408,\n",
      "         0.00379944, 0.00787354],\n",
      "        [-0.00224304, -0.00946045, -0.000938416, ..., -0.00250244,\n",
      "         -0.000972748, 0.0168457],\n",
      "        [-0.00402832, 0.00289917, 0.0022583, ..., -0.00723267,\n",
      "         0.00650024, -0.00430298]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00448608, -0.00750732, 0.000961304, ..., -0.00720215,\n",
      "        -0.00308228, -0.00463867],\n",
      "       [0.0072937, -0.0126953, 0.00170898, ..., 0.00762939, 0.00668335,\n",
      "        -0.00415039],\n",
      "       [0.00726318, -0.00241089, -0.00753784, ..., 0.00952148,\n",
      "        0.00256348, -0.000511169],\n",
      "       ...,\n",
      "       [-0.00393677, -0.00762939, -0.010437, ..., -0.0071106,\n",
      "        -0.00775146, -0.00108337],\n",
      "       [0.00836182, -0.00994873, -0.00283813, ..., -0.00386047,\n",
      "        0.00262451, 0.00759888],\n",
      "       [-0.0126953, -0.00424194, 0.0045166, ..., 0.00787354, 0.0133057,\n",
      "        -0.00854492]], dtype=bfloat16), a=Array([[ 0.00014633,  0.00200139, -0.00434174, ..., -0.001957  ,\n",
      "        -0.01323679, -0.00078773],\n",
      "       [ 0.00267099, -0.01303148,  0.02141839, ..., -0.00115613,\n",
      "        -0.01118799, -0.00374962]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.882812, 0.957031, 0.742188, ..., 0.757812, 0.648438, 0.628906],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.14844, 1.125, 1.20312, ..., 1.07031, 1.04688, 0.898438],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.878906, 1.07812, 0.859375, ..., 0.964844, 0.373047, 0.929688],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.185547, -0.140625, -0.193359, ..., -0.111328, -0.271484,\n",
      "       -0.130859], dtype=bfloat16)}}, 'layer_15': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.0168457, -0.00282288, -0.00848389, ..., -0.000402451,\n",
      "         0.00836182, 0.00297546],\n",
      "        [-0.000614166, -0.00144196, -0.0137329, ..., 0.0151978,\n",
      "         -0.0101318, -0.00854492],\n",
      "        [-0.0120239, -0.000213623, 0.0101318, ..., 0.0107422,\n",
      "         -0.00123596, 0.00125122],\n",
      "        ...,\n",
      "        [0.00402832, -8.44002e-05, -0.00552368, ..., -0.00778198,\n",
      "         0.0175781, 0.0107422],\n",
      "        [-0.000610352, 0.00182343, 0.00952148, ..., -0.00363159,\n",
      "         -0.0035553, 0.00653076],\n",
      "        [0.00115204, 0.00149536, 0.00094223, ..., 0.000331879,\n",
      "         -0.00921631, -0.0115967]],\n",
      "\n",
      "       [[0.00964355, 0.00242615, 0.0151367, ..., -0.000629425,\n",
      "         0.0194092, -0.010437],\n",
      "        [0.00637817, -0.0272217, 0.00279236, ..., 0.00326538,\n",
      "         0.00588989, 8.05855e-05],\n",
      "        [0.0366211, -0.012207, -0.0181885, ..., 0.00311279, -0.00558472,\n",
      "         -0.00257874],\n",
      "        ...,\n",
      "        [0.012207, -0.00418091, -0.00692749, ..., -0.0189209,\n",
      "         0.000314713, -0.0322266],\n",
      "        [0.00848389, -0.00180817, 0.00202942, ..., -0.00561523,\n",
      "         -0.0185547, -0.0117188],\n",
      "        [-0.000291824, -0.0101318, 0.00212097, ..., -0.0181885,\n",
      "         0.0168457, 0.0027771]],\n",
      "\n",
      "       [[-0.0294189, -0.017334, -0.0128784, ..., 0.00878906,\n",
      "         -0.00260925, 0.0148926],\n",
      "        [-0.000396729, -0.0090332, 0.0127563, ..., -0.0164795,\n",
      "         -0.00476074, -0.00689697],\n",
      "        [0.0030365, 0.0119629, -0.00891113, ..., 0.00854492,\n",
      "         -0.00178528, 0.00817871],\n",
      "        ...,\n",
      "        [-0.00112152, 0.000385284, 0.0012207, ..., 0.0174561,\n",
      "         -0.0101929, -0.0123901],\n",
      "        [-0.00195312, 0.0170898, -0.0115356, ..., 0.0123901, -0.0206299,\n",
      "         0.00714111],\n",
      "        [-0.020874, -0.00610352, -0.00704956, ..., -0.00130463,\n",
      "         -0.0114746, -0.0154419]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.000160217, 0.00378418, -0.00205994, ..., -0.0115356,\n",
      "         -0.00546265, 0.000394821],\n",
      "        [0.000583649, -0.00378418, -0.0238037, ..., -0.0062561,\n",
      "         -0.000118732, 0.0108643],\n",
      "        [-0.0158691, -0.019043, -0.00595093, ..., -0.00259399,\n",
      "         0.0192871, 0.00299072],\n",
      "        ...,\n",
      "        [-0.0114746, 0.00939941, -0.00909424, ..., -0.0103149,\n",
      "         -0.00100708, 0.0146484],\n",
      "        [0.012085, 0.0106201, -0.0164795, ..., -0.0213623, 0.00344849,\n",
      "         -0.00439453],\n",
      "        [-0.00756836, 0.00210571, 0.0174561, ..., 0.000762939, 0.010498,\n",
      "         -0.00174713]],\n",
      "\n",
      "       [[0.00650024, -0.0157471, -0.00491333, ..., 0.00576782,\n",
      "         -0.0112305, 0.0142822],\n",
      "        [-0.00750732, -0.00418091, -0.00151062, ..., 0.00854492,\n",
      "         0.0119019, 0.00772095],\n",
      "        [0.000701904, 0.00153351, 0.00354004, ..., -0.00708008,\n",
      "         0.000659943, -0.0027771],\n",
      "        ...,\n",
      "        [0.0131226, 0.00128174, -0.00595093, ..., 0.00527954,\n",
      "         -0.0168457, -0.00643921],\n",
      "        [-0.000240326, -0.00805664, -0.0112305, ..., 0.00952148,\n",
      "         -0.00744629, -0.00817871],\n",
      "        [0.0195312, 0.00105286, 0.0105591, ..., 0.0164795, -0.0114136,\n",
      "         0.000831604]],\n",
      "\n",
      "       [[-0.0111694, 0.0155029, 0.00958252, ..., -0.00132751, 0.0262451,\n",
      "         -0.0183105],\n",
      "        [0.00361633, 0.012085, -0.00445557, ..., -0.0174561, -0.0140991,\n",
      "         -0.0101929],\n",
      "        [-0.00546265, 0.00640869, 0.00332642, ..., 0.0133667,\n",
      "         0.00149536, 0.00162506],\n",
      "        ...,\n",
      "        [-0.00927734, -0.00698853, -0.00805664, ..., 0.00842285,\n",
      "         0.0115967, 0.015564],\n",
      "        [0.0185547, 0.00113678, 0.0134888, ..., -0.00811768, 0.00891113,\n",
      "         0.0218506],\n",
      "        [-0.0115356, 0.00744629, -0.0175781, ..., -0.000427246,\n",
      "         0.00393677, 0.0115356]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00140381, -0.00793457, -0.0098877, ..., 0.00331116,\n",
      "          -0.0317383, 0.0133667],\n",
      "         [0.0025177, 0.00622559, -0.00466919, ..., 0.0270996,\n",
      "          -0.00500488, -0.0158691],\n",
      "         [0.00543213, 0.00257874, -0.0139771, ..., 0.00561523,\n",
      "          -0.0177002, -0.00506592],\n",
      "         ...,\n",
      "         [0.00521851, 6.91414e-05, 0.00297546, ..., 0.0257568,\n",
      "          0.0149536, -0.0114136],\n",
      "         [-0.00285339, -0.00704956, -0.00491333, ..., 0.000789642,\n",
      "          0.0239258, 0.0136719],\n",
      "         [-0.00640869, 0.00297546, 0.00335693, ..., -0.0230713,\n",
      "          0.0157471, 0.00848389]],\n",
      "\n",
      "        [[-0.00714111, -0.00170135, -0.00370789, ..., -0.00292969,\n",
      "          -0.0194092, 0.0212402],\n",
      "         [-0.00619507, -0.0107422, 0.00166321, ..., 0.00170898,\n",
      "          -0.0090332, 0.000923157],\n",
      "         [0.00524902, -0.00787354, -0.010498, ..., -0.00185394,\n",
      "          -0.017334, -0.00233459],\n",
      "         ...,\n",
      "         [0.00811768, -0.00765991, 0.0039978, ..., -0.00151825,\n",
      "          0.00193787, 0.00933838],\n",
      "         [0.00616455, -0.0065918, 0.00285339, ..., -0.00540161,\n",
      "          -0.0112305, -0.012207],\n",
      "         [0.00637817, -0.00643921, -0.00552368, ..., 0.00405884,\n",
      "          -0.00695801, -0.0013504]],\n",
      "\n",
      "        [[0.00396729, -0.0071106, 0.00131226, ..., -0.0266113,\n",
      "          0.0129395, -0.00921631],\n",
      "         [-0.0117798, -0.00102997, -0.00939941, ..., 0.0166016,\n",
      "          -0.017334, -0.0189209],\n",
      "         [-0.00656128, -0.0123901, -0.000701904, ..., 0.00279236,\n",
      "          0.0203857, 0.0144043],\n",
      "         ...,\n",
      "         [-0.00656128, -0.00592041, -0.00167084, ..., -0.0230713,\n",
      "          0.00202942, -0.00631714],\n",
      "         [-0.00110626, 0.010376, -0.00650024, ..., -0.000541687,\n",
      "          0.0262451, -0.0327148],\n",
      "         [0.00268555, -0.00405884, -0.0144653, ..., 0.0126953,\n",
      "          0.0219727, -0.00186157]],\n",
      "\n",
      "        [[-0.00193787, -0.00332642, -0.00141144, ..., -0.0227051,\n",
      "          -0.019165, -0.00735474],\n",
      "         [0.00753784, -0.000900269, 0.00686646, ..., 0.00153351,\n",
      "          -0.0019455, -0.0256348],\n",
      "         [0.00114441, -0.00747681, -0.0183105, ..., -0.00665283,\n",
      "          0.020752, 0.000352859],\n",
      "         ...,\n",
      "         [-0.00366211, 0.00704956, 0.0194092, ..., -0.0124512,\n",
      "          0.0112305, 0.00970459],\n",
      "         [-0.00210571, 0.00656128, -0.0100098, ..., -0.00274658,\n",
      "          -0.0106201, -0.00515747],\n",
      "         [-0.00190735, 0.00151825, 0.0144043, ..., 0.0181885,\n",
      "          0.00300598, -0.0183105]]],\n",
      "\n",
      "\n",
      "       [[[-0.00549316, -0.000341415, 0.00297546, ..., -0.0134277,\n",
      "          0.000637054, -0.0101318],\n",
      "         [-0.0123901, -0.0050354, 0.00540161, ..., 0.00836182,\n",
      "          0.00595093, -0.0101318],\n",
      "         [-0.00756836, 0.0131226, -0.000322342, ..., 0.0100708,\n",
      "          -0.00823975, -0.00248718],\n",
      "         ...,\n",
      "         [0.0183105, 0.00466919, -0.00485229, ..., 0.00326538,\n",
      "          -0.012146, 0.0142212],\n",
      "         [-0.00744629, -0.0186768, -0.00212097, ..., 0.017334,\n",
      "          0.00708008, -0.0222168],\n",
      "         [-0.00842285, -0.00534058, -0.00109863, ..., -0.00460815,\n",
      "          0.017334, -0.00087738]],\n",
      "\n",
      "        [[-0.0166016, -0.00775146, 0.00352478, ..., -0.0125122,\n",
      "          -0.00613403, -0.00637817],\n",
      "         [-0.0219727, -0.0236816, 0.0327148, ..., -0.0088501,\n",
      "          -0.0153198, -0.0180664],\n",
      "         [-0.00466919, 0.00337219, 0.00866699, ..., -0.0116577,\n",
      "          0.0120239, 0.00558472],\n",
      "         ...,\n",
      "         [-0.000896454, -0.00153351, -0.00139618, ..., 0.00460815,\n",
      "          0.0177002, -0.0118408],\n",
      "         [-0.000135422, 0.00509644, 0.00958252, ..., -0.0203857,\n",
      "          4.29153e-05, -0.0111694],\n",
      "         [0.00939941, 0.00479126, -0.0072937, ..., 0.0129395,\n",
      "          0.0184326, -0.00151062]],\n",
      "\n",
      "        [[0.00842285, 0.00534058, 0.0116577, ..., -0.00585938,\n",
      "          -0.00656128, -0.0057373],\n",
      "         [-0.0112915, 0.0100098, -0.0231934, ..., 0.00686646,\n",
      "          0.0115356, 0.0180664],\n",
      "         [-0.00485229, 0.00282288, 0.0218506, ..., -0.0037384,\n",
      "          -0.00619507, 0.0110474],\n",
      "         ...,\n",
      "         [-0.0166016, 0.010376, -0.00830078, ..., 0.00567627,\n",
      "          -0.00173187, 0.000255585],\n",
      "         [0.0124512, 0.006073, 0.0107422, ..., 0.0100098, 0.00104523,\n",
      "          0.0101318],\n",
      "         [-0.0175781, 0.00692749, -0.00769043, ..., -0.00921631,\n",
      "          -0.00897217, 0.000991821]],\n",
      "\n",
      "        [[0.000105858, -0.000778198, -0.00296021, ..., -0.00613403,\n",
      "          0.00473022, -0.0202637],\n",
      "         [0.017334, 0.00811768, -0.00634766, ..., -0.000999451,\n",
      "          0.0214844, 0.00150299],\n",
      "         [0.00546265, 0.00154114, -0.0119019, ..., -0.00312805,\n",
      "          -3.86238e-05, -0.00640869],\n",
      "         ...,\n",
      "         [-0.00230408, -0.0150146, 0.0177002, ..., 0.0027771,\n",
      "          -0.0184326, -0.0180664],\n",
      "         [0.00101471, -0.0164795, -0.00289917, ..., 0.0162354,\n",
      "          0.00650024, 0.00527954],\n",
      "         [-0.0236816, -0.0136108, 0.00946045, ..., 0.00125122,\n",
      "          0.0147095, -0.00994873]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00256348, 0.00549316, 0.00212097, ..., -0.0311279,\n",
      "         -0.050293, 0.0174561],\n",
      "        [-0.00634766, 0.00346375, 0.00292969, ..., 0.00616455,\n",
      "         -0.032959, 0.0307617],\n",
      "        [0.00218201, -0.00286865, 0.00202942, ..., 0.00866699,\n",
      "         -0.00686646, -0.0062561],\n",
      "        ...,\n",
      "        [0.0032196, 0.00312805, 0.000907898, ..., 0.0311279,\n",
      "         -0.00122833, -0.00927734],\n",
      "        [0.00102997, 0.00021553, -0.00421143, ..., -0.00878906,\n",
      "         0.00964355, 0.00279236],\n",
      "        [0.00112152, 0.0032959, -0.00160217, ..., -0.00436401,\n",
      "         0.0371094, -0.0268555]],\n",
      "\n",
      "       [[0.0116577, -0.00552368, -0.00335693, ..., 0.00497437,\n",
      "         0.00177765, 0.000587463],\n",
      "        [-0.00518799, 0.0101929, -0.000181198, ..., -0.00878906,\n",
      "         -0.012085, -0.00154877],\n",
      "        [-0.0245361, -0.00576782, 0.00897217, ..., 0.00695801,\n",
      "         -0.0022583, -0.000181198],\n",
      "        ...,\n",
      "        [0.000816345, -0.00588989, -0.00190735, ..., 0.0035553,\n",
      "         0.0111084, 0.00213623],\n",
      "        [0.00482178, 0.00558472, 0.00921631, ..., 0.00141907,\n",
      "         0.00289917, 0.000244141],\n",
      "        [0.0238037, -0.0123291, -0.0181885, ..., 0.012085, -0.00595093,\n",
      "         -0.0159912]],\n",
      "\n",
      "       [[-0.0010376, 0.0113525, 0.00588989, ..., 0.0227051, 0.00515747,\n",
      "         0.0127563],\n",
      "        [0.00479126, 0.001297, 0.00308228, ..., 0.0187988, -0.00601196,\n",
      "         0.0072937],\n",
      "        [0.00034523, 0.0140991, 0.00631714, ..., -0.0266113, 0.00291443,\n",
      "         0.0090332],\n",
      "        ...,\n",
      "        [0.0072937, -0.0122681, -0.00286865, ..., 0.00171661,\n",
      "         0.00430298, 0.00497437],\n",
      "        [0.00118256, 0.0098877, 0.00205994, ..., 0.00656128, 0.00418091,\n",
      "         -0.0109863],\n",
      "        [0.00025177, 0.00189209, -0.0101318, ..., 0.00823975,\n",
      "         -0.000272751, 0.0239258]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00241089, 0.00402832, 0.00317383, ..., -0.0456543,\n",
      "         0.00854492, -0.0238037],\n",
      "        [-0.00170135, 0.0115356, -0.00216675, ..., 0.0505371, 0.0230713,\n",
      "         0.0183105],\n",
      "        [-0.00153351, -0.00799561, -0.00222778, ..., 0.0229492,\n",
      "         -0.0187988, 0.0422363],\n",
      "        ...,\n",
      "        [0.00188446, 0.00619507, -0.00326538, ..., -0.0598145,\n",
      "         -0.0125732, 0.00125122],\n",
      "        [4.22001e-05, -0.00245667, 0.00946045, ..., -0.000888824,\n",
      "         -0.00411987, 0.027832],\n",
      "        [-0.00154877, -0.00656128, 0.0062561, ..., 0.0183105, 0.0108032,\n",
      "         -0.0137939]],\n",
      "\n",
      "       [[0.0170898, -0.00360107, 0.00909424, ..., -0.0106201,\n",
      "         -0.00704956, 0.00317383],\n",
      "        [-0.0119629, -0.0169678, -0.00222778, ..., 0.00102234,\n",
      "         0.0114746, -0.00958252],\n",
      "        [-0.000522614, -0.00601196, -0.0280762, ..., 0.0162354,\n",
      "         -0.00257874, 0.0100098],\n",
      "        ...,\n",
      "        [-0.0012207, 0.00994873, 0.00656128, ..., -0.00227356,\n",
      "         -0.00101471, 0.00274658],\n",
      "        [-0.00680542, 0.00396729, -0.0150757, ..., 0.0140991,\n",
      "         -0.00317383, -0.0133667],\n",
      "        [-0.00564575, -0.00387573, 0.0308838, ..., 0.00976562,\n",
      "         -0.00460815, -0.00328064]],\n",
      "\n",
      "       [[0.00421143, 0.000881195, 0.00094986, ..., 0.0126953,\n",
      "         0.00177002, -0.0185547],\n",
      "        [-0.00616455, 0.00248718, -0.00100708, ..., 0.00296021,\n",
      "         0.0209961, -0.0461426],\n",
      "        [-0.00259399, 0.00366211, 0.000778198, ..., -0.0133057,\n",
      "         0.0110474, -0.00830078],\n",
      "        ...,\n",
      "        [-0.00154877, -0.00187683, 0.00184631, ..., -0.0172119,\n",
      "         -0.0142822, -0.0283203],\n",
      "        [0.00585938, -0.0010376, 0.00527954, ..., 0.00540161,\n",
      "         -0.00787354, -0.013916],\n",
      "        [-0.0019989, 0.00224304, -0.00396729, ..., 0.00744629,\n",
      "         -0.00343323, 0.00250244]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.0158691, -0.00306702, -0.0169678, ..., -0.00346375,\n",
      "         -0.00723267, 0.0071106],\n",
      "        [0.00154114, 0.0124512, -0.00494385, ..., -0.0050354,\n",
      "         0.00292969, 0.00830078],\n",
      "        [0.00976562, 0.0098877, 0.00415039, ..., 0.00436401, 0.00518799,\n",
      "         0.00274658],\n",
      "        ...,\n",
      "        [0.00238037, -0.00686646, -0.00427246, ..., -0.00216675,\n",
      "         -0.00653076, -0.00130463],\n",
      "        [0.0108032, -0.00337219, 0.00323486, ..., -0.00646973,\n",
      "         -0.00509644, 0.00180817],\n",
      "        [0.00248718, -0.0102539, -0.000656128, ..., 0.006073,\n",
      "         0.00549316, -0.0161133]],\n",
      "\n",
      "       [[0.00247192, -0.000621796, 0.0150146, ..., 0.00136566,\n",
      "         -0.00390625, -0.00204468],\n",
      "        [-0.0035553, -0.00488281, -0.000709534, ..., 0.0038147,\n",
      "         0.0020752, -0.00534058],\n",
      "        [0.00165558, 0.000364304, 0.00063324, ..., -0.00494385,\n",
      "         -0.012146, -0.00248718],\n",
      "        ...,\n",
      "        [-0.0127563, -0.00415039, 0.000648499, ..., -0.00117493,\n",
      "         0.00454712, -0.00260925],\n",
      "        [-0.00787354, -0.00140381, 0.00805664, ..., 0.00994873,\n",
      "         -0.00527954, 0.00239563],\n",
      "        [-0.0130615, 0.00297546, 0.0130615, ..., -0.00296021,\n",
      "         0.00732422, 0.0103149]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00221252, -0.00897217, -0.00634766, ..., -0.0098877,\n",
      "        0.000938416, 0.00341797],\n",
      "       [0.00756836, 0.0078125, -0.00595093, ..., 0.00372314, -0.00233459,\n",
      "        -0.00744629],\n",
      "       [0.00286865, -0.000667572, -0.00567627, ..., -0.000865936,\n",
      "        -0.00744629, 0.00106049],\n",
      "       ...,\n",
      "       [-0.000312805, 0.00146484, -4.26769e-05, ..., -0.00289917,\n",
      "        0.00549316, -0.0110474],\n",
      "       [-0.00363159, 0.000465393, -0.00878906, ..., 0.00512695,\n",
      "        -0.0153198, -0.00315857],\n",
      "       [-0.00222778, 0.0050354, -0.000159264, ..., 0.000162125,\n",
      "        -0.00457764, -0.00518799]], dtype=bfloat16), a=Array([[ 0.00193953,  0.00879681, -0.02188212, ...,  0.00268727,\n",
      "         0.00692501, -0.02095343],\n",
      "       [-0.01345678,  0.01583269,  0.00739929, ...,  0.00684354,\n",
      "        -0.01523105,  0.00528662]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.125, 1.09375, 1.17969, ..., 1.22656, 0.921875, 0.847656],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.42188, 1.45312, 1.50781, ..., 1.46094, 1.53125, 1.23438],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.589844, 0.570312, 0.498047, ..., 0.628906, 0.259766, 0.570312],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.176758, -0.133789, -0.176758, ..., -0.145508, -0.251953,\n",
      "       -0.133789], dtype=bfloat16)}}, 'layer_16': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00282288, -0.00491333, 0.00744629, ..., -0.013855,\n",
      "         -0.0124512, 0.00215149],\n",
      "        [-0.00564575, 0.00302124, 0.00509644, ..., -0.00497437,\n",
      "         -0.00494385, 0.0125122],\n",
      "        [0.0194092, -0.017334, -0.0115967, ..., -0.006073, -0.000450134,\n",
      "         0.00485229],\n",
      "        ...,\n",
      "        [-0.00531006, 0.00254822, 0.00154114, ..., 0.00196838,\n",
      "         -0.00180054, -0.00136566],\n",
      "        [-0.00259399, -0.0110474, 0.0270996, ..., 0.0019989, 0.0102539,\n",
      "         -0.0157471],\n",
      "        [0.00411987, -0.0177002, 0.00878906, ..., -0.000873566,\n",
      "         -0.0050354, 0.00320435]],\n",
      "\n",
      "       [[-0.00143433, -0.00588989, 0.00817871, ..., -0.00421143,\n",
      "         -0.00512695, -0.0218506],\n",
      "        [0.00524902, -0.00442505, 0.00817871, ..., 0.00163269,\n",
      "         -0.00509644, 0.00558472],\n",
      "        [-0.00939941, -0.012207, 0.0101318, ..., 0.00460815, 0.00267029,\n",
      "         -0.00497437],\n",
      "        ...,\n",
      "        [0.00567627, 0.0126953, -0.00714111, ..., -0.0122681, 0.0314941,\n",
      "         -0.00326538],\n",
      "        [0.0151978, 0.00338745, -0.00497437, ..., 0.00830078,\n",
      "         -0.000114918, 0.0129395],\n",
      "        [0.00698853, 0.0189209, 0.000946045, ..., 0.00233459,\n",
      "         0.00976562, 0.0116577]],\n",
      "\n",
      "       [[-0.0131836, 0.020874, 0.0127563, ..., -0.00842285, -0.043457,\n",
      "         0.0125122],\n",
      "        [-0.00585938, 0.00543213, -0.00250244, ..., -0.00878906,\n",
      "         0.00811768, -0.00179291],\n",
      "        [0.00897217, 0.0322266, -0.0128784, ..., -0.0249023, -0.0395508,\n",
      "         0.00479126],\n",
      "        ...,\n",
      "        [0.017334, -0.017334, -0.00921631, ..., -0.0115967, 0.00117493,\n",
      "         0.0137939],\n",
      "        [-0.00515747, 0.0117188, 0.00643921, ..., -0.0098877,\n",
      "         -0.0178223, 0.00735474],\n",
      "        [0.0349121, 0.0117798, -0.0339355, ..., -0.00183105, 0.00245667,\n",
      "         -0.0153198]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00193787, 0.00515747, 0.0117188, ..., -0.0144653,\n",
      "         -0.00613403, 0.0192871],\n",
      "        [0.00518799, 0.00744629, 0.00231934, ..., -0.00909424,\n",
      "         -0.0230713, -0.0112915],\n",
      "        [-0.00222778, 0.00460815, 0.0135498, ..., 0.0150757, 0.00231934,\n",
      "         -0.00358582],\n",
      "        ...,\n",
      "        [-0.00500488, 0.00720215, 0.017334, ..., -0.00994873,\n",
      "         -0.0158691, 0.0098877],\n",
      "        [-0.012146, 0.00671387, 0.00982666, ..., -0.0267334,\n",
      "         -0.00148773, -0.000459671],\n",
      "        [-0.00799561, -0.00622559, 0.000614166, ..., 0.0137329,\n",
      "         0.00665283, -0.00921631]],\n",
      "\n",
      "       [[0.00117493, 0.00332642, -0.00921631, ..., 0.00982666,\n",
      "         0.00192261, 0.00106812],\n",
      "        [-0.0172119, 0.00393677, 0.00695801, ..., 0.0105591, 0.0020752,\n",
      "         0.000473022],\n",
      "        [-0.012146, -0.0144043, 0.00328064, ..., 0.0178223, 0.00897217,\n",
      "         0.00221252],\n",
      "        ...,\n",
      "        [0.0030365, -0.000972748, -0.000484467, ..., 0.00643921,\n",
      "         0.00994873, 0.00952148],\n",
      "        [-0.00668335, 0.00747681, 0.0286865, ..., -0.0038147,\n",
      "         -0.0128784, -0.00306702],\n",
      "        [0.00491333, 0.00222778, 0.00616455, ..., -0.0129395, 0.0119019,\n",
      "         0.00982666]],\n",
      "\n",
      "       [[-0.0157471, -0.0125122, -0.00671387, ..., -0.00466919,\n",
      "         0.0111084, 0.0144043],\n",
      "        [0.00190735, 0.00411987, 0.0039978, ..., 0.000326157,\n",
      "         -0.00102997, 0.0220947],\n",
      "        [-0.00637817, 0.00656128, 0.0111694, ..., -0.00976562,\n",
      "         -0.00408936, -0.0157471],\n",
      "        ...,\n",
      "        [-0.00650024, 0.015625, -0.000671387, ..., 0.00720215,\n",
      "         -9.77516e-06, -0.00872803],\n",
      "        [-0.00202942, -0.000404358, -0.0201416, ..., 0.00650024,\n",
      "         -0.000720978, -0.0175781],\n",
      "        [0.00595093, -0.00958252, -0.0264893, ..., 0.00215149,\n",
      "         -0.00653076, 0.017334]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00704956, -0.000284195, 0.00430298, ..., 0.0123901,\n",
      "          -0.000141144, -0.0114746],\n",
      "         [-0.00708008, -0.00482178, 0.00476074, ..., 0.0172119,\n",
      "          0.0106812, 0.00723267],\n",
      "         [0.00726318, 0.000553131, 0.00622559, ..., 0.0166016,\n",
      "          0.00811768, -0.00124359],\n",
      "         ...,\n",
      "         [-0.000476837, -0.000751495, 0.00970459, ..., 0.0110474,\n",
      "          -0.00360107, -0.034668],\n",
      "         [0.00276184, 0.00101471, 0.00370789, ..., -0.00848389,\n",
      "          -0.0205078, -0.00662231],\n",
      "         [0.00242615, -0.000389099, 0.00601196, ..., -0.0159912,\n",
      "          -0.00442505, -0.0192871]],\n",
      "\n",
      "        [[-0.00245667, 0.00866699, -0.00540161, ..., -0.00145721,\n",
      "          0.00454712, -0.00120544],\n",
      "         [-0.000175476, -0.00390625, 0.00744629, ..., 0.0123901,\n",
      "          0.0140381, 0.0039978],\n",
      "         [0.00817871, 0.00476074, -0.003479, ..., 0.0159912,\n",
      "          -0.00436401, 0.0203857],\n",
      "         ...,\n",
      "         [0.0016098, 0.0039978, 0.00756836, ..., -0.00549316,\n",
      "          0.00405884, -0.000831604],\n",
      "         [-0.00778198, -0.00656128, -0.00500488, ..., -0.00848389,\n",
      "          0.00238037, -0.00318909],\n",
      "         [-0.00187683, 0.00558472, 0.0043335, ..., -0.00274658,\n",
      "          0.00473022, -0.00309753]],\n",
      "\n",
      "        [[0.0101318, 0.00640869, 0.00442505, ..., 0.0222168, 0.020752,\n",
      "          0.00616455],\n",
      "         [-0.00558472, -0.00683594, 0.00334167, ..., -0.0155029,\n",
      "          -0.00762939, 0.00582886],\n",
      "         [0.000717163, -0.00173187, -0.00613403, ..., 0.00860596,\n",
      "          0.00239563, -0.0110474],\n",
      "         ...,\n",
      "         [0.00334167, 0.00151062, -0.00445557, ..., 0.0144043,\n",
      "          0.0123901, 0.00488281],\n",
      "         [-0.00759888, 0.00105286, -0.00179291, ..., -0.0170898,\n",
      "          0.00157928, -0.00204468],\n",
      "         [0.0018158, -0.00358582, 0.000831604, ..., 0.006073,\n",
      "          0.0043335, -0.0106812]],\n",
      "\n",
      "        [[-0.00075531, 0.00386047, -0.000291824, ..., 0.0132446,\n",
      "          0.00546265, -0.0206299],\n",
      "         [0.000185966, -0.0109253, 0.00159454, ..., -0.0214844,\n",
      "          -0.0129395, 0.00195312],\n",
      "         [0.00187683, 0.00132751, 0.00144958, ..., -0.0198975,\n",
      "          -0.0157471, 0.0126953],\n",
      "         ...,\n",
      "         [0.00830078, 0.0016861, -0.00170135, ..., -0.0151367,\n",
      "          0.0220947, -0.0252686],\n",
      "         [-0.00271606, 0.00411987, -0.00102234, ..., -0.00106812,\n",
      "          -0.0228271, 0.0198975],\n",
      "         [-0.00382996, 0.000243187, -0.0101318, ..., 0.00579834,\n",
      "          0.0114136, 0.00102997]]],\n",
      "\n",
      "\n",
      "       [[[0.000991821, -0.0109253, 0.0150757, ..., -0.00259399,\n",
      "          0.00674438, 0.00927734],\n",
      "         [-0.00233459, -0.00285339, -0.00393677, ..., 0.00769043,\n",
      "          -0.0151367, -0.00622559],\n",
      "         [-0.00185394, 0.0189209, -0.00254822, ..., -0.00680542,\n",
      "          0.00386047, 0.0187988],\n",
      "         ...,\n",
      "         [-0.00723267, 0.0114136, 0.00976562, ..., -0.00537109,\n",
      "          0.0126343, 0.0112915],\n",
      "         [-0.019043, -0.00622559, -0.00521851, ..., 0.00193787,\n",
      "          -0.0032959, -0.000301361],\n",
      "         [-0.0227051, -0.0105591, 0.0050354, ..., 0.00457764,\n",
      "          0.00628662, 0.0108032]],\n",
      "\n",
      "        [[-0.000839233, -0.00549316, 0.00153351, ..., -0.00735474,\n",
      "          0.00341797, -0.0142212],\n",
      "         [-0.0107422, -0.0117188, -0.00230408, ..., -0.0187988,\n",
      "          -0.0150757, -0.00823975],\n",
      "         [-0.0195312, -0.00132751, 0.00476074, ..., 0.00186157,\n",
      "          0.0125122, 0.0189209],\n",
      "         ...,\n",
      "         [-0.00634766, 0.0158691, 0.00257874, ..., 0.0106201,\n",
      "          0.0137939, -0.0246582],\n",
      "         [0.0142822, -0.0111694, 0.00439453, ..., -0.00358582,\n",
      "          0.00830078, 0.00268555],\n",
      "         [-0.00224304, 0.0202637, 0.00302124, ..., -0.0172119,\n",
      "          -0.000915527, 0.00689697]],\n",
      "\n",
      "        [[-0.00454712, -0.00282288, -0.00366211, ..., 0.00552368,\n",
      "          -0.00337219, -0.00427246],\n",
      "         [-0.00256348, 0.0103149, 0.00775146, ..., 0.0098877,\n",
      "          0.00631714, -0.0144043],\n",
      "         [-0.000759125, 0.00662231, 1.61678e-06, ..., -0.00506592,\n",
      "          0.0108643, 0.00312805],\n",
      "         ...,\n",
      "         [-0.0150146, -0.00585938, 0.012207, ..., -0.00254822,\n",
      "          -0.0148315, 0.0106812],\n",
      "         [-0.00509644, -0.0270996, 0.00778198, ..., -0.0050354,\n",
      "          -0.00872803, 0.0203857],\n",
      "         [0.00382996, 0.00024128, 0.00866699, ..., -0.0174561,\n",
      "          0.0115356, -0.00173187]],\n",
      "\n",
      "        [[-0.0106812, -0.00576782, -0.00564575, ..., 0.00308228,\n",
      "          -0.00747681, 0.0130615],\n",
      "         [-0.0217285, -0.00244141, -0.00640869, ..., 0.010437,\n",
      "          0.000126839, -0.000383377],\n",
      "         [0.0146484, -0.00144958, 0.0111694, ..., -0.00176239,\n",
      "          -0.00291443, -0.0114746],\n",
      "         ...,\n",
      "         [0.00244141, 0.00311279, -0.00141907, ..., -0.00231934,\n",
      "          -0.00619507, 0.00421143],\n",
      "         [-0.00202942, 0.0172119, -0.000196457, ..., 0.0161133,\n",
      "          -0.00619507, -0.00909424],\n",
      "         [0.0167236, 0.0112305, -0.00836182, ..., -0.00588989,\n",
      "          -0.00714111, 0.00491333]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00270081, -0.0148926, 0.013916, ..., 0.00193024, 0.0117798,\n",
      "         0.0299072],\n",
      "        [0.010376, -0.00279236, -0.00582886, ..., -0.0109863, 0.0164795,\n",
      "         -0.0249023],\n",
      "        [-0.00576782, -0.00265503, 0.00540161, ..., 0.0234375,\n",
      "         0.00732422, -0.0114136],\n",
      "        ...,\n",
      "        [0.00775146, -0.000617981, -0.000740051, ..., 0.0142822,\n",
      "         0.0339355, 0.0218506],\n",
      "        [0.00209045, -0.00174713, 0.00188446, ..., -0.0200195,\n",
      "         -0.0012207, 0.012207],\n",
      "        [0.012207, 0.00205994, 0.00613403, ..., 0.00343323, 0.0114746,\n",
      "         0.00848389]],\n",
      "\n",
      "       [[-0.00830078, -8.10623e-05, 0.0101929, ..., -0.00747681,\n",
      "         0.00631714, 0.0177002],\n",
      "        [0.00915527, -0.00598145, -0.00964355, ..., -0.0166016,\n",
      "         0.0205078, -0.0358887],\n",
      "        [-0.00662231, 0.00585938, 0.001297, ..., 0.0154419, 0.0153198,\n",
      "         -0.0192871],\n",
      "        ...,\n",
      "        [0.00714111, 0.00769043, -0.00180054, ..., 0.017334, 0.0100098,\n",
      "         0.0227051],\n",
      "        [-0.0155029, -0.00497437, 0.0247803, ..., -0.0112915,\n",
      "         0.00169373, 0.000591278],\n",
      "        [0.00994873, -0.00152588, 0.000804901, ..., 0.00300598,\n",
      "         0.0019455, -0.00836182]],\n",
      "\n",
      "       [[-0.00683594, 0.0025177, 0.00325012, ..., -0.00735474,\n",
      "         -0.0123291, -0.0153198],\n",
      "        [0.00302124, -0.00765991, -0.0016098, ..., 0.013916,\n",
      "         -0.00473022, 0.0172119],\n",
      "        [0.00291443, -0.00601196, -0.0109253, ..., 0.0132446,\n",
      "         -0.00662231, -0.00759888],\n",
      "        ...,\n",
      "        [0.00112152, -0.00186157, 0.00775146, ..., 0.019043, 0.0016861,\n",
      "         -0.0233154],\n",
      "        [-0.0038147, -0.00389099, -0.00540161, ..., 0.0090332,\n",
      "         -0.000778198, 0.00187683],\n",
      "        [-0.00239563, 0.00328064, -0.00799561, ..., -0.0111694,\n",
      "         -0.00866699, 0.0128784]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.000705719, 0.0032196, 0.00668335, ..., 0.0239258,\n",
      "         -0.00741577, 0.00108337],\n",
      "        [0.00595093, -0.0234375, 0.0124512, ..., -0.00680542,\n",
      "         -0.00762939, 0.0169678],\n",
      "        [0.00714111, -0.00320435, 0.00866699, ..., -0.0288086, 0.013916,\n",
      "         0.0187988],\n",
      "        ...,\n",
      "        [-0.00174713, 0.0055542, 0.00619507, ..., -0.00154877,\n",
      "         0.00631714, -0.00063324],\n",
      "        [0.00671387, -0.000444412, -0.0018692, ..., -0.00598145,\n",
      "         -0.0166016, 0.0166016],\n",
      "        [0.00415039, 0.00720215, -0.000312805, ..., -0.00512695,\n",
      "         0.0055542, -0.019043]],\n",
      "\n",
      "       [[-0.015625, 0.00430298, 0.00805664, ..., 0.024292, -0.0214844,\n",
      "         -0.00765991],\n",
      "        [0.00588989, 0.00369263, -0.0110474, ..., -0.0354004,\n",
      "         0.00799561, -0.0194092],\n",
      "        [0.00387573, 0.00164795, 0.0109253, ..., -0.000648499,\n",
      "         -0.0291748, 0.00759888],\n",
      "        ...,\n",
      "        [-0.012146, 0.00750732, -0.00280762, ..., 0.00714111,\n",
      "         -0.00312805, 0.00750732],\n",
      "        [0.00210571, -0.000339508, 0.0101929, ..., 0.00622559,\n",
      "         -0.00350952, -0.00479126],\n",
      "        [-0.00662231, 0.000377655, -0.00101471, ..., -0.0142822,\n",
      "         0.0235596, 0.001091]],\n",
      "\n",
      "       [[-0.0078125, 0.00811768, 0.00311279, ..., 0.00328064,\n",
      "         -0.0522461, -0.029541],\n",
      "        [-0.0110474, 0.0152588, -0.000161171, ..., -0.0167236,\n",
      "         -0.0143433, -0.0122681],\n",
      "        [0.000170708, 0.00405884, 0.000545502, ..., 0.000583649,\n",
      "         -0.0272217, 0.0130615],\n",
      "        ...,\n",
      "        [-0.0145874, 0.00396729, 0.000488281, ..., -0.0112305,\n",
      "         0.0038147, -0.00448608],\n",
      "        [0.0116577, 0.00285339, 0.00130463, ..., -0.00325012, 0.029541,\n",
      "         -0.0187988],\n",
      "        [-0.0133667, 0.0126343, 0.019165, ..., -0.0169678, 0.0198975,\n",
      "         -0.013916]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00106049, -0.0136108, -0.00315857, ..., 0.00205994,\n",
      "         0.0202637, -0.00112915],\n",
      "        [-0.00866699, 0.00778198, 0.00350952, ..., 0.00312805,\n",
      "         -0.00454712, 0.012146],\n",
      "        [0.00958252, -0.00154877, -0.0101318, ..., 0.00415039,\n",
      "         -0.00650024, 0.00376892],\n",
      "        ...,\n",
      "        [-0.0108643, -0.00299072, 0.012085, ..., 0.00637817,\n",
      "         -0.00457764, 0.00167084],\n",
      "        [0.0065918, 0.0032196, 0.00130463, ..., 0.00878906, -0.00418091,\n",
      "         0.0067749],\n",
      "        [0.00309753, -0.0119629, -0.00732422, ..., -0.00280762,\n",
      "         0.00454712, 0.000349045]],\n",
      "\n",
      "       [[0.00952148, -0.0090332, 0.0032196, ..., -0.00366211,\n",
      "         -0.00823975, 0.00186157],\n",
      "        [0.00927734, -0.000930786, 0.0142822, ..., 0.00188446,\n",
      "         0.00306702, -0.0157471],\n",
      "        [-0.00341797, -0.00379944, -0.00598145, ..., 0.00582886,\n",
      "         0.0147095, -0.00708008],\n",
      "        ...,\n",
      "        [0.0016861, 0.00259399, -0.000118732, ..., -0.00289917,\n",
      "         -0.00476074, -0.00382996],\n",
      "        [-0.00741577, -0.003479, 0.000694275, ..., 0.00209045,\n",
      "         -0.00299072, 0.0122681],\n",
      "        [-0.00836182, -0.0144043, 0.00823975, ..., -0.00540161,\n",
      "         -0.00982666, 0.00424194]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00172424, -0.00161743, -0.00848389, ..., -0.00291443,\n",
      "        0.00527954, 0.00119019],\n",
      "       [-0.00860596, -0.00769043, -0.00497437, ..., 0.0038147,\n",
      "        0.00157166, -0.0187988],\n",
      "       [0.00671387, 0.00686646, -0.0110474, ..., 0.00595093,\n",
      "        -0.000713348, 0.000938416],\n",
      "       ...,\n",
      "       [-0.00582886, 0.0067749, 0.00124359, ..., -0.00720215,\n",
      "        -0.00762939, -0.0102539],\n",
      "       [-0.00579834, 0.00897217, 0.0119629, ..., 0.00188446, 0.00151825,\n",
      "        0.00209045],\n",
      "       [0.00674438, 0.00418091, 0.00909424, ..., 0.0129395, 0.00224304,\n",
      "        -0.000789642]], dtype=bfloat16), a=Array([[-0.00321405, -0.01531544,  0.01043977, ...,  0.01724594,\n",
      "        -0.00019943, -0.00515615],\n",
      "       [-0.00242979, -0.00892317, -0.00779914, ...,  0.01742655,\n",
      "         0.00521834,  0.00618159]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.25781, 1.17969, 1.125, ..., 0.96875, 1.0625, 0.910156], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.8125, 1.82812, 1.90625, ..., 1.71094, 1.84375, 1.57031],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.871094, 0.992188, 0.765625, ..., 0.648438, 0.5625, 0.960938],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.108398, -0.0561523, -0.0947266, ..., -0.074707, -0.150391,\n",
      "       -0.0505371], dtype=bfloat16)}}, 'layer_17': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0317383, 0.0122681, 0.00708008, ..., -0.00114441, -0.0109863,\n",
      "         -0.0137329],\n",
      "        [-0.0032196, 0.00421143, -0.00300598, ..., -0.00148773,\n",
      "         0.022583, 0.00244141],\n",
      "        [-0.0183105, 0.0147095, 0.0153809, ..., 0.00364685, -0.00582886,\n",
      "         0.0088501],\n",
      "        ...,\n",
      "        [-0.012085, 0.00151825, -0.00445557, ..., -0.00270081,\n",
      "         -0.0141602, -0.00202942],\n",
      "        [-0.00415039, 0.0164795, -0.00891113, ..., -0.00759888,\n",
      "         0.0157471, 0.0017395],\n",
      "        [-0.013916, -0.0183105, 0.0150146, ..., -0.00158691, 0.00245667,\n",
      "         0.00976562]],\n",
      "\n",
      "       [[-0.0118408, -0.00198364, 0.00976562, ..., -0.000541687,\n",
      "         0.0178223, -0.00332642],\n",
      "        [-0.0109253, 0.00325012, -0.0285645, ..., -0.00891113,\n",
      "         -0.0111084, 0.0119629],\n",
      "        [0.0088501, -0.0219727, 0.0115967, ..., -0.00891113, 0.015625,\n",
      "         0.00427246],\n",
      "        ...,\n",
      "        [-0.00350952, 0.0212402, -0.0180664, ..., -0.00561523,\n",
      "         0.00939941, -0.00276184],\n",
      "        [0.00473022, 0.019043, -0.00772095, ..., 0.0123291, 0.00110626,\n",
      "         -0.00352478],\n",
      "        [0.0101929, 0.0319824, 0.0158691, ..., 0.0143433, 0.0107422,\n",
      "         0.0162354]],\n",
      "\n",
      "       [[0.00582886, -0.00970459, -0.00854492, ..., 0.00878906,\n",
      "         0.00570679, 0.0113525],\n",
      "        [0.0114136, 0.000610352, -0.0090332, ..., 0.0247803, -0.0090332,\n",
      "         0.00454712],\n",
      "        [-8.53539e-05, 0.0194092, 0.00233459, ..., -0.0137939,\n",
      "         0.00567627, -0.0209961],\n",
      "        ...,\n",
      "        [0.00958252, 0.00674438, 0.00337219, ..., -0.00294495, 0.012146,\n",
      "         -0.00352478],\n",
      "        [0.00753784, -0.00872803, -0.00469971, ..., -0.0143433,\n",
      "         0.00732422, 0.0125732],\n",
      "        [-0.017334, 0.0196533, -0.00891113, ..., -0.0115356, 0.00259399,\n",
      "         -0.00927734]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.0125122, -0.00297546, -0.0196533, ..., 0.00482178,\n",
      "         0.0117188, 0.0150146],\n",
      "        [-0.00836182, -0.00866699, 0.0142212, ..., 0.00756836,\n",
      "         -0.0251465, -0.00109863],\n",
      "        [-0.00366211, -0.00415039, 0.0230713, ..., 0.0071106,\n",
      "         0.000556946, -0.0106812],\n",
      "        ...,\n",
      "        [0.0145874, 0.0196533, 0.0196533, ..., 0.0238037, 0.0216064,\n",
      "         -0.00463867],\n",
      "        [0.00157166, -0.00334167, 0.013855, ..., -0.00436401,\n",
      "         0.00297546, -0.00154877],\n",
      "        [-0.00482178, -0.000984192, 0.00152588, ..., -0.000324249,\n",
      "         0.0136719, -0.000839233]],\n",
      "\n",
      "       [[-0.0027771, -0.0115356, 0.00367737, ..., 0.00125885, 0.0101929,\n",
      "         -0.000766754],\n",
      "        [0.00976562, -0.0267334, -0.00469971, ..., 0.0233154,\n",
      "         0.00209045, 0.0175781],\n",
      "        [-0.000938416, -0.000587463, -0.00491333, ..., 0.0222168,\n",
      "         0.00552368, -0.0134277],\n",
      "        ...,\n",
      "        [0.0125732, 0.00872803, 0.0194092, ..., 0.0011673, -0.006073,\n",
      "         0.00891113],\n",
      "        [-0.00268555, -0.00352478, 0.00366211, ..., 0.00164032,\n",
      "         0.0213623, -0.00640869],\n",
      "        [0.0134888, -0.00772095, -0.0172119, ..., 0.00196838,\n",
      "         -0.00367737, 0.00479126]],\n",
      "\n",
      "       [[0.00952148, 0.0117188, -0.00805664, ..., 0.0117798,\n",
      "         -0.00405884, -0.00314331],\n",
      "        [-0.00360107, 0.0174561, -0.00491333, ..., -0.0281982,\n",
      "         -0.00358582, -0.0181885],\n",
      "        [-0.00933838, -0.00212097, 0.000314713, ..., -0.0175781,\n",
      "         -0.00421143, 0.017334],\n",
      "        ...,\n",
      "        [0.000135422, -0.0018692, -0.0158691, ..., -0.00408936,\n",
      "         0.00457764, 0.0108032],\n",
      "        [-0.000572205, -0.00271606, -0.0101318, ..., 0.00878906,\n",
      "         -0.019165, -0.000774384],\n",
      "        [-0.00585938, 0.00531006, 0.000314713, ..., -6.94394e-06,\n",
      "         0.00479126, -0.00190735]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0192871, 0.00017643, 0.0133667, ..., 0.00613403,\n",
      "          0.0174561, 0.00860596],\n",
      "         [0.00372314, 0.0108643, 0.00494385, ..., -0.00488281,\n",
      "          -0.00485229, 0.00616455],\n",
      "         [-0.00564575, -0.00165558, -0.00241089, ..., 0.000965118,\n",
      "          -0.000172615, 0.0109863],\n",
      "         ...,\n",
      "         [0.00650024, 0.00958252, -0.0100708, ..., -0.0322266,\n",
      "          -0.00756836, -0.00494385],\n",
      "         [-0.0123901, 0.00540161, 0.00897217, ..., 0.00878906,\n",
      "          -0.0142212, 0.000303268],\n",
      "         [5.93662e-05, 0.0157471, -0.00799561, ..., -0.0149536,\n",
      "          -0.0106812, -0.0250244]],\n",
      "\n",
      "        [[-0.00756836, -0.00488281, 0.0124512, ..., -0.00946045,\n",
      "          -0.00576782, 0.00289917],\n",
      "         [-9.82285e-05, 0.0011673, 0.00028801, ..., 0.00640869,\n",
      "          0.0111084, 0.00674438],\n",
      "         [0.00506592, 0.000450134, -0.00448608, ..., -0.00119781,\n",
      "          0.000888824, -0.00257874],\n",
      "         ...,\n",
      "         [-0.00361633, 0.00439453, 0.0050354, ..., 0.00704956,\n",
      "          -0.00430298, -0.0202637],\n",
      "         [0.00674438, -0.00454712, -0.00830078, ..., 0.00221252,\n",
      "          0.00939941, -0.00222778],\n",
      "         [0.00363159, -0.00534058, -0.00265503, ..., -0.00628662,\n",
      "          -0.0148315, 0.0185547]],\n",
      "\n",
      "        [[-0.00668335, 0.00610352, 0.00341797, ..., -0.00662231,\n",
      "          0.00747681, -0.00970459],\n",
      "         [-0.00726318, -0.00151825, -0.00445557, ..., 0.000142097,\n",
      "          -0.000349045, -0.0125122],\n",
      "         [0.00302124, -0.000762939, 0.00145721, ..., -0.00115967,\n",
      "          -0.00671387, -0.00500488],\n",
      "         ...,\n",
      "         [-0.00028801, -0.00158691, -0.00518799, ..., -0.00282288,\n",
      "          -0.00224304, 0.0152588],\n",
      "         [0.00127411, 0.00196838, -0.00482178, ..., -0.0108643,\n",
      "          -0.0141602, 0.00134277],\n",
      "         [0.0018692, -0.00137329, 0.00424194, ..., -0.00161743,\n",
      "          0.00933838, -0.00744629]],\n",
      "\n",
      "        [[-0.00723267, -0.00704956, -0.00787354, ..., 0.0213623,\n",
      "          0.0012207, -0.00133514],\n",
      "         [-0.00488281, -0.00241089, 0.00430298, ..., -0.00285339,\n",
      "          -0.00245667, 0.00872803],\n",
      "         [-0.00878906, 0.00300598, 0.0098877, ..., 0.0150757,\n",
      "          0.00183105, 0.000364304],\n",
      "         ...,\n",
      "         [0.0136719, -0.00866699, -0.00241089, ..., 0.0125122,\n",
      "          0.0172119, 0.0178223],\n",
      "         [-0.0108032, 0.0057373, -0.00708008, ..., -0.00111389,\n",
      "          0.00166321, -0.00131226],\n",
      "         [-0.00427246, 0.0163574, -0.00204468, ..., -0.0177002,\n",
      "          0.0062561, 0.0213623]]],\n",
      "\n",
      "\n",
      "       [[[-0.00601196, 0.0183105, 0.00151825, ..., -0.00418091,\n",
      "          0.0288086, 0.00558472],\n",
      "         [-0.00118256, -0.0030365, -0.00317383, ..., 0.00418091,\n",
      "          0.00915527, 0.0129395],\n",
      "         [0.00228882, 0.00289917, 0.015564, ..., -0.000640869,\n",
      "          -0.000185013, 0.0161133],\n",
      "         ...,\n",
      "         [-0.00643921, -0.0303955, 0.010376, ..., -0.0152588,\n",
      "          -0.00165558, 0.00610352],\n",
      "         [0.0250244, 0.0141602, 0.00671387, ..., 0.00537109,\n",
      "          0.00994873, -0.000679016],\n",
      "         [-0.00958252, -0.0032196, 0.00921631, ..., -0.000295639,\n",
      "          -0.00735474, 0.0197754]],\n",
      "\n",
      "        [[0.012146, 0.00765991, 0.00309753, ..., 0.00376892, 0.0102539,\n",
      "          0.0101929],\n",
      "         [0.0151367, 0.00860596, 0.0151978, ..., 0.00952148,\n",
      "          0.00579834, -0.000602722],\n",
      "         [0.012146, -0.00424194, 0.00279236, ..., 0.00582886,\n",
      "          0.0234375, -0.013855],\n",
      "         ...,\n",
      "         [0.00915527, 0.0090332, -0.0115356, ..., -0.00680542,\n",
      "          0.0189209, 0.00454712],\n",
      "         [0.0187988, -0.0155029, -0.0115967, ..., 0.0149536, 0.0196533,\n",
      "          0.0107422],\n",
      "         [-0.0125732, 0.00224304, -0.000415802, ..., 0.0195312,\n",
      "          0.00315857, -0.0100098]],\n",
      "\n",
      "        [[0.00312805, -0.010498, 0.00149536, ..., 0.0090332,\n",
      "          -0.00323486, -0.00708008],\n",
      "         [0.00263977, 0.00430298, -1.38879e-05, ..., 0.000553131,\n",
      "          0.0112305, 0.00927734],\n",
      "         [0.003479, 0.000839233, -0.00216675, ..., 0.00288391,\n",
      "          0.00320435, 0.00952148],\n",
      "         ...,\n",
      "         [0.00588989, 0.00860596, 0.00360107, ..., 0.0231934,\n",
      "          -0.000398636, 0.0244141],\n",
      "         [0.020752, -0.00253296, -0.00543213, ..., 0.00848389,\n",
      "          -0.0116577, 0.00756836],\n",
      "         [-0.0110474, -0.022583, -0.00994873, ..., 0.0187988,\n",
      "          0.00393677, 0.00448608]],\n",
      "\n",
      "        [[0.0324707, -0.0140381, 0.00110626, ..., -0.0122681,\n",
      "          0.00170898, -0.0126953],\n",
      "         [0.00909424, 0.0281982, 0.00382996, ..., -0.00604248,\n",
      "          -0.00236511, 0.00361633],\n",
      "         [-0.0178223, -0.00439453, 0.00720215, ..., -0.0253906,\n",
      "          0.0043335, 0.0107422],\n",
      "         ...,\n",
      "         [-0.00836182, -0.0245361, -0.022583, ..., -0.00323486,\n",
      "          0.0153809, -0.00151825],\n",
      "         [-0.00656128, 0.00366211, -0.00866699, ..., 0.0065918,\n",
      "          -0.0252686, 0.00512695],\n",
      "         [-0.00689697, -0.0197754, 0.0317383, ..., -0.0020752,\n",
      "          0.00823975, -0.00512695]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00518799, -0.00567627, -0.00671387, ..., -0.00190735,\n",
      "         -0.000797272, 0.0127563],\n",
      "        [-0.00300598, 0.00149536, -0.00622559, ..., -0.0444336,\n",
      "         0.026001, -0.03125],\n",
      "        [-0.00244141, 0.0112915, -0.00848389, ..., 0.0180664, 0.0197754,\n",
      "         0.017334],\n",
      "        ...,\n",
      "        [0.00601196, 0.00402832, 0.0163574, ..., 0.00265503, 0.00650024,\n",
      "         -0.019165],\n",
      "        [0.00309753, -0.00500488, -0.00224304, ..., -0.0131226,\n",
      "         0.0123291, -0.00314331],\n",
      "        [-0.00415039, 0.0055542, 0.00317383, ..., 0.00241089,\n",
      "         -0.0280762, -0.0170898]],\n",
      "\n",
      "       [[0.0062561, -0.00698853, -0.0107422, ..., -0.00817871,\n",
      "         -0.00139618, -0.00271606],\n",
      "        [0.0014801, 0.0163574, 0.00964355, ..., -0.00153351, 0.00376892,\n",
      "         -0.00299072],\n",
      "        [-0.00236511, 0.00811768, 0.00415039, ..., 0.00166321,\n",
      "         0.00311279, 0.0201416],\n",
      "        ...,\n",
      "        [0.0252686, -0.00595093, 0.00482178, ..., 0.00509644,\n",
      "         -0.00656128, -0.0147705],\n",
      "        [0.00128937, -0.0169678, -0.00552368, ..., 0.013916,\n",
      "         -0.00601196, 0.0111694],\n",
      "        [0.00346375, 0.00137329, -0.00315857, ..., -0.00567627,\n",
      "         -0.00270081, -0.00970459]],\n",
      "\n",
      "       [[0.00257874, -0.00204468, -3.6478e-05, ..., 0.010376,\n",
      "         0.00160217, 0.0273438],\n",
      "        [-0.0136108, 0.00393677, -0.00982666, ..., 0.000972748,\n",
      "         0.00262451, -0.012146],\n",
      "        [-0.00369263, -0.00604248, -0.00619507, ..., -0.00393677,\n",
      "         0.00177002, 0.00028038],\n",
      "        ...,\n",
      "        [-0.00543213, 0.00473022, 0.000663757, ..., -0.0032196,\n",
      "         0.0240479, -0.0020752],\n",
      "        [0.00646973, 0.0142212, 0.00328064, ..., -0.0111084, -0.0133057,\n",
      "         -0.00344849],\n",
      "        [-0.0119019, -0.000999451, 0.0038147, ..., 0.00121307,\n",
      "         -0.0150757, 0.00497437]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.000214577, 0.00283813, -0.00328064, ..., 0.00430298,\n",
      "         0.00221252, -0.00265503],\n",
      "        [0.00485229, 0.00389099, 0.00552368, ..., -0.000307083,\n",
      "         0.0110474, 0.00122833],\n",
      "        [0.0189209, -0.0189209, 0.0236816, ..., 0.00939941, -0.00113678,\n",
      "         -0.00592041],\n",
      "        ...,\n",
      "        [-0.00598145, 0.00640869, -0.0212402, ..., -0.00088501,\n",
      "         -0.00387573, 0.000171661],\n",
      "        [0.0111694, -0.0106201, 0.0098877, ..., -0.003479, -5.72205e-05,\n",
      "         -0.00418091],\n",
      "        [-0.000234604, 0.00927734, -0.0245361, ..., 0.00408936,\n",
      "         0.00262451, 0.00325012]],\n",
      "\n",
      "       [[-0.00291443, -0.0035553, 0.0101318, ..., 0.0106812, 0.00588989,\n",
      "         0.0170898],\n",
      "        [0.00460815, 0.00231934, 0.00245667, ..., 0.00527954, 0.0065918,\n",
      "         0.0134888],\n",
      "        [0.0067749, 0.00445557, 0.0137329, ..., 0.00382996, 0.0126953,\n",
      "         -0.00634766],\n",
      "        ...,\n",
      "        [-0.00227356, 0.00527954, 0.0110474, ..., 0.00750732, 0.0016861,\n",
      "         0.0218506],\n",
      "        [-0.00570679, 0.00338745, 0.017334, ..., -0.00405884,\n",
      "         -0.0100098, 0.00628662],\n",
      "        [-0.00772095, -0.00622559, -0.0105591, ..., -0.0168457,\n",
      "         0.0065918, 0.0147095]],\n",
      "\n",
      "       [[0.000831604, 0.0102539, -0.0020752, ..., 0.00588989, 0.0161133,\n",
      "         -0.0098877],\n",
      "        [-0.00138855, 0.00509644, 0.00946045, ..., 0.00439453,\n",
      "         -0.00370789, 0.00613403],\n",
      "        [-0.00946045, -0.00558472, -0.00521851, ..., 0.0115967,\n",
      "         0.0065918, 0.0114746],\n",
      "        ...,\n",
      "        [-0.00842285, 0.000572205, -0.00144196, ..., 0.00689697,\n",
      "         0.00524902, 0.0148315],\n",
      "        [-0.00946045, -0.00314331, -0.00665283, ..., 0.00497437,\n",
      "         0.010376, 0.00656128],\n",
      "        [-0.00665283, -0.00527954, -0.0078125, ..., -0.0195312,\n",
      "         -0.0106812, 0.0128784]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.000762939, 0.000923157, 0.0124512, ..., 0.0088501,\n",
      "         -0.00473022, -0.00534058],\n",
      "        [-0.00778198, -0.00637817, -0.00735474, ..., 0.00604248,\n",
      "         0.00136566, 0.00665283],\n",
      "        [0.00897217, 0.000124931, -0.000396729, ..., 0.0118408,\n",
      "         -0.00245667, -0.000808716],\n",
      "        ...,\n",
      "        [0.00805664, 0.00159454, 0.00805664, ..., -0.00488281,\n",
      "         0.00570679, -0.0102539],\n",
      "        [0.00643921, -0.00396729, -0.00704956, ..., 0.00271606,\n",
      "         -0.0198975, 0.00637817],\n",
      "        [-0.0126953, 0.00253296, -0.00190735, ..., -0.00170135,\n",
      "         0.00411987, 0.0100708]],\n",
      "\n",
      "       [[-0.00891113, -0.00860596, 0.00540161, ..., 0.00170135,\n",
      "         0.00665283, -0.00180817],\n",
      "        [-0.0130615, 0.00717163, 0.0109863, ..., -0.00312805,\n",
      "         0.00164795, 0.00747681],\n",
      "        [5.29289e-05, -0.0050354, -0.00424194, ..., -0.00144958,\n",
      "         0.00274658, -0.0252686],\n",
      "        ...,\n",
      "        [-0.00805664, 0.006073, 0.000946045, ..., -0.00299072,\n",
      "         0.00460815, 0.00393677],\n",
      "        [-0.00982666, 0.00111389, -0.00509644, ..., -0.00683594,\n",
      "         -0.00112152, 0.00717163],\n",
      "        [-0.00289917, 0.0169678, 0.000934601, ..., 0.00732422,\n",
      "         0.0143433, 0.00704956]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00213623, -0.00421143, -0.000114918, ..., -0.00062561,\n",
      "        -0.00126648, 0.00830078],\n",
      "       [0.0128174, 0.00976562, -0.00543213, ..., -0.00656128,\n",
      "        -0.00646973, 0.0153809],\n",
      "       [0.00427246, -0.00823975, -0.00216675, ..., 0.00115967,\n",
      "        0.00267029, 0.00753784],\n",
      "       ...,\n",
      "       [-0.010498, 0.00167847, 0.0109863, ..., -0.00778198, 0.000522614,\n",
      "        -0.000385284],\n",
      "       [-0.00634766, -0.0045166, -0.00172424, ..., -0.00308228,\n",
      "        0.00230408, 0.0115967],\n",
      "       [0.00367737, 0.00604248, -0.0290527, ..., -0.00247192, 0.00361633,\n",
      "        0.00732422]], dtype=bfloat16), a=Array([[ 0.00229674,  0.00096951,  0.00196753, ...,  0.00066601,\n",
      "         0.00454113, -0.01169481],\n",
      "       [-0.00571106, -0.00023862, -0.00663244, ...,  0.00123321,\n",
      "        -0.01802823,  0.00163148]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.17188, 1.17188, 1.03125, ..., 1.05469, 0.980469, 1.01562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.125, 2.04688, 2.1875, ..., 2, 2.15625, 1.875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.535156, 0.675781, 0.472656, ..., 0.484375, 0.423828, 0.667969],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.0554199, -0.00891113, -0.0585938, ..., -0.0483398, -0.0942383,\n",
      "       -0.000480652], dtype=bfloat16)}}, 'layer_18': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00476074, -0.00531006, 0.0158691, ..., -0.00159454,\n",
      "         -0.00141144, 0.00190735],\n",
      "        [-0.0219727, 0.010376, -0.00674438, ..., -0.0142822, 0.00604248,\n",
      "         -0.0180664],\n",
      "        [-0.0105591, 0.000965118, 0.00817871, ..., 0.00358582,\n",
      "         -0.00759888, -0.0233154],\n",
      "        ...,\n",
      "        [0.0159912, 0.0162354, -0.00531006, ..., -0.00830078,\n",
      "         -0.000839233, -0.00909424],\n",
      "        [-0.0275879, 0.0137329, 0.0078125, ..., 0.0062561, 0.00366211,\n",
      "         -0.0115967],\n",
      "        [0.0119019, 0.00939941, 0.000579834, ..., 0.00219727,\n",
      "         -0.00309753, 0.010498]],\n",
      "\n",
      "       [[0.0116577, -0.020752, 0.000831604, ..., -0.00305176,\n",
      "         -0.00306702, 0.00102997],\n",
      "        [-0.00154877, 0.00171661, 0.000991821, ..., -0.00233459,\n",
      "         0.0137939, -0.00469971],\n",
      "        [-0.0251465, 1.86265e-06, -0.0179443, ..., -0.0253906,\n",
      "         0.0118408, -0.0025177],\n",
      "        ...,\n",
      "        [0.00592041, -0.0220947, 0.00491333, ..., -0.00689697, 0.015625,\n",
      "         0.0112915],\n",
      "        [-0.00212097, 0.0141602, -0.0131836, ..., -0.0209961,\n",
      "         -0.00964355, 0.0224609],\n",
      "        [-0.00543213, 0.000159264, 0.00340271, ..., 0.0209961,\n",
      "         0.0136108, -0.0164795]],\n",
      "\n",
      "       [[0.00427246, 0.00927734, 0.0111084, ..., 0.0118408, -0.0272217,\n",
      "         0.00891113],\n",
      "        [0.00138855, -0.019043, 0.0130005, ..., 0.0349121, 0.00442505,\n",
      "         0.00289917],\n",
      "        [-0.00188446, 0.0126953, 0.00323486, ..., -0.00153351,\n",
      "         -0.006073, 0.00952148],\n",
      "        ...,\n",
      "        [-0.0157471, -0.00497437, 0.00224304, ..., 0.00209045,\n",
      "         0.00176239, 0.00159454],\n",
      "        [-0.00364685, -0.00396729, 0.0150146, ..., -0.00485229,\n",
      "         -0.00897217, -0.00769043],\n",
      "        [0.000461578, -0.0103149, -0.0117188, ..., -0.00143433,\n",
      "         -0.0102539, 0.00726318]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00564575, 0.00291443, 0.00210571, ..., -0.00331116,\n",
      "         0.00616455, 0.0134888],\n",
      "        [0.00088501, 0.00289917, 0.00463867, ..., -0.00274658,\n",
      "         -0.010376, 0.00271606],\n",
      "        [0.00595093, -0.0178223, -0.00259399, ..., -2.32458e-05,\n",
      "         0.0268555, -0.00769043],\n",
      "        ...,\n",
      "        [-0.00488281, 0.0180664, 0.017334, ..., 0.00379944, 0.0161133,\n",
      "         0.0117188],\n",
      "        [0.000522614, 0.0159912, -0.00408936, ..., -0.0098877,\n",
      "         0.00726318, -0.00860596],\n",
      "        [-0.000583649, -0.00384521, 0.0114136, ..., -0.00169373,\n",
      "         0.00393677, 0.0043335]],\n",
      "\n",
      "       [[-0.00616455, -0.0022583, -0.00148773, ..., -0.00227356,\n",
      "         -0.010498, 0.000396729],\n",
      "        [0.00604248, -0.00378418, -0.00891113, ..., -0.00579834,\n",
      "         -0.0224609, -0.00167847],\n",
      "        [0.010498, 0.0209961, 0.00308228, ..., -0.00405884, -0.00387573,\n",
      "         0.00588989],\n",
      "        ...,\n",
      "        [-0.000161171, -0.0134277, 0.00540161, ..., 0.00744629,\n",
      "         0.00366211, -0.00402832],\n",
      "        [0.000881195, -0.00144196, -0.000179291, ..., -0.00299072,\n",
      "         0.0109863, -0.00331116],\n",
      "        [-0.00418091, 3.40939e-05, 0.0105591, ..., 0.0216064,\n",
      "         0.00230408, -0.0019989]],\n",
      "\n",
      "       [[0.0067749, -0.0119019, -0.00285339, ..., 0.0019989, 0.00604248,\n",
      "         0.010437],\n",
      "        [-0.00170898, 0.00650024, 0.010376, ..., -0.00106049, 0.024292,\n",
      "         -0.00466919],\n",
      "        [-0.010437, -0.0354004, -0.0129395, ..., -0.00182343,\n",
      "         -0.000984192, -0.00537109],\n",
      "        ...,\n",
      "        [-0.00274658, 0.0118408, -0.0100098, ..., -0.0163574,\n",
      "         0.00469971, 0.013855],\n",
      "        [0.0184326, -0.00418091, -0.0148315, ..., 0.00982666,\n",
      "         -0.0148926, 0.00723267],\n",
      "        [0.00982666, 0.00256348, -0.00738525, ..., -0.0290527,\n",
      "         -0.00595093, 0.00463867]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00123596, 0.00038147, 0.001297, ..., 0.000425339,\n",
      "          0.0184326, 0.0088501],\n",
      "         [-0.0112305, 0.00179291, -0.00723267, ..., 0.0224609,\n",
      "          0.0117798, -0.00296021],\n",
      "         [-0.0119629, 0.00326538, -0.00933838, ..., -0.022583,\n",
      "          -0.00239563, -0.00512695],\n",
      "         ...,\n",
      "         [-0.000923157, 0.00717163, 0.0120239, ..., 0.00753784,\n",
      "          0.00250244, 0.00141144],\n",
      "         [-0.00204468, -0.000526428, 0.00227356, ..., 0.0106201,\n",
      "          -0.000166893, 0.0055542],\n",
      "         [-0.00823975, 0.0014801, -0.000545502, ..., -0.0198975,\n",
      "          -0.00448608, 0.0123291]],\n",
      "\n",
      "        [[0.00201416, -0.000640869, 0.0125122, ..., 0.00325012,\n",
      "          0.00115967, 0.00263977],\n",
      "         [-0.00830078, 0.00491333, 0.00174713, ..., -0.00082016,\n",
      "          0.00878906, -0.0236816],\n",
      "         [-0.00104523, 0.000644684, 0.0147095, ..., 0.00328064,\n",
      "          -0.00354004, 0.0238037],\n",
      "         ...,\n",
      "         [0.00848389, 0.00050354, 0.00349426, ..., 0.00909424,\n",
      "          -0.00744629, -0.00595093],\n",
      "         [-0.00656128, 0.00567627, 0.00738525, ..., -0.00245667,\n",
      "          -0.0167236, 0.00218201],\n",
      "         [-0.00665283, 0.0090332, 0.00094986, ..., -0.00253296,\n",
      "          0.00314331, 0.0105591]],\n",
      "\n",
      "        [[-0.0118408, 0.00274658, -0.0206299, ..., -0.0255127,\n",
      "          -0.00939941, 0.0148926],\n",
      "         [-0.00952148, 0.0131836, 0.0013504, ..., 0.00332642,\n",
      "          -0.0274658, 0.00595093],\n",
      "         [-0.0050354, 0.00643921, 0.0117798, ..., 0.00683594,\n",
      "          -0.0178223, -0.0015564],\n",
      "         ...,\n",
      "         [0.00384521, -0.00592041, -0.000701904, ..., 0.000371933,\n",
      "          -0.00139618, -0.00164795],\n",
      "         [-0.000640869, -0.0178223, -0.0111694, ..., -0.0239258,\n",
      "          -0.0067749, -0.0195312],\n",
      "         [-0.00112152, 0.00723267, -0.0164795, ..., -0.0187988,\n",
      "          0.010376, -0.0175781]],\n",
      "\n",
      "        [[0.00463867, -0.00112915, 0.0065918, ..., -0.013855,\n",
      "          -0.00585938, 0.00167084],\n",
      "         [0.00878906, -0.0161133, -0.00598145, ..., -0.000184059,\n",
      "          0.0214844, -0.00842285],\n",
      "         [0.0062561, -0.00375366, -0.00201416, ..., 0.0189209,\n",
      "          -0.003479, -0.00515747],\n",
      "         ...,\n",
      "         [-0.00891113, -0.00289917, -0.00823975, ..., -0.00242615,\n",
      "          0.00285339, -0.0112305],\n",
      "         [-0.0062561, -0.00500488, -0.00238037, ..., 0.00485229,\n",
      "          0.0197754, 0.0161133],\n",
      "         [0.00408936, 0.000163078, -0.0078125, ..., 0.00320435,\n",
      "          0.00970459, 0.0125732]]],\n",
      "\n",
      "\n",
      "       [[[-0.0016098, -0.0163574, -0.022583, ..., 0.0281982,\n",
      "          -0.00866699, 0.00279236],\n",
      "         [-0.0183105, 0.0101318, 0.00130463, ..., 0.0192871, 0.0236816,\n",
      "          0.0130615],\n",
      "         [0.0361328, 0.00939941, -0.00830078, ..., -0.0229492,\n",
      "          0.013916, 0.00946045],\n",
      "         ...,\n",
      "         [-0.0200195, -0.0205078, -0.000429153, ..., -0.0169678,\n",
      "          -0.00102997, 0.00579834],\n",
      "         [-0.0211182, 0.00488281, -0.00128174, ..., 0.00396729,\n",
      "          0.0161133, -0.0108643],\n",
      "         [-0.00662231, -0.013855, -0.0230713, ..., 0.0045166,\n",
      "          0.00143433, 0.00723267]],\n",
      "\n",
      "        [[0.00765991, 0.0253906, -0.00463867, ..., 0.000134468,\n",
      "          0.0088501, -0.00144196],\n",
      "         [0.00375366, -0.0224609, 0.00271606, ..., 0.0039978,\n",
      "          0.0045166, -0.00732422],\n",
      "         [0.0209961, 0.00747681, 0.00982666, ..., 0.0279541,\n",
      "          0.000938416, -0.00921631],\n",
      "         ...,\n",
      "         [0.0159912, 0.00576782, -0.00817871, ..., 0.0126953,\n",
      "          -0.0050354, -0.00282288],\n",
      "         [-0.0251465, 0.00772095, -0.0186768, ..., 0.00799561,\n",
      "          0.00106049, -0.0198975],\n",
      "         [0.0144043, -0.0217285, 0.0185547, ..., 0.0244141, 0.00121307,\n",
      "          0.00964355]],\n",
      "\n",
      "        [[0.00543213, -0.0088501, 0.000219345, ..., -0.00366211,\n",
      "          -0.0101318, -0.0145874],\n",
      "         [0.003479, 0.00811768, 0.00582886, ..., 0.00117493,\n",
      "          -0.0032196, 0.0115356],\n",
      "         [-0.00120544, -0.00469971, 0.0020752, ..., 0.00540161,\n",
      "          -0.0103149, -0.00271606],\n",
      "         ...,\n",
      "         [-0.00288391, -0.000701904, 0.00595093, ..., -0.00292969,\n",
      "          0.00165558, -0.0150757],\n",
      "         [0.0125122, 0.00741577, 0.0229492, ..., -0.00256348,\n",
      "          -0.00793457, -0.00576782],\n",
      "         [-0.00101471, -0.00113678, -0.0112915, ..., 0.0151978,\n",
      "          -4.41074e-05, 0.0147095]],\n",
      "\n",
      "        [[0.0101929, -0.00300598, 0.000782013, ..., -0.00769043,\n",
      "          -0.0050354, 0.00135803],\n",
      "         [7.45058e-06, 0.000114441, -0.00479126, ..., 0.00576782,\n",
      "          -0.00028038, 0.00131226],\n",
      "         [0.00891113, 0.00509644, 0.00872803, ..., -0.0037384,\n",
      "          0.0262451, -0.00686646],\n",
      "         ...,\n",
      "         [8.58307e-06, 0.00167847, -0.00619507, ..., -0.00509644,\n",
      "          0.0067749, 0.00112915],\n",
      "         [0.00418091, 0.00476074, -0.0071106, ..., 0.0117798,\n",
      "          0.0273438, 0.0212402],\n",
      "         [0.000151634, -0.00408936, 0.00299072, ..., -0.00491333,\n",
      "          -0.00190735, 0.00970459]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00411987, -0.0011673, 0.00509644, ..., 0.00524902,\n",
      "         0.00285339, 0.00744629],\n",
      "        [0.00485229, 0.0132446, 0.0067749, ..., -0.00878906,\n",
      "         -0.00854492, 0.00656128],\n",
      "        [-0.00897217, 0.0212402, 0.00288391, ..., 0.000797272,\n",
      "         0.00050354, -0.027832],\n",
      "        ...,\n",
      "        [0.0164795, 0.00167847, -0.00326538, ..., -0.0143433,\n",
      "         0.00131989, -0.000789642],\n",
      "        [-0.00105286, -0.00671387, -0.0128784, ..., 0.0167236,\n",
      "         -0.00171661, -0.00561523],\n",
      "        [-0.0114746, 0.0111694, 0.00147247, ..., -0.00106812,\n",
      "         -0.00210571, 0.0180664]],\n",
      "\n",
      "       [[0.00210571, -0.0115356, 0.00274658, ..., -0.015564, 0.0112915,\n",
      "         -0.0125732],\n",
      "        [0.000137329, -0.00231934, -0.00793457, ..., -0.00643921,\n",
      "         0.00191498, -0.012085],\n",
      "        [0.0030365, 0.00283813, 0.0011673, ..., -0.00515747, 0.00364685,\n",
      "         -0.000530243],\n",
      "        ...,\n",
      "        [0.0164795, 0.00161743, -0.000476837, ..., -0.00114441,\n",
      "         -0.0203857, -0.0212402],\n",
      "        [0.000583649, -0.00276184, -0.0110474, ..., 0.0214844,\n",
      "         -0.00335693, 0.0120239],\n",
      "        [-0.0114746, 0.0114136, 0.010437, ..., -0.00500488,\n",
      "         -0.000526428, -0.00185394]],\n",
      "\n",
      "       [[0.0120239, -0.00238037, 0.00982666, ..., 0.0159912, -0.0158691,\n",
      "         0.00811768],\n",
      "        [-0.0144043, 0.0202637, 0.012207, ..., -0.0170898, -0.0123901,\n",
      "         -0.00552368],\n",
      "        [0.00233459, 0.00476074, 0.0198975, ..., 0.0172119, 0.0131836,\n",
      "         -0.0192871],\n",
      "        ...,\n",
      "        [-0.0111694, 0.00512695, -0.0018692, ..., 0.0108643, 0.00346375,\n",
      "         -0.00579834],\n",
      "        [0.00411987, -0.00221252, -0.00817871, ..., -0.0124512,\n",
      "         -0.0184326, -0.000595093],\n",
      "        [-0.00717163, -0.00357056, 0.00497437, ..., 0.0014801,\n",
      "         -0.0332031, 0.0133667]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.0037384, 0.00805664, 0.0146484, ..., -0.0336914, -0.0101318,\n",
      "         0.0145264],\n",
      "        [0.0065918, 0.00102234, 0.00787354, ..., 0.0292969, 0.00318909,\n",
      "         -0.026001],\n",
      "        [0.00370789, -0.0174561, 0.0145264, ..., -0.00349426, 0.0120239,\n",
      "         0.00891113],\n",
      "        ...,\n",
      "        [0.00775146, -0.000371933, 0.00708008, ..., -0.0245361,\n",
      "         0.0407715, 0.000526428],\n",
      "        [-0.0151978, -0.00259399, -0.000728607, ..., -0.00921631,\n",
      "         0.00309753, -0.020752],\n",
      "        [-0.0022583, 0.00775146, 0.00265503, ..., -0.0101318,\n",
      "         -0.00946045, -0.0161133]],\n",
      "\n",
      "       [[-0.000142097, 0.00286865, 0.0126343, ..., 0.00439453,\n",
      "         -0.00357056, -0.00172424],\n",
      "        [-0.00817871, 0.00518799, 0.0106201, ..., 0.0177002, 0.0157471,\n",
      "         -0.00131226],\n",
      "        [-0.00982666, -0.00878906, -0.000457764, ..., -0.0108032,\n",
      "         0.0159912, -0.0102539],\n",
      "        ...,\n",
      "        [0.0140381, 0.00546265, -0.0078125, ..., -0.00714111,\n",
      "         0.00534058, 0.00708008],\n",
      "        [0.00506592, 0.00424194, 0.000736237, ..., -0.00976562,\n",
      "         0.00735474, -0.0100708],\n",
      "        [-0.0022583, 0.0030365, 0.0107422, ..., 0.0125122, 0.0181885,\n",
      "         -0.0268555]],\n",
      "\n",
      "       [[-0.00994873, 0.00778198, -0.00534058, ..., 0.0120239,\n",
      "         -0.0119629, 0.0136108],\n",
      "        [0.00473022, -0.0127563, -0.0032196, ..., 0.00166321,\n",
      "         0.00338745, -0.00108337],\n",
      "        [-0.00159454, -0.00379944, 0.00769043, ..., -0.00294495,\n",
      "         -0.00369263, -0.00213623],\n",
      "        ...,\n",
      "        [0.0016098, 0.00952148, -0.0192871, ..., 0.00509644,\n",
      "         -0.00189972, 0.00692749],\n",
      "        [-0.00463867, 0.0123901, 0.00454712, ..., 0.0108643, 0.00964355,\n",
      "         0.00616455],\n",
      "        [0.00570679, -0.00354004, -0.00726318, ..., 0.00726318,\n",
      "         0.00011158, 0.00439453]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00238037, 0.015625, -0.00811768, ..., 0.00692749,\n",
      "         0.00759888, 0.00279236],\n",
      "        [-0.0115967, -0.00695801, -0.0098877, ..., 0.00476074,\n",
      "         -0.000191689, 0.0125732],\n",
      "        [0.00698853, -0.00994873, 0.00366211, ..., -0.00364685,\n",
      "         0.000926971, 0.0032959],\n",
      "        ...,\n",
      "        [0.000195503, -0.0105591, -0.00463867, ..., 0.00469971,\n",
      "         -0.00671387, -0.00759888],\n",
      "        [0.00285339, 0.0129395, -0.00497437, ..., -0.00182343,\n",
      "         -0.00216675, -0.0067749],\n",
      "        [0.0137329, 0.00518799, 0.00325012, ..., 0.0101929, -0.00056839,\n",
      "         0.000640869]],\n",
      "\n",
      "       [[-0.00704956, 0.0164795, -0.0167236, ..., -0.0130005,\n",
      "         -0.00579834, 0.00747681],\n",
      "        [0.0128784, -0.00267029, 0.00619507, ..., 0.000946045,\n",
      "         -0.0016861, 0.00427246],\n",
      "        [-0.000858307, 0.00601196, -0.0013504, ..., -0.00741577,\n",
      "         -0.00927734, 0.0115967],\n",
      "        ...,\n",
      "        [0.00982666, -0.000402451, 0.0098877, ..., 0.00891113,\n",
      "         0.00564575, -0.0050354],\n",
      "        [-0.00830078, -0.00175476, 0.00276184, ..., 0.00292969,\n",
      "         -0.0109863, 0.00405884],\n",
      "        [0.00175476, -0.0106812, -0.00378418, ..., 6.19888e-05,\n",
      "         -0.00361633, 0.0106201]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00424194, 0.00421143, -0.00646973, ..., -0.00610352,\n",
      "        -0.00107574, 0.00671387],\n",
      "       [0.00817871, 0.00123596, 0.00230408, ..., 0.00741577, -0.00878906,\n",
      "        0.00331116],\n",
      "       [-0.012085, -0.00415039, -0.0150146, ..., 0.00367737, -0.00738525,\n",
      "        -0.0032196],\n",
      "       ...,\n",
      "       [-0.00762939, 0.0129395, -0.0129395, ..., 0.00970459, 0.0116577,\n",
      "        0.00994873],\n",
      "       [-0.00241089, -0.000701904, 0.00732422, ..., 0.00280762,\n",
      "        0.000246048, 0.00210571],\n",
      "       [0.00576782, -0.00817871, 0.0120239, ..., -0.00363159, 0.00442505,\n",
      "        -0.00546265]], dtype=bfloat16), a=Array([[-0.01076485, -0.01254259,  0.00719575, ..., -0.01088936,\n",
      "         0.02172294,  0.00355693],\n",
      "       [-0.00358216, -0.01947643, -0.00234379, ..., -0.00571739,\n",
      "         0.02209909,  0.01588861]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.36719, 1.41406, 1.35938, ..., 1.39062, 1.60938, 1.26562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.46875, 2.42188, 2.48438, ..., 2.34375, 2.53125, 2.3125],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.443359, 0.570312, 0.347656, ..., 0.453125, 0.388672, 0.5625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.160156, 0.269531, 0.191406, ..., 0.158203, 0.11377, 0.259766],      dtype=bfloat16)}}, 'layer_19': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00750732, -0.0223389, -0.0175781, ..., 0.00497437,\n",
      "         -0.00921631, 0.00454712],\n",
      "        [0.00891113, -0.00183868, 0.00268555, ..., 0.00430298,\n",
      "         -0.000682831, -0.0246582],\n",
      "        [-0.00296021, 0.0268555, -0.00227356, ..., 2.11e-05,\n",
      "         -0.00108337, -0.0115967],\n",
      "        ...,\n",
      "        [0.00183868, 0.0186768, 0.0125122, ..., 0.00291443, 0.00198364,\n",
      "         0.0100098],\n",
      "        [0.0014267, -0.00778198, 0.0117188, ..., -0.0055542,\n",
      "         -0.00970459, 0.00402832],\n",
      "        [0.000923157, 0.0194092, -0.0078125, ..., -0.00656128,\n",
      "         -0.0098877, 0.0175781]],\n",
      "\n",
      "       [[-0.0230713, 0.00787354, 0.00418091, ..., -0.0014267,\n",
      "         -0.0128784, 0.0206299],\n",
      "        [-0.0334473, -0.0140381, -0.00408936, ..., 0.00376892,\n",
      "         -0.00482178, -0.0142822],\n",
      "        [0.0122681, -0.00680542, 0.00732422, ..., -0.0112305,\n",
      "         -0.0130615, -0.00598145],\n",
      "        ...,\n",
      "        [0.0183105, -0.00396729, -0.00860596, ..., -0.00396729,\n",
      "         0.00643921, -0.00121307],\n",
      "        [0.0117798, -0.0212402, -0.0203857, ..., -0.00491333,\n",
      "         0.00136566, 0.0106201],\n",
      "        [-0.0255127, 0.000686646, 0.00723267, ..., -0.00125122,\n",
      "         -0.00231934, -0.0175781]],\n",
      "\n",
      "       [[0.02771, -0.00946045, 0.00805664, ..., -0.0241699, 0.010437,\n",
      "         0.0202637],\n",
      "        [0.00120544, 0.0100098, -0.0168457, ..., 0.00753784, -0.0117188,\n",
      "         -0.0157471],\n",
      "        [-0.00891113, 0.00213623, 0.00683594, ..., -0.00069809,\n",
      "         -0.00469971, 0.0050354],\n",
      "        ...,\n",
      "        [0.00230408, 0.00958252, -0.000648499, ..., 0.00558472,\n",
      "         0.0299072, 0.00866699],\n",
      "        [0.00787354, -0.00708008, -0.0201416, ..., -0.000511169,\n",
      "         -0.00952148, -0.019165],\n",
      "        [-0.00037384, 0.0161133, -0.00952148, ..., -0.012207,\n",
      "         -0.0179443, 0.00561523]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.019165, -0.00248718, 0.00157166, ..., -0.0025177, 0.0145874,\n",
      "         -0.00315857],\n",
      "        [-0.0236816, -0.0134888, 0.0142212, ..., 0.00695801,\n",
      "         -0.00848389, -0.00891113],\n",
      "        [-0.000518799, -0.00393677, 0.0213623, ..., 0.0167236,\n",
      "         -0.010437, -0.00561523],\n",
      "        ...,\n",
      "        [0.0126343, 0.00306702, 0.0200195, ..., -0.00909424, 0.0136108,\n",
      "         -0.0109253],\n",
      "        [-0.000797272, -0.00427246, -0.00860596, ..., -0.00491333,\n",
      "         0.00201416, 0.0145264],\n",
      "        [0.00671387, -0.0174561, -0.0134277, ..., -0.00836182,\n",
      "         -0.0174561, -0.0187988]],\n",
      "\n",
      "       [[0.000854492, -0.0142822, -0.0130615, ..., -0.000839233,\n",
      "         -0.00363159, -0.00866699],\n",
      "        [-0.00668335, -0.00921631, 0.0113525, ..., -0.006073,\n",
      "         -9.71556e-06, 0.0032959],\n",
      "        [0.0149536, 0.00120544, 0.00325012, ..., -0.0109863,\n",
      "         -0.00775146, -0.000915527],\n",
      "        ...,\n",
      "        [-0.0294189, 0.0045166, -0.0039978, ..., -0.00343323,\n",
      "         0.00634766, -0.00720215],\n",
      "        [0.00939941, -0.00162506, 0.0154419, ..., -0.000239372,\n",
      "         -0.010437, 6.19888e-05],\n",
      "        [0.00982666, 0.0112915, 0.00579834, ..., 8.58307e-05,\n",
      "         -0.0090332, 0.00262451]],\n",
      "\n",
      "       [[0.00340271, 0.00123596, 0.0136108, ..., 0.00515747, 0.00390625,\n",
      "         0.00811768],\n",
      "        [0.0253906, -0.0181885, -0.00634766, ..., -0.00112152,\n",
      "         0.0078125, -0.00579834],\n",
      "        [-0.0144653, -0.0142822, -0.00509644, ..., 0.0209961,\n",
      "         0.00482178, -0.0131836],\n",
      "        ...,\n",
      "        [0.0110474, -0.0105591, 0.00842285, ..., 0.0001688, 0.0119019,\n",
      "         -0.00836182],\n",
      "        [-0.0113525, -0.00646973, -0.0157471, ..., -0.0179443,\n",
      "         -0.00201416, 0.0198975],\n",
      "        [0.00408936, 0.00482178, 0.00363159, ..., 0.00267029, 0.013916,\n",
      "         -0.0098877]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00921631, 0.0206299, 0.00215149, ..., -0.00518799,\n",
      "          -0.0263672, 0.00195312],\n",
      "         [0.00430298, 0.00476074, -0.00124359, ..., -0.00842285,\n",
      "          0.0212402, -0.00393677],\n",
      "         [-0.00309753, 0.0020752, 0.00312805, ..., 0.00291443,\n",
      "          -0.00753784, -0.000436783],\n",
      "         ...,\n",
      "         [0.00270081, 0.00358582, 0.00228882, ..., -0.0151367,\n",
      "          -0.00280762, 0.00836182],\n",
      "         [-0.00521851, -0.0103149, 0.00390625, ..., 0.000900269,\n",
      "          0.00111389, -0.00390625],\n",
      "         [0.000724792, 0.00375366, 0.00372314, ..., 0.00518799,\n",
      "          -0.0169678, 0.00215149]],\n",
      "\n",
      "        [[-0.0113525, 0.00367737, -0.00192261, ..., -0.0162354,\n",
      "          -0.0170898, 0.00558472],\n",
      "         [-0.0117798, -0.00976562, 0.00274658, ..., 0.0106812,\n",
      "          0.0018158, 0.00946045],\n",
      "         [0.00133514, 0.00244141, -0.000157356, ..., -0.00209045,\n",
      "          0.0181885, 0.00482178],\n",
      "         ...,\n",
      "         [0.000128746, 0.0057373, -0.0119019, ..., -0.00198364,\n",
      "          0.00161743, 0.000211716],\n",
      "         [0.00288391, 0.010498, 0.0109253, ..., 0.00361633,\n",
      "          -0.00427246, -0.0189209],\n",
      "         [0.00482178, -0.00268555, -0.0106201, ..., 0.0150146,\n",
      "          -0.00662231, 0.015564]],\n",
      "\n",
      "        [[-0.006073, -0.00389099, -0.0109863, ..., 0.0114746,\n",
      "          0.0290527, 0.00308228],\n",
      "         [-0.00714111, -0.00933838, 0.00250244, ..., 0.00927734,\n",
      "          -0.00460815, 0.0336914],\n",
      "         [0.0037384, -0.00704956, -0.000667572, ..., -0.0223389,\n",
      "          0.00717163, -0.0118408],\n",
      "         ...,\n",
      "         [0.00149536, 0.00405884, -0.00518799, ..., 0.00567627,\n",
      "          0.0249023, 0.00860596],\n",
      "         [-0.00369263, -0.00213623, 0.0115967, ..., 0.000896454,\n",
      "          0.00473022, -0.00506592],\n",
      "         [-0.00436401, -4.14848e-05, -0.000850677, ..., 0.00485229,\n",
      "          0.019043, -0.00164795]],\n",
      "\n",
      "        [[-0.00683594, -0.0154419, -0.0166016, ..., -0.0126953,\n",
      "          0.0152588, 0.0168457],\n",
      "         [-0.00628662, 0.00741577, -0.00775146, ..., -0.00891113,\n",
      "          0.0134888, -0.000356674],\n",
      "         [-0.0140991, 0.00769043, -0.00634766, ..., -0.022583,\n",
      "          -0.00188446, 0.00717163],\n",
      "         ...,\n",
      "         [-0.00686646, 0.00588989, -0.0157471, ..., 0.00735474,\n",
      "          -0.00946045, 0.00619507],\n",
      "         [0.0032959, 0.0149536, -0.00650024, ..., 0.0142212,\n",
      "          -0.00466919, 0.00964355],\n",
      "         [-0.00056076, -0.0213623, -0.0270996, ..., -0.00506592,\n",
      "          -0.00595093, -0.0115356]]],\n",
      "\n",
      "\n",
      "       [[[0.0098877, 0.00341797, -0.00494385, ..., -0.0136108,\n",
      "          -0.00245667, 0.0106812],\n",
      "         [0.00488281, 0.00494385, -0.00891113, ..., -0.00248718,\n",
      "          -0.0136108, -0.0143433],\n",
      "         [0.000720978, -0.0157471, -0.00358582, ..., -0.00759888,\n",
      "          0.0118408, -0.00247192],\n",
      "         ...,\n",
      "         [0.00402832, 0.0101318, 0.0134888, ..., -0.00549316,\n",
      "          0.0167236, 0.00034523],\n",
      "         [-0.006073, 0.00121307, -0.0177002, ..., 0.00964355,\n",
      "          -0.0117798, -0.0143433],\n",
      "         [-0.00114441, -0.00268555, -0.00585938, ..., -0.00759888,\n",
      "          -0.0137329, -0.0169678]],\n",
      "\n",
      "        [[-0.00442505, -0.00340271, 0.00190735, ..., 0.00132751,\n",
      "          -0.000686646, -0.0132446],\n",
      "         [-0.00126648, 0.0126343, 0.0147095, ..., 0.00823975,\n",
      "          0.0126953, -0.00332642],\n",
      "         [0.0010376, 0.0146484, 0.000629425, ..., -0.00909424,\n",
      "          -0.00341797, 0.00352478],\n",
      "         ...,\n",
      "         [-0.012207, -0.00958252, -0.00300598, ..., 0.00927734,\n",
      "          0.0019989, -0.00209045],\n",
      "         [-0.0184326, 0.0136719, 0.0249023, ..., 0.00527954,\n",
      "          -0.00811768, 0.0038147],\n",
      "         [-3.47197e-06, 0.00540161, 0.00244141, ..., -0.000724792,\n",
      "          0.0151978, 0.00268555]],\n",
      "\n",
      "        [[-0.0256348, -0.00891113, -0.00276184, ..., 0.0212402,\n",
      "          0.00588989, 0.00598145],\n",
      "         [0.00338745, 0.010498, -0.00102234, ..., 0.00509644,\n",
      "          -0.0025177, -0.0112305],\n",
      "         [0.00186157, -0.00689697, 0.0106201, ..., 0.0286865,\n",
      "          -0.00196838, -0.0162354],\n",
      "         ...,\n",
      "         [-0.0125732, 0.00186157, 0.0172119, ..., -0.0107422,\n",
      "          -0.000385284, 0.00527954],\n",
      "         [0.00242615, -0.00628662, -0.0142822, ..., 0.0030365,\n",
      "          -0.00219727, -0.0181885],\n",
      "         [-0.00393677, -0.0184326, -0.00939941, ..., -0.00817871,\n",
      "          0.000299454, -0.0128174]],\n",
      "\n",
      "        [[0.00524902, 0.00946045, 0.0100708, ..., -0.010498,\n",
      "          -0.00190735, 0.0139771],\n",
      "         [-0.0159912, -0.0268555, -0.00631714, ..., -0.00671387,\n",
      "          -0.00335693, -0.00216675],\n",
      "         [-0.00411987, 0.00891113, -0.00367737, ..., 0.00582886,\n",
      "          0.000226021, 0.0114746],\n",
      "         ...,\n",
      "         [-0.00106049, -0.00830078, 0.0205078, ..., 0.00805664,\n",
      "          -0.017334, -4.76837e-05],\n",
      "         [-0.00527954, 0.0123291, 0.00518799, ..., 0.00872803,\n",
      "          -0.0253906, 0.00793457],\n",
      "         [0.0115356, -4.22001e-05, -0.0114136, ..., -0.0078125,\n",
      "          0.0219727, -0.0050354]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00717163, 0.00741577, -0.0159912, ..., 0.013855, -0.0158691,\n",
      "         -0.0354004],\n",
      "        [-0.00299072, 0.000965118, 0.00640869, ..., -0.00445557,\n",
      "         0.012207, -0.0200195],\n",
      "        [0.00598145, -0.00518799, 0.0100098, ..., -0.0202637,\n",
      "         0.000105858, 0.000583649],\n",
      "        ...,\n",
      "        [-0.00860596, -0.00970459, 0.006073, ..., -0.0253906,\n",
      "         -0.00891113, 0.00357056],\n",
      "        [0.015564, 0.0088501, 0.0027771, ..., -0.0115356, 0.00897217,\n",
      "         -0.0368652],\n",
      "        [-0.0123901, -0.00421143, -0.00506592, ..., 0.0144043,\n",
      "         0.00430298, 0.0507812]],\n",
      "\n",
      "       [[0.00817871, 0.00683594, -0.0252686, ..., 0.0419922, -0.0166016,\n",
      "         0.00558472],\n",
      "        [-0.00704956, -0.00537109, 0.00127411, ..., -0.00352478,\n",
      "         0.00854492, -0.00546265],\n",
      "        [-0.0117188, -0.00349426, 0.0122681, ..., -0.0388184,\n",
      "         -0.0126343, 0.0195312],\n",
      "        ...,\n",
      "        [-0.0159912, 0.00515747, -4.33922e-05, ..., -0.0228271,\n",
      "         -0.00692749, -0.00964355],\n",
      "        [0.0126343, -0.00674438, 0.003479, ..., -0.00386047,\n",
      "         -0.000272751, 0.00242615],\n",
      "        [-0.0130005, 0.00817871, -0.00588989, ..., 0.012085, 0.0123291,\n",
      "         0.0144043]],\n",
      "\n",
      "       [[-0.00267029, -0.00860596, 0.00436401, ..., -0.0250244,\n",
      "         -0.0437012, -0.0180664],\n",
      "        [0.00735474, -0.00430298, 0.000808716, ..., -0.032959,\n",
      "         -0.0112915, 0.00439453],\n",
      "        [-0.00506592, -0.00196838, -0.006073, ..., 0.0126343,\n",
      "         -0.0119629, -0.00946045],\n",
      "        ...,\n",
      "        [0.000720978, 0.0114746, 0.0157471, ..., -0.00830078,\n",
      "         -0.00680542, 0.000366211],\n",
      "        [0.00720215, 0.00958252, -0.00182343, ..., 0.00976562,\n",
      "         -0.0122681, -0.00778198],\n",
      "        [-0.00317383, 0.0100098, -0.00448608, ..., -0.0146484,\n",
      "         -0.00628662, 0.0444336]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00149536, -0.00405884, 0.00205994, ..., -0.00302124,\n",
      "         -0.0045166, -0.0131226],\n",
      "        [0.00567627, 0.00213623, -0.00491333, ..., 0.00738525,\n",
      "         -0.00469971, 0.00866699],\n",
      "        [-0.0062561, 0.000370026, -0.00056839, ..., 0.00239563,\n",
      "         0.00653076, 0.00778198],\n",
      "        ...,\n",
      "        [-0.00759888, -0.00268555, -2.43187e-05, ..., 0.00592041,\n",
      "         0.0224609, -0.00331116],\n",
      "        [-0.00445557, -0.00686646, -0.000709534, ..., -0.00196838,\n",
      "         -0.0174561, -0.00328064],\n",
      "        [0.00121307, -0.00436401, 0.00656128, ..., 0.026123, 0.0209961,\n",
      "         -0.00188446]],\n",
      "\n",
      "       [[-0.00138855, -0.006073, 0.0102539, ..., -0.0234375, 0.0108032,\n",
      "         0.0334473],\n",
      "        [-0.00357056, 0.0055542, -0.00106812, ..., -0.00939941,\n",
      "         -0.00141144, 0.00424194],\n",
      "        [-0.00836182, -2.2769e-05, -0.00582886, ..., -8.63075e-05,\n",
      "         -0.00769043, 0.00253296],\n",
      "        ...,\n",
      "        [0.00805664, -0.000648499, -0.012085, ..., 0.0216064,\n",
      "         -0.0227051, 0.00915527],\n",
      "        [-0.0198975, 0.0181885, -0.00143433, ..., -0.0161133,\n",
      "         -0.00114441, 0.0127563],\n",
      "        [-0.00396729, 0.0050354, 0.000537872, ..., 0.0181885,\n",
      "         0.00408936, 0.0105591]],\n",
      "\n",
      "       [[0.00564575, -0.026123, -0.00163269, ..., 0.0200195,\n",
      "         -0.00176239, 0.0251465],\n",
      "        [0.00323486, -0.0239258, 0.00190735, ..., -0.00683594,\n",
      "         -0.0100708, 0.0280762],\n",
      "        [0.00552368, 0.00723267, 0.00646973, ..., 0.0144043,\n",
      "         -0.00909424, -0.0200195],\n",
      "        ...,\n",
      "        [0.00148773, -0.0244141, 0.000946045, ..., 0.00328064,\n",
      "         0.0127563, -0.0107422],\n",
      "        [-0.0112305, 0.0062561, -0.0102539, ..., 0.00263977, 0.0112305,\n",
      "         0.00454712],\n",
      "        [-0.00341797, -0.0139771, -0.00537109, ..., 0.0198975,\n",
      "         0.00445557, 0.0258789]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00408936, 0.00610352, -0.00308228, ..., 0.00424194,\n",
      "         -0.00604248, -0.0163574],\n",
      "        [0.00424194, -0.00402832, 0.0131226, ..., 0.00219727,\n",
      "         -0.00704956, -0.00805664],\n",
      "        [0.00302124, 0.00546265, -0.00137329, ..., -0.00292969,\n",
      "         0.00302124, 0.00130463],\n",
      "        ...,\n",
      "        [-0.00306702, 0.000694275, -0.00509644, ..., -0.0114746,\n",
      "         -0.0107422, 0.00115967],\n",
      "        [-0.0133667, 0.00823975, -0.00133514, ..., -0.00171661,\n",
      "         -0.00386047, 0.0274658],\n",
      "        [0.000307083, 0.00482178, 0.00187683, ..., -0.00891113,\n",
      "         0.00588989, 0.00698853]],\n",
      "\n",
      "       [[-0.0153198, -0.0194092, 0.00585938, ..., 0.00134277,\n",
      "         0.00314331, 0.00427246],\n",
      "        [0.00186157, -0.00909424, 0.00546265, ..., 0.00163269,\n",
      "         -0.0128174, 0.00549316],\n",
      "        [0.00204468, 0.0125732, 0.00592041, ..., -0.0109253, 0.0039978,\n",
      "         -0.00170135],\n",
      "        ...,\n",
      "        [-0.00402832, -0.0131226, 0.0112305, ..., 0.00866699,\n",
      "         -0.0098877, -0.00506592],\n",
      "        [0.0174561, -0.00570679, -0.0114136, ..., -0.00241089,\n",
      "         0.0144653, 0.0130615],\n",
      "        [0.00147247, -0.00063324, -0.00390625, ..., -0.00576782,\n",
      "         0.0131226, -0.0062561]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.0167236, -0.00549316, 0.012085, ..., -0.000341415, 0.00144196,\n",
      "        0.00224304],\n",
      "       [-0.0109253, -0.00775146, -0.00131226, ..., -0.0147705,\n",
      "        -0.0090332, -0.0127563],\n",
      "       [0.00320435, 0.00165558, -0.00338745, ..., -0.00567627, 0.0043335,\n",
      "        0.00250244],\n",
      "       ...,\n",
      "       [0.00169373, -2.93255e-05, 0.000782013, ..., -0.00326538,\n",
      "        -0.00546265, -0.0108032],\n",
      "       [-0.000270844, 0.00552368, 0.00241089, ..., -0.00364685,\n",
      "        0.0109863, 0.00244141],\n",
      "       [0.00204468, 0.00463867, 0.0017395, ..., -0.00337219,\n",
      "        -0.000480652, -1.07288e-05]], dtype=bfloat16), a=Array([[-0.01803358, -0.00303927,  0.00691553, ...,  0.00371117,\n",
      "         0.00372419,  0.00021878],\n",
      "       [ 0.00078573, -0.00061509, -0.0201269 , ...,  0.01225177,\n",
      "         0.00519481,  0.00182117]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.25, 1.07812, 1.29688, ..., 1.35156, 1.29688, 1.14062], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.64062, 2.625, 2.73438, ..., 2.51562, 2.625, 2.3125], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.414062, 0.59375, 0.5, ..., 0.451172, 0.375, 0.554688], dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.175781, 0.236328, 0.203125, ..., 0.168945, 0.128906, 0.248047],      dtype=bfloat16)}}, 'layer_2': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0179443, -0.00765991, 0.000134468, ..., 0.00238037,\n",
      "         0.00204468, -0.00454712],\n",
      "        [-0.0106812, 0.0088501, -0.0234375, ..., 0.0123901, 0.0126953,\n",
      "         -0.00958252],\n",
      "        [-0.0106812, -0.00132751, 0.0142822, ..., 0.00848389,\n",
      "         0.00247192, -0.00479126],\n",
      "        ...,\n",
      "        [0.000219345, -0.00680542, -0.00891113, ..., 0.0174561,\n",
      "         -0.00689697, -0.00141144],\n",
      "        [0.00671387, 0.0116577, 0.0183105, ..., 0.0170898, -0.00218201,\n",
      "         0.00595093],\n",
      "        [-0.00133514, 0.00509644, 0.000167847, ..., 0.0203857,\n",
      "         0.00964355, 0.0043335]],\n",
      "\n",
      "       [[0.00111389, -0.0143433, -0.00133514, ..., -0.00105286,\n",
      "         -0.000720978, -0.00686646],\n",
      "        [0.0197754, 0.00570679, 0.00402832, ..., 0.0039978, 0.00854492,\n",
      "         -0.0187988],\n",
      "        [-0.00769043, -0.00308228, -0.0142212, ..., 0.024292, 0.0110474,\n",
      "         -0.00297546],\n",
      "        ...,\n",
      "        [-0.00994873, -0.0161133, -0.000617981, ..., 0.0200195,\n",
      "         -0.00273132, 0.00227356],\n",
      "        [0.0123291, 0.0071106, -0.0158691, ..., -0.00842285,\n",
      "         -0.00174713, -0.00717163],\n",
      "        [-0.0236816, -0.00167084, -0.0101929, ..., -0.0045166,\n",
      "         0.0162354, -0.00723267]],\n",
      "\n",
      "       [[-0.00136566, 0.000253677, 0.0108032, ..., -0.000656128,\n",
      "         0.0194092, -0.001091],\n",
      "        [0.0250244, 0.00592041, 0.0168457, ..., 0.0263672, -0.0256348,\n",
      "         0.0163574],\n",
      "        [-0.00512695, 0.0201416, 0.000267029, ..., -0.0102539,\n",
      "         -0.0161133, -5.50747e-05],\n",
      "        ...,\n",
      "        [0.00167847, -0.0090332, -0.022583, ..., -0.00350952, 0.0118408,\n",
      "         0.015625],\n",
      "        [-0.00939941, 0.00350952, -0.00263977, ..., 0.0045166,\n",
      "         -0.00216675, -0.00811768],\n",
      "        [0.0124512, -0.00726318, -0.00292969, ..., 0.020752, -0.0133057,\n",
      "         -0.00280762]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00811768, -0.0158691, 0.0117188, ..., -0.0120239, 0.0187988,\n",
      "         0.00613403],\n",
      "        [-0.00213623, 0.00958252, -0.034668, ..., -0.00579834,\n",
      "         -0.0167236, 0.00567627],\n",
      "        [-0.0297852, 0.0114746, -0.00305176, ..., 0.0072937, 0.00970459,\n",
      "         -0.00317383],\n",
      "        ...,\n",
      "        [-0.00282288, -0.00491333, -0.00424194, ..., 0.00512695,\n",
      "         0.0118408, 0.00564575],\n",
      "        [0.000312805, 0.000450134, 0.00341797, ..., 0.0045166,\n",
      "         -0.00375366, -0.00592041],\n",
      "        [0.00289917, 0.00671387, 0.00159454, ..., 0.00872803,\n",
      "         0.00793457, 0.00540161]],\n",
      "\n",
      "       [[0.0140991, -0.013855, -0.006073, ..., -0.026123, -0.00082016,\n",
      "         -0.00157928],\n",
      "        [0.000160217, 0.00915527, -0.00546265, ..., 0.0102539,\n",
      "         0.0015564, -0.0117798],\n",
      "        [-0.00726318, -0.0314941, -0.00228882, ..., -0.0197754,\n",
      "         -0.00352478, 0.0211182],\n",
      "        ...,\n",
      "        [0.00778198, -0.0045166, -0.00582886, ..., -0.000717163,\n",
      "         -0.00805664, -0.0123901],\n",
      "        [0.013916, 0.000169754, -0.00222778, ..., -0.00921631,\n",
      "         0.0113525, 0.00534058],\n",
      "        [-0.00775146, 0.00418091, 0.00970459, ..., 0.00445557,\n",
      "         -0.00463867, 0.00619507]],\n",
      "\n",
      "       [[0.00088501, 0.00958252, 0.0150146, ..., 0.0014267, -0.0100708,\n",
      "         -0.0128784],\n",
      "        [-0.0090332, -0.00689697, -0.0128784, ..., 0.0235596,\n",
      "         -0.0302734, -0.00476074],\n",
      "        [0.00454712, -0.0140991, 0.0037384, ..., -0.00149536,\n",
      "         -0.0168457, -0.000778198],\n",
      "        ...,\n",
      "        [0.00149536, 0.012085, 0.00436401, ..., 0.0209961, -0.0344238,\n",
      "         -0.00540161],\n",
      "        [0.00958252, -0.013916, -0.0106201, ..., -0.0163574, 0.0125732,\n",
      "         0.0183105],\n",
      "        [-0.00463867, -0.00518799, 0.00701904, ..., 0.0148926,\n",
      "         0.00473022, 0.0151978]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00317383, 0.0146484, -0.0119019, ..., 0.0163574,\n",
      "          0.00218201, -0.0238037],\n",
      "         [-0.0131836, -0.0285645, -0.0101318, ..., -0.0187988,\n",
      "          0.0247803, 0.00741577],\n",
      "         [-8.10623e-05, -0.0163574, -0.00125122, ..., 0.00546265,\n",
      "          0.0110474, 0.0151367],\n",
      "         ...,\n",
      "         [0.000873566, 4.60148e-05, -0.0217285, ..., -0.0183105,\n",
      "          0.0057373, 0.0209961],\n",
      "         [0.0114136, -0.00701904, -0.010437, ..., 0.0124512,\n",
      "          -0.0120239, 0.000789642],\n",
      "         [0.00741577, 0.00585938, 0.0045166, ..., -0.00424194,\n",
      "          -0.0035553, -0.00512695]],\n",
      "\n",
      "        [[-0.000177383, -0.0206299, -0.00276184, ..., 0.00233459,\n",
      "          -2.75373e-05, 0.0181885],\n",
      "         [-0.00109863, 0.00592041, -0.00180054, ..., -0.0114136,\n",
      "          0.0125732, 0.0139771],\n",
      "         [-0.0189209, 0.00161743, 0.00823975, ..., 0.0109863,\n",
      "          0.0162354, 0.00524902],\n",
      "         ...,\n",
      "         [-0.00534058, 0.00367737, 0.00167847, ..., 0.0142212,\n",
      "          0.0127563, -0.026123],\n",
      "         [-0.0090332, 0.0167236, 0.00469971, ..., 0.0043335, 0.0157471,\n",
      "          0.00585938],\n",
      "         [0.00209045, -0.0098877, 0.00445557, ..., -0.0090332,\n",
      "          0.0163574, -0.0187988]],\n",
      "\n",
      "        [[-0.00112152, 0.0072937, 0.0142212, ..., -0.0181885,\n",
      "          -0.00263977, 0.0129395],\n",
      "         [-0.00442505, -0.00686646, 0.00753784, ..., -0.00135803,\n",
      "          0.0444336, -0.03125],\n",
      "         [-0.000184059, -0.00662231, -0.0131226, ..., 0.0170898,\n",
      "          0.00424194, 0.0354004],\n",
      "         ...,\n",
      "         [-0.00326538, -0.0181885, -0.00668335, ..., 0.000862122,\n",
      "          -0.0148926, -0.0122681],\n",
      "         [0.0164795, -0.0071106, 0.0222168, ..., 0.0114746,\n",
      "          -0.00793457, -0.0153198],\n",
      "         [-0.00024128, 0.0114136, 0.0016861, ..., -0.0119019,\n",
      "          0.0219727, 0.0246582]],\n",
      "\n",
      "        [[-0.0124512, 0.000232697, -0.0169678, ..., 0.0017395,\n",
      "          -0.0157471, 0.0108032],\n",
      "         [0.000946045, 0.00964355, 0.00741577, ..., -0.0164795,\n",
      "          0.0189209, -0.00811768],\n",
      "         [-0.00176239, -0.0113525, -0.0126343, ..., 0.00112915,\n",
      "          -0.00159454, 0.00421143],\n",
      "         ...,\n",
      "         [-0.00218201, 0.00897217, 0.019043, ..., 0.00494385,\n",
      "          -0.00671387, -0.00631714],\n",
      "         [0.0314941, 0.00308228, 0.0150757, ..., -0.00634766,\n",
      "          -0.00476074, 0.000198364],\n",
      "         [-0.000244141, -0.00769043, 0.0166016, ..., 0.0150757,\n",
      "          0.000117302, 0.0125732]]],\n",
      "\n",
      "\n",
      "       [[[0.00939941, -0.00668335, 0.00512695, ..., 0.026123,\n",
      "          0.000907898, -0.00689697],\n",
      "         [-0.00294495, -0.00588989, -0.00830078, ..., -0.00830078,\n",
      "          -0.00424194, 0.0011673],\n",
      "         [0.00393677, -0.00546265, -0.0140991, ..., 0.0030365,\n",
      "          0.0043335, 0.00424194],\n",
      "         ...,\n",
      "         [-0.0128174, 0.00543213, 0.0118408, ..., -0.0218506,\n",
      "          -0.0115967, -0.00680542],\n",
      "         [0.00247192, 0.00138092, 0.000991821, ..., 0.00285339,\n",
      "          0.00151062, 0.00128937],\n",
      "         [0.00149536, 0.00823975, -0.0127563, ..., 0.00714111,\n",
      "          -0.0018158, -0.00994873]],\n",
      "\n",
      "        [[-0.0107422, 0.0197754, -0.00994873, ..., 0.0108643,\n",
      "          -0.0131226, 0.0154419],\n",
      "         [-0.00282288, 0.0194092, 0.000267029, ..., -0.0172119,\n",
      "          -0.00628662, -0.0132446],\n",
      "         [-0.00215149, 0.0130005, -0.00698853, ..., -0.0356445,\n",
      "          0.00222778, -0.000827789],\n",
      "         ...,\n",
      "         [0.00150299, 0.00482178, -0.00112915, ..., -0.00270081,\n",
      "          0.0072937, -0.0163574],\n",
      "         [0.00442505, -0.0145264, 0.000972748, ..., 0.00219727,\n",
      "          -0.000226974, 0.0155029],\n",
      "         [0.0115356, 0.0198975, 0.00897217, ..., 0.00854492,\n",
      "          0.000968933, 0.00952148]],\n",
      "\n",
      "        [[0.00793457, 0.0072937, 0.0385742, ..., 0.000576019,\n",
      "          -0.00320435, -0.00297546],\n",
      "         [0.0134277, -0.0148926, -0.010498, ..., 0.0240479,\n",
      "          -0.00415039, 0.00674438],\n",
      "         [-0.0142822, 0.045166, 0.00131989, ..., 0.00375366,\n",
      "          -0.00270081, -0.00726318],\n",
      "         ...,\n",
      "         [0.00811768, 0.0101929, -0.0108032, ..., -0.0088501,\n",
      "          0.00227356, -0.0220947],\n",
      "         [-0.013855, -0.00115204, -0.00318909, ..., -0.00270081,\n",
      "          0.00259399, -0.00634766],\n",
      "         [-0.0055542, 0.00216675, -0.000564575, ..., -0.00726318,\n",
      "          0.00488281, -0.00448608]],\n",
      "\n",
      "        [[0.0108643, 0.00631714, -0.0090332, ..., -0.000185966,\n",
      "          -0.00836182, -0.0128784],\n",
      "         [0.00305176, 0.00872803, -0.015625, ..., 0.00147247,\n",
      "          0.00320435, 0.00358582],\n",
      "         [-0.00558472, 0.0101929, -0.00744629, ..., 0.0117798,\n",
      "          0.00189972, -0.010437],\n",
      "         ...,\n",
      "         [-0.00382996, 0.00151825, -0.00136566, ..., -0.00119019,\n",
      "          0.0107422, -0.0247803],\n",
      "         [0.0111694, 0.00308228, 0.00823975, ..., -0.0115967,\n",
      "          0.0103149, 0.00683594],\n",
      "         [0.0119019, -0.00286865, 0.00137329, ..., 0.00146484,\n",
      "          -0.0108643, 0.00393677]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00762939, 0.00537109, 0.00680542, ..., -0.00151062,\n",
      "         -0.0045166, 0.00384521],\n",
      "        [-0.00163269, 0.0178223, 0.00485229, ..., -0.0140991,\n",
      "         -0.0124512, -0.015564],\n",
      "        [0.00933838, 0.00933838, 0.00830078, ..., 0.00994873,\n",
      "         0.00111389, -0.00723267],\n",
      "        ...,\n",
      "        [0.00393677, -0.00708008, -0.00216675, ..., -0.00069046,\n",
      "         0.0120239, -0.0126343],\n",
      "        [0.0194092, 0.0162354, -0.0198975, ..., 0.00964355, 0.00637817,\n",
      "         0.00952148],\n",
      "        [-0.00178528, 0.0101929, 0.00196838, ..., 0.0148926,\n",
      "         -0.00357056, -0.0168457]],\n",
      "\n",
      "       [[-0.0115967, -0.0105591, -0.0062561, ..., 0.00162506,\n",
      "         -0.00147247, -0.0170898],\n",
      "        [0.00793457, 0.00741577, -0.0134888, ..., 0.0103149,\n",
      "         -0.00325012, -0.024292],\n",
      "        [-0.00221252, 0.0120239, -0.00276184, ..., -0.00994873,\n",
      "         -0.0014801, -0.0308838],\n",
      "        ...,\n",
      "        [0.0269775, -0.00262451, 0.00491333, ..., 0.0136108, -0.0018692,\n",
      "         0.0217285],\n",
      "        [4.55379e-05, 0.0183105, -0.0133667, ..., -0.0100098, -0.013916,\n",
      "         -0.00628662],\n",
      "        [-0.00811768, 0.0114746, -0.00119781, ..., 0.0055542,\n",
      "         -0.00695801, 0.0223389]],\n",
      "\n",
      "       [[0.000957489, -0.00418091, -0.00668335, ..., 0.0317383,\n",
      "         -0.0043335, -0.0205078],\n",
      "        [0.00946045, 0.00205994, -0.0088501, ..., -0.0112915, -0.036377,\n",
      "         -0.0269775],\n",
      "        [0.00191498, 0.00141907, -0.00389099, ..., -0.00387573,\n",
      "         -0.0551758, -0.00579834],\n",
      "        ...,\n",
      "        [0.032959, -0.0344238, 0.000368118, ..., 0.00228882, 0.0170898,\n",
      "         0.0473633],\n",
      "        [-0.0118408, 0.00308228, 0.00402832, ..., 0.00149536,\n",
      "         0.00720215, -0.00378418],\n",
      "        [-0.015564, 0.000793457, -0.00927734, ..., 0.00823975,\n",
      "         -0.00976562, 0.0291748]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00262451, 0.00811768, 0.00616455, ..., 0.0125732,\n",
      "         -0.00811768, 0.00958252],\n",
      "        [-0.00927734, 0.0133057, -0.00964355, ..., -0.0118408,\n",
      "         0.0152588, -0.000153542],\n",
      "        [0.00613403, 0.0196533, -0.0155029, ..., -0.0119629, 0.0103149,\n",
      "         -0.00189209],\n",
      "        ...,\n",
      "        [-0.0253906, 0.0341797, -0.0245361, ..., -0.00201416,\n",
      "         -0.00546265, 0.00292969],\n",
      "        [0.00292969, -0.0137329, 0.000843048, ..., -0.0150146,\n",
      "         0.00442505, -0.0133057],\n",
      "        [0.0194092, 0.0336914, -0.0177002, ..., 0.0111694, 0.0201416,\n",
      "         -0.00376892]],\n",
      "\n",
      "       [[-0.00613403, 0.0100098, 0.00494385, ..., -0.0246582,\n",
      "         0.00135803, -0.00994873],\n",
      "        [0.0118408, 0.00421143, -0.0289307, ..., 0.00334167, -0.0200195,\n",
      "         -0.0113525],\n",
      "        [-0.00866699, 0.0136108, -0.0145264, ..., 0.0213623, -0.0252686,\n",
      "         -0.00352478],\n",
      "        ...,\n",
      "        [0.00540161, 0.00131989, -0.00747681, ..., -0.00872803,\n",
      "         -0.000576019, 0.0038147],\n",
      "        [0.0202637, -0.0119019, -0.0235596, ..., 0.0157471, 0.00222778,\n",
      "         0.00823975],\n",
      "        [-0.00183868, -0.010498, -0.000139236, ..., 0.00161743,\n",
      "         0.0137329, -0.0134277]],\n",
      "\n",
      "       [[0.0012207, -0.00120544, 0.00518799, ..., 1.70469e-05,\n",
      "         -0.000579834, -0.00314331],\n",
      "        [0.00136566, 0.0100098, -0.00463867, ..., -0.00512695,\n",
      "         0.00680542, 0.00280762],\n",
      "        [0.00335693, 0.00387573, -0.00169373, ..., 0.0196533, 0.0123901,\n",
      "         -0.00244141],\n",
      "        ...,\n",
      "        [-0.00131226, 0.00933838, -0.00216675, ..., 0.00300598,\n",
      "         0.00160217, -0.0125732],\n",
      "        [0.00265503, -0.00692749, 0.00372314, ..., -0.00282288,\n",
      "         0.00897217, 0.00933838],\n",
      "        [-0.00265503, 0.00708008, 0.00205994, ..., 0.00891113,\n",
      "         -0.0111694, 0.0155029]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00469971, 0.0118408, 0.0032959, ..., -0.00427246, 0.0030365,\n",
      "         0.00741577],\n",
      "        [-0.00228882, -0.00170135, -0.00753784, ..., -0.0129395,\n",
      "         0.00726318, 0.00878906],\n",
      "        [-0.00695801, -0.0100708, -0.0103149, ..., 0.00460815,\n",
      "         -0.00244141, -0.00534058],\n",
      "        ...,\n",
      "        [-0.000804901, -2.63453e-05, -0.00242615, ..., -0.0120239,\n",
      "         -0.000541687, 0.00430298],\n",
      "        [0.0142212, -0.00415039, -0.00183868, ..., 0.012207,\n",
      "         -0.00463867, 0.0062561],\n",
      "        [0.00360107, -0.00897217, 0.0107422, ..., -0.0107422, 0.0098877,\n",
      "         -0.00570679]],\n",
      "\n",
      "       [[-0.00445557, 0.00024128, 0.00317383, ..., -0.00291443,\n",
      "         0.00273132, 0.00473022],\n",
      "        [-0.0113525, -0.000762939, 0.00344849, ..., 0.00653076,\n",
      "         0.0158691, 0.00405884],\n",
      "        [0.0032196, -0.0159912, -0.00386047, ..., 0.0144043,\n",
      "         -0.00350952, -0.00294495],\n",
      "        ...,\n",
      "        [0.00334167, -0.00285339, -0.00041008, ..., 0.0149536,\n",
      "         0.00204468, -0.00170898],\n",
      "        [-0.00137329, -0.00534058, 0.00860596, ..., -0.00408936,\n",
      "         0.00509644, -0.00466919],\n",
      "        [-0.00201416, -0.00982666, 0.00180817, ..., 0.00191498,\n",
      "         0.000337601, -0.00576782]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00933838, 0.00193024, -0.0123291, ..., 0.00848389, 0.0016098,\n",
      "        -0.0016098],\n",
      "       [-0.00610352, 0.00439453, -0.00933838, ..., -0.0180664, -0.012085,\n",
      "        -0.00595093],\n",
      "       [0.000587463, 0.000507355, 0.00582886, ..., 0.00244141,\n",
      "        -0.00236511, 0.00350952],\n",
      "       ...,\n",
      "       [0.000671387, 0.00939941, 0.00823975, ..., -0.00537109, 0.0020752,\n",
      "        -0.0136719],\n",
      "       [-0.00512695, 0.0159912, -0.00854492, ..., -0.0137329,\n",
      "        -0.000907898, -0.0090332],\n",
      "       [-0.0123291, -0.00537109, 0.010437, ..., 0.00189209, -0.0038147,\n",
      "        0.00291443]], dtype=bfloat16), a=Array([[-0.01155356,  0.00352542, -0.00475057, ...,  0.00461095,\n",
      "         0.00289454, -0.0215128 ],\n",
      "       [ 0.00688512, -0.00726845, -0.00535207, ...,  0.00995815,\n",
      "         0.00537037,  0.00453264]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.232422, -0.229492, -0.160156, ..., -0.414062, 0.0179443,\n",
      "       -0.265625], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.131836, 0.105469, 0.139648, ..., -0.141602, 0.326172, 0.135742],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.714844, 0.667969, 0.71875, ..., 1.07812, 0.300781, 0.515625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.5, 0.511719, 0.53125, ..., 0.941406, 0.00320435, 0.40625],      dtype=bfloat16)}}, 'layer_20': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00756836, -0.00601196, -0.00952148, ..., 0.0114136,\n",
      "         -0.00830078, -0.00546265],\n",
      "        [-0.00179291, -0.006073, -0.000801086, ..., 0.00212097,\n",
      "         -0.00817871, -0.00640869],\n",
      "        [-0.000724792, 0.0166016, -0.00154877, ..., -0.00344849,\n",
      "         0.019043, -0.0019455],\n",
      "        ...,\n",
      "        [0.00778198, -0.0098877, -0.00139618, ..., 0.0174561,\n",
      "         -0.0107422, 0.00497437],\n",
      "        [-0.00378418, -0.00352478, 0.00100708, ..., 0.0101929,\n",
      "         0.00653076, -0.0043335],\n",
      "        [-0.00352478, 0.00154877, 0.00714111, ..., 0.00291443,\n",
      "         -0.00872803, 0.0057373]],\n",
      "\n",
      "       [[-0.00158691, -0.00390625, 0.00430298, ..., 0.000968933,\n",
      "         -0.00189972, -0.00187683],\n",
      "        [0.00216675, 0.00302124, 0.0227051, ..., -0.0184326,\n",
      "         -0.00274658, -0.00227356],\n",
      "        [-0.0098877, -0.010498, 0.00138855, ..., -0.000701904,\n",
      "         0.0106201, 0.0136719],\n",
      "        ...,\n",
      "        [-0.00106049, -0.00154114, 0.00830078, ..., 0.000740051,\n",
      "         -0.00717163, -0.0022583],\n",
      "        [-0.00156403, -0.0141602, -0.00662231, ..., -0.00506592,\n",
      "         0.00717163, 0.00315857],\n",
      "        [0.00793457, 0.00494385, -0.00469971, ..., -0.0161133,\n",
      "         0.00656128, 0.0229492]],\n",
      "\n",
      "       [[-0.0123901, 0.00105286, 0.0206299, ..., -0.0088501, -0.0241699,\n",
      "         0.00653076],\n",
      "        [-0.00921631, 0.00191498, 0.0162354, ..., -0.0126343,\n",
      "         0.00164032, -0.00454712],\n",
      "        [0.00811768, 0.0183105, -0.019043, ..., -0.0131836, 0.0135498,\n",
      "         -0.0128784],\n",
      "        ...,\n",
      "        [-0.0146484, 0.0251465, -0.0205078, ..., 0.00202942,\n",
      "         -0.00106812, -0.00350952],\n",
      "        [-0.0142212, 0.0219727, 0.00280762, ..., 0.00970459, 0.00247192,\n",
      "         0.000272751],\n",
      "        [-0.00267029, -0.00494385, 0.0020752, ..., 0.00308228,\n",
      "         0.0141602, 0.00698853]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00662231, -0.00270081, -0.00424194, ..., 0.00332642,\n",
      "         -0.00848389, -0.0211182],\n",
      "        [-0.00775146, -0.0108032, -0.0155029, ..., -0.0222168,\n",
      "         0.0131836, -0.000682831],\n",
      "        [-0.000541687, 0.00866699, 0.0227051, ..., 0.00031662,\n",
      "         -0.019165, 0.00878906],\n",
      "        ...,\n",
      "        [0.0012207, -0.00328064, 0.0125732, ..., 0.0088501, -0.0136108,\n",
      "         0.00878906],\n",
      "        [0.00183868, 0.00396729, 0.00762939, ..., -0.00315857,\n",
      "         0.00187683, -0.00337219],\n",
      "        [-0.00595093, -0.0045166, 0.0108032, ..., -0.00299072,\n",
      "         -0.00836182, 0.0125732]],\n",
      "\n",
      "       [[-0.012146, -0.00759888, 0.00744629, ..., -0.0162354,\n",
      "         -0.00634766, -0.00187683],\n",
      "        [-0.00631714, -0.00524902, 0.0222168, ..., 0.00595093,\n",
      "         -0.0159912, 0.0098877],\n",
      "        [-0.00576782, -0.000743866, -0.0125122, ..., -0.000206947,\n",
      "         -0.00165558, -0.00564575],\n",
      "        ...,\n",
      "        [-0.00485229, 0.0150146, -0.00382996, ..., 0.0145264,\n",
      "         0.00946045, 0.0114136],\n",
      "        [0.0109863, -0.00601196, 0.0106201, ..., -0.0194092,\n",
      "         -0.00631714, 0.0134888],\n",
      "        [-0.000572205, -0.00125122, -0.0103149, ..., 0.00753784,\n",
      "         0.00363159, 0.0149536]],\n",
      "\n",
      "       [[0.0109863, 0.00238037, -0.0090332, ..., 0.0166016, 0.0159912,\n",
      "         -0.00187683],\n",
      "        [0.00964355, 0.00854492, -0.0109253, ..., -0.0159912,\n",
      "         0.00747681, -0.0140381],\n",
      "        [0.00964355, -0.00479126, 0.00164795, ..., 0.0118408,\n",
      "         -0.0105591, 0.0148315],\n",
      "        ...,\n",
      "        [-0.0090332, -0.0133667, 0.00131226, ..., -0.00650024,\n",
      "         -0.00830078, -0.00259399],\n",
      "        [-0.00540161, 0.00537109, -0.0170898, ..., 0.00872803,\n",
      "         -0.00939941, -0.00506592],\n",
      "        [0.00263977, -0.00154877, 0.00939941, ..., -0.00346375,\n",
      "         -0.0281982, 0.00939941]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0022583, -0.00382996, -0.00463867, ..., -0.0157471,\n",
      "          -0.0196533, -0.000295639],\n",
      "         [-0.00445557, -0.0114746, 0.00848389, ..., -0.0134888,\n",
      "          0.00158691, 0.000934601],\n",
      "         [0.00430298, -0.00389099, -0.0177002, ..., 0.00582886,\n",
      "          0.00357056, -0.0186768],\n",
      "         ...,\n",
      "         [-0.00601196, 0.0078125, 0.00141907, ..., 0.0195312,\n",
      "          0.00921631, -0.0231934],\n",
      "         [0.0103149, 0.0264893, -0.0057373, ..., -0.000440598,\n",
      "          -0.0098877, 0.00674438],\n",
      "         [0.0019989, 0.000709534, 0.00379944, ..., -0.000789642,\n",
      "          0.00616455, -0.00271606]],\n",
      "\n",
      "        [[0.000831604, 0.0112915, -0.00111389, ..., -0.0131836,\n",
      "          0.000356674, 0.000659943],\n",
      "         [-0.00173187, 0.00276184, 0.00588989, ..., 0.00314331,\n",
      "          -0.0115356, -0.00291443],\n",
      "         [-0.00111389, -0.00994873, -0.00137329, ..., -0.0236816,\n",
      "          -0.00250244, -0.0159912],\n",
      "         ...,\n",
      "         [-0.00610352, 0.0103149, -0.000255585, ..., -0.022583,\n",
      "          0.00107574, 0.000614166],\n",
      "         [0.0170898, 0.0152588, 0.0055542, ..., 0.0178223, 0.0142212,\n",
      "          0.00570679],\n",
      "         [-0.00182343, -0.00482178, 2.90871e-05, ..., 0.0383301,\n",
      "          -0.00497437, -0.00836182]],\n",
      "\n",
      "        [[-0.0167236, -0.0247803, 0.0178223, ..., 0.0217285,\n",
      "          -0.00512695, 0.00010252],\n",
      "         [-0.0107422, -0.0245361, -0.000125885, ..., -0.00346375,\n",
      "          -0.00442505, -0.0181885],\n",
      "         [0.000991821, 0.00970459, 0.000541687, ..., -0.024292,\n",
      "          -0.00393677, -0.00872803],\n",
      "         ...,\n",
      "         [-0.00634766, 0.00939941, 0.00704956, ..., 0.0119629,\n",
      "          -0.00245667, -0.013855],\n",
      "         [0.00300598, 0.00549316, 0.00854492, ..., 0.0111084,\n",
      "          -0.00439453, 0.012146],\n",
      "         [-0.00650024, -0.00279236, -0.00311279, ..., -0.00107574,\n",
      "          -0.00121307, -0.0108643]],\n",
      "\n",
      "        [[-0.0027771, -0.017334, -0.00360107, ..., 0.0163574,\n",
      "          0.00704956, -0.0139771],\n",
      "         [-0.0117798, -0.00604248, 0.00186157, ..., 0.0212402,\n",
      "          0.00674438, 0.0137939],\n",
      "         [-0.00811768, 0.00537109, -0.00305176, ..., -0.0305176,\n",
      "          0.00518799, 0.0150757],\n",
      "         ...,\n",
      "         [-0.00619507, 0.00370789, 0.00970459, ..., 9.0003e-06,\n",
      "          -0.00558472, -0.0108032],\n",
      "         [0.00228882, 0.0179443, -0.0114746, ..., 0.000747681,\n",
      "          -0.0131836, 0.00704956],\n",
      "         [-0.0098877, 0.00811768, 0.00830078, ..., -0.00823975,\n",
      "          0.00537109, -0.00346375]]],\n",
      "\n",
      "\n",
      "       [[[-0.0129395, -0.0135498, -0.0120239, ..., -0.00179291,\n",
      "          0.00756836, -0.00915527],\n",
      "         [0.00717163, 0.00637817, 0.0123291, ..., 0.00326538,\n",
      "          0.0146484, 0.00915527],\n",
      "         [0.0196533, -0.00964355, 0.00668335, ..., 0.0115967,\n",
      "          -0.00134277, 0.00515747],\n",
      "         ...,\n",
      "         [-0.00817871, 0.0113525, -0.00982666, ..., 0.000930786,\n",
      "          0.0228271, 0.0103149],\n",
      "         [-0.00238037, -0.020874, 0.0100098, ..., -0.00634766,\n",
      "          0.00643921, -0.0126953],\n",
      "         [-0.0119629, -0.00592041, 0.00265503, ..., 1.15037e-05,\n",
      "          -0.0115967, -0.00349426]],\n",
      "\n",
      "        [[0.0131836, -0.00415039, -0.0100708, ..., 0.00805664,\n",
      "          0.029541, -0.0168457],\n",
      "         [-0.00300598, -0.00878906, -0.012085, ..., -0.00811768,\n",
      "          -0.00787354, 0.0280762],\n",
      "         [-0.00680542, -0.0107422, 0.000667572, ..., 0.0109863,\n",
      "          -0.00228882, 0.0111084],\n",
      "         ...,\n",
      "         [-0.0177002, -0.00598145, 0.000142097, ..., -0.00811768,\n",
      "          -0.00286865, 0.0150146],\n",
      "         [0.0339355, 0.00323486, -0.0169678, ..., 0.019043,\n",
      "          -0.00695801, -0.00631714],\n",
      "         [-0.0168457, 0.00759888, 0.0218506, ..., -0.00173187,\n",
      "          -0.0115967, 0.0141602]],\n",
      "\n",
      "        [[0.0285645, -0.0152588, -0.00915527, ..., 0.00836182,\n",
      "          -0.0153809, 0.0078125],\n",
      "         [-0.0219727, -0.00714111, 0.0178223, ..., -0.0105591,\n",
      "          -0.0103149, 0.0153198],\n",
      "         [-0.0115356, -0.00622559, -0.0212402, ..., -0.0167236,\n",
      "          -0.00601196, 0.0119019],\n",
      "         ...,\n",
      "         [-0.0119019, -0.00634766, -0.0185547, ..., 0.000675201,\n",
      "          0.00775146, -0.00421143],\n",
      "         [-0.0157471, 0.0088501, 0.0140381, ..., -0.0214844,\n",
      "          -0.00540161, 0.00367737],\n",
      "         [0.00592041, 0.00765991, 0.00209045, ..., 0.000295639,\n",
      "          0.00662231, 0.00312805]],\n",
      "\n",
      "        [[-0.0100708, -0.0109863, -0.00698853, ..., -0.00915527,\n",
      "          0.00189209, 0.00396729],\n",
      "         [-0.000953674, -0.00418091, 0.00558472, ..., 0.00552368,\n",
      "          0.00189209, -0.0071106],\n",
      "         [0.00102997, 0.0148926, 0.00927734, ..., -0.00231934,\n",
      "          0.00866699, -0.00335693],\n",
      "         ...,\n",
      "         [-0.00248718, -0.00765991, -0.0140991, ..., 0.0120239,\n",
      "          -0.000549316, 0.00762939],\n",
      "         [0.0137939, -0.0178223, -0.0118408, ..., 0.0233154,\n",
      "          -0.00469971, -0.0065918],\n",
      "         [-3.3617e-05, 0.00279236, -0.0115356, ..., -0.000297546,\n",
      "          -0.000957489, 0.00497437]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00193024, -0.00836182, -0.00127411, ..., -0.00482178,\n",
      "         -0.0319824, 0.0105591],\n",
      "        [-0.00236511, 0.00860596, -0.00686646, ..., 0.0235596,\n",
      "         -0.0115356, -0.0177002],\n",
      "        [-0.0135498, 0.00204468, 0.000249863, ..., -0.00854492,\n",
      "         -0.0214844, -0.0050354],\n",
      "        ...,\n",
      "        [-0.0135498, -0.00723267, -0.00701904, ..., -0.00772095,\n",
      "         0.0107422, 0.00183105],\n",
      "        [-0.00698853, 0.0162354, 0.000495911, ..., 0.0067749,\n",
      "         -0.0158691, -0.00145721],\n",
      "        [0.00439453, -0.00469971, -0.000816345, ..., -0.00604248,\n",
      "         0.0172119, 0.00970459]],\n",
      "\n",
      "       [[0.00521851, -0.00506592, -0.0144653, ..., -0.0149536,\n",
      "         0.0136719, 0.012146],\n",
      "        [0.00500488, 0.00195312, 0.00793457, ..., -0.00512695,\n",
      "         0.00683594, -0.0107422],\n",
      "        [0.00387573, 0.00778198, 0.0101318, ..., 0.0158691, -0.0152588,\n",
      "         -0.00561523],\n",
      "        ...,\n",
      "        [-0.0122681, 0.0103149, -0.0107422, ..., 0.00958252, 0.00610352,\n",
      "         -0.00494385],\n",
      "        [0.00150299, 0.00299072, 0.000976562, ..., 0.000377655,\n",
      "         0.000286102, -0.00701904],\n",
      "        [0.0107422, -0.00854492, 0.0183105, ..., -0.00494385,\n",
      "         0.00424194, -0.00674438]],\n",
      "\n",
      "       [[-0.00263977, -0.0158691, -0.00958252, ..., 0.00421143,\n",
      "         -0.0209961, -0.00248718],\n",
      "        [0.00976562, 0.0220947, 0.0189209, ..., -0.0192871, -0.0168457,\n",
      "         0.015625],\n",
      "        [-0.00872803, -5.62668e-05, 0.0109863, ..., 0.00332642,\n",
      "         -0.0039978, -0.0065918],\n",
      "        ...,\n",
      "        [0.00860596, -0.0292969, -0.00094223, ..., 0.0239258, 0.0109253,\n",
      "         0.00570679],\n",
      "        [-0.00056076, 0.00680542, 0.0234375, ..., -0.0115356,\n",
      "         0.00308228, 0.0157471],\n",
      "        [0.000216484, 0.00411987, -0.0167236, ..., 0.00300598,\n",
      "         -0.0110474, -0.00982666]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.0043335, -0.00154877, 0.0158691, ..., 0.0258789,\n",
      "         -0.00738525, 0.00799561],\n",
      "        [0.010498, 0.0088501, 0.0114746, ..., 0.00273132, -0.00158691,\n",
      "         -0.0266113],\n",
      "        [0.00994873, -0.0123901, -0.00683594, ..., -0.00897217,\n",
      "         -0.00222778, 0.0130615],\n",
      "        ...,\n",
      "        [-0.0128784, -0.00218201, 0.00741577, ..., 0.00379944,\n",
      "         0.00119019, -0.00405884],\n",
      "        [-0.0145264, -0.00119019, -0.0100708, ..., -0.0246582,\n",
      "         0.0144043, 0.0103149],\n",
      "        [-0.00305176, -0.00946045, 0.00750732, ..., 0.00191498,\n",
      "         -0.0136108, -0.0143433]],\n",
      "\n",
      "       [[0.00296021, -0.0206299, 0.0163574, ..., -0.00285339,\n",
      "         -0.00872803, -0.0166016],\n",
      "        [0.0168457, 4.1008e-05, -0.00909424, ..., -0.00891113,\n",
      "         0.00340271, 0.0169678],\n",
      "        [-0.0179443, -0.00964355, 0.0057373, ..., 0.0113525,\n",
      "         -0.00408936, 0.003479],\n",
      "        ...,\n",
      "        [-0.0180664, 0.00111389, -3.48091e-05, ..., -0.0198975,\n",
      "         -0.00100708, -0.00159454],\n",
      "        [0.00891113, 0.00866699, 0.00747681, ..., -0.00601196,\n",
      "         -0.00063324, 0.00291443],\n",
      "        [-0.00521851, 0.00668335, -0.0127563, ..., 0.010437, 0.00216675,\n",
      "         0.000896454]],\n",
      "\n",
      "       [[0.00518799, -0.00056839, 0.00460815, ..., -0.0129395,\n",
      "         -0.0045166, 0.00915527],\n",
      "        [-0.001297, 0.00415039, -0.00233459, ..., -0.0202637, 0.0198975,\n",
      "         0.00346375],\n",
      "        [-0.00524902, -0.00102997, 0.0126343, ..., 0.020874, 0.0119019,\n",
      "         0.00717163],\n",
      "        ...,\n",
      "        [-0.00250244, -0.010498, -0.012207, ..., -0.0109253, 0.0206299,\n",
      "         -0.0098877],\n",
      "        [0.00454712, -0.00212097, -0.00241089, ..., -0.0137329,\n",
      "         0.010376, -0.00247192],\n",
      "        [0.00279236, -0.00215149, -0.0012207, ..., -0.00927734,\n",
      "         -0.015625, -0.0150757]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00689697, 0.0146484, 0.00717163, ..., 0.00154877, 0.00634766,\n",
      "         -0.00582886],\n",
      "        [-0.00279236, -0.00576782, -0.00228882, ..., 0.006073,\n",
      "         -0.00370789, -0.00312805],\n",
      "        [0.00430298, 0.00222778, -0.00585938, ..., -0.00860596,\n",
      "         0.00692749, 0.00128174],\n",
      "        ...,\n",
      "        [0.00662231, 0.00494385, -0.00982666, ..., -0.00145721,\n",
      "         0.00546265, -0.00970459],\n",
      "        [-0.00524902, 0.0027771, -0.00482178, ..., 0.00125122,\n",
      "         0.0147095, 0.0030365],\n",
      "        [-0.00123596, -0.00318909, 0.0146484, ..., 0.000352859,\n",
      "         -0.00564575, -0.00291443]],\n",
      "\n",
      "       [[-0.00570679, 0.0039978, -0.00357056, ..., -0.00473022,\n",
      "         0.0117798, 0.0223389],\n",
      "        [-0.00192261, 0.0078125, 0.00230408, ..., -0.00185394,\n",
      "         0.000358582, 0.00302124],\n",
      "        [0.00164032, 0.00325012, -0.00714111, ..., 0.00878906,\n",
      "         -0.00500488, -0.00408936],\n",
      "        ...,\n",
      "        [-0.00112915, 0.0137329, -0.00637817, ..., 0.00145721,\n",
      "         -0.0133667, -0.00328064],\n",
      "        [-0.00325012, -0.0057373, 0.00509644, ..., 0.00878906,\n",
      "         0.0105591, 0.0133667],\n",
      "        [-0.00411987, 0.00126648, -0.00872803, ..., -0.00088501,\n",
      "         0.00140381, 0.0100708]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00915527, 0.00689697, -0.00189972, ..., -0.00546265,\n",
      "        0.00509644, 0.000930786],\n",
      "       [-0.0124512, -0.0078125, 0.00325012, ..., 0.0147705, 0.000320435,\n",
      "        -0.00552368],\n",
      "       [0.0035553, 0.00112915, -0.00585938, ..., -0.0151367, 0.00549316,\n",
      "        0.00169373],\n",
      "       ...,\n",
      "       [0.00292969, -0.00210571, -0.00390625, ..., 0.00123596,\n",
      "        -9.25064e-05, -0.0071106],\n",
      "       [0.00726318, 0.0186768, 0.00289917, ..., -0.0159912, 0.0107422,\n",
      "        -0.0132446],\n",
      "       [0.0148315, 0.0125732, -0.0025177, ..., 0.00946045, -0.00424194,\n",
      "        0.0115967]], dtype=bfloat16), a=Array([[-0.00383564, -0.00756023, -0.01255484, ...,  0.01498562,\n",
      "        -0.01903302,  0.02186585],\n",
      "       [-0.00933835,  0.0013327 ,  0.01779663, ..., -0.00167542,\n",
      "         0.00606556, -0.00059748]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.39062, 1.32031, 1.55469, ..., 1.32031, 1.50781, 1.29688],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.84375, 2.875, 2.90625, ..., 2.64062, 2.78125, 2.5625], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.359375, 0.330078, 0.347656, ..., 0.306641, 0.318359, 0.5],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.0220947, 0.0688477, 0.0303955, ..., 0.0279541, 0.0133057,\n",
      "       0.108887], dtype=bfloat16)}}, 'layer_21': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00692749, 0.0206299, -0.00121307, ..., 0.00306702,\n",
      "         0.00421143, -0.00147247],\n",
      "        [0.00878906, 0.0067749, -0.000530243, ..., 0.0213623, 0.0128784,\n",
      "         0.00209045],\n",
      "        [0.0123291, -0.0161133, -0.0114136, ..., -0.00393677,\n",
      "         -0.0213623, 0.0153198],\n",
      "        ...,\n",
      "        [0.00558472, 0.00848389, -0.0152588, ..., 0.0109253,\n",
      "         -0.00640869, 0.00136566],\n",
      "        [-0.0124512, 0.00445557, -0.0162354, ..., -0.0288086,\n",
      "         -0.00354004, -0.00787354],\n",
      "        [-0.0117188, 0.00579834, 3.69549e-05, ..., 0.0147705,\n",
      "         -0.00143433, 0.0164795]],\n",
      "\n",
      "       [[-0.00282288, 0.000257492, 0.00479126, ..., -0.0135498,\n",
      "         0.00125885, 0.00141907],\n",
      "        [0.0062561, -0.00122833, 0.00466919, ..., 0.00340271,\n",
      "         -0.000919342, 0.00738525],\n",
      "        [-0.00131226, 0.00037384, 0.0158691, ..., -0.00753784,\n",
      "         -0.00216675, 0.010437],\n",
      "        ...,\n",
      "        [0.00628662, 0.00634766, -0.00836182, ..., 0.00524902, 0.012207,\n",
      "         0.00241089],\n",
      "        [-0.0133057, -0.00101471, 0.0108643, ..., 0.00817871, 0.0117798,\n",
      "         -0.00308228],\n",
      "        [0.00296021, -0.0175781, 0.000478745, ..., -0.00411987,\n",
      "         -0.012085, 0.0098877]],\n",
      "\n",
      "       [[-0.0027771, -0.00915527, -0.00878906, ..., -0.00210571,\n",
      "         0.00309753, 0.0174561],\n",
      "        [0.00531006, -0.0154419, -0.0123291, ..., 0.00643921,\n",
      "         -0.0283203, 0.00497437],\n",
      "        [-0.0123901, 0.0038147, -0.0246582, ..., 0.0107422, 0.00201416,\n",
      "         0.0167236],\n",
      "        ...,\n",
      "        [-0.0236816, -0.00415039, 0.0183105, ..., -0.0322266,\n",
      "         -0.00231934, 0.0405273],\n",
      "        [-0.00646973, -0.0167236, 0.0180664, ..., 0.00488281,\n",
      "         -0.00418091, -0.0113525],\n",
      "        [0.00537109, 0.0146484, -0.00112915, ..., 0.00613403,\n",
      "         -0.0123291, 0.0112305]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00306702, 0.00842285, -0.00202942, ..., -0.0139771,\n",
      "         0.019165, 0.0108032],\n",
      "        [0.0035553, -0.00364685, -0.00811768, ..., 0.0144653,\n",
      "         -0.000400543, 0.0126343],\n",
      "        [0.000564575, -0.00402832, -0.00141907, ..., -0.00558472,\n",
      "         -0.00366211, 0.000205994],\n",
      "        ...,\n",
      "        [-0.00340271, 0.00958252, -0.0152588, ..., -0.00494385,\n",
      "         0.00799561, -0.00312805],\n",
      "        [0.00372314, -0.00534058, 0.0105591, ..., -0.00534058,\n",
      "         0.0116577, -0.0145874],\n",
      "        [0.00543213, -0.0130005, -0.00448608, ..., 0.00735474,\n",
      "         0.000180244, -0.0035553]],\n",
      "\n",
      "       [[-0.00386047, -0.000926971, 0.012146, ..., 0.0098877, 0.015625,\n",
      "         0.0150146],\n",
      "        [-0.0100708, -0.00964355, 0.00228882, ..., 0.00308228,\n",
      "         -0.00187683, -0.00643921],\n",
      "        [-0.00338745, -0.00234985, 0.0161133, ..., -0.012207,\n",
      "         -0.00775146, 0.00088501],\n",
      "        ...,\n",
      "        [0.00515747, 0.026123, 0.0203857, ..., -0.000804901, 0.00891113,\n",
      "         -0.00915527],\n",
      "        [-0.0163574, -0.0241699, 0.00891113, ..., 0.0067749, 0.00909424,\n",
      "         0.0150146],\n",
      "        [-0.00171661, -0.00787354, -0.0140381, ..., -0.00357056,\n",
      "         -0.00537109, -0.0201416]],\n",
      "\n",
      "       [[0.0147705, 0.00933838, -0.006073, ..., -0.0116577, -0.0050354,\n",
      "         -0.0159912],\n",
      "        [0.0157471, 0.0140991, 0.00167084, ..., -0.00328064, 0.00759888,\n",
      "         0.0131836],\n",
      "        [0.00111389, 0.019043, -0.00769043, ..., 0.00836182, 0.00582886,\n",
      "         0.0177002],\n",
      "        ...,\n",
      "        [-0.000522614, -0.0134277, -0.0300293, ..., 0.0129395,\n",
      "         -0.0285645, 0.0144653],\n",
      "        [0.000984192, 0.0126343, 0.00415039, ..., -0.012085, 0.0004673,\n",
      "         -0.00909424],\n",
      "        [0.000265121, 0.00726318, 0.0129395, ..., 0.00389099,\n",
      "         -0.00314331, 0.00445557]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0141602, 0.00115204, 0.00933838, ..., 0.0134277,\n",
      "          -0.00177765, 0.00280762],\n",
      "         [0.000257492, 0.0025177, -0.0012207, ..., -0.00543213,\n",
      "          -0.000656128, -0.0251465],\n",
      "         [-0.00488281, 0.00262451, 0.00604248, ..., 0.00521851,\n",
      "          0.00646973, -0.019165],\n",
      "         ...,\n",
      "         [-0.0197754, 0.0110474, -0.00218201, ..., -0.0224609,\n",
      "          0.0144043, 0.00315857],\n",
      "         [0.012207, 0.0151978, -0.00546265, ..., -0.00402832,\n",
      "          -0.0134888, -0.00247192],\n",
      "         [0.0115967, -0.0166016, -0.00805664, ..., 0.00842285,\n",
      "          0.00653076, -0.00152588]],\n",
      "\n",
      "        [[-0.006073, -0.00976562, -0.00445557, ..., -0.00189209,\n",
      "          0.00585938, -0.00683594],\n",
      "         [6.81877e-05, -0.0134277, 0.0126343, ..., 0.0130005,\n",
      "          0.0175781, 0.020752],\n",
      "         [-0.00909424, -0.00427246, 0.0109863, ..., -0.00299072,\n",
      "          -0.00933838, 0.0115967],\n",
      "         ...,\n",
      "         [0.00427246, -0.00491333, 0.0045166, ..., -0.00101471,\n",
      "          0.00811768, 0.0354004],\n",
      "         [0.00328064, 0.00933838, -0.00860596, ..., -0.00921631,\n",
      "          -0.0174561, -0.0181885],\n",
      "         [0.0131836, -0.0101929, -0.00147247, ..., 0.00860596,\n",
      "          -0.00952148, -0.00469971]],\n",
      "\n",
      "        [[0.00210571, -0.00357056, -0.00124359, ..., -0.00439453,\n",
      "          -0.0118408, -0.0178223],\n",
      "         [0.00386047, 0.00411987, 0.000282288, ..., -0.00909424,\n",
      "          0.000286102, 0.00836182],\n",
      "         [-0.00159454, -0.0123291, 0.00279236, ..., 0.0125122,\n",
      "          0.0132446, 0.00312805],\n",
      "         ...,\n",
      "         [0.00708008, 0.00793457, 0.00219727, ..., -0.0115356,\n",
      "          0.00218201, 0.00604248],\n",
      "         [-0.00830078, -0.00279236, 0.00222778, ..., -0.0019989,\n",
      "          -0.0110474, 0.00958252],\n",
      "         [-0.000873566, -0.00263977, -0.00427246, ..., -0.0168457,\n",
      "          -0.0175781, 0.00106049]],\n",
      "\n",
      "        [[-0.00793457, -0.00653076, 0.00120544, ..., 0.00292969,\n",
      "          -0.00646973, -0.00323486],\n",
      "         [0.017334, 0.00619507, -0.0184326, ..., 8.4877e-05,\n",
      "          0.00386047, 0.00436401],\n",
      "         [-0.00622559, -0.0112305, 0.000518799, ..., -0.00191498,\n",
      "          0.00671387, -0.0124512],\n",
      "         ...,\n",
      "         [0.00034523, 0.0103149, -0.0100708, ..., -0.015564,\n",
      "          -0.00376892, 0.00494385],\n",
      "         [-0.00970459, -0.000297546, 0.00376892, ..., -0.00354004,\n",
      "          0.0110474, 0.0114136],\n",
      "         [-0.0078125, -0.00161743, -0.00775146, ..., -0.0110474,\n",
      "          0.00512695, -0.0019989]]],\n",
      "\n",
      "\n",
      "       [[[-0.0025177, 0.0257568, 0.00714111, ..., 0.00952148,\n",
      "          -0.020874, -0.000991821],\n",
      "         [0.0153809, 0.0126953, -0.012207, ..., 0.0071106, 0.00689697,\n",
      "          -0.0117798],\n",
      "         [0.0098877, -0.00418091, 0.00309753, ..., -0.022583,\n",
      "          -0.0169678, 0.00717163],\n",
      "         ...,\n",
      "         [0.0067749, 0.02771, 3.50475e-05, ..., 0.0112915, -0.0103149,\n",
      "          0.00735474],\n",
      "         [-0.00421143, 0.00189209, -0.0196533, ..., 0.0128174,\n",
      "          0.0090332, -0.000617981],\n",
      "         [-0.00384521, 0.0177002, 0.0126953, ..., -0.00634766,\n",
      "          0.00994873, 0.0174561]],\n",
      "\n",
      "        [[0.00933838, -0.00193787, -0.00159454, ..., -0.00897217,\n",
      "          -0.00689697, 0.0107422],\n",
      "         [0.00915527, -0.0224609, 0.00230408, ..., -0.00169373,\n",
      "          -0.019043, 0.00469971],\n",
      "         [0.0101318, -0.00320435, -0.0230713, ..., 0.0146484, 0.020752,\n",
      "          0.0101929],\n",
      "         ...,\n",
      "         [-0.0098877, 0.00280762, 0.0157471, ..., -0.0172119,\n",
      "          -0.00320435, 0.00188446],\n",
      "         [0.0130615, -0.00262451, -0.00115967, ..., -0.0223389,\n",
      "          -0.0148926, -0.00259399],\n",
      "         [0.0187988, -0.0117188, 0.00582886, ..., 0.0108643,\n",
      "          -0.00497437, 0.015625]],\n",
      "\n",
      "        [[-0.00485229, 0.0045166, 0.00543213, ..., 0.00878906,\n",
      "          0.0117188, 0.00656128],\n",
      "         [-0.0129395, 0.00738525, -0.00227356, ..., 0.0150757,\n",
      "          -0.00634766, 0.0166016],\n",
      "         [-0.00334167, -0.0151978, 0.00561523, ..., -0.00878906,\n",
      "          -0.0174561, -0.0114746],\n",
      "         ...,\n",
      "         [-0.00759888, -0.0045166, 0.00723267, ..., 0.000911713,\n",
      "          -0.00897217, -0.0200195],\n",
      "         [-0.00170898, -0.00860596, -0.00302124, ..., -0.00628662,\n",
      "          -0.00106049, 0.00236511],\n",
      "         [0.0220947, 0.012146, -0.00753784, ..., -0.00369263,\n",
      "          0.0106812, 0.00613403]],\n",
      "\n",
      "        [[0.00454712, 0.000138283, -0.0115356, ..., 0.0117188,\n",
      "          0.00552368, 0.00915527],\n",
      "         [0.00561523, -0.0114136, 0.00460815, ..., 0.0124512,\n",
      "          -0.00588989, -0.0169678],\n",
      "         [-0.00952148, 0.0117188, 0.0162354, ..., 0.0131836, 0.0140991,\n",
      "          -0.00842285],\n",
      "         ...,\n",
      "         [0.00689697, -0.00265503, -0.0103149, ..., 0.0118408,\n",
      "          0.000207901, -0.0107422],\n",
      "         [0.0150757, 0.0136108, 0.010376, ..., 0.0149536, 0.00062561,\n",
      "          -0.00994873],\n",
      "         [0.010376, -0.0159912, -0.00125885, ..., -0.00717163,\n",
      "          0.0147095, -0.0133667]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00183105, 0.0106812, -0.00762939, ..., -0.00634766,\n",
      "         0.00509644, -0.0039978],\n",
      "        [0.0148926, 0.00183105, 0.000583649, ..., 0.00376892,\n",
      "         -0.0236816, -0.0139771],\n",
      "        [-0.0203857, -0.0275879, 0.000511169, ..., -0.00294495,\n",
      "         0.00195312, 0.0154419],\n",
      "        ...,\n",
      "        [0.0151367, 0.00378418, 0.00717163, ..., -0.00958252,\n",
      "         0.00830078, -0.00646973],\n",
      "        [-0.012085, -0.0124512, 0.00537109, ..., 0.000478745,\n",
      "         -0.00854492, -0.0185547],\n",
      "        [-0.00604248, -0.000991821, -0.000667572, ..., 0.0143433,\n",
      "         -0.00872803, 0.000141144]],\n",
      "\n",
      "       [[-0.00183868, -0.0101929, -0.000610352, ..., -0.00463867,\n",
      "         0.0233154, 0.0209961],\n",
      "        [-7.67708e-05, -0.000762939, -0.00680542, ..., 0.0136108,\n",
      "         -0.0366211, -0.0344238],\n",
      "        [-0.00213623, -0.0192871, -0.0175781, ..., -0.0106201,\n",
      "         0.0283203, -0.00656128],\n",
      "        ...,\n",
      "        [-0.00668335, -0.0257568, -0.00430298, ..., -0.00582886,\n",
      "         0.0334473, 0.0155029],\n",
      "        [0.00671387, 0.000350952, 0.00271606, ..., -0.00939941,\n",
      "         -0.00485229, -0.0025177],\n",
      "        [-0.00110626, 0.00299072, 0.0203857, ..., -0.017334, -0.0119019,\n",
      "         0.00242615]],\n",
      "\n",
      "       [[-0.0134277, 0.0130615, 0.00473022, ..., 0.00830078,\n",
      "         -0.00131226, 0.00872803],\n",
      "        [0.0130615, -0.0162354, -0.00656128, ..., 0.0119019, 0.00390625,\n",
      "         0.00970459],\n",
      "        [0.00445557, -0.00150299, -0.00665283, ..., 0.00224304,\n",
      "         0.0170898, -0.0189209],\n",
      "        ...,\n",
      "        [-0.012085, -0.00701904, -0.00515747, ..., -0.0177002,\n",
      "         -0.00537109, -0.0192871],\n",
      "        [-0.013855, 0.00921631, 0.00619507, ..., -0.00262451,\n",
      "         0.00482178, 0.0067749],\n",
      "        [0.0019989, -0.000839233, 0.00195312, ..., 0.00238037,\n",
      "         0.0133667, -0.00325012]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00637817, 0.00375366, -0.000957489, ..., -0.0124512,\n",
      "         -0.00946045, -0.0113525],\n",
      "        [0.00604248, 0.00082016, -0.0115356, ..., 0.0183105, 0.0119019,\n",
      "         0.0234375],\n",
      "        [0.0088501, -0.00561523, -0.000173569, ..., -0.0200195,\n",
      "         0.00726318, 0.00665283],\n",
      "        ...,\n",
      "        [0.00643921, -0.0037384, 0.000115395, ..., -0.000766754,\n",
      "         -0.00340271, -0.0012207],\n",
      "        [-0.00769043, 0.00854492, -0.0111084, ..., 0.0270996,\n",
      "         -0.0211182, -0.0017395],\n",
      "        [0.00476074, -0.0014267, 0.0072937, ..., 0.0186768, 0.017334,\n",
      "         -0.00305176]],\n",
      "\n",
      "       [[-0.00215149, -0.00349426, 0.00976562, ..., 0.0106201,\n",
      "         0.00854492, -0.0117188],\n",
      "        [-0.00671387, 0.000553131, -0.00610352, ..., -0.00854492,\n",
      "         0.0142822, 0.00384521],\n",
      "        [-0.00811768, 0.00842285, 0.00927734, ..., -0.019165,\n",
      "         0.00656128, -0.00479126],\n",
      "        ...,\n",
      "        [0.00170898, -0.00106049, -0.00506592, ..., 0.00964355,\n",
      "         -0.0222168, 0.00585938],\n",
      "        [0.00236511, 0.00747681, 0.00915527, ..., 0.00604248,\n",
      "         -0.00643921, -0.0153198],\n",
      "        [-0.0057373, -0.00619507, 0.00331116, ..., 0.00132751,\n",
      "         0.00686646, -0.00701904]],\n",
      "\n",
      "       [[-0.0157471, 0.0027771, 0.0136719, ..., 0.0043335, -0.00144958,\n",
      "         -0.00527954],\n",
      "        [-0.0020752, 0.00463867, -0.0037384, ..., -0.00946045,\n",
      "         -0.00131989, -0.0125732],\n",
      "        [-0.00183868, 0.0088501, -0.00970459, ..., -0.0163574,\n",
      "         -0.00424194, -0.0157471],\n",
      "        ...,\n",
      "        [0.0172119, -0.00939941, -0.00250244, ..., 0.00204468,\n",
      "         0.0107422, 0.000352859],\n",
      "        [-0.00196838, 0.010376, -0.000263214, ..., -0.00561523,\n",
      "         0.0111694, 0.0131226],\n",
      "        [0.00442505, -0.00872803, -0.00469971, ..., 0.00411987,\n",
      "         0.00224304, 0.00836182]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00723267, 0.00106812, -0.0110474, ..., 0.0136719,\n",
      "         -0.00854492, -0.00500488],\n",
      "        [-0.0027771, -0.0148926, 0.00454712, ..., 0.00701904,\n",
      "         -0.0101929, -0.000617981],\n",
      "        [-0.000182152, -0.0107422, 0.0032959, ..., 0.0116577,\n",
      "         -0.0101929, -0.0119629],\n",
      "        ...,\n",
      "        [-0.00151062, -0.0037384, -0.00585938, ..., -0.000541687,\n",
      "         0.00189209, 0.00424194],\n",
      "        [0.0020752, 0.00158691, 0.000522614, ..., 0.00280762,\n",
      "         -0.0174561, 0.0103149],\n",
      "        [0.00527954, 0.00244141, 0.00102997, ..., 0.00171661,\n",
      "         -0.00132751, 0.000736237]],\n",
      "\n",
      "       [[-0.000545502, 0.00354004, -0.00552368, ..., 0.00402832,\n",
      "         0.00787354, 0.00592041],\n",
      "        [0.0100098, 0.00204468, 0.00442505, ..., 0.0136719, -0.0111694,\n",
      "         -0.0118408],\n",
      "        [0.00454712, 0.0016098, -0.012085, ..., -0.00500488, -0.0144043,\n",
      "         0.00213623],\n",
      "        ...,\n",
      "        [0.00056839, 0.000366211, 0.000511169, ..., 0.00238037,\n",
      "         0.000923157, -0.0125732],\n",
      "        [-0.00469971, -0.00069809, -0.00793457, ..., 0.0018692,\n",
      "         0.00769043, -0.0175781],\n",
      "        [0.00759888, -0.00137329, 0.0055542, ..., -0.00212097,\n",
      "         0.00588989, 0.00891113]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00314331, 0.0147705, -0.00466919, ..., 0.00262451, -0.00154114,\n",
      "        0.00112152],\n",
      "       [-0.00227356, -0.0139771, 0.000432968, ..., 0.00161743, 0.0137939,\n",
      "        0.0107422],\n",
      "       [-0.00878906, 0.00561523, -0.00198364, ..., -0.00326538,\n",
      "        0.00354004, -0.00424194],\n",
      "       ...,\n",
      "       [0.00415039, -0.00100708, 0.0177002, ..., 0.0088501, -0.010376,\n",
      "        0.000713348],\n",
      "       [0.0144043, -0.000417709, -0.00613403, ..., 0.003479, 0.00114441,\n",
      "        -0.00628662],\n",
      "       [0.00248718, -0.0116577, 0.00793457, ..., 0.00177765, -0.0147095,\n",
      "        0.0202637]], dtype=bfloat16), a=Array([[-0.00473069, -0.01229254,  0.00118823, ...,  0.00760194,\n",
      "        -0.01410474, -0.00785806],\n",
      "       [-0.00138563, -0.00167912,  0.01098308, ...,  0.01268801,\n",
      "         0.0018889 , -0.00222404]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.34375, 1.36719, 1.53906, ..., 1.33594, 1.35156, 1.24219],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([3.1875, 3.34375, 3.375, ..., 3.04688, 3.32812, 3.03125], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.421875, 0.402344, 0.400391, ..., 0.457031, 0.480469, 0.53125],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.0605469, -0.0107422, -0.0512695, ..., -0.0512695, -0.0771484,\n",
      "       0.0262451], dtype=bfloat16)}}, 'layer_22': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0078125, -0.00454712, -0.00616455, ..., 0.00674438,\n",
      "         -0.0180664, 0.00726318],\n",
      "        [-0.0151978, 0.00622559, -0.00735474, ..., -0.000341415,\n",
      "         -0.0103149, -0.0038147],\n",
      "        [0.0227051, 0.0100098, 0.00187683, ..., 0.0175781, 0.00117493,\n",
      "         0.000652313],\n",
      "        ...,\n",
      "        [0.00317383, 0.00262451, 0.00970459, ..., -0.0146484,\n",
      "         -0.0163574, -0.012146],\n",
      "        [-0.00491333, 8.82149e-05, -0.000953674, ..., -0.0197754,\n",
      "         -0.000747681, -0.00473022],\n",
      "        [-0.00836182, -0.00239563, 0.00361633, ..., 0.0118408,\n",
      "         -0.0164795, 0.00769043]],\n",
      "\n",
      "       [[-0.00759888, -0.00302124, -0.00153351, ..., 0.00601196,\n",
      "         0.00384521, 0.013916],\n",
      "        [0.00234985, 0.00031662, -0.0159912, ..., 0.00274658, -0.017334,\n",
      "         -0.00643921],\n",
      "        [-0.000341415, 0.00579834, 0.0118408, ..., -0.0145874,\n",
      "         0.0071106, -0.0126953],\n",
      "        ...,\n",
      "        [-0.000904083, 0.00302124, -0.00196838, ..., 0.00108337,\n",
      "         -0.00515747, -0.00952148],\n",
      "        [-0.00891113, -0.00662231, 0.000206947, ..., -0.00150299,\n",
      "         0.00823975, -0.00120544],\n",
      "        [0.012207, -0.00582886, -0.00744629, ..., 0.0122681, -0.0100708,\n",
      "         0.0162354]],\n",
      "\n",
      "       [[0.0162354, 0.00279236, 0.0108032, ..., -0.0236816, 0.00138855,\n",
      "         -0.000440598],\n",
      "        [0.0197754, -0.00312805, -0.00964355, ..., -0.00267029,\n",
      "         0.0114746, 0.0148926],\n",
      "        [0.00153351, -0.00732422, -0.00466919, ..., 0.00286865,\n",
      "         0.00756836, 0.00811768],\n",
      "        ...,\n",
      "        [0.0137329, 0.00273132, 0.00424194, ..., 0.032959, 0.020874,\n",
      "         0.00408936],\n",
      "        [-0.0135498, -0.0161133, 0.00286865, ..., -0.00595093,\n",
      "         0.0131226, 0.00717163],\n",
      "        [0.0111694, 0.0139771, -0.0098877, ..., -0.012085, 0.00598145,\n",
      "         -0.00204468]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00454712, -0.0219727, -0.00558472, ..., -0.00958252,\n",
      "         0.0223389, 0.0032959],\n",
      "        [0.0162354, 0.00393677, 0.001091, ..., -0.00115204, -0.00842285,\n",
      "         -0.00964355],\n",
      "        [-0.0159912, -0.00692749, -0.00772095, ..., 0.0057373,\n",
      "         -0.00653076, -0.00482178],\n",
      "        ...,\n",
      "        [0.00288391, 0.00247192, 0.0119629, ..., 0.00314331, 0.012085,\n",
      "         -0.0120239],\n",
      "        [0.00805664, -0.00335693, 0.0126953, ..., -0.00512695,\n",
      "         0.0106812, -0.00146484],\n",
      "        [-0.0147095, -0.0157471, 0.0198975, ..., -0.00107574,\n",
      "         -0.000656128, -0.0112305]],\n",
      "\n",
      "       [[0.026001, -0.00854492, 0.00125122, ..., 0.0148926, 0.0019455,\n",
      "         0.00787354],\n",
      "        [0.0144043, 0.00164795, -0.00976562, ..., -0.00720215,\n",
      "         0.0108643, -0.00482178],\n",
      "        [-0.0105591, -0.0112305, 0.00891113, ..., -0.00622559,\n",
      "         0.00695801, -0.00921631],\n",
      "        ...,\n",
      "        [-0.0019455, -0.0111084, -0.019165, ..., -0.019165, -0.0211182,\n",
      "         -0.0108643],\n",
      "        [0.00860596, 0.00222778, 0.020752, ..., 0.00476074, -0.00848389,\n",
      "         0.00695801],\n",
      "        [0.00259399, 0.00213623, 0.00109863, ..., 0.00753784,\n",
      "         -0.00140381, -0.00772095]],\n",
      "\n",
      "       [[-0.0275879, -0.00193024, 0.0137329, ..., -0.00946045,\n",
      "         -0.0039978, -0.00527954],\n",
      "        [-0.0246582, -0.0153809, 0.00132751, ..., 0.0164795, -0.0187988,\n",
      "         0.00282288],\n",
      "        [0.0072937, 0.020874, 0.00592041, ..., 0.00592041, -0.00320435,\n",
      "         0.0124512],\n",
      "        ...,\n",
      "        [-0.0128784, 0.00270081, 0.00598145, ..., 0.00836182, 0.0184326,\n",
      "         -0.0038147],\n",
      "        [-0.013855, -0.00662231, -0.0143433, ..., 0.00107574,\n",
      "         -0.00695801, -0.0255127],\n",
      "        [0.00263977, -0.00411987, -0.00244141, ..., -0.00335693,\n",
      "         -0.00172424, -0.000972748]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00689697, -0.00328064, -0.00402832, ..., -0.00262451,\n",
      "          -0.000362396, -0.00653076],\n",
      "         [0.00662231, 0.000375748, -0.00552368, ..., 0.00379944,\n",
      "          -0.0308838, -0.00546265],\n",
      "         [0.0102539, -0.0140381, -0.0238037, ..., -0.00756836,\n",
      "          0.00442505, -0.00872803],\n",
      "         ...,\n",
      "         [-0.0129395, -0.0137939, 0.00125885, ..., -0.0162354,\n",
      "          0.0122681, 0.0162354],\n",
      "         [0.00390625, 0.000873566, -0.0106812, ..., 0.0166016,\n",
      "          -0.000522614, 0.0233154],\n",
      "         [-0.00653076, 0.00765991, -0.000946045, ..., 0.00765991,\n",
      "          -0.0163574, 0.00312805]],\n",
      "\n",
      "        [[-0.00101471, -0.00376892, -0.00878906, ..., -0.000354767,\n",
      "          -0.00105286, 0.0035553],\n",
      "         [0.00650024, -0.00769043, 0.00466919, ..., 0.00805664,\n",
      "          -0.00331116, 0.0194092],\n",
      "         [5.55515e-05, 0.0043335, 0.00457764, ..., 0.00665283,\n",
      "          0.00159454, -0.00582886],\n",
      "         ...,\n",
      "         [0.00294495, 0.00479126, -0.00387573, ..., 0.00171661,\n",
      "          -0.000297546, -0.00952148],\n",
      "         [0.00326538, 0.0043335, 0.0057373, ..., -0.00595093,\n",
      "          0.00604248, -0.0115967],\n",
      "         [0.00552368, -0.00631714, -0.0039978, ..., 0.00799561,\n",
      "          -0.0106812, -0.00750732]],\n",
      "\n",
      "        [[0.00543213, -0.00521851, -0.00161743, ..., -0.0106812,\n",
      "          0.00946045, 0.00653076],\n",
      "         [-0.00213623, -0.00515747, 0.0071106, ..., -0.00460815,\n",
      "          -0.00153351, -0.00239563],\n",
      "         [0.0032959, 0.00643921, -0.00014782, ..., 0.0170898,\n",
      "          -0.00701904, 0.00915527],\n",
      "         ...,\n",
      "         [0.00273132, -0.00154114, 0.00439453, ..., -0.0170898,\n",
      "          -0.00823975, -0.000854492],\n",
      "         [-0.000488281, -0.00143433, -0.00476074, ..., 0.0123291,\n",
      "          -0.0219727, -0.00430298],\n",
      "         [-0.00161743, -0.0055542, -0.00747681, ..., -0.0205078,\n",
      "          -0.0133667, -0.00933838]],\n",
      "\n",
      "        [[-0.00166321, 0.0027771, -0.00254822, ..., 0.00595093,\n",
      "          -0.0112915, -0.024292],\n",
      "         [4.69685e-05, 0.00909424, -0.0106812, ..., 0.00144196,\n",
      "          -0.00836182, 0.0218506],\n",
      "         [0.00531006, -0.00354004, 0.00860596, ..., 0.0168457,\n",
      "          -0.00285339, 0.000740051],\n",
      "         ...,\n",
      "         [0.000444412, -0.00976562, -0.00285339, ..., -0.0107422,\n",
      "          0.0112305, 0.0125122],\n",
      "         [0.0103149, -0.00598145, -0.00334167, ..., -0.00473022,\n",
      "          -0.0195312, -0.00427246],\n",
      "         [-0.0045166, 0.00411987, -0.012146, ..., 0.00306702, 0.017334,\n",
      "          0.0027771]]],\n",
      "\n",
      "\n",
      "       [[[-0.0180664, -0.00692749, 0.00382996, ..., -0.000455856,\n",
      "          -0.0168457, -0.00191498],\n",
      "         [-0.00315857, -0.00726318, 0.00817871, ..., 0.0120239,\n",
      "          -0.00643921, -0.00772095],\n",
      "         [-0.0144043, -0.00473022, 0.010376, ..., -0.00283813,\n",
      "          -0.00637817, -0.00537109],\n",
      "         ...,\n",
      "         [0.00289917, 0.00598145, -0.00897217, ..., 0.00720215,\n",
      "          0.000751495, 0.0129395],\n",
      "         [-0.00891113, -0.0250244, 0.00424194, ..., -0.0126343,\n",
      "          0.0072937, -0.019043],\n",
      "         [0.00610352, -0.00291443, -0.0106201, ..., -0.0166016,\n",
      "          0.000591278, 0.0247803]],\n",
      "\n",
      "        [[0.00191498, -0.012207, 0.00300598, ..., -0.00138855,\n",
      "          0.00408936, -0.00300598],\n",
      "         [0.015564, 0.00527954, -0.00506592, ..., -0.00927734,\n",
      "          0.000907898, 0.0050354],\n",
      "         [-0.00254822, -0.00765991, 0.00370789, ..., -0.013855,\n",
      "          0.0088501, -0.00515747],\n",
      "         ...,\n",
      "         [-0.0090332, 0.0317383, 0.000648499, ..., -0.0107422,\n",
      "          -0.000200272, 0.000495911],\n",
      "         [0.0102539, 0.00188446, -0.00683594, ..., 0.0167236,\n",
      "          -0.0106201, 0.0203857],\n",
      "         [0.0057373, -0.00689697, 0.00872803, ..., 0.00469971,\n",
      "          0.00588989, -0.000576019]],\n",
      "\n",
      "        [[-0.00848389, -0.0050354, -0.00552368, ..., -0.00805664,\n",
      "          -0.00756836, 0.00500488],\n",
      "         [-0.0109253, -0.0229492, -0.00185394, ..., -0.0126953,\n",
      "          0.0116577, -0.0169678],\n",
      "         [-0.0183105, 0.00552368, -0.00762939, ..., -0.00872803,\n",
      "          -0.000915527, 0.00674438],\n",
      "         ...,\n",
      "         [-0.00473022, -0.0119629, -0.0154419, ..., 0.00476074,\n",
      "          -0.00964355, 0.000911713],\n",
      "         [-0.0090332, 0.0167236, 0.00488281, ..., 0.00273132,\n",
      "          -0.0151978, 0.00567627],\n",
      "         [-0.0128784, 0.00540161, 0.00765991, ..., -0.0185547,\n",
      "          -0.00527954, -0.00964355]],\n",
      "\n",
      "        [[-0.00692749, -0.0162354, 0.00939941, ..., -0.0140991,\n",
      "          0.0148315, -0.0201416],\n",
      "         [0.0018158, 4.64916e-05, 0.00976562, ..., 0.0303955,\n",
      "          0.00643921, 0.0114136],\n",
      "         [0.0245361, 0.0144653, 0.0055542, ..., 0.0147705, -0.00915527,\n",
      "          0.000480652],\n",
      "         ...,\n",
      "         [-0.001091, -0.00976562, -0.0019989, ..., -0.00585938,\n",
      "          -0.00506592, -0.00689697],\n",
      "         [0.00372314, -0.0240479, -0.0100098, ..., 0.0065918,\n",
      "          -0.0120239, -0.0109253],\n",
      "         [0.0223389, -0.00765991, 0.00325012, ..., 0.00921631,\n",
      "          -0.00515747, 0.0111694]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.0062561, 0.0123291, 0.0133057, ..., 0.0137329, 2.80142e-05,\n",
      "         -0.00144196],\n",
      "        [-0.012146, 0.00387573, 0.0106201, ..., -0.0341797, 0.0163574,\n",
      "         0.0172119],\n",
      "        [-0.00842285, 0.00424194, 6.4373e-05, ..., -0.00389099,\n",
      "         -0.0317383, 0.0253906],\n",
      "        ...,\n",
      "        [0.0140381, -0.000843048, -0.020874, ..., 0.00393677,\n",
      "         -0.00793457, 0.0284424],\n",
      "        [-0.0126953, 0.0212402, -0.0127563, ..., -0.000904083,\n",
      "         0.0105591, -0.0314941],\n",
      "        [0.00175476, -0.00891113, -0.0388184, ..., -0.0136719,\n",
      "         0.0144043, 0.0181885]],\n",
      "\n",
      "       [[-0.00349426, -0.00564575, 0.0177002, ..., 0.013916,\n",
      "         -0.00817871, -0.00218201],\n",
      "        [-0.00430298, 0.00970459, -0.00787354, ..., 0.00241089,\n",
      "         -0.000846863, 0.0211182],\n",
      "        [-0.00543213, 0.00787354, 0.0253906, ..., 0.0273438,\n",
      "         -0.00363159, 0.00222778],\n",
      "        ...,\n",
      "        [0.00509644, -0.00297546, 0.00460815, ..., 0.0299072,\n",
      "         -0.0144043, -0.0126343],\n",
      "        [-0.00344849, 0.00747681, 0.0088501, ..., -0.0164795, 0.0157471,\n",
      "         -0.0145264],\n",
      "        [-0.0098877, -0.00747681, 0.0211182, ..., -0.0147705, 0.0115967,\n",
      "         0.0161133]],\n",
      "\n",
      "       [[2.49147e-05, 0.00156403, 0.00202942, ..., -0.00280762,\n",
      "         0.00160217, 0.0495605],\n",
      "        [-0.00311279, 0.012207, 0.00134277, ..., 0.00230408,\n",
      "         -0.00689697, -0.02771],\n",
      "        [0.00927734, 0.0072937, 0.00469971, ..., -0.00723267,\n",
      "         -0.0151367, 0.00897217],\n",
      "        ...,\n",
      "        [-0.00178528, -0.00793457, -0.00817871, ..., 0.0339355,\n",
      "         -0.00958252, -0.00598145],\n",
      "        [-0.00442505, -0.00952148, -0.0150757, ..., 0.0187988,\n",
      "         0.00747681, -0.0247803],\n",
      "        [0.00282288, -0.0032959, -0.0100098, ..., -0.0183105,\n",
      "         -0.0179443, -0.0169678]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00830078, 0.00595093, -0.0206299, ..., -0.00349426,\n",
      "         -0.0183105, -0.00775146],\n",
      "        [-0.00439453, 0.000976562, 0.00747681, ..., -0.0305176,\n",
      "         0.0131226, -0.00537109],\n",
      "        [0.000572205, 0.0123291, -0.0133667, ..., 0.00549316,\n",
      "         -0.000482559, 0.00424194],\n",
      "        ...,\n",
      "        [0.00390625, -0.00619507, -0.0212402, ..., -0.0179443,\n",
      "         -0.00976562, -0.000123024],\n",
      "        [-0.00708008, 0.00534058, -0.00411987, ..., 0.00735474,\n",
      "         -0.00133514, -0.00184631],\n",
      "        [-0.00515747, -0.0130615, 0.0158691, ..., -0.0098877,\n",
      "         -0.00534058, 0.020874]],\n",
      "\n",
      "       [[-0.00370789, -0.000587463, -0.00457764, ..., -0.0143433,\n",
      "         0.0045166, 0.0181885],\n",
      "        [-0.00653076, 0.0270996, -0.00436401, ..., 0.00643921,\n",
      "         0.000425339, -0.0334473],\n",
      "        [0.00056839, -0.0158691, -0.00735474, ..., -0.0112305,\n",
      "         0.00396729, 0.0105591],\n",
      "        ...,\n",
      "        [-0.00683594, -0.00408936, -0.00215149, ..., -0.00415039,\n",
      "         -0.0262451, 0.00939941],\n",
      "        [0.0147705, -0.0136719, -3.93391e-05, ..., 0.019165, 0.0123901,\n",
      "         -0.0119629],\n",
      "        [-0.00230408, 0.0134888, 0.00179291, ..., 0.0158691, 0.0043335,\n",
      "         -0.00897217]],\n",
      "\n",
      "       [[0.00257874, -0.00384521, -0.00231934, ..., -0.0279541,\n",
      "         0.00653076, 0.0219727],\n",
      "        [0.00274658, -0.00311279, -0.00180817, ..., -0.0189209,\n",
      "         0.00952148, -0.0358887],\n",
      "        [-0.00860596, 0.00408936, -0.00479126, ..., -0.0203857,\n",
      "         0.0322266, 0.0378418],\n",
      "        ...,\n",
      "        [-0.000991821, 0.00921631, 0.00561523, ..., 0.00878906,\n",
      "         -0.041748, -0.00653076],\n",
      "        [-0.00595093, 0.010437, 0.000118256, ..., 0.0111084, 0.0336914,\n",
      "         -0.00195312],\n",
      "        [-0.00860596, 0.00188446, -0.00161743, ..., 0.0216064,\n",
      "         0.0157471, -0.0268555]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00372314, 0.00527954, -0.00463867, ..., 0.00141144,\n",
      "         0.00518799, -0.00280762],\n",
      "        [0.00244141, 0.00454712, -0.00302124, ..., 0.00637817,\n",
      "         0.00411987, 0.00332642],\n",
      "        [0.000312805, -0.00970459, 0.00497437, ..., 0.00817871,\n",
      "         -0.00668335, -0.0100708],\n",
      "        ...,\n",
      "        [0.00128174, -0.00793457, 0.0103149, ..., 0.00601196,\n",
      "         -0.00360107, 0.0141602],\n",
      "        [0.0131836, -0.0124512, -0.000495911, ..., 0.0062561, 0.0201416,\n",
      "         -0.00263977],\n",
      "        [-0.00823975, 0.00212097, 0.00811768, ..., -0.00939941,\n",
      "         -0.00457764, -0.00242615]],\n",
      "\n",
      "       [[0.00110626, -0.00113678, -0.001091, ..., 0.00363159,\n",
      "         0.00610352, -0.00210571],\n",
      "        [0.0109863, -0.00479126, 0.00286865, ..., 0.00860596,\n",
      "         -0.00445557, -0.0050354],\n",
      "        [0.00328064, 0.00915527, 0.00753784, ..., 0.0125732,\n",
      "         -0.00970459, -0.00222778],\n",
      "        ...,\n",
      "        [-0.00202942, 0.00171661, 7.43866e-05, ..., -1.62125e-05,\n",
      "         -0.0198975, -0.0164795],\n",
      "        [0.00075531, 0.0045166, 0.00872803, ..., 0.0088501, -0.0090332,\n",
      "         0.0136108],\n",
      "        [-0.00506592, 0.00182343, 0.00778198, ..., -0.00149536,\n",
      "         -0.0071106, 0.00524902]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00393677, 0.00209045, -0.0140991, ..., -0.00386047,\n",
      "        -0.0123901, 0.00726318],\n",
      "       [-0.000331879, 0.00204468, -0.0101318, ..., -0.00121307,\n",
      "        0.0088501, -0.0050354],\n",
      "       [0.00126648, 0.000553131, 0.00234985, ..., -0.00521851,\n",
      "        -0.00653076, -0.0112305],\n",
      "       ...,\n",
      "       [-0.00242615, -0.00778198, -0.000192642, ..., -0.00717163,\n",
      "        0.00897217, 0.00274658],\n",
      "       [-0.00402832, -0.00273132, 0.00485229, ..., 0.00445557,\n",
      "        -0.0030365, -0.00927734],\n",
      "       [0.00236511, 0.00588989, 0.00753784, ..., 0.00762939, 0.00259399,\n",
      "        0.00494385]], dtype=bfloat16), a=Array([[ 0.00068823,  0.00820747,  0.00691753, ..., -0.01032871,\n",
      "         0.01214039, -0.01452747],\n",
      "       [-0.00807814, -0.00087587,  0.01156158, ..., -0.00500905,\n",
      "         0.0198493 ,  0.00917682]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.54688, 2.875, 2.70312, ..., 2.375, 2.73438, 2.35938], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([3.73438, 3.75, 3.84375, ..., 3.57812, 3.89062, 3.48438], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.232422, 0.261719, 0.180664, ..., 0.330078, 0.298828, 0.355469],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.090332, -0.0563965, -0.0976562, ..., -0.104004, -0.11084,\n",
      "       -0.0168457], dtype=bfloat16)}}, 'layer_23': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.0125122, -0.0043335, -0.000934601, ..., -0.0128784,\n",
      "         0.003479, 0.00340271],\n",
      "        [0.00946045, -0.0143433, -0.0109253, ..., 0.00334167,\n",
      "         -0.00372314, 0.00442505],\n",
      "        [0.00139618, 0.00994873, 0.000694275, ..., 0.00265503,\n",
      "         0.0152588, -0.00473022],\n",
      "        ...,\n",
      "        [-0.0088501, 0.00952148, -0.012146, ..., 0.00165558, -0.0151367,\n",
      "         -0.00175476],\n",
      "        [-0.00476074, 0.00341797, -0.00167084, ..., 0.0133057,\n",
      "         -0.0145264, -0.0125732],\n",
      "        [-0.00209045, 0.0127563, -0.00561523, ..., 0.00191498,\n",
      "         -0.00427246, 0.000195503]],\n",
      "\n",
      "       [[0.00628662, 0.00836182, -0.000455856, ..., 0.0166016,\n",
      "         0.00726318, -0.00427246],\n",
      "        [-0.0144043, 0.0177002, 0.0183105, ..., -0.0030365, 0.0136719,\n",
      "         -0.00604248],\n",
      "        [0.0014267, -0.010437, -0.0116577, ..., -0.00872803, -0.0168457,\n",
      "         0.00315857],\n",
      "        ...,\n",
      "        [0.0106812, -0.0105591, 0.0153809, ..., -0.0106201, 0.00759888,\n",
      "         0.000915527],\n",
      "        [-0.00897217, -0.00750732, -0.00457764, ..., -0.0133667,\n",
      "         0.0128784, 0.00332642],\n",
      "        [0.00680542, -0.0116577, 0.00854492, ..., -0.00285339,\n",
      "         0.00585938, 0.00294495]],\n",
      "\n",
      "       [[-0.00256348, 0.00306702, -0.00415039, ..., 0.0166016,\n",
      "         -0.0133667, -0.00294495],\n",
      "        [-0.00506592, -0.0164795, 0.00479126, ..., -0.0241699,\n",
      "         0.000299454, 0.00515747],\n",
      "        [0.0140991, 0.010498, 0.00753784, ..., -0.00253296, -0.00686646,\n",
      "         -5.36442e-05],\n",
      "        ...,\n",
      "        [-0.00692749, -0.00927734, 0.0280762, ..., -0.00279236,\n",
      "         -0.00643921, -0.00601196],\n",
      "        [0.0170898, 0.00506592, 0.000450134, ..., 0.000846863, 0.019043,\n",
      "         0.00595093],\n",
      "        [0.0109863, 0.00105286, 0.0133057, ..., 0.0143433, -0.00162506,\n",
      "         -0.000816345]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.0144043, 0.00396729, -0.0065918, ..., -0.00561523, 0.0180664,\n",
      "         0.0101929],\n",
      "        [-0.00402832, -0.0194092, 0.00218201, ..., 0.0123291, 0.0108643,\n",
      "         -0.00107574],\n",
      "        [0.0127563, -0.00878906, 0.00701904, ..., 0.019043, -0.00616455,\n",
      "         0.00022316],\n",
      "        ...,\n",
      "        [-0.0114746, -0.00193024, 0.0158691, ..., 0.00315857,\n",
      "         -0.00276184, 0.0130005],\n",
      "        [-0.00289917, 0.00518799, -0.00445557, ..., 0.00735474,\n",
      "         0.00370789, -0.00811768],\n",
      "        [0.00221252, -0.0065918, 0.00160217, ..., -0.00723267,\n",
      "         -0.00552368, 0.0137939]],\n",
      "\n",
      "       [[5.76973e-05, -0.0018692, -0.00811768, ..., -0.00970459,\n",
      "         0.00102997, 0.010498],\n",
      "        [-0.0178223, 0.0115356, 0.00119019, ..., -0.0108643, -0.0161133,\n",
      "         -0.00189209],\n",
      "        [0.0136719, 0.0214844, 0.0162354, ..., 0.017334, -0.00069809,\n",
      "         -0.00778198],\n",
      "        ...,\n",
      "        [0.00344849, -0.0119629, -0.019165, ..., -0.000865936,\n",
      "         -0.00227356, 0.00933838],\n",
      "        [0.010376, -0.0129395, 0.00994873, ..., -0.000709534, 0.0136108,\n",
      "         0.0130005],\n",
      "        [-0.00273132, 0.00147247, 0.0132446, ..., 0.00723267,\n",
      "         0.00933838, -0.00717163]],\n",
      "\n",
      "       [[0.00637817, 0.00735474, 0.000268936, ..., -0.00704956,\n",
      "         -0.00717163, -0.000843048],\n",
      "        [-0.00253296, -0.00558472, -0.0071106, ..., 0.015625,\n",
      "         -7.58171e-05, 0.00119781],\n",
      "        [0.00927734, -0.0117798, -0.00325012, ..., -0.0117798,\n",
      "         0.00854492, -0.0134888],\n",
      "        ...,\n",
      "        [-0.0239258, -0.00193024, 0.00921631, ..., -0.00628662,\n",
      "         -0.0142822, -0.00778198],\n",
      "        [-0.00215149, -0.0103149, -0.0247803, ..., -0.0035553,\n",
      "         0.0112915, 0.0126343],\n",
      "        [-0.00297546, -0.0217285, -0.00689697, ..., -0.00263977,\n",
      "         0.0098877, 0.0198975]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.015564, 0.00558472, 0.00100708, ..., 0.0016098,\n",
      "          -0.0285645, -0.0078125],\n",
      "         [0.0179443, -0.0249023, 0.0014267, ..., 0.00695801,\n",
      "          0.00860596, 0.0139771],\n",
      "         [-0.00805664, -0.00680542, -0.00151062, ..., -0.00570679,\n",
      "          0.00448608, 0.00927734],\n",
      "         ...,\n",
      "         [0.00741577, -0.00482178, 0.00448608, ..., 0.0186768,\n",
      "          0.00805664, -0.00238037],\n",
      "         [0.0014801, 0.0158691, -0.00753784, ..., -0.00674438,\n",
      "          -0.0045166, -0.00369263],\n",
      "         [-0.0057373, 0.0132446, 0.0103149, ..., 0.00558472,\n",
      "          0.00799561, -0.00222778]],\n",
      "\n",
      "        [[0.0062561, 0.00288391, 0.00334167, ..., -0.0102539,\n",
      "          0.00294495, -0.0184326],\n",
      "         [0.00289917, 0.000282288, 0.0072937, ..., 0.00221252,\n",
      "          0.00552368, 0.00231934],\n",
      "         [0.00283813, 0.020752, 0.0125122, ..., 0.0110474, 0.0117188,\n",
      "          0.00878906],\n",
      "         ...,\n",
      "         [-0.0112915, -0.00817871, -0.00424194, ..., 0.00570679,\n",
      "          -0.0132446, 0.00970459],\n",
      "         [0.00952148, 0.0131836, -0.00180054, ..., -0.00909424,\n",
      "          -0.00376892, 0.0130615],\n",
      "         [0.00527954, -0.0186768, -0.00488281, ..., -0.00720215,\n",
      "          -0.0128784, 0.0310059]],\n",
      "\n",
      "        [[-0.00231934, 0.000329971, 0.00897217, ..., 0.00964355,\n",
      "          -0.00939941, -0.00595093],\n",
      "         [-0.00473022, 0.0057373, 0.0115356, ..., -0.00106812,\n",
      "          0.0219727, -0.00172424],\n",
      "         [0.00123596, 0.00418091, 0.0137329, ..., -0.00326538,\n",
      "          -0.00332642, -0.0150757],\n",
      "         ...,\n",
      "         [-0.00601196, 0.00121307, 0.00396729, ..., -0.0109863,\n",
      "          -0.00299072, 0.0126953],\n",
      "         [0.00759888, 0.00860596, -0.00328064, ..., -0.00756836,\n",
      "          -0.00830078, -0.0283203],\n",
      "         [-0.0100098, -0.00817871, -0.000370026, ..., -0.0268555,\n",
      "          0.00334167, -0.0256348]],\n",
      "\n",
      "        [[0.00717163, 0.00415039, 0.00494385, ..., 0.0148315,\n",
      "          0.00122833, -0.00262451],\n",
      "         [-0.0132446, -0.00430298, 0.00494385, ..., 0.00485229,\n",
      "          0.0140991, 0.0072937],\n",
      "         [-0.00921631, -0.00515747, 0.0072937, ..., -0.00830078,\n",
      "          0.0131836, 0.00680542],\n",
      "         ...,\n",
      "         [0.0119019, -2.45571e-05, -0.00561523, ..., 0.0118408,\n",
      "          0.0308838, -0.00105286],\n",
      "         [0.0116577, -0.0032959, -0.00236511, ..., -0.000865936,\n",
      "          0.00488281, 0.00497437],\n",
      "         [0.00726318, 0.00823975, 0.00292969, ..., 0.00289917,\n",
      "          0.00331116, -0.0122681]]],\n",
      "\n",
      "\n",
      "       [[[-0.0115356, 0.0196533, -0.00463867, ..., -0.00769043,\n",
      "          -0.00628662, -0.00537109],\n",
      "         [-0.00921631, -0.00457764, 0.026123, ..., 0.0209961,\n",
      "          0.0187988, 0.00436401],\n",
      "         [-0.00372314, -0.0112915, 0.0131226, ..., -0.0137329,\n",
      "          -0.00259399, -0.00817871],\n",
      "         ...,\n",
      "         [-0.0157471, 0.00750732, 0.00939941, ..., 0.00274658,\n",
      "          0.0101929, 0.00201416],\n",
      "         [0.00177765, -0.00318909, 0.0127563, ..., -0.0108643,\n",
      "          -0.0194092, -0.00136566],\n",
      "         [0.00717163, -0.00854492, -0.00656128, ..., 0.000682831,\n",
      "          -0.00698853, 0.0019989]],\n",
      "\n",
      "        [[0.00823975, -0.00549316, 0.00257874, ..., -0.0159912,\n",
      "          0.00933838, 0.00482178],\n",
      "         [0.0100708, -0.0101318, -0.0185547, ..., 0.00778198,\n",
      "          -0.00836182, 0.00271606],\n",
      "         [-0.00708008, -0.00325012, -0.0157471, ..., -0.0161133,\n",
      "          -0.00714111, -0.00628662],\n",
      "         ...,\n",
      "         [-0.0136719, 0.00646973, 0.00239563, ..., -0.0264893,\n",
      "          0.0123291, 0.00674438],\n",
      "         [-0.00300598, -0.00909424, -0.00787354, ..., 0.0262451,\n",
      "          3.01003e-06, 0.0272217],\n",
      "         [-0.00970459, 0.0143433, 0.00787354, ..., -0.0216064,\n",
      "          0.00369263, -0.0222168]],\n",
      "\n",
      "        [[0.0128174, 0.0072937, 0.0128174, ..., -0.0120239, -0.0155029,\n",
      "          -0.000843048],\n",
      "         [-0.000637054, -0.0106812, -0.00257874, ..., -0.0123291,\n",
      "          -0.00588989, 0.0019989],\n",
      "         [-0.00564575, 0.00744629, -0.00747681, ..., 0.00491333,\n",
      "          0.00753784, -0.00842285],\n",
      "         ...,\n",
      "         [0.0123901, 0.00750732, -0.00619507, ..., -0.00244141,\n",
      "          -0.00909424, -0.00157166],\n",
      "         [0.019043, 0.019165, -0.00250244, ..., 0.00848389,\n",
      "          -0.000328064, 0.012207],\n",
      "         [0.0200195, -0.0110474, 0.00141144, ..., 0.0200195, 0.0162354,\n",
      "          -0.0236816]],\n",
      "\n",
      "        [[-0.00366211, -0.0146484, -0.00144958, ..., -0.000197411,\n",
      "          -0.0187988, -0.0106812],\n",
      "         [0.0161133, 0.00994873, 0.000205994, ..., 0.0114746,\n",
      "          -0.00141907, -0.00320435],\n",
      "         [-0.00582886, 0.00842285, -0.0067749, ..., -0.00613403,\n",
      "          -0.0134888, -0.00854492],\n",
      "         ...,\n",
      "         [0.0115356, -0.0253906, 0.0098877, ..., -0.0125732,\n",
      "          -0.00202942, 0.0200195],\n",
      "         [-0.0214844, -0.00598145, -0.00306702, ..., 0.00350952,\n",
      "          0.0100098, -0.00650024],\n",
      "         [0.019165, 0.0128784, -0.00418091, ..., -0.0319824,\n",
      "          0.00576782, 0.0112305]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00866699, 7.27177e-06, -0.00256348, ..., 0.0162354,\n",
      "         -0.0301514, 0.00227356],\n",
      "        [0.00166321, 0.00708008, -0.00482178, ..., 0.000196457,\n",
      "         0.0223389, 0.0214844],\n",
      "        [-0.00671387, -0.0062561, -0.0144653, ..., -0.00720215,\n",
      "         -0.022583, -0.00534058],\n",
      "        ...,\n",
      "        [-0.00344849, -0.00212097, -0.00778198, ..., 0.00283813,\n",
      "         -0.0153809, -0.0039978],\n",
      "        [0.00488281, 0.0014801, 0.00188446, ..., -0.00178528,\n",
      "         -0.0124512, 0.00811768],\n",
      "        [-0.00227356, 0.00445557, 0.00115204, ..., -0.00457764,\n",
      "         -0.00613403, -0.0195312]],\n",
      "\n",
      "       [[-0.0108032, -0.00909424, 0.010376, ..., 0.0169678, -0.00772095,\n",
      "         -0.00775146],\n",
      "        [0.000816345, -0.00759888, -0.00891113, ..., -0.00346375,\n",
      "         0.003479, 0.00842285],\n",
      "        [-0.000675201, 0.00891113, -0.0166016, ..., -0.003479,\n",
      "         -0.000747681, 0.000644684],\n",
      "        ...,\n",
      "        [0.00457764, 0.0200195, 0.010498, ..., -0.017334, 0.00265503,\n",
      "         -0.00686646],\n",
      "        [-0.00343323, 0.00689697, -0.00842285, ..., -0.00686646,\n",
      "         -0.00665283, 0.00326538],\n",
      "        [-0.0129395, 0.00154114, 0.0098877, ..., -0.00476074,\n",
      "         -0.0101929, 0.00334167]],\n",
      "\n",
      "       [[0.000272751, -0.00518799, 0.00375366, ..., -0.0305176,\n",
      "         -0.0189209, 0.00726318],\n",
      "        [-0.000299454, 0.000923157, 0.00257874, ..., -0.0223389,\n",
      "         -0.00872803, -0.00326538],\n",
      "        [-0.000339508, -0.00062561, 0.0030365, ..., -0.0324707,\n",
      "         -0.0126343, 0.00372314],\n",
      "        ...,\n",
      "        [1.18613e-05, 0.0016861, 0.00267029, ..., 0.000850677,\n",
      "         0.00424194, -0.0136719],\n",
      "        [0.000858307, 0.000701904, -0.0106201, ..., -0.0167236,\n",
      "         0.00753784, -0.0336914],\n",
      "        [-0.00445557, 0.000127792, 0.00177002, ..., 0.00488281,\n",
      "         -0.00463867, -0.0186768]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.000797272, -0.00375366, 0.0163574, ..., -0.00332642,\n",
      "         0.000152588, -0.0105591],\n",
      "        [-0.00343323, 0.00297546, -0.00405884, ..., 0.012146,\n",
      "         -0.0032959, 0.00141907],\n",
      "        [0.0098877, 0.00637817, -0.00491333, ..., 0.00582886,\n",
      "         -0.0072937, 0.00656128],\n",
      "        ...,\n",
      "        [0.000322342, 0.00244141, 0.00415039, ..., -0.0018692, 0.010498,\n",
      "         0.0192871],\n",
      "        [-0.00616455, 0.000249863, 0.00970459, ..., -0.00637817,\n",
      "         0.00357056, 0.00094986],\n",
      "        [0.00579834, -0.00260925, 0.000679016, ..., 0.00540161,\n",
      "         0.00601196, 0.0279541]],\n",
      "\n",
      "       [[-0.000595093, -0.0088501, -0.0144043, ..., -0.0159912,\n",
      "         -0.0299072, 0.0262451],\n",
      "        [0.00268555, -0.00817871, 0.00579834, ..., 4.36306e-05,\n",
      "         0.00637817, 0.00221252],\n",
      "        [-0.000206947, 0.00497437, 0.010498, ..., -5.126e-05,\n",
      "         -0.00588989, 0.0412598],\n",
      "        ...,\n",
      "        [0.0045166, 0.0019989, -0.00140381, ..., -0.0062561,\n",
      "         -0.00878906, -0.0170898],\n",
      "        [-0.00139618, 0.0139771, -0.00176239, ..., -0.0244141,\n",
      "         0.00361633, 0.0071106],\n",
      "        [-0.00436401, -0.00842285, -0.00187683, ..., -0.00106049,\n",
      "         -0.00491333, 0.0106201]],\n",
      "\n",
      "       [[-0.00285339, 0.00970459, -0.00842285, ..., -0.0108032,\n",
      "         -0.0292969, 0.0375977],\n",
      "        [-0.0179443, 0.0169678, 0.0161133, ..., 0.00166321, 0.00296021,\n",
      "         0.012207],\n",
      "        [0.00367737, 0.00439453, -0.00738525, ..., 0.00643921,\n",
      "         -0.0257568, 0.0109253],\n",
      "        ...,\n",
      "        [0.0157471, 0.00723267, 0.00133514, ..., -0.0105591, -0.019165,\n",
      "         0.0125122],\n",
      "        [0.000717163, 0.0151978, 0.00708008, ..., -0.0285645,\n",
      "         0.00866699, 0.00427246],\n",
      "        [-0.0159912, -0.0197754, 0.0128784, ..., -0.00448608,\n",
      "         -0.00354004, 0.00735474]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.001297, 0.00415039, 0.000614166, ..., -0.00891113,\n",
      "         -0.0113525, -0.013855],\n",
      "        [0.00167084, -0.00411987, 0.00518799, ..., -0.00466919,\n",
      "         0.00497437, 0.00169373],\n",
      "        [0.00546265, 0.00170135, 0.00372314, ..., 0.00744629,\n",
      "         0.00933838, 0.00236511],\n",
      "        ...,\n",
      "        [0.0122681, 0.00576782, -0.00579834, ..., 0.0050354, 0.00233459,\n",
      "         -0.00174713],\n",
      "        [0.00482178, -0.00195312, 0.00104523, ..., -0.00424194,\n",
      "         -0.0102539, 0.0120239],\n",
      "        [-0.0149536, 0.00439453, 0.00230408, ..., 0.00860596,\n",
      "         -0.00695801, 0.0147095]],\n",
      "\n",
      "       [[-0.0131226, 0.000778198, 0.0140381, ..., -0.00778198,\n",
      "         -0.00248718, -0.000667572],\n",
      "        [0.00613403, -0.00204468, 0.00332642, ..., 0.00171661,\n",
      "         -0.00524902, -0.000797272],\n",
      "        [0.00415039, 0.000109196, -0.0205078, ..., 0.010498, 0.00546265,\n",
      "         0.00170135],\n",
      "        ...,\n",
      "        [-0.00717163, 0.00326538, 0.010376, ..., -0.00424194,\n",
      "         -0.00174713, 0.00202942],\n",
      "        [0.0189209, -0.00939941, -0.00531006, ..., -0.00386047,\n",
      "         -0.00527954, -0.00558472],\n",
      "        [-0.00204468, -0.00222778, 0.00549316, ..., 0.00463867,\n",
      "         -0.00187683, -0.00387573]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00427246, -0.0030365, -0.00289917, ..., 0.00360107,\n",
      "        -0.00704956, -0.00637817],\n",
      "       [-0.00165558, -0.0067749, -0.0055542, ..., -0.00305176,\n",
      "        -0.0101929, -0.00793457],\n",
      "       [0.000318527, 0.0168457, -0.0045166, ..., 0.0150757, -0.00173187,\n",
      "        -0.00817871],\n",
      "       ...,\n",
      "       [0.00762939, -0.00921631, 2.75373e-05, ..., -0.00393677,\n",
      "        0.00860596, -0.0032196],\n",
      "       [-0.0022583, 0.00933838, 0.003479, ..., 0.00717163, 0.00778198,\n",
      "        0.013916],\n",
      "       [-0.00534058, -0.00933838, -0.00469971, ..., -0.00762939,\n",
      "        0.00482178, -0.0150757]], dtype=bfloat16), a=Array([[ 0.00148038,  0.0081275 ,  0.0149825 , ...,  0.00171928,\n",
      "        -0.0045339 ,  0.00112129],\n",
      "       [-0.01026383,  0.0025746 , -0.02289991, ..., -0.00131096,\n",
      "         0.00538384, -0.00893523]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.21875, 2.28125, 2.20312, ..., 2.07812, 2.29688, 2.03125],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.15625, 4.28125, 4.34375, ..., 4.25, 4.53125, 4], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.306641, 0.337891, 0.300781, ..., 0.367188, 0.396484, 0.429688],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.158203, -0.146484, -0.166016, ..., -0.147461, -0.173828,\n",
      "       -0.10791], dtype=bfloat16)}}, 'layer_24': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00497437, 0.020874, 0.00302124, ..., 0.0132446, 0.0116577,\n",
      "         0.00646973],\n",
      "        [0.00631714, -0.00579834, -0.00897217, ..., 0.00726318,\n",
      "         0.0117188, 0.00854492],\n",
      "        [-0.00946045, 0.0185547, 0.00367737, ..., 0.00233459,\n",
      "         0.00558472, -0.00610352],\n",
      "        ...,\n",
      "        [0.0169678, 0.0125732, 0.0244141, ..., 0.0131226, 0.0279541,\n",
      "         -0.0105591],\n",
      "        [0.00176239, -0.0257568, 0.0108643, ..., -0.00860596,\n",
      "         -0.0130005, -0.00799561],\n",
      "        [0.00326538, -0.0111084, 0.00473022, ..., -3.09944e-05,\n",
      "         0.0184326, 0.00662231]],\n",
      "\n",
      "       [[0.00958252, 0.0240479, -0.0124512, ..., -0.0098877, -0.010376,\n",
      "         0.00289917],\n",
      "        [0.0157471, -0.00799561, -0.00378418, ..., 0.0206299, 0.0136719,\n",
      "         -0.00872803],\n",
      "        [0.0145264, -0.00805664, 0.015625, ..., 0.00283813, -0.0145874,\n",
      "         0.00650024],\n",
      "        ...,\n",
      "        [-0.00799561, -0.00799561, -5.126e-05, ..., -0.0144043,\n",
      "         -0.00466919, 0.00598145],\n",
      "        [-0.0038147, -0.00234985, -0.00982666, ..., 0.0172119,\n",
      "         0.0130005, 0.0111694],\n",
      "        [-0.0222168, -0.00234985, -0.00476074, ..., -0.00497437,\n",
      "         -0.0223389, -0.00254822]],\n",
      "\n",
      "       [[0.0203857, -0.022583, 0.0131226, ..., 0.0273438, -0.00878906,\n",
      "         -0.00830078],\n",
      "        [-0.00186157, -0.00747681, -0.010376, ..., 0.0158691, 0.0167236,\n",
      "         -0.000671387],\n",
      "        [0.00157928, 0.0147705, -0.0155029, ..., -0.00031662,\n",
      "         0.00939941, 0.0220947],\n",
      "        ...,\n",
      "        [0.00823975, 0.00741577, 0.00309753, ..., 0.0133057, 0.00848389,\n",
      "         -0.00340271],\n",
      "        [-0.00674438, -0.0128784, 0.00805664, ..., -0.000154495,\n",
      "         0.00469971, 0.0172119],\n",
      "        [-0.0212402, -0.0147705, -0.00860596, ..., 0.0297852, 0.0090332,\n",
      "         0.00582886]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00976562, 0.0168457, 0.010498, ..., 0.0107422, 0.0234375,\n",
      "         -0.00665283],\n",
      "        [-0.0244141, -0.0132446, 0.0223389, ..., 0.00823975, -0.0144043,\n",
      "         0.0167236],\n",
      "        [0.00337219, 0.0132446, -0.0194092, ..., -0.0134277, 0.00219727,\n",
      "         -0.012085],\n",
      "        ...,\n",
      "        [-0.00370789, 0.0022583, -0.0019455, ..., 0.0202637, 0.0114746,\n",
      "         -0.00227356],\n",
      "        [0.0125732, -0.00125885, -0.00744629, ..., 0.0101929,\n",
      "         -0.0203857, 0.0114746],\n",
      "        [-0.0290527, 0.00842285, 0.000793457, ..., -0.00302124,\n",
      "         0.0071106, -0.0177002]],\n",
      "\n",
      "       [[-0.000322342, -0.00592041, 0.00145721, ..., 0.00402832,\n",
      "         0.00619507, -0.0045166],\n",
      "        [0.00144196, -0.00482178, 0.0015564, ..., -0.00531006,\n",
      "         -0.00872803, -0.0198975],\n",
      "        [0.0129395, -0.00515747, -0.00405884, ..., 0.0115967,\n",
      "         -0.00326538, 0.00872803],\n",
      "        ...,\n",
      "        [-0.00970459, 0.0134277, -0.00402832, ..., -0.00338745,\n",
      "         -0.0019989, -0.012085],\n",
      "        [-0.0105591, -0.00692749, 0.00262451, ..., 0.0109253,\n",
      "         -0.0112915, -0.00491333],\n",
      "        [0.0128784, -0.00601196, -0.00198364, ..., -0.00159454,\n",
      "         -0.0166016, -0.00320435]],\n",
      "\n",
      "       [[0.00552368, 0.00366211, 0.00245667, ..., -0.0146484,\n",
      "         -0.00561523, 0.00221252],\n",
      "        [0.00299072, -0.0101929, -0.00439453, ..., 0.000961304,\n",
      "         -0.00191498, 0.0234375],\n",
      "        [0.0146484, -0.0125732, -0.0272217, ..., 0.00202942, 0.0170898,\n",
      "         -0.000583649],\n",
      "        ...,\n",
      "        [0.00570679, -0.0174561, 0.022583, ..., 0.0236816, 0.000946045,\n",
      "         0.0116577],\n",
      "        [-0.00708008, -0.0169678, -0.00106049, ..., 0.00982666,\n",
      "         0.00170135, -0.00927734],\n",
      "        [0.00445557, 0.0137329, 0.000823975, ..., -0.00567627, 0.010376,\n",
      "         0.00714111]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00221252, 0.00494385, -0.00315857, ..., -0.00166321,\n",
      "          -0.00515747, 0.00872803],\n",
      "         [-0.00174713, -0.00152588, 0.00558472, ..., -0.00415039,\n",
      "          0.00460815, -0.00787354],\n",
      "         [2.53916e-05, -0.00202942, -0.00384521, ..., -0.00512695,\n",
      "          0.0146484, -0.015625],\n",
      "         ...,\n",
      "         [0.0112915, 0.00296021, -0.0183105, ..., -0.0109863,\n",
      "          -0.0101929, 0.000862122],\n",
      "         [-0.00680542, -0.00765991, 0.000364304, ..., -0.0102539,\n",
      "          0.00631714, 0.0050354],\n",
      "         [-0.0140991, 0.00958252, 0.00190735, ..., -0.00454712,\n",
      "          -0.015625, 0.00994873]],\n",
      "\n",
      "        [[-0.0245361, -0.0100098, 0.0117188, ..., 0.0180664, 0.0327148,\n",
      "          -0.0291748],\n",
      "         [-0.00326538, -0.00744629, 0.00769043, ..., 0.00952148,\n",
      "          -0.000968933, 0.00778198],\n",
      "         [0.00509644, -0.0174561, 0.0114136, ..., 0.00156403,\n",
      "          0.0216064, 0.000237465],\n",
      "         ...,\n",
      "         [0.0109863, -0.00393677, -0.00271606, ..., -0.0317383,\n",
      "          -0.0129395, 0.010498],\n",
      "         [-0.0241699, 0.00595093, 0.0112915, ..., -0.000621796,\n",
      "          0.0125122, -0.00430298],\n",
      "         [0.00668335, -0.00270081, -0.0113525, ..., -0.0136108,\n",
      "          -0.0157471, 0.0251465]],\n",
      "\n",
      "        [[-0.00469971, 0.00296021, 0.0206299, ..., 0.010498, 0.0142212,\n",
      "          -0.00454712],\n",
      "         [-0.0351562, 0.0174561, 0.0126343, ..., -0.00442505,\n",
      "          0.00494385, 0.00561523],\n",
      "         [-0.00296021, -0.0148926, 0.0124512, ..., -0.00561523,\n",
      "          -0.0122681, -0.00273132],\n",
      "         ...,\n",
      "         [0.012146, -0.0140991, 0.0196533, ..., 0.0103149, -0.00601196,\n",
      "          -0.0101318],\n",
      "         [0.00366211, -0.000991821, 0.00260925, ..., 0.0142212,\n",
      "          -0.000406265, -0.00897217],\n",
      "         [0.020752, -0.00358582, 0.0132446, ..., 0.000112534, 0.026001,\n",
      "          0.0185547]],\n",
      "\n",
      "        [[-0.00817871, 0.00043869, -0.00579834, ..., -0.0145874,\n",
      "          0.0020752, 0.00842285],\n",
      "         [0.00376892, -0.0238037, -0.0071106, ..., -0.00210571,\n",
      "          -0.0157471, 0.00436401],\n",
      "         [-0.00136566, 4.3869e-05, -0.00848389, ..., -0.00109863,\n",
      "          -0.00317383, 0.0147095],\n",
      "         ...,\n",
      "         [-0.00482178, -0.00610352, 0.000461578, ..., 0.00695801,\n",
      "          0.0181885, -0.00120544],\n",
      "         [0.00328064, -0.00427246, -0.00405884, ..., 0.00805664,\n",
      "          0.0289307, 0.000774384],\n",
      "         [-0.0161133, 0.0179443, -0.0152588, ..., -0.0153809,\n",
      "          -0.0159912, -0.00564575]]],\n",
      "\n",
      "\n",
      "       [[[0.0159912, 0.0115967, 0.0071106, ..., -0.0122681, 0.00357056,\n",
      "          -0.022583],\n",
      "         [0.0157471, -0.0131836, -0.00958252, ..., -0.00267029,\n",
      "          -0.00646973, -0.00665283],\n",
      "         [-0.00424194, -0.00958252, 0.0187988, ..., 0.0109253,\n",
      "          -0.00634766, 0.00172424],\n",
      "         ...,\n",
      "         [0.00164795, 0.0102539, 0.00860596, ..., 0.00367737,\n",
      "          0.0106201, -0.00830078],\n",
      "         [-0.00753784, 0.0178223, -0.00179291, ..., 0.00506592,\n",
      "          -0.0148315, -0.0130615],\n",
      "         [0.0117188, -0.000341415, -0.0013504, ..., 0.00408936,\n",
      "          -0.00233459, 0.00488281]],\n",
      "\n",
      "        [[-0.0196533, 0.0159912, 0.000858307, ..., -0.00759888,\n",
      "          0.00540161, 0.0286865],\n",
      "         [0.0285645, 0.0175781, -0.00756836, ..., -0.00631714,\n",
      "          4.73857e-06, 0.0256348],\n",
      "         [-0.00994873, 0.00427246, 0.0120239, ..., -0.017334,\n",
      "          0.00270081, 0.0180664],\n",
      "         ...,\n",
      "         [-0.0234375, -0.017334, -0.0123291, ..., -0.0142212,\n",
      "          -0.0123291, -0.0336914],\n",
      "         [0.0143433, -0.00909424, -0.0139771, ..., -0.0107422,\n",
      "          -0.00970459, -0.00358582],\n",
      "         [0.00964355, -0.000171661, -0.0136719, ..., 0.00656128,\n",
      "          -0.0180664, -0.0186768]],\n",
      "\n",
      "        [[0.0010376, -0.0019989, 0.00497437, ..., -0.00337219,\n",
      "          0.00375366, -0.0222168],\n",
      "         [0.00405884, 0.00376892, 0.0144043, ..., -0.00601196,\n",
      "          -0.00326538, 0.0131226],\n",
      "         [0.000488281, 0.015564, 0.00382996, ..., 0.00915527,\n",
      "          0.0107422, -0.00958252],\n",
      "         ...,\n",
      "         [0.0106812, 0.0090332, 0.0205078, ..., -0.00115204,\n",
      "          -0.00909424, 0.00787354],\n",
      "         [0.00628662, -0.00762939, 0.00866699, ..., 0.00860596,\n",
      "          0.00108337, -0.000115871],\n",
      "         [-0.0161133, 0.0147095, -0.0143433, ..., 0.0105591,\n",
      "          -0.00793457, 0.00531006]],\n",
      "\n",
      "        [[0.00958252, 0.00439453, 0.0112305, ..., 0.00653076,\n",
      "          0.00180054, 0.0128174],\n",
      "         [-3.95775e-05, 0.0126953, -0.00180817, ..., 0.00640869,\n",
      "          -0.0150146, -0.0211182],\n",
      "         [-0.00570679, -0.00585938, -0.0111694, ..., 0.00588989,\n",
      "          -0.0189209, 0.00127411],\n",
      "         ...,\n",
      "         [0.00723267, -0.000389099, 0.0185547, ..., 0.0140381,\n",
      "          0.000843048, 0.0112305],\n",
      "         [0.00302124, -0.00170898, -0.0102539, ..., 0.00628662,\n",
      "          -0.00848389, -0.00167084],\n",
      "         [0.0201416, -0.00891113, -0.0132446, ..., -0.00848389,\n",
      "          0.00634766, 0.0090332]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00372314, -0.000329971, 0.000394821, ..., 0.00280762,\n",
      "         0.0111084, 0.0108643],\n",
      "        [0.00222778, -0.00069046, 0.00268555, ..., -0.00367737,\n",
      "         0.00570679, -0.0375977],\n",
      "        [0.00150299, 0.00238037, 0.00448608, ..., 0.0397949, 0.00218201,\n",
      "         -0.00723267],\n",
      "        ...,\n",
      "        [-0.00020504, -0.0018158, -0.00213623, ..., 0.0136108,\n",
      "         0.0202637, -0.0197754],\n",
      "        [0.00415039, 0.00735474, 0.00805664, ..., 0.0150757,\n",
      "         0.000976562, -0.00891113],\n",
      "        [0.0019989, -0.00270081, 0.00546265, ..., -0.0177002,\n",
      "         -0.0272217, 0.0137329]],\n",
      "\n",
      "       [[0.0109863, -0.0155029, -0.00148773, ..., 0.00382996, 0.0194092,\n",
      "         0.0125122],\n",
      "        [0.0101318, -0.0126343, 0.00133514, ..., 0.0144653, -0.00430298,\n",
      "         0.00218201],\n",
      "        [-0.0126953, 0.00454712, 0.0136108, ..., 0.00738525, 0.0108643,\n",
      "         -0.015625],\n",
      "        ...,\n",
      "        [0.000926971, -0.0235596, 0.0125122, ..., 0.00531006, 0.0114136,\n",
      "         0.00561523],\n",
      "        [-0.00338745, 0.0162354, -0.00157928, ..., 0.0100098,\n",
      "         -0.0170898, -0.0164795],\n",
      "        [0.00811768, 0.0123291, 0.0101929, ..., -0.00497437, -0.0112915,\n",
      "         -0.0145874]],\n",
      "\n",
      "       [[-0.0147705, -0.00540161, -0.00387573, ..., -0.000196457,\n",
      "         0.00205994, -0.00521851],\n",
      "        [-0.00224304, -0.00159454, 0.00952148, ..., -0.0187988,\n",
      "         0.00683594, 0.0111694],\n",
      "        [-0.00552368, -0.0118408, 0.0213623, ..., 0.00457764,\n",
      "         0.00860596, -0.00254822],\n",
      "        ...,\n",
      "        [-0.00186157, -0.00512695, 0.00378418, ..., -0.0305176,\n",
      "         0.0022583, 0.0178223],\n",
      "        [0.00552368, 0.0037384, -0.0106812, ..., 0.0194092, 0.00376892,\n",
      "         -0.0196533],\n",
      "        [-0.0019989, -0.00231934, 0.00157928, ..., -0.0131226,\n",
      "         -0.0110474, -0.00436401]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00279236, -0.00811768, -0.00320435, ..., 0.00524902,\n",
      "         0.0115356, 0.00482178],\n",
      "        [-0.00153351, -0.00367737, -0.0100708, ..., -0.00933838,\n",
      "         0.0164795, 0.0164795],\n",
      "        [0.000263214, -0.00137329, -0.00221252, ..., -0.000137329,\n",
      "         0.0148926, -0.0184326],\n",
      "        ...,\n",
      "        [0.00163269, 0.0125122, 0.0144653, ..., -0.00640869,\n",
      "         -0.00939941, 0.00552368],\n",
      "        [0.00125885, -0.00772095, 0.00025177, ..., 0.0220947,\n",
      "         0.00878906, 0.00166321],\n",
      "        [-0.00294495, 0.00177002, 0.0065918, ..., -0.0027771,\n",
      "         0.00747681, 0.0339355]],\n",
      "\n",
      "       [[-0.00592041, 0.0043335, 0.0078125, ..., -0.0123901, -0.0194092,\n",
      "         0.0163574],\n",
      "        [-0.0133667, -0.00189972, 0.015564, ..., -0.00860596,\n",
      "         0.00805664, 0.00332642],\n",
      "        [0.00382996, -0.00588989, -0.00265503, ..., -0.015564,\n",
      "         0.0229492, -1.3113e-05],\n",
      "        ...,\n",
      "        [9.9659e-05, -0.0123901, 0.0146484, ..., -0.00747681,\n",
      "         0.00364685, -0.00360107],\n",
      "        [0.0117798, 0.00023365, -0.000295639, ..., 0.00363159,\n",
      "         -0.00193024, -0.00189972],\n",
      "        [0.0116577, 0.0012207, -0.00747681, ..., 0.00842285, 0.00317383,\n",
      "         0.0114746]],\n",
      "\n",
      "       [[0.00198364, 0.00698853, -0.0174561, ..., -0.00485229,\n",
      "         -0.00415039, -0.00897217],\n",
      "        [0.00457764, -0.00506592, 0.00131226, ..., -0.0213623,\n",
      "         -0.0500488, 0.0127563],\n",
      "        [0.00184631, -0.00130463, 0.000679016, ..., 0.00317383,\n",
      "         -0.013916, -0.032959],\n",
      "        ...,\n",
      "        [0.00212097, 0.00793457, -0.00750732, ..., 0.00689697,\n",
      "         0.0322266, 0.0200195],\n",
      "        [-0.000211716, -0.00552368, -0.000448227, ..., -0.00491333,\n",
      "         -0.00343323, -0.00473022],\n",
      "        [0.000694275, -0.00628662, 0.00469971, ..., -0.00457764,\n",
      "         0.00564575, -0.00128937]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00430298, 0.0016861, -0.0071106, ..., 0.0150757, 0.0130005,\n",
      "         0.00210571],\n",
      "        [-0.00549316, -0.00268555, 0.00460815, ..., -0.00448608,\n",
      "         0.00500488, -0.00549316],\n",
      "        [0.00823975, 0.00326538, -0.00153351, ..., 0.0101929, 0.0111694,\n",
      "         -0.00185394],\n",
      "        ...,\n",
      "        [-0.00671387, -0.0129395, 0.0249023, ..., 0.0108643, 0.00741577,\n",
      "         -0.00836182],\n",
      "        [-0.00631714, 0.0140991, 0.00915527, ..., -0.0112305,\n",
      "         0.000347137, -0.0043335],\n",
      "        [0.00265503, -0.0043335, -0.00958252, ..., -0.00579834,\n",
      "         0.00643921, 0.0045166]],\n",
      "\n",
      "       [[-0.00292969, 0.00933838, 0.0136719, ..., -0.00671387,\n",
      "         0.00082016, -0.00521851],\n",
      "        [-0.0043335, -0.000457764, -0.0115356, ..., -0.00043869,\n",
      "         -0.0030365, 0.00543213],\n",
      "        [-0.0111084, -0.017334, -0.00357056, ..., 0.00460815,\n",
      "         -0.00454712, 0.00799561],\n",
      "        ...,\n",
      "        [0.00585938, 0.00817871, -0.00308228, ..., -0.00866699,\n",
      "         -0.00723267, -0.000858307],\n",
      "        [0.00418091, -0.0120239, 0.00242615, ..., 0.0032959,\n",
      "         -7.34329e-05, 0.000499725],\n",
      "        [0.0067749, -0.00531006, -0.00872803, ..., 0.0071106,\n",
      "         0.00613403, 0.00799561]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.000617981, 0.00732422, 0.012085, ..., -0.00393677,\n",
      "        -0.00442505, -0.0090332],\n",
      "       [0.0147705, 0.010498, -0.00524902, ..., 0.00778198, -0.00952148,\n",
      "        0.00671387],\n",
      "       [-0.00787354, -0.010498, -0.000862122, ..., -0.0162354,\n",
      "        -0.00921631, -0.00415039],\n",
      "       ...,\n",
      "       [0.0113525, -0.00836182, 0.00159454, ..., 0.00460815,\n",
      "        -0.000349045, -0.0137329],\n",
      "       [0.00185394, 0.00137329, -0.00756836, ..., 0.00860596, 0.00543213,\n",
      "        0.00915527],\n",
      "       [-0.0150757, -0.00402832, 0.00286865, ..., -0.000164032,\n",
      "        0.00543213, -0.0152588]], dtype=bfloat16), a=Array([[ 0.0118248 ,  0.00209964,  0.00429165, ...,  0.00531876,\n",
      "         0.0007639 , -0.01389843],\n",
      "       [ 0.00161521,  0.01745081, -0.0089213 , ...,  0.01427022,\n",
      "        -0.00016093,  0.01795714]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.5625, 2.40625, 2.51562, ..., 2.625, 2.76562, 2.46875], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.75, 4.78125, 4.90625, ..., 5.59375, 5.34375, 4.6875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.248047, 0.223633, 0.21582, ..., 0.345703, 0.259766, 0.339844],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.188477, -0.169922, -0.19043, ..., -0.158203, -0.195312,\n",
      "       -0.142578], dtype=bfloat16)}}, 'layer_25': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00209045, -0.00415039, -0.000907898, ..., -0.0712891,\n",
      "         -0.012085, -0.000808716],\n",
      "        [0.000637054, 0.0110474, -0.00257874, ..., 0.00187683,\n",
      "         -0.00485229, 0.0177002],\n",
      "        [0.000518799, -0.0141602, 0.00421143, ..., -0.0125122,\n",
      "         -0.0264893, -0.00254822],\n",
      "        ...,\n",
      "        [-0.00250244, -0.0202637, 0.00671387, ..., -0.0234375,\n",
      "         0.0113525, 0.00488281],\n",
      "        [-0.00219727, 0.00726318, 0.00138855, ..., 0.0118408,\n",
      "         -0.0161133, -0.0120239],\n",
      "        [0.0135498, 0.00123596, -0.00418091, ..., -0.00518799,\n",
      "         0.00549316, 0.00140381]],\n",
      "\n",
      "       [[-0.00344849, 0.0055542, 0.0201416, ..., -0.024292, 0.012207,\n",
      "         0.00260925],\n",
      "        [0.00915527, -0.00396729, -0.00772095, ..., -0.00372314,\n",
      "         0.000119209, 0.0197754],\n",
      "        [0.00305176, 0.0100098, -0.00701904, ..., 0.0115967, 0.00674438,\n",
      "         0.0149536],\n",
      "        ...,\n",
      "        [0.00640869, 0.0241699, -0.0107422, ..., 0.00222778,\n",
      "         -0.00157928, 0.00332642],\n",
      "        [0.00601196, 0.00270081, 0.00314331, ..., -0.00939941,\n",
      "         -0.00708008, 0.00360107],\n",
      "        [0.0174561, 0.00762939, 0.0078125, ..., -0.0162354, 0.00634766,\n",
      "         0.00515747]],\n",
      "\n",
      "       [[0.0164795, 0.0155029, -0.00268555, ..., -0.00457764, 0.0155029,\n",
      "         0.00964355],\n",
      "        [-0.000679016, -0.0111694, 0.0178223, ..., -0.017334,\n",
      "         -0.00741577, -0.0339355],\n",
      "        [-0.00723267, -0.0228271, -0.0162354, ..., 0.0201416,\n",
      "         -0.00939941, 0.00294495],\n",
      "        ...,\n",
      "        [0.0233154, 0.000736237, -0.03125, ..., -0.013855, 0.00159454,\n",
      "         0.0115356],\n",
      "        [0.00735474, 0.0167236, -0.00665283, ..., -0.000343323,\n",
      "         0.00135803, -0.0175781],\n",
      "        [-0.00650024, -0.0108032, -0.00518799, ..., -0.00595093,\n",
      "         -0.0020752, -0.0122681]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.022583, -0.00340271, -0.0022583, ..., 0.00872803,\n",
      "         0.00958252, -0.0101318],\n",
      "        [-0.0136108, 0.00231934, 0.0131226, ..., 0.0125122, 0.00297546,\n",
      "         -0.000452042],\n",
      "        [-0.0202637, 0.0200195, -0.0132446, ..., 0.0107422, 0.0181885,\n",
      "         0.00439453],\n",
      "        ...,\n",
      "        [0.0137939, -0.00271606, -0.0102539, ..., -0.00244141,\n",
      "         0.000230789, 0.00463867],\n",
      "        [-0.00146484, -0.00695801, 0.019165, ..., -0.00132751,\n",
      "         0.00366211, -0.00836182],\n",
      "        [-0.0314941, 0.0140381, 0.0137939, ..., -0.00604248,\n",
      "         0.000411987, -0.00349426]],\n",
      "\n",
      "       [[-0.00570679, 0.0164795, -0.0136108, ..., 0.00915527, 0.0098877,\n",
      "         0.00488281],\n",
      "        [-0.00491333, -0.00106812, 0.00189972, ..., 0.00245667,\n",
      "         -4.52995e-05, 0.00285339],\n",
      "        [0.00101471, -0.0119019, -0.00564575, ..., 0.00695801,\n",
      "         -0.00448608, -0.0169678],\n",
      "        ...,\n",
      "        [0.00527954, 0.0251465, 0.0133057, ..., -0.00842285, 0.00396729,\n",
      "         0.00616455],\n",
      "        [-0.00166321, 0.0148926, 0.00753784, ..., 0.00689697,\n",
      "         0.00970459, 0.00613403],\n",
      "        [0.00836182, 0.0161133, -0.0120239, ..., 0.000896454,\n",
      "         -0.0067749, -0.00119019]],\n",
      "\n",
      "       [[0.00405884, 0.00212097, 0.0154419, ..., -0.00927734,\n",
      "         0.000349045, -0.0185547],\n",
      "        [0.0170898, -0.00738525, -0.000200272, ..., -0.00747681,\n",
      "         0.00909424, -0.00552368],\n",
      "        [0.00162506, 0.00191498, 0.00172424, ..., -0.0016861, 0.017334,\n",
      "         -0.00732422],\n",
      "        ...,\n",
      "        [0.00270081, -0.0018692, 0.00610352, ..., 0.00273132,\n",
      "         -0.00247192, -0.0126343],\n",
      "        [-0.000915527, -0.010437, 0.00720215, ..., 0.0027771,\n",
      "         0.00509644, -0.00476074],\n",
      "        [0.00512695, -0.0137329, 0.00306702, ..., 0.00402832,\n",
      "         -0.00860596, 0.00448608]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.0196533, -0.00787354, 0.00144196, ..., -0.0155029,\n",
      "          -0.0220947, -0.00457764],\n",
      "         [0.0145264, 0.00842285, -0.0135498, ..., -0.0148315,\n",
      "          0.0117798, -0.0122681],\n",
      "         [0.0032196, 0.013855, -0.00239563, ..., 0.0126953, 0.0129395,\n",
      "          0.0157471],\n",
      "         ...,\n",
      "         [-0.000180244, 0.0134888, 0.00138855, ..., 0.00915527,\n",
      "          0.00280762, 0.00338745],\n",
      "         [0.00285339, -0.00405884, -0.00878906, ..., 0.00891113,\n",
      "          -0.0128784, -0.00184631],\n",
      "         [-0.00283813, -0.00619507, -0.00445557, ..., 0.00561523,\n",
      "          -0.0238037, 0.0112305]],\n",
      "\n",
      "        [[-0.00588989, 0.0124512, -0.000211716, ..., -0.00442505,\n",
      "          -0.00601196, 0.00238037],\n",
      "         [-0.0057373, -0.0174561, -0.00265503, ..., 0.00616455,\n",
      "          -1.84774e-05, 0.00279236],\n",
      "         [0.00125885, 0.013855, -0.00297546, ..., 0.0134888,\n",
      "          -0.00872803, 0.0027771],\n",
      "         ...,\n",
      "         [-0.0255127, -0.00023365, -0.0230713, ..., 0.00860596,\n",
      "          0.00430298, -0.0065918],\n",
      "         [0.000862122, 0.00540161, -0.000356674, ..., 0.00372314,\n",
      "          0.0149536, 0.0123291],\n",
      "         [0.00145721, -0.0153198, -0.00285339, ..., 0.0130615,\n",
      "          0.00442505, -0.00952148]],\n",
      "\n",
      "        [[-0.000128746, 0.0228271, -0.000640869, ..., -0.00830078,\n",
      "          0.0045166, 0.00741577],\n",
      "         [0.00946045, -0.00112152, -0.00256348, ..., -0.0189209,\n",
      "          -0.010498, -0.00775146],\n",
      "         [-0.00701904, -0.0117798, -0.0112915, ..., -0.0134277,\n",
      "          -0.00537109, -0.00576782],\n",
      "         ...,\n",
      "         [0.0220947, -0.0192871, 0.00372314, ..., 0.00219727,\n",
      "          0.000274658, 0.00457764],\n",
      "         [-0.0090332, 0.00634766, -0.0108032, ..., -0.00131989,\n",
      "          0.0168457, 0.00787354],\n",
      "         [0.00326538, -0.00616455, 0.00759888, ..., -0.00131226,\n",
      "          -0.0115967, -0.0162354]],\n",
      "\n",
      "        [[0.00567627, -0.0108032, -0.00646973, ..., -0.000965118,\n",
      "          -0.00256348, 0.00188446],\n",
      "         [0.00772095, 0.0177002, 0.00836182, ..., 0.0128784,\n",
      "          -0.00778198, -0.0116577],\n",
      "         [-0.0128784, 0.0134277, 0.00415039, ..., -0.00247192,\n",
      "          -0.0194092, -0.00357056],\n",
      "         ...,\n",
      "         [-0.0166016, -0.0119629, -0.0168457, ..., -0.00188446,\n",
      "          -0.0244141, 0.00153351],\n",
      "         [0.00415039, -0.00270081, 0.00854492, ..., -0.0119629,\n",
      "          0.0134277, 0.0163574],\n",
      "         [0.0112915, -0.0219727, -0.00102997, ..., 0.00878906,\n",
      "          -0.00604248, 0.0067749]]],\n",
      "\n",
      "\n",
      "       [[[-0.0219727, 0.000953674, -0.00442505, ..., -0.00616455,\n",
      "          0.0141602, 0.00946045],\n",
      "         [0.00509644, 0.00476074, 0.0153198, ..., 0.00750732,\n",
      "          0.0116577, 0.00582886],\n",
      "         [0.0294189, 0.00104523, -0.017334, ..., -0.00153351,\n",
      "          0.00759888, 0.0151367],\n",
      "         ...,\n",
      "         [-0.0175781, -0.0015564, 0.00830078, ..., -0.00723267,\n",
      "          0.00445557, 0.00363159],\n",
      "         [0.0100708, -0.0127563, -0.00379944, ..., -0.000595093,\n",
      "          -0.00738525, 0.0118408],\n",
      "         [-0.00872803, 0.00656128, 0.0107422, ..., -0.000919342,\n",
      "          -0.00350952, 0.00799561]],\n",
      "\n",
      "        [[0.0231934, 0.00183868, 0.00476074, ..., 0.0107422,\n",
      "          -0.00247192, -0.0106201],\n",
      "         [0.00933838, -0.00512695, -0.03125, ..., 0.00128937,\n",
      "          0.0131226, 0.00454712],\n",
      "         [-0.00062561, 0.0219727, -0.00241089, ..., -0.0174561,\n",
      "          -0.0133667, -0.00482178],\n",
      "         ...,\n",
      "         [-0.0088501, -0.00970459, 0.0197754, ..., 0.000303268,\n",
      "          0.0233154, -0.00772095],\n",
      "         [0.0144043, -0.00793457, -0.0110474, ..., 0.00976562,\n",
      "          0.00604248, -0.00860596],\n",
      "         [0.00695801, -0.0178223, -0.0035553, ..., 0.0117188,\n",
      "          -0.0129395, 0.00257874]],\n",
      "\n",
      "        [[0.0241699, 0.0057373, 0.0167236, ..., -0.0117188, 0.00112152,\n",
      "          0.027832],\n",
      "         [0.0088501, 0.000411987, -0.0284424, ..., -0.00463867,\n",
      "          0.0148926, -0.0252686],\n",
      "         [0.00485229, -0.00540161, 0.0108643, ..., 0.0236816,\n",
      "          -0.0214844, -0.0155029],\n",
      "         ...,\n",
      "         [-0.0146484, -0.0268555, -0.00909424, ..., 0.0162354,\n",
      "          0.00811768, 0.00982666],\n",
      "         [-0.0134888, 0.00418091, -0.0150757, ..., 0.00640869,\n",
      "          -0.0109253, 0.00216675],\n",
      "         [0.0109863, -4.48227e-05, -0.00177765, ..., -0.0197754,\n",
      "          0.012146, 0.00497437]],\n",
      "\n",
      "        [[-0.0129395, -0.0135498, 0.0148926, ..., -0.00714111,\n",
      "          0.0164795, 0.0140991],\n",
      "         [0.00476074, -0.000452042, 0.000478745, ..., 0.0065918,\n",
      "          0.0137329, 0.0154419],\n",
      "         [-0.00723267, 0.000930786, -0.0112915, ..., 0.006073,\n",
      "          0.0123291, -0.00479126],\n",
      "         ...,\n",
      "         [0.0140381, -0.0045166, -0.0035553, ..., 0.00230408, 0.012146,\n",
      "          -0.0039978],\n",
      "         [0.00308228, -0.00939941, -0.0140991, ..., 0.000329971,\n",
      "          -0.00317383, -0.00585938],\n",
      "         [0.0032196, 0.019043, 0.00260925, ..., 0.00787354, 0.0164795,\n",
      "          -0.00665283]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00360107, -0.0090332, -0.0025177, ..., 0.00239563,\n",
      "         -0.00735474, 0.00689697],\n",
      "        [0.00543213, -0.00297546, -0.00231934, ..., -0.0122681,\n",
      "         0.00241089, -0.012207],\n",
      "        [-0.00723267, 9.67979e-05, 0.0114746, ..., -0.00247192,\n",
      "         0.00524902, -0.0130005],\n",
      "        ...,\n",
      "        [-0.000492096, -0.000682831, -0.000747681, ..., -0.0168457,\n",
      "         -0.0303955, -0.00759888],\n",
      "        [-0.00154114, 0.0078125, 0.00454712, ..., -0.00537109,\n",
      "         -0.0134277, 0.0220947],\n",
      "        [0.00540161, -0.000324249, -0.00402832, ..., 0.010437,\n",
      "         0.0170898, 0.00219727]],\n",
      "\n",
      "       [[0.0229492, 0.0130615, -0.0170898, ..., 0.00494385, 0.0184326,\n",
      "         -0.0180664],\n",
      "        [-0.0119019, 0.00640869, 0.0222168, ..., -0.00738525,\n",
      "         0.00799561, -0.00384521],\n",
      "        [0.0109253, 0.00367737, -0.0078125, ..., -0.00683594,\n",
      "         0.00897217, -0.000926971],\n",
      "        ...,\n",
      "        [-0.0150757, -0.0324707, 0.0175781, ..., -0.0167236, -0.0159912,\n",
      "         0.00227356],\n",
      "        [0.0071106, 0.015625, -0.00537109, ..., 0.0217285, 0.00976562,\n",
      "         -0.00100708],\n",
      "        [0.00897217, -0.0122681, -0.0128174, ..., -0.000153542,\n",
      "         -0.00601196, 0.00405884]],\n",
      "\n",
      "       [[-0.000408173, 0.00717163, -0.0179443, ..., 0.000150681,\n",
      "         0.0264893, -0.0147095],\n",
      "        [-0.000469208, -0.00349426, 0.00350952, ..., 0.0270996,\n",
      "         0.00836182, 0.012146],\n",
      "        [-0.00151062, 0.00128174, 0.00970459, ..., 0.0184326,\n",
      "         0.00582886, -0.0106812],\n",
      "        ...,\n",
      "        [0.0114136, 0.00302124, 0.00952148, ..., -0.0222168,\n",
      "         -0.00778198, 0.0135498],\n",
      "        [0.0166016, 0.000740051, -0.00152588, ..., -0.00726318,\n",
      "         -0.00233459, 0.0130615],\n",
      "        [0.0111694, 0.00157928, 0.00273132, ..., 0.00921631, 0.0103149,\n",
      "         -0.0218506]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00860596, 0.0155029, -0.0322266, ..., -0.0161133,\n",
      "         0.00531006, 0.00112152],\n",
      "        [0.00308228, 0.00445557, 0.00695801, ..., 6.58035e-05,\n",
      "         -0.00164032, -0.00378418],\n",
      "        [-0.0072937, 0.00340271, -0.0251465, ..., 0.00750732,\n",
      "         -1.71661e-05, 0.0120239],\n",
      "        ...,\n",
      "        [0.00360107, 0.00558472, -0.00723267, ..., -3.79086e-05,\n",
      "         -0.00546265, 0.000201225],\n",
      "        [0.00245667, 0.00131226, -0.0151367, ..., -0.00192261,\n",
      "         0.00842285, 0.0112915],\n",
      "        [0.00595093, 0.00482178, 0.0228271, ..., 0.00500488, -0.0112915,\n",
      "         -0.0166016]],\n",
      "\n",
      "       [[-0.0038147, 0.00524902, -0.00234985, ..., 0.0103149,\n",
      "         0.000938416, 0.00750732],\n",
      "        [-0.00616455, 0.00485229, 0.00279236, ..., 0.0172119,\n",
      "         -0.00994873, -0.00674438],\n",
      "        [-0.001297, 0.00162506, 0.0065918, ..., -0.00183105, -0.0134888,\n",
      "         -0.0196533],\n",
      "        ...,\n",
      "        [-0.00245667, -0.00485229, -0.00335693, ..., -0.0098877,\n",
      "         -0.000705719, -0.00218201],\n",
      "        [-0.00540161, 0.000793457, 0.000892639, ..., 0.00186157,\n",
      "         -0.000448227, -0.00430298],\n",
      "        [-0.0030365, -0.0119019, -0.00811768, ..., -0.0112915,\n",
      "         0.0209961, 0.00817871]],\n",
      "\n",
      "       [[0.00364685, -0.00375366, 0.00726318, ..., 0.00836182,\n",
      "         -0.00592041, -0.00189972],\n",
      "        [-0.00379944, 0.00173187, -0.00460815, ..., -0.0078125,\n",
      "         -0.00811768, -0.0110474],\n",
      "        [0.00424194, 0.00674438, -0.00296021, ..., 0.0100708, -0.026001,\n",
      "         0.00772095],\n",
      "        ...,\n",
      "        [0.00227356, 0.00946045, -0.00494385, ..., 0.00479126,\n",
      "         -0.0202637, -0.000843048],\n",
      "        [0.000801086, -0.00427246, -0.00117493, ..., 0.000976562,\n",
      "         -0.000873566, -0.0100098],\n",
      "        [0.00643921, -0.0045166, 0.0100098, ..., 0.00576782, 0.00567627,\n",
      "         -0.0142822]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00134277, -0.0019989, -0.00135803, ..., 0.00349426,\n",
      "         0.006073, -0.00616455],\n",
      "        [-0.00325012, -0.0118408, 0.00141907, ..., 0.00158691,\n",
      "         -0.0088501, 0.00375366],\n",
      "        [-0.00500488, 0.00619507, 0.000537872, ..., 0.00613403,\n",
      "         -0.0141602, 9.67979e-05],\n",
      "        ...,\n",
      "        [-0.00210571, 0.00927734, -0.00171661, ..., -0.0108032,\n",
      "         0.00457764, -0.00524902],\n",
      "        [0.00187683, -0.0043335, 0.00047493, ..., 0.00805664,\n",
      "         -0.00582886, 0.00121307],\n",
      "        [-0.00512695, 0.0189209, 0.00549316, ..., 0.0090332, 0.0112305,\n",
      "         -0.00180054]],\n",
      "\n",
      "       [[-0.000442505, 0.00631714, -0.0145264, ..., 0.0116577,\n",
      "         -0.0285645, 0.0109863],\n",
      "        [-0.00811768, 0.00735474, 0.000740051, ..., 0.00543213,\n",
      "         0.0159912, -0.00104523],\n",
      "        [0.000354767, 0.00460815, 0.00811768, ..., -0.00714111,\n",
      "         0.000473022, -0.00463867],\n",
      "        ...,\n",
      "        [0.00567627, 0.00294495, 0.000293732, ..., -0.00643921,\n",
      "         -0.0001688, 0.00521851],\n",
      "        [-0.00044632, -0.0162354, -0.0045166, ..., -0.0133667,\n",
      "         0.00102997, 0.00460815],\n",
      "        [0.000747681, 0.00662231, -0.00585938, ..., 0.0136108,\n",
      "         -0.0057373, 0.00769043]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00257874, 0.00442505, -0.00585938, ..., -0.000991821,\n",
      "        -0.00772095, -0.010437],\n",
      "       [0.00349426, -0.00023365, 0.0017395, ..., -0.00118256,\n",
      "        0.000984192, 0.00157928],\n",
      "       [-0.00170898, 0.00787354, -0.00218201, ..., 0.00439453,\n",
      "        -0.00270081, 0.00552368],\n",
      "       ...,\n",
      "       [0.0108032, 0.00576782, 0.00878906, ..., 0.00213623, 0.000214577,\n",
      "        0.00247192],\n",
      "       [-0.00750732, 0.00897217, 0.0100098, ..., -0.0163574, 0.0020752,\n",
      "        0.00190735],\n",
      "       [-0.00193787, 0.00216675, 0.00515747, ..., 0.0039978, -0.00384521,\n",
      "        -0.0078125]], dtype=bfloat16), a=Array([[-0.005503  , -0.00465591,  0.02688703, ...,  0.00167953,\n",
      "        -0.00383867,  0.01666052],\n",
      "       [ 0.00788943, -0.01279993, -0.01336973, ...,  0.00526251,\n",
      "        -0.00046879,  0.01022278]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.39062, 2.375, 2.32812, ..., 3.42188, 2.84375, 2.29688], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.6875, 4.84375, 4.9375, ..., 5.9375, 4.5625, 4.6875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.296875, 0.261719, 0.265625, ..., 0.380859, 0.296875, 0.373047],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.136719, -0.134766, -0.133789, ..., -0.0761719, -0.129883,\n",
      "       -0.105957], dtype=bfloat16)}}, 'layer_3': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.015625, -0.0299072, 0.0206299, ..., -0.0202637, 0.0197754,\n",
      "         -0.012207],\n",
      "        [-0.0192871, 0.0227051, 0.0184326, ..., 0.0123291, 0.00288391,\n",
      "         0.0112305],\n",
      "        [0.000459671, 0.00396729, -0.0102539, ..., -0.0130615,\n",
      "         0.00952148, -0.0108032],\n",
      "        ...,\n",
      "        [0.019043, -0.00643921, -0.0116577, ..., -0.00726318,\n",
      "         0.00836182, -0.00267029],\n",
      "        [-0.0019989, 0.0212402, -0.00149536, ..., -0.00289917,\n",
      "         0.0106812, 0.00469971],\n",
      "        [0.00921631, -0.00738525, -0.00189209, ..., 0.00689697,\n",
      "         -5.36442e-05, 0.000396729]],\n",
      "\n",
      "       [[0.000303268, -0.0166016, -0.00671387, ..., 0.0151367,\n",
      "         0.0283203, 0.00352478],\n",
      "        [-0.00448608, 0.0101318, 0.0255127, ..., -0.0157471, 0.00933838,\n",
      "         0.0114746],\n",
      "        [0.0178223, 0.00769043, -0.0124512, ..., -0.00701904,\n",
      "         0.00369263, 0.00765991],\n",
      "        ...,\n",
      "        [-0.00765991, 0.00127411, 0.0045166, ..., 0.00567627, 0.0152588,\n",
      "         0.0078125],\n",
      "        [-0.00262451, 0.00268555, -0.00546265, ..., 0.0234375,\n",
      "         0.00167084, -0.0037384],\n",
      "        [-0.0136108, -0.0147705, 0.00442505, ..., 0.00778198,\n",
      "         -0.00196838, 0.0117188]],\n",
      "\n",
      "       [[0.0196533, 0.00656128, -0.0249023, ..., -0.0224609, 0.00595093,\n",
      "         0.00218201],\n",
      "        [0.012085, 0.00817871, -0.00970459, ..., -0.00288391,\n",
      "         0.00878906, -0.0071106],\n",
      "        [0.0180664, -0.0157471, 0.00909424, ..., 0.00019455,\n",
      "         -0.00714111, -0.00159454],\n",
      "        ...,\n",
      "        [-0.00897217, 0.0113525, 0.0065918, ..., -0.000667572,\n",
      "         -0.0148926, -0.00170898],\n",
      "        [-0.00817871, -0.00382996, -0.00653076, ..., -0.00267029,\n",
      "         -0.00714111, 0.0131836],\n",
      "        [0.006073, 0.00588989, -0.00927734, ..., 0.00872803,\n",
      "         -0.00552368, 0.00308228]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00656128, -0.000621796, -0.00131989, ..., 0.0110474,\n",
      "         0.00418091, -0.00683594],\n",
      "        [0.00747681, 0.0103149, 0.00285339, ..., 0.00650024,\n",
      "         -0.00318909, 0.00897217],\n",
      "        [0.00823975, 0.00567627, -0.0119629, ..., -0.000549316,\n",
      "         -0.000310898, -0.0043335],\n",
      "        ...,\n",
      "        [0.00500488, 0.00698853, -0.00050354, ..., 0.00386047,\n",
      "         0.00830078, -0.00112915],\n",
      "        [-0.00244141, -0.00263977, -0.00915527, ..., -0.00872803,\n",
      "         0.00189209, 0.0195312],\n",
      "        [0.0197754, -0.00939941, 0.00701904, ..., -0.0270996,\n",
      "         -0.0119629, -0.00369263]],\n",
      "\n",
      "       [[0.00216675, 0.00140381, -0.00817871, ..., 0.00256348,\n",
      "         0.0105591, 0.0100708],\n",
      "        [0.0115967, -0.00701904, -0.00531006, ..., 0.0222168,\n",
      "         -0.00101471, 0.0219727],\n",
      "        [0.00430298, 0.0114746, -0.000157356, ..., 0.0114136,\n",
      "         -0.00276184, -0.0336914],\n",
      "        ...,\n",
      "        [-0.00527954, -0.00546265, -6.62804e-05, ..., -0.00131226,\n",
      "         -0.00326538, -0.00167084],\n",
      "        [0.020874, -0.00933838, 0.0129395, ..., -0.0189209, 0.00668335,\n",
      "         -0.0167236],\n",
      "        [0.00172424, 0.0139771, 0.0115356, ..., 0.00473022, 0.0186768,\n",
      "         0.00897217]],\n",
      "\n",
      "       [[-0.0109253, 0.000478745, -0.00268555, ..., 0.00378418,\n",
      "         0.0123901, 0.00787354],\n",
      "        [0.00976562, 0.00482178, 0.0078125, ..., -0.000762939,\n",
      "         0.00805664, -0.001297],\n",
      "        [-0.00418091, -0.00546265, -0.00238037, ..., 0.00588989,\n",
      "         0.0158691, 0.00292969],\n",
      "        ...,\n",
      "        [-0.00260925, -0.00537109, -0.00239563, ..., 0.00393677,\n",
      "         -0.0136108, 0.0102539],\n",
      "        [0.00515747, 0.0222168, 0.0203857, ..., 0.00292969, -0.001091,\n",
      "         -0.0126953],\n",
      "        [-0.0140991, 0.0140991, -0.0122681, ..., -0.00309753,\n",
      "         -0.0112305, -0.00823975]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00799561, 0.00439453, 0.0146484, ..., 0.00332642,\n",
      "          -0.00872803, 0.00245667],\n",
      "         [0.00144196, 0.000379562, 0.0100708, ..., 0.00619507,\n",
      "          0.0202637, -0.0181885],\n",
      "         [-0.0039978, -0.00389099, 0.00952148, ..., -0.0145264,\n",
      "          -0.00448608, -0.00946045],\n",
      "         ...,\n",
      "         [-0.00671387, -0.00314331, -0.00933838, ..., 0.00708008,\n",
      "          -0.000869751, -0.00619507],\n",
      "         [-0.0039978, 0.00305176, 0.00212097, ..., 0.000107288,\n",
      "          0.00308228, 0.00463867],\n",
      "         [-0.00720215, -0.00915527, -0.00386047, ..., 0.00759888,\n",
      "          0.010376, 0.00497437]],\n",
      "\n",
      "        [[-0.00897217, 0.0106201, 0.0142212, ..., -0.0098877,\n",
      "          0.0187988, 0.00328064],\n",
      "         [0.00543213, -0.0126953, 0.000207901, ..., 0.0140991,\n",
      "          -0.000507355, 0.00750732],\n",
      "         [-0.00482178, -0.000507355, 0.00265503, ..., -0.0211182,\n",
      "          -0.00196838, 0.0098877],\n",
      "         ...,\n",
      "         [-0.0123291, 0.0194092, -0.0166016, ..., -0.017334, 0.0296631,\n",
      "          0.00244141],\n",
      "         [0.00543213, 0.00132751, 0.00524902, ..., 0.00127411,\n",
      "          -0.00166321, -0.0163574],\n",
      "         [-0.000159264, -0.0131226, 0.000957489, ..., 0.0155029,\n",
      "          0.0169678, -0.0109253]],\n",
      "\n",
      "        [[-0.00494385, 0.020752, -0.00315857, ..., -0.0137939,\n",
      "          -0.00698853, 0.0125732],\n",
      "         [0.00178528, 0.00836182, -0.00297546, ..., -0.0145874,\n",
      "          -0.0163574, 0.00102997],\n",
      "         [-0.00939941, 0.0120239, -0.00469971, ..., -0.0169678,\n",
      "          -0.00205994, -0.00271606],\n",
      "         ...,\n",
      "         [-0.0134277, 0.0150146, 0.0115967, ..., -0.000663757,\n",
      "          -0.00230408, 0.0109863],\n",
      "         [0.0212402, -0.00799561, -0.00402832, ..., -0.00927734,\n",
      "          0.00161743, -0.00323486],\n",
      "         [-0.0098877, 0.00370789, -0.0158691, ..., 0.0145264,\n",
      "          0.0211182, 0.00653076]],\n",
      "\n",
      "        [[0.00543213, 0.00634766, 0.0136719, ..., 0.00124359,\n",
      "          -0.0019989, -0.00836182],\n",
      "         [0.000747681, 0.0111084, 0.00717163, ..., -0.0067749,\n",
      "          0.0045166, 0.0105591],\n",
      "         [0.00389099, 0.0107422, -0.0137329, ..., -0.0159912,\n",
      "          -0.0107422, 0.00613403],\n",
      "         ...,\n",
      "         [0.00408936, 0.00527954, 0.00378418, ..., -0.00463867,\n",
      "          0.0314941, -0.00524902],\n",
      "         [-0.0235596, -0.0186768, 0.00671387, ..., 0.00650024,\n",
      "          0.013855, -0.00221252],\n",
      "         [0.0131226, -0.00570679, 0.00376892, ..., 0.00765991,\n",
      "          -0.0140381, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[6.10352e-05, -0.0125122, -0.0101318, ..., 0.0174561,\n",
      "          -0.00221252, -0.0045166],\n",
      "         [0.00180817, 0.00753784, -0.0037384, ..., -0.0101318,\n",
      "          0.00260925, -0.00622559],\n",
      "         [0.0153809, 0.000652313, -0.00750732, ..., -0.00390625,\n",
      "          0.00668335, -0.000930786],\n",
      "         ...,\n",
      "         [-0.0253906, -0.0145264, 0.0108032, ..., -0.00842285,\n",
      "          -0.00970459, 0.0222168],\n",
      "         [-0.0163574, 0.00564575, 0.000514984, ..., -0.00476074,\n",
      "          0.0177002, 0.00361633],\n",
      "         [-0.0129395, -0.0133667, -0.00805664, ..., 0.00424194,\n",
      "          0.00439453, -0.0196533]],\n",
      "\n",
      "        [[-0.0136719, -0.0129395, -0.0105591, ..., 0.0134888,\n",
      "          0.00775146, -0.00772095],\n",
      "         [-0.010498, 0.000766754, 0.0175781, ..., -0.00270081,\n",
      "          -0.00253296, 0.000911713],\n",
      "         [0.0247803, 0.0186768, -0.00402832, ..., 0.0011673, 0.0131836,\n",
      "          0.0143433],\n",
      "         ...,\n",
      "         [0.0154419, 0.000701904, 0.00387573, ..., -0.00247192,\n",
      "          0.0090332, -0.0149536],\n",
      "         [-0.00765991, -0.0134277, 0.00396729, ..., 0.00787354,\n",
      "          0.0038147, -0.00793457],\n",
      "         [-0.00436401, 0.00994873, 0.000455856, ..., -0.000923157,\n",
      "          -0.00878906, 0.00421143]],\n",
      "\n",
      "        [[-0.00159454, -0.0257568, 0.00592041, ..., -0.0032196,\n",
      "          0.00302124, 0.00204468],\n",
      "         [0.00964355, -0.0222168, 0.0112915, ..., -0.00357056,\n",
      "          -0.00927734, -0.00140381],\n",
      "         [0.0111084, -0.00402832, -0.0109863, ..., -0.00524902,\n",
      "          0.0150146, 0.000471115],\n",
      "         ...,\n",
      "         [0.00518799, -0.0159912, -0.0123291, ..., -0.0180664,\n",
      "          -0.00213623, -0.0192871],\n",
      "         [-0.00769043, 0.00769043, 0.00872803, ..., 0.000686646,\n",
      "          0.00982666, 0.00415039],\n",
      "         [0.00254822, -0.00337219, -0.0112915, ..., 0.00202942,\n",
      "          -0.00305176, -0.00479126]],\n",
      "\n",
      "        [[-0.00921631, 0.00309753, -0.00172424, ..., -0.0137329,\n",
      "          0.000972748, 0.00183105],\n",
      "         [-0.00570679, -0.00765991, -0.00056076, ..., 0.00656128,\n",
      "          0.00111389, 0.0307617],\n",
      "         [-0.0123901, 0.00805664, 0.00546265, ..., 0.000911713,\n",
      "          -0.00897217, 0.000644684],\n",
      "         ...,\n",
      "         [0.0163574, 0.0103149, -0.0157471, ..., -0.00389099,\n",
      "          -0.00643921, 0.012146],\n",
      "         [0.0055542, 0.0114746, 0.0133667, ..., 0.00439453,\n",
      "          -0.000429153, 0.0106201],\n",
      "         [0.0050354, 0.0088501, -0.00704956, ..., -0.00485229,\n",
      "          -0.0255127, 0.00921631]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.0116577, 0.00300598, 0.0112305, ..., 0.000368118,\n",
      "         -0.00994873, -0.00274658],\n",
      "        [0.0219727, 0.019043, -0.006073, ..., -0.00280762, -0.00668335,\n",
      "         0.0152588],\n",
      "        [-0.00592041, 0.00576782, 0.0205078, ..., 0.00512695,\n",
      "         0.00546265, -0.000368118],\n",
      "        ...,\n",
      "        [0.00186157, 0.000762939, 0.00479126, ..., -0.00897217,\n",
      "         0.00823975, 0.00524902],\n",
      "        [0.0062561, 0.00357056, -0.00866699, ..., 0.0153198, 0.00134277,\n",
      "         -0.012146],\n",
      "        [-0.0112915, -0.00485229, -0.0055542, ..., 0.00970459,\n",
      "         0.00198364, 0.00151825]],\n",
      "\n",
      "       [[0.0016098, -0.00738525, -0.0153809, ..., 0.0133667, -0.010437,\n",
      "         0.00457764],\n",
      "        [0.00723267, 0.00952148, -0.00640869, ..., -0.00567627,\n",
      "         0.0272217, -0.00674438],\n",
      "        [-0.00193787, 0.00338745, 0.00154114, ..., -0.0123901,\n",
      "         -0.0229492, -0.00775146],\n",
      "        ...,\n",
      "        [-0.00595093, -0.0153198, 0.0102539, ..., 0.0174561, 0.00588989,\n",
      "         -0.00367737],\n",
      "        [0.00695801, -0.00106049, -0.00927734, ..., -0.00650024,\n",
      "         0.00680542, -0.00579834],\n",
      "        [-0.00034523, -0.00227356, -0.00147247, ..., 0.00311279,\n",
      "         -0.0113525, -0.012085]],\n",
      "\n",
      "       [[-0.00732422, 0.00527954, 0.000640869, ..., -0.00537109,\n",
      "         0.0149536, -0.00671387],\n",
      "        [0.000991821, -0.00421143, -0.00335693, ..., -0.00174713,\n",
      "         0.0109863, -0.00457764],\n",
      "        [0.00118256, 0.00167084, 0.00793457, ..., -0.00793457,\n",
      "         0.00686646, 0.0103149],\n",
      "        ...,\n",
      "        [0.000511169, -0.00466919, -0.00570679, ..., -0.0236816,\n",
      "         0.00769043, 0.0131836],\n",
      "        [0.000930786, -0.00111389, 0.00331116, ..., 0.0167236,\n",
      "         0.00982666, -0.00509644],\n",
      "        [7.29561e-05, -0.0013504, 0.00279236, ..., 0.00300598,\n",
      "         0.0197754, 0.0109253]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00601196, -0.0158691, -0.0122681, ..., -0.00897217,\n",
      "         -0.00309753, 0.00387573],\n",
      "        [0.0178223, -0.00994873, 0.0229492, ..., -0.00311279, -0.024292,\n",
      "         0.0172119],\n",
      "        [-0.0186768, -0.00224304, -0.0133667, ..., -0.0241699,\n",
      "         0.00265503, -0.00628662],\n",
      "        ...,\n",
      "        [-0.00120544, -0.0019989, -0.0174561, ..., -0.012207,\n",
      "         -0.0148315, -0.00656128],\n",
      "        [0.0251465, -0.00506592, 0.00062561, ..., 0.00665283,\n",
      "         -0.00215149, 0.00167847],\n",
      "        [-0.0137329, 0.0150757, -0.0223389, ..., -0.00198364,\n",
      "         -0.00939941, 0.00515747]],\n",
      "\n",
      "       [[-0.00263977, -0.0107422, -0.00349426, ..., 0.015564, -0.010376,\n",
      "         0.0218506],\n",
      "        [0.00482178, -0.0150146, -0.0151978, ..., 0.00747681, 0.0116577,\n",
      "         -0.00221252],\n",
      "        [-0.000556946, 0.00192261, 0.000352859, ..., -0.00056839,\n",
      "         0.0214844, -0.00775146],\n",
      "        ...,\n",
      "        [0.024292, 0.00946045, -0.0134888, ..., 0.0179443, 0.00106812,\n",
      "         0.0137939],\n",
      "        [-0.00358582, 0.000610352, -0.00509644, ..., -0.00411987,\n",
      "         -0.000896454, -0.0113525],\n",
      "        [-0.00222778, 0.00418091, -0.00634766, ..., -0.00119781,\n",
      "         0.0145874, -0.0105591]],\n",
      "\n",
      "       [[0.00830078, 0.0169678, 0.00180054, ..., 0.0111084, -0.00151825,\n",
      "         0.0145874],\n",
      "        [-0.032959, 0.00222778, -0.0115356, ..., -0.0145874, 0.0111084,\n",
      "         -0.0123291],\n",
      "        [0.00735474, 0.0118408, 0.000335693, ..., 0.000514984,\n",
      "         -0.00311279, -0.0179443],\n",
      "        ...,\n",
      "        [-0.00162506, -0.0179443, -0.012085, ..., -0.0252686,\n",
      "         -0.00958252, 0.00268555],\n",
      "        [-0.00805664, -0.000915527, 0.0055542, ..., 0.00418091,\n",
      "         0.00909424, -0.0213623],\n",
      "        [0.0211182, 0.0119629, 0.00262451, ..., -0.00546265,\n",
      "         0.000679016, 0.0116577]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.0014801, -0.0143433, 0.00695801, ..., 0.012146, 0.00023365,\n",
      "         0.0136719],\n",
      "        [0.00289917, 0.0139771, 0.00445557, ..., -0.0205078,\n",
      "         -0.000701904, 0.0143433],\n",
      "        [-0.00491333, 0.00331116, -0.00842285, ..., -0.00366211,\n",
      "         -0.00939941, 0.000350952],\n",
      "        ...,\n",
      "        [0.0181885, -0.00546265, -0.0146484, ..., 0.00830078,\n",
      "         -0.00576782, -0.000362396],\n",
      "        [0.00364685, 0.00326538, 0.0132446, ..., -0.00183868,\n",
      "         0.00262451, 0.00878906],\n",
      "        [0.00830078, 0.00946045, -0.000115395, ..., 0.00213623,\n",
      "         -0.0119019, 0.0100098]],\n",
      "\n",
      "       [[0.00500488, -0.00418091, 0.00485229, ..., 0.0114136,\n",
      "         2.67029e-05, 0.00567627],\n",
      "        [0.00346375, -0.00171661, -0.0170898, ..., -0.00897217,\n",
      "         0.0159912, 0.00927734],\n",
      "        [0.000652313, -0.00653076, -0.00534058, ..., -0.00982666,\n",
      "         0.0112305, 0.00402832],\n",
      "        ...,\n",
      "        [-0.00552368, -0.00457764, 0.0168457, ..., 0.0150146,\n",
      "         -0.00671387, -0.0106812],\n",
      "        [0.00436401, 0.0136108, 0.00341797, ..., 0.0038147, 0.00561523,\n",
      "         -0.00891113],\n",
      "        [-0.000225067, -0.000610352, -0.0218506, ..., 0.00540161,\n",
      "         -0.020874, 0.006073]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.0088501, -0.000556946, -0.000946045, ..., -0.0131226,\n",
      "        0.0123901, -0.0098877],\n",
      "       [-0.00291443, -0.00637817, 0.000459671, ..., -0.0131226,\n",
      "        0.0115967, -0.000145912],\n",
      "       [0.00283813, -0.0108643, -0.00254822, ..., 0.0130005, 0.0150146,\n",
      "        -0.0141602],\n",
      "       ...,\n",
      "       [0.0125732, -0.0057373, -0.00263977, ..., 0.0128784, -0.0127563,\n",
      "        0.00408936],\n",
      "       [0.00213623, 0.0135498, 0.00668335, ..., 0.00769043, 0.00402832,\n",
      "        -0.0148315],\n",
      "       [0.00242615, 0.0039978, -0.0019989, ..., -0.0148926, -0.000553131,\n",
      "        0.00582886]], dtype=bfloat16), a=Array([[-0.00757848,  0.00208123, -0.0095167 , ...,  0.01346242,\n",
      "         0.01381325, -0.00154688],\n",
      "       [-0.01088316, -0.00166531, -0.02113895, ..., -0.00199354,\n",
      "         0.00065937,  0.00700611]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.166992, -0.209961, -0.139648, ..., -0.363281, -0.0634766,\n",
      "       -0.261719], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.361328, 0.380859, 0.306641, ..., 0.0698242, 0.480469, 0.386719],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.617188, 0.453125, 0.699219, ..., 0.785156, 0.363281, 0.527344],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.859375, 0.824219, 0.894531, ..., 1.19531, 0.0356445, 0.714844],      dtype=bfloat16)}}, 'layer_4': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00259399, 0.0158691, -0.00891113, ..., -0.00567627,\n",
      "         -0.00279236, 0.0189209],\n",
      "        [-0.0251465, 0.00376892, 0.00233459, ..., 0.0015564,\n",
      "         -0.00531006, 0.0140991],\n",
      "        [-0.00817871, -0.00141907, -0.00140381, ..., -0.00107574,\n",
      "         0.000276566, 0.00308228],\n",
      "        ...,\n",
      "        [-0.00946045, 0.0183105, 0.0145874, ..., -0.00793457,\n",
      "         -0.0045166, -0.0289307],\n",
      "        [0.00836182, 0.00315857, 0.00286865, ..., -0.00561523,\n",
      "         -0.000976562, 0.00254822],\n",
      "        [0.00964355, 0.00242615, 0.00306702, ..., 0.000713348,\n",
      "         -0.00386047, -0.0183105]],\n",
      "\n",
      "       [[-0.0107422, -0.00476074, -0.00515747, ..., -0.000923157,\n",
      "         0.00650024, -0.00674438],\n",
      "        [0.00689697, 0.00640869, 0.0037384, ..., 0.0120239, 0.00665283,\n",
      "         -0.00534058],\n",
      "        [-0.00921631, 0.0032959, 0.0114746, ..., 0.0233154, -0.006073,\n",
      "         0.00537109],\n",
      "        ...,\n",
      "        [0.00970459, 0.0273438, 0.006073, ..., 0.00692749, 0.0213623,\n",
      "         0.00656128],\n",
      "        [0.0166016, -0.0107422, 2.22921e-05, ..., -0.000862122,\n",
      "         -0.00686646, 0.00297546],\n",
      "        [-0.00558472, 0.0234375, 0.000579834, ..., 0.00171661,\n",
      "         -0.0178223, 0.00527954]],\n",
      "\n",
      "       [[-0.00524902, -0.00897217, 0.00915527, ..., -0.0203857,\n",
      "         0.000713348, -0.00167084],\n",
      "        [-0.00726318, -0.0115356, -0.00205994, ..., 0.00561523,\n",
      "         -0.00338745, -0.00274658],\n",
      "        [-0.0151978, -0.00263977, -0.00271606, ..., 0.00994873,\n",
      "         -0.00479126, 0.000193596],\n",
      "        ...,\n",
      "        [-0.0219727, 0.00765991, 0.0185547, ..., -0.00454712,\n",
      "         -0.00891113, 0.0050354],\n",
      "        [-0.00515747, 0.0117188, 0.0112305, ..., -0.00469971,\n",
      "         -0.00473022, 0.00476074],\n",
      "        [-0.00738525, -0.0126343, 0.0140381, ..., 0.00527954,\n",
      "         0.00415039, 0.010437]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00848389, 0.00230408, -0.00427246, ..., -0.0187988,\n",
      "         0.00479126, 0.00512695],\n",
      "        [0.000869751, -0.000356674, -0.0022583, ..., -0.00390625,\n",
      "         0.0217285, -0.00314331],\n",
      "        [0.0180664, 0.012085, -0.00994873, ..., -0.00198364,\n",
      "         -0.00473022, -0.0236816],\n",
      "        ...,\n",
      "        [-0.0109253, 0.0017395, 0.00257874, ..., -0.000326157,\n",
      "         0.00787354, -0.00485229],\n",
      "        [-0.00817871, -0.0114136, 0.0128174, ..., -0.00300598,\n",
      "         -0.0127563, -0.00247192],\n",
      "        [-0.00622559, 0.00296021, 0.00830078, ..., -0.00259399,\n",
      "         -0.0195312, -0.00257874]],\n",
      "\n",
      "       [[-0.0088501, 0.00439453, 0.00109863, ..., -0.00389099,\n",
      "         0.00415039, 0.0015564],\n",
      "        [-0.00469971, -0.00787354, 0.000728607, ..., -0.00506592,\n",
      "         -0.0235596, -0.0172119],\n",
      "        [-0.0071106, -0.000896454, -0.00195312, ..., 0.00393677,\n",
      "         -0.00299072, -0.00306702],\n",
      "        ...,\n",
      "        [-0.00576782, 0.00157928, -0.0136719, ..., 0.0174561,\n",
      "         0.00188446, -0.00421143],\n",
      "        [0.000606537, 0.0179443, -0.0280762, ..., 0.0114746, -0.0163574,\n",
      "         0.00946045],\n",
      "        [-0.0030365, 0.0170898, -0.00104523, ..., 0.00564575,\n",
      "         -0.00933838, 0.0166016]],\n",
      "\n",
      "       [[-0.00375366, 0.00228882, 0.0088501, ..., -0.0011673,\n",
      "         -0.000455856, -0.0112305],\n",
      "        [0.00704956, 0.0108032, -0.00799561, ..., -0.00300598,\n",
      "         -0.00087738, -0.00296021],\n",
      "        [-0.00259399, -0.0106812, 0.00335693, ..., -0.000976562,\n",
      "         -0.00357056, -0.00735474],\n",
      "        ...,\n",
      "        [0.00338745, 0.0151978, 0.00823975, ..., -0.00708008,\n",
      "         0.00762939, -0.00122833],\n",
      "        [-0.00732422, -0.00836182, 0.00149536, ..., -0.0163574,\n",
      "         -0.0137329, -0.00518799],\n",
      "        [0.00300598, -0.0148315, 0.022583, ..., -0.0148315, 0.0250244,\n",
      "         -0.00753784]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00939941, 0.00136566, 0.0114746, ..., -0.00131989,\n",
      "          -0.00726318, 0.00236511],\n",
      "         [-0.000113964, -0.00466919, -0.00756836, ..., -0.0162354,\n",
      "          0.00113678, 0.00248718],\n",
      "         [-0.00157928, 0.00799561, -0.0139771, ..., -0.00202942,\n",
      "          -0.0205078, -0.0102539],\n",
      "         ...,\n",
      "         [-0.00772095, -0.0209961, -0.00387573, ..., 0.00436401,\n",
      "          0.00610352, -0.0155029],\n",
      "         [0.0269775, -0.0123901, -0.0132446, ..., -0.00939941,\n",
      "          -0.00387573, -0.0130005],\n",
      "         [-0.0102539, -0.0245361, 0.010376, ..., 0.0106812,\n",
      "          -0.00222778, -0.0220947]],\n",
      "\n",
      "        [[0.00427246, -0.00297546, 0.000284195, ..., -0.0164795,\n",
      "          0.0147095, -0.0169678],\n",
      "         [0.00708008, 0.000326157, -0.00296021, ..., -0.0078125,\n",
      "          0.0285645, -0.00567627],\n",
      "         [0.00714111, -0.00285339, -0.0131226, ..., -0.00878906,\n",
      "          -0.0181885, -0.0358887],\n",
      "         ...,\n",
      "         [0.00701904, 0.0132446, -0.00848389, ..., -0.0172119,\n",
      "          -0.00656128, -0.02771],\n",
      "         [-0.0235596, -0.00169373, -0.029541, ..., -0.00421143,\n",
      "          0.0285645, 0.0106812],\n",
      "         [0.0241699, 0.0118408, 0.00540161, ..., -0.00848389,\n",
      "          -0.000816345, -0.0114746]],\n",
      "\n",
      "        [[0.00921631, 0.00735474, 0.00297546, ..., -0.00454712,\n",
      "          0.013855, -0.0119629],\n",
      "         [0.00634766, 0.00854492, -0.0223389, ..., 0.00328064,\n",
      "          -0.0444336, -0.00576782],\n",
      "         [0.015564, 0.0126953, -0.00102997, ..., -0.0106201,\n",
      "          -0.00891113, 0.00964355],\n",
      "         ...,\n",
      "         [0.000644684, 0.00500488, 0.0090332, ..., 0.00204468,\n",
      "          -0.000149727, 0.015564],\n",
      "         [0.012146, -0.00964355, -0.0141602, ..., 0.0361328,\n",
      "          -0.00285339, 0.0216064],\n",
      "         [0.0126953, 0.0065918, -0.00704956, ..., -0.00598145,\n",
      "          -0.00836182, 0.0301514]],\n",
      "\n",
      "        [[0.00500488, -0.00683594, -0.00662231, ..., -0.0178223,\n",
      "          -0.0124512, 0.00695801],\n",
      "         [0.00212097, -0.00646973, 0.00927734, ..., -0.00473022,\n",
      "          0.0125732, -0.0144043],\n",
      "         [0.00236511, -0.00379944, 0.00463867, ..., -0.000213623,\n",
      "          0.00933838, 0.0186768],\n",
      "         ...,\n",
      "         [0.0139771, -0.0111694, -0.00415039, ..., 0.0167236,\n",
      "          -0.00921631, -0.0220947],\n",
      "         [-0.0115967, 0.0123901, 5.05447e-05, ..., 0.00860596,\n",
      "          0.00415039, 0.00122833],\n",
      "         [0.00201416, -0.00209045, -0.00476074, ..., -0.0149536,\n",
      "          -0.012146, 0.0184326]]],\n",
      "\n",
      "\n",
      "       [[[-0.00970459, 0.0101318, 0.000556946, ..., -0.00817871,\n",
      "          0.0111694, 0.00524902],\n",
      "         [-0.0072937, -0.00494385, 0.0170898, ..., -0.00692749,\n",
      "          -0.00521851, 0.0223389],\n",
      "         [-0.000778198, 0.00830078, 0.00860596, ..., 0.0139771,\n",
      "          -0.0027771, -0.00408936],\n",
      "         ...,\n",
      "         [-0.00370789, -0.0100098, 0.00476074, ..., -0.0098877,\n",
      "          0.0151367, -0.00387573],\n",
      "         [0.0123901, 0.00588989, 0.00369263, ..., -0.00360107,\n",
      "          0.015625, -0.00848389],\n",
      "         [-0.00698853, -0.0175781, 0.0100708, ..., -0.0202637,\n",
      "          -0.00308228, 0.000930786]],\n",
      "\n",
      "        [[0.0163574, 0.0027771, -0.00248718, ..., -0.0266113,\n",
      "          -0.00701904, 0.00130463],\n",
      "         [-0.0137329, -0.00830078, -0.0050354, ..., 0.0140381,\n",
      "          0.00588989, -0.00476074],\n",
      "         [0.0174561, 0.00613403, -0.0106812, ..., 0.0101318,\n",
      "          0.000637054, 0.00146484],\n",
      "         ...,\n",
      "         [-0.00686646, -0.0131226, 0.0206299, ..., 0.00854492,\n",
      "          0.00872803, 0.00114441],\n",
      "         [0.00171661, 0.00680542, 0.00201416, ..., 0.00579834,\n",
      "          0.00245667, 0.0124512],\n",
      "         [0.0172119, -0.0132446, -0.0018158, ..., 0.00662231,\n",
      "          0.00866699, 0.010498]],\n",
      "\n",
      "        [[0.0113525, 0.00558472, -0.0164795, ..., 0.00239563,\n",
      "          0.00156403, 0.0133057],\n",
      "         [0.00123596, -0.00769043, -0.00939941, ..., 0.00671387,\n",
      "          0.0228271, 0.000862122],\n",
      "         [0.00376892, -0.00424194, 0.0123291, ..., -0.00732422,\n",
      "          -0.00964355, -0.0126953],\n",
      "         ...,\n",
      "         [0.0147705, 0.0200195, 0.0161133, ..., -0.00512695,\n",
      "          -0.00592041, 0.00668335],\n",
      "         [-0.000839233, -0.0235596, 0.00448608, ..., -0.000785828,\n",
      "          0.0132446, 0.0214844],\n",
      "         [-0.00674438, 0.000946045, 0.0134888, ..., 0.00643921,\n",
      "          -0.00341797, -0.000368118]],\n",
      "\n",
      "        [[-0.0108032, 0.0145874, -0.00601196, ..., 0.00201416,\n",
      "          0.00698853, -0.00209045],\n",
      "         [-0.000904083, -0.0123901, 0.0114136, ..., 0.00156403,\n",
      "          -0.00543213, 0.0235596],\n",
      "         [-0.00193787, 0.00219727, 0.000652313, ..., 0.00878906,\n",
      "          -0.0302734, 0.00701904],\n",
      "         ...,\n",
      "         [0.0266113, 0.00964355, 0.0196533, ..., 0.0189209, 0.00836182,\n",
      "          -0.0032196],\n",
      "         [0.0135498, -0.0109863, -0.0170898, ..., -0.00714111,\n",
      "          -0.0102539, 0.00115967],\n",
      "         [-0.00613403, -0.00332642, 0.00341797, ..., 0.00946045,\n",
      "          0.0308838, 0.0206299]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.0043335, 0.0185547, -0.00393677, ..., -0.0256348,\n",
      "         -0.00582886, 0.0195312],\n",
      "        [-0.00364685, -0.0148315, 0.0123291, ..., -0.0136108,\n",
      "         -0.0288086, -0.0100708],\n",
      "        [0.00494385, -0.010437, 0.0137939, ..., 0.00765991, -0.0218506,\n",
      "         -0.020752],\n",
      "        ...,\n",
      "        [0.00156403, 0.0327148, -0.0163574, ..., -0.00198364, 0.0299072,\n",
      "         -0.00256348],\n",
      "        [0.0130005, -0.00213623, 0.00726318, ..., -0.00848389,\n",
      "         -0.0144653, 0.0162354],\n",
      "        [0.0037384, 0.0117798, -0.022583, ..., -0.0112305, -0.0169678,\n",
      "         -0.0161133]],\n",
      "\n",
      "       [[0.0107422, -0.0129395, 0.00279236, ..., 0.00439453, 0.00292969,\n",
      "         -0.00132751],\n",
      "        [-0.000182152, -0.00315857, -0.00387573, ..., 0.0180664,\n",
      "         0.00765991, 0.0236816],\n",
      "        [-0.0122681, -0.00878906, -0.00262451, ..., -0.00285339,\n",
      "         -0.00436401, -0.0142822],\n",
      "        ...,\n",
      "        [0.0120239, 0.020752, 0.00601196, ..., -0.012146, 0.0167236,\n",
      "         -0.00358582],\n",
      "        [-0.00233459, -0.00964355, 0.000118732, ..., -0.00122833,\n",
      "         -0.00212097, 0.012207],\n",
      "        [0.0045166, -0.0022583, -0.0142212, ..., -0.00546265,\n",
      "         0.00646973, 0.0115967]],\n",
      "\n",
      "       [[-0.0200195, -0.0130615, 0.00765991, ..., -0.00430298,\n",
      "         0.00405884, 0.003479],\n",
      "        [0.00543213, 0.00408936, -0.00787354, ..., -0.00126648,\n",
      "         -0.0169678, 0.000545502],\n",
      "        [0.010437, 0.00738525, -0.00179291, ..., 0.00872803, 0.017334,\n",
      "         0.00245667],\n",
      "        ...,\n",
      "        [0.00588989, -0.00909424, 0.00082016, ..., 0.00543213,\n",
      "         -0.0039978, 0.0119629],\n",
      "        [-0.00692749, 0.000991821, -0.0174561, ..., -0.00558472,\n",
      "         -0.00418091, -0.0111084],\n",
      "        [0.00187683, -0.00897217, 0.00866699, ..., 0.00878906,\n",
      "         -0.0108643, 0.0150146]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.0045166, -0.00686646, -0.00793457, ..., -0.012207,\n",
      "         -0.012085, -0.00424194],\n",
      "        [-0.0144653, -0.0111084, -0.0123291, ..., 0.00799561,\n",
      "         -0.00811768, 0.0145874],\n",
      "        [0.0134277, -0.0249023, -0.00765991, ..., 0.000235558,\n",
      "         -0.00396729, -0.0125122],\n",
      "        ...,\n",
      "        [0.00209045, -0.0123291, -0.0098877, ..., 0.00823975, 0.0032196,\n",
      "         -0.000782013],\n",
      "        [-0.00695801, -0.0407715, -0.00469971, ..., -0.00811768,\n",
      "         -0.00195312, -0.000499725],\n",
      "        [0.00265503, 0.0014801, 0.00878906, ..., -0.00300598,\n",
      "         0.00418091, 0.0114746]],\n",
      "\n",
      "       [[-0.00332642, -6.38962e-05, -0.0088501, ..., -0.0170898,\n",
      "         0.0112915, 0.0114746],\n",
      "        [-0.000312805, -0.00189209, 0.00439453, ..., -0.00515747,\n",
      "         -0.0018158, -0.0166016],\n",
      "        [-0.00848389, -0.0013504, 0.00717163, ..., 0.00276184,\n",
      "         -0.00337219, 0.00521851],\n",
      "        ...,\n",
      "        [-0.0111084, -0.0101929, 0.00671387, ..., 0.024292, 0.0230713,\n",
      "         -0.0166016],\n",
      "        [0.00497437, 0.00744629, 0.0045166, ..., -0.00564575, 0.010376,\n",
      "         -0.00650024],\n",
      "        [0.00744629, -0.00241089, 0.00848389, ..., 0.0151978,\n",
      "         -0.00622559, -0.00747681]],\n",
      "\n",
      "       [[-0.00454712, 0.00248718, -0.0071106, ..., -0.0291748,\n",
      "         -0.00442505, 0.00436401],\n",
      "        [-0.00775146, 0.00442505, -0.00628662, ..., 9.58443e-05,\n",
      "         -0.00512695, -0.00512695],\n",
      "        [-0.00546265, -0.00830078, -0.000976562, ..., -0.00132751,\n",
      "         0.0251465, -0.00976562],\n",
      "        ...,\n",
      "        [0.00156403, -0.0123901, -0.00579834, ..., 0.010498, 0.0177002,\n",
      "         -0.00415039],\n",
      "        [-0.00668335, -0.00897217, -0.00811768, ..., -0.0115356,\n",
      "         -0.00331116, -0.017334],\n",
      "        [-0.00279236, 0.000486374, -0.0155029, ..., 0.0157471,\n",
      "         0.00500488, 0.00619507]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00686646, -0.00628662, 0.00628662, ..., 0.00848389,\n",
      "         -0.00756836, 0.010437],\n",
      "        [-0.00315857, -0.00463867, 0.000448227, ..., 0.00482178,\n",
      "         0.00245667, 0.00927734],\n",
      "        [-0.00408936, -0.0167236, -0.00994873, ..., 0.00382996,\n",
      "         -0.000411987, 0.00799561],\n",
      "        ...,\n",
      "        [0.00136566, 0.000133514, 0.00891113, ..., -0.00331116,\n",
      "         0.0016098, 0.00376892],\n",
      "        [0.00485229, 0.0161133, 0.00567627, ..., 0.000400543,\n",
      "         -0.00130463, 0.0108643],\n",
      "        [-2.32458e-05, 0.00163269, -0.00280762, ..., 0.0102539,\n",
      "         -0.00695801, -0.0032959]],\n",
      "\n",
      "       [[0.00744629, 0.00872803, 0.0055542, ..., 0.00276184, -0.0142212,\n",
      "         -0.00976562],\n",
      "        [-0.00102997, 0.00312805, 0.000511169, ..., 0.00805664,\n",
      "         0.00634766, -0.00811768],\n",
      "        [-0.00787354, -0.000740051, -0.00221252, ..., 0.024292,\n",
      "         0.00418091, -0.0035553],\n",
      "        ...,\n",
      "        [-0.010498, 0.000972748, -0.00540161, ..., -0.000459671,\n",
      "         -0.00294495, -0.0112305],\n",
      "        [-0.00305176, 0.000495911, 0.00708008, ..., -0.0113525,\n",
      "         -0.00866699, 0.00848389],\n",
      "        [0.0144653, -0.00479126, -0.0032196, ..., 0.0043335, 0.00506592,\n",
      "         0.00811768]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00891113, 0.00970459, -0.00151062, ..., -0.0108032,\n",
      "        -0.00360107, 0.00717163],\n",
      "       [-0.000900269, 0.00148773, -0.00619507, ..., -0.00320435,\n",
      "        -0.00695801, -0.00671387],\n",
      "       [0.00463867, -0.0111084, 0.00196838, ..., 0.0101318, 0.0045166,\n",
      "        -0.000709534],\n",
      "       ...,\n",
      "       [0.000488281, 0.00909424, 0.0111694, ..., 0.015625, -0.00994873,\n",
      "        0.0118408],\n",
      "       [6.19888e-05, 0.00524902, -0.00720215, ..., -0.00184631,\n",
      "        -0.00628662, 0.0113525],\n",
      "       [-0.0112915, -0.00358582, 0.00182343, ..., -0.0201416,\n",
      "        -0.00463867, 0.00230408]], dtype=bfloat16), a=Array([[ 0.00232868,  0.00122111, -0.02715557, ...,  0.00275968,\n",
      "         0.0063306 ,  0.00120457],\n",
      "       [ 0.01015269, -0.00104287, -0.01713954, ...,  0.01712951,\n",
      "        -0.02799168, -0.01150994]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.193359, -0.28125, -0.21582, ..., -0.378906, -0.0407715,\n",
      "       -0.332031], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.285156, 0.245117, 0.246094, ..., 0.0476074, 0.613281, 0.271484],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.652344, 0.507812, 0.613281, ..., 0.824219, -0.0534668, 0.363281],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.554688, 0.570312, 0.554688, ..., 0.851562, 0.124512, 0.453125],      dtype=bfloat16)}}, 'layer_5': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00173187, 0.00221252, -0.00119781, ..., -0.00017643,\n",
      "         -0.00933838, 0.00221252],\n",
      "        [-0.00540161, -0.00692749, -0.0183105, ..., -0.00308228,\n",
      "         -0.0032959, -0.00570679],\n",
      "        [-0.00933838, 0.00866699, -0.000465393, ..., -0.00982666,\n",
      "         -0.00107574, 0.00363159],\n",
      "        ...,\n",
      "        [0.00193787, -0.00178528, 0.0117188, ..., 0.00375366,\n",
      "         -0.00518799, -0.00415039],\n",
      "        [-0.00576782, -0.00338745, -0.0158691, ..., -0.0135498,\n",
      "         0.00976562, -0.00182343],\n",
      "        [0.000747681, -0.00860596, 0.000545502, ..., -0.00326538,\n",
      "         -0.0212402, -0.00579834]],\n",
      "\n",
      "       [[-0.00534058, -0.00289917, -0.0189209, ..., 0.0020752,\n",
      "         0.0131836, 0.00976562],\n",
      "        [-0.00469971, -0.0137939, -0.0229492, ..., 0.00193787,\n",
      "         0.00415039, 0.00671387],\n",
      "        [0.0344238, -0.000243187, 0.0314941, ..., -0.0183105, 0.0134888,\n",
      "         0.0180664],\n",
      "        ...,\n",
      "        [0.0354004, -0.00952148, 0.00732422, ..., -0.0162354,\n",
      "         0.00183105, -0.00830078],\n",
      "        [-0.00174713, -0.000307083, -0.0013504, ..., 0.0179443,\n",
      "         0.000797272, 0.000595093],\n",
      "        [-0.000766754, 0.0057373, -0.0108643, ..., -0.000553131,\n",
      "         -0.0149536, 0.00376892]],\n",
      "\n",
      "       [[0.00842285, -0.0273438, 0.00836182, ..., -0.00683594,\n",
      "         -0.00805664, 0.0151978],\n",
      "        [-0.0118408, 0.0202637, -0.0159912, ..., -0.00872803,\n",
      "         -0.0179443, -0.00364685],\n",
      "        [-0.0184326, 0.0144043, -0.00927734, ..., -0.00448608,\n",
      "         0.00346375, -0.0117188],\n",
      "        ...,\n",
      "        [0.0155029, 0.00393677, 0.0115967, ..., -0.0118408, -0.00692749,\n",
      "         0.00178528],\n",
      "        [-0.00439453, 0.00367737, 0.0088501, ..., 0.0140381,\n",
      "         -0.00148773, -0.000299454],\n",
      "        [0.0133667, 0.00762939, -0.00396729, ..., -0.0166016,\n",
      "         0.00270081, -0.00576782]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00759888, 0.0351562, -0.0119019, ..., -0.0136108,\n",
      "         -0.0115967, 0.0172119],\n",
      "        [-0.0022583, -0.00366211, -0.00610352, ..., 0.0100708,\n",
      "         0.0134888, -0.0179443],\n",
      "        [0.0129395, -0.00616455, -0.0150146, ..., 0.012207,\n",
      "         -0.000759125, 0.019165],\n",
      "        ...,\n",
      "        [-0.00104523, 0.0145264, 0.0146484, ..., 0.00897217,\n",
      "         -0.00576782, -0.000854492],\n",
      "        [0.0246582, -0.00204468, -0.00952148, ..., -0.00546265,\n",
      "         0.00274658, 0.0162354],\n",
      "        [-0.00476074, -0.0153198, -0.0137329, ..., 0.00160217,\n",
      "         0.00506592, -0.015564]],\n",
      "\n",
      "       [[0.0114746, 0.00726318, 0.0198975, ..., -0.0184326, -0.0179443,\n",
      "         -0.00289917],\n",
      "        [-0.017334, -0.00231934, -0.0245361, ..., -0.0219727,\n",
      "         0.00616455, 0.0105591],\n",
      "        [0.00280762, -0.00765991, -0.00469971, ..., 0.00756836,\n",
      "         -0.0167236, -0.0198975],\n",
      "        ...,\n",
      "        [0.00130463, 0.0314941, -0.000253677, ..., -0.00160217,\n",
      "         -0.00866699, 0.0194092],\n",
      "        [0.0158691, 0.00723267, -0.00616455, ..., 0.0130005, -0.0115356,\n",
      "         -0.00167847],\n",
      "        [0.00112915, 0.0167236, -0.0144653, ..., 0.0212402, 0.0101929,\n",
      "         0.0108643]],\n",
      "\n",
      "       [[-0.0135498, -0.0130615, -0.0126953, ..., 0.013855, 0.00866699,\n",
      "         -0.00372314],\n",
      "        [0.0172119, 1.29342e-05, 0.0118408, ..., -0.0122681, -0.0240479,\n",
      "         0.00686646],\n",
      "        [0.0140991, 0.0159912, 0.00491333, ..., 0.00604248, -0.00994873,\n",
      "         0.00236511],\n",
      "        ...,\n",
      "        [-0.00335693, 0.0145874, -0.0151367, ..., 0.0286865, -0.0229492,\n",
      "         -0.0251465],\n",
      "        [-0.00512695, 0.0109253, 0.0216064, ..., -0.00128174,\n",
      "         0.00283813, -0.00165558],\n",
      "        [0.0284424, -0.0157471, 0.00872803, ..., 0.0169678, 0.00369263,\n",
      "         0.00970459]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00860596, -0.0126343, 0.00297546, ..., 0.00340271,\n",
      "          -0.00137329, 0.00334167],\n",
      "         [-0.00430298, -0.00567627, -0.00491333, ..., -0.0122681,\n",
      "          0.00337219, 0.000347137],\n",
      "         [-0.0140991, -0.00665283, -0.00198364, ..., 0.0109253,\n",
      "          -0.00714111, 0.006073],\n",
      "         ...,\n",
      "         [-0.0101318, -0.00671387, -0.00842285, ..., 0.000900269,\n",
      "          0.00418091, -0.00418091],\n",
      "         [0.022583, 0.0211182, -0.0140991, ..., 0.00358582, 0.0268555,\n",
      "          0.00138855],\n",
      "         [-0.0133667, -0.0012207, 0.00952148, ..., -0.0161133,\n",
      "          -0.00601196, 0.00357056]],\n",
      "\n",
      "        [[0.0012207, 0.00227356, 0.00137329, ..., -0.0351562,\n",
      "          0.0255127, -0.0220947],\n",
      "         [-0.000549316, -0.000705719, 0.00117493, ..., -0.0100098,\n",
      "          -0.0155029, 0.0195312],\n",
      "         [0.00415039, 0.00106049, 0.00126648, ..., -0.00640869,\n",
      "          0.0039978, -0.00793457],\n",
      "         ...,\n",
      "         [0.00294495, 0.00805664, -0.0062561, ..., -0.0118408,\n",
      "          0.00241089, -0.0131226],\n",
      "         [0.0167236, 0.00270081, 0.0108032, ..., 0.0128174, -0.0252686,\n",
      "          0.0184326],\n",
      "         [-0.00753784, 0.00411987, 0.000591278, ..., -0.0170898,\n",
      "          0.00872803, 0.0187988]],\n",
      "\n",
      "        [[0.012085, 0.00817871, -0.00866699, ..., 0.00170135,\n",
      "          0.0213623, -0.0035553],\n",
      "         [-0.00878906, -0.0043335, 0.00552368, ..., -0.00405884,\n",
      "          -8.29697e-05, 0.00695801],\n",
      "         [-0.00811768, -0.0101318, 0.00128174, ..., -0.0178223,\n",
      "          -0.00112915, 0.00294495],\n",
      "         ...,\n",
      "         [0.0244141, -0.00762939, -0.0011673, ..., 0.00759888,\n",
      "          -0.0016098, 0.00430298],\n",
      "         [-0.0162354, 0.00500488, -0.0218506, ..., 0.0201416,\n",
      "          0.0267334, 0.0219727],\n",
      "         [-0.00427246, -0.00296021, -0.0103149, ..., -0.019043,\n",
      "          0.00570679, -0.00375366]],\n",
      "\n",
      "        [[0.00288391, -0.00592041, -0.000976562, ..., -0.0136108,\n",
      "          0.000167847, 0.00439453],\n",
      "         [-0.000230789, -0.000923157, -0.0151978, ..., 0.00294495,\n",
      "          0.0174561, 0.00656128],\n",
      "         [0.0146484, -0.00610352, 0.00289917, ..., -0.000808716,\n",
      "          0.00411987, 0.02771],\n",
      "         ...,\n",
      "         [0.0115356, 0.00735474, 0.00369263, ..., 0.0088501, 0.0107422,\n",
      "          -0.0264893],\n",
      "         [0.00202942, 0.00195312, 0.00970459, ..., 0.0236816,\n",
      "          0.0164795, -0.00193024],\n",
      "         [0.017334, 0.00323486, 0.00567627, ..., -0.0324707, 0.0336914,\n",
      "          -0.0115356]]],\n",
      "\n",
      "\n",
      "       [[[0.00292969, 0.000740051, -0.0045166, ..., -0.0185547,\n",
      "          0.010437, -0.0174561],\n",
      "         [-0.00598145, 0.00741577, 0.00927734, ..., -0.00396729,\n",
      "          0.00491333, -0.00479126],\n",
      "         [0.0098877, -0.00224304, 0.00445557, ..., 0.00259399,\n",
      "          -0.0125732, 0.00830078],\n",
      "         ...,\n",
      "         [-0.00650024, -0.012085, -0.00346375, ..., 0.0240479,\n",
      "          -0.00349426, 0.0234375],\n",
      "         [-0.0187988, -0.00323486, -0.00285339, ..., -0.00457764,\n",
      "          0.00799561, 0.00228882],\n",
      "         [-0.00872803, 0.00909424, -0.0050354, ..., -9.25064e-05,\n",
      "          0.0194092, 0.0128784]],\n",
      "\n",
      "        [[0.0167236, -0.0213623, -0.00457764, ..., 0.013916,\n",
      "          -0.00582886, -0.00069046],\n",
      "         [-0.00405884, -0.00823975, -0.00268555, ..., 0.0290527,\n",
      "          0.00854492, -0.00393677],\n",
      "         [-0.0136108, 0.000314713, 0.0187988, ..., -0.00323486,\n",
      "          -0.0119629, -0.027832],\n",
      "         ...,\n",
      "         [0.0179443, -0.0113525, 0.00358582, ..., -0.010437,\n",
      "          -0.00836182, -0.010437],\n",
      "         [-0.0130005, 0.003479, 0.0109863, ..., 0.0111084, 0.000774384,\n",
      "          -0.00424194],\n",
      "         [0.00140381, 0.00811768, -0.00088501, ..., 0.00723267,\n",
      "          -0.0134277, 0.00144958]],\n",
      "\n",
      "        [[-0.0235596, -0.0134888, 0.020874, ..., 0.0102539, 0.0120239,\n",
      "          -0.0088501],\n",
      "         [0.0290527, 0.0025177, -0.00473022, ..., -0.00842285,\n",
      "          -0.00817871, -0.00637817],\n",
      "         [-0.00328064, -0.00946045, -0.0269775, ..., 0.00204468,\n",
      "          0.0057373, -0.00421143],\n",
      "         ...,\n",
      "         [-0.0308838, 0.00473022, -0.012146, ..., 0.013916, 0.00201416,\n",
      "          0.00842285],\n",
      "         [-0.00043869, 0.00289917, 0.000801086, ..., -0.00311279,\n",
      "          -0.00540161, -0.010437],\n",
      "         [0.00063324, -0.010498, -0.000637054, ..., 0.00488281,\n",
      "          -0.00823975, 0.0158691]],\n",
      "\n",
      "        [[0.0120239, -0.00735474, 0.0050354, ..., -0.00439453,\n",
      "          0.0111084, -0.000492096],\n",
      "         [0.0117798, 0.010498, 0.00192261, ..., -0.0230713, -0.019165,\n",
      "          -0.0107422],\n",
      "         [-0.00994873, 0.0102539, 0.0114746, ..., 0.0283203, 0.0162354,\n",
      "          -0.00262451],\n",
      "         ...,\n",
      "         [-0.000835419, 0.0152588, 0.0167236, ..., 0.00222778,\n",
      "          0.0101318, -0.00183105],\n",
      "         [0.00762939, 0.00259399, -0.00683594, ..., -0.0123901,\n",
      "          0.00756836, -0.00622559],\n",
      "         [0.0195312, 0.0118408, 0.0289307, ..., -0.0236816, -0.010376,\n",
      "          -0.0157471]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.0055542, -0.00805664, 0.000514984, ..., 0.00656128,\n",
      "         0.00552368, 0.00491333],\n",
      "        [0.0116577, 0.000495911, 0.0125122, ..., -0.00646973,\n",
      "         0.00325012, -0.00114441],\n",
      "        [-0.0297852, -0.0129395, 0.00775146, ..., 0.0032196, 0.0133057,\n",
      "         0.00811768],\n",
      "        ...,\n",
      "        [-0.0107422, -0.00308228, 0.0147095, ..., 0.000801086,\n",
      "         0.000576019, -0.00631714],\n",
      "        [0.00799561, 0.0065918, -0.00473022, ..., 0.00570679,\n",
      "         -0.0192871, 0.00202942],\n",
      "        [-0.0062561, 0.00427246, 0.00332642, ..., -0.0118408,\n",
      "         0.00765991, 0.00872803]],\n",
      "\n",
      "       [[-0.00357056, 0.00469971, -0.00646973, ..., 0.012085,\n",
      "         0.00153351, 0.0211182],\n",
      "        [-0.00518799, 0.00328064, 0.0220947, ..., 0.00732422,\n",
      "         0.000648499, -0.0126343],\n",
      "        [-0.00137329, -0.00276184, 0.00735474, ..., -0.0112305,\n",
      "         0.00178528, -0.00915527],\n",
      "        ...,\n",
      "        [-0.0233154, 0.00933838, 0.0290527, ..., -0.0140991, 0.00222778,\n",
      "         -0.0236816],\n",
      "        [-0.00177765, 0.00328064, -0.0062561, ..., 0.00427246,\n",
      "         -0.0168457, 0.00653076],\n",
      "        [-0.00212097, -0.0100708, -0.0134277, ..., -0.00500488,\n",
      "         0.00741577, -0.000255585]],\n",
      "\n",
      "       [[0.00177765, 0.00735474, 0.00424194, ..., -0.012207, 0.022583,\n",
      "         -0.0253906],\n",
      "        [-0.00720215, -0.0100098, -0.0150757, ..., -0.0375977,\n",
      "         -0.0050354, 0.0361328],\n",
      "        [-0.00714111, -0.0100708, 0.000379562, ..., -0.013916,\n",
      "         -0.00753784, -0.0101929],\n",
      "        ...,\n",
      "        [0.00927734, 0.0134888, 0.0196533, ..., 0.00512695, -0.00296021,\n",
      "         -0.0109863],\n",
      "        [-0.00405884, -0.00479126, -0.00147247, ..., -0.00363159,\n",
      "         0.00122833, 0.0177002],\n",
      "        [-0.00430298, 0.000303268, -0.00799561, ..., -0.0166016,\n",
      "         0.0250244, 0.0133667]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00171661, 0.00564575, 0.00317383, ..., -0.0098877,\n",
      "         -0.0019989, -0.00119019],\n",
      "        [-0.012146, -0.00265503, -0.0108643, ..., -0.003479,\n",
      "         -0.00534058, -0.00561523],\n",
      "        [0.0170898, -0.0218506, 0.0147095, ..., -0.00390625,\n",
      "         -0.00216675, 0.00521851],\n",
      "        ...,\n",
      "        [-0.00567627, 0.00378418, -0.00408936, ..., -0.00982666,\n",
      "         -0.0147705, -0.000123024],\n",
      "        [-0.00126648, -0.00174713, 0.00787354, ..., 0.00285339,\n",
      "         0.00145721, -0.00379944],\n",
      "        [0.00720215, 0.00585938, -0.000553131, ..., 0.00549316,\n",
      "         0.00799561, 0.00753784]],\n",
      "\n",
      "       [[-0.00219727, 0.00297546, 0.000383377, ..., -0.00288391,\n",
      "         -0.00552368, -0.00463867],\n",
      "        [0.00909424, -0.0147095, 0.00230408, ..., -0.00222778,\n",
      "         0.00384521, -0.00613403],\n",
      "        [0.00328064, -0.00509644, 0.00169373, ..., -0.00756836,\n",
      "         0.0108643, -0.0163574],\n",
      "        ...,\n",
      "        [-0.00186157, 0.000797272, 0.0109253, ..., -0.00946045,\n",
      "         -0.0292969, 0.0361328],\n",
      "        [-0.0198975, 0.00466919, -0.00646973, ..., 0.0102539,\n",
      "         -0.00878906, -0.000865936],\n",
      "        [0.00254822, 9.9659e-05, 0.000142097, ..., -0.00396729,\n",
      "         -0.02771, 0.0216064]],\n",
      "\n",
      "       [[-0.00662231, 0.00915527, 0.00976562, ..., -0.00753784,\n",
      "         -0.00247192, -0.00189972],\n",
      "        [0.00457764, 0.0137939, 0.0172119, ..., -0.00114441,\n",
      "         -0.000972748, 0.000953674],\n",
      "        [-0.00309753, -0.0206299, -0.00161743, ..., -0.0111084,\n",
      "         0.00375366, 0.00372314],\n",
      "        ...,\n",
      "        [0.00430298, -0.00370789, 0.00183868, ..., 0.000461578,\n",
      "         0.00300598, -0.00708008],\n",
      "        [0.00195312, 0.00753784, -0.0101318, ..., 0.00787354,\n",
      "         0.00823975, 0.00479126],\n",
      "        [-0.00878906, 0.00364685, 0.00169373, ..., 0.000904083,\n",
      "         7.00951e-05, -0.00482178]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00107574, 0.00662231, -0.00872803, ..., 0.00561523,\n",
      "         0.00909424, 0.00312805],\n",
      "        [0.00601196, 0.00418091, 0.0105591, ..., 0.00534058, 0.013855,\n",
      "         0.00239563],\n",
      "        [0.00866699, -0.00952148, 0.000545502, ..., -0.00732422,\n",
      "         0.0146484, 0.00436401],\n",
      "        ...,\n",
      "        [-0.00112152, -0.00421143, 0.00994873, ..., -0.00723267,\n",
      "         -0.0111694, -0.00160217],\n",
      "        [0.0150146, 0.00436401, -0.0100098, ..., -0.00787354,\n",
      "         -0.00469971, 0.0131836],\n",
      "        [-0.000587463, 0.00497437, 0.0137329, ..., 0.00494385,\n",
      "         -0.000392914, -0.0118408]],\n",
      "\n",
      "       [[0.000370026, -0.0118408, 0.0289307, ..., -0.0141602,\n",
      "         -0.00805664, 0.00604248],\n",
      "        [-0.001297, 0.000196457, -0.0127563, ..., 0.00222778, -0.013916,\n",
      "         -0.000614166],\n",
      "        [-0.00506592, 0.0108032, 0.00958252, ..., -0.00375366,\n",
      "         -0.00933838, -0.00294495],\n",
      "        ...,\n",
      "        [-0.0038147, -0.010376, -0.0035553, ..., 0.0106812, 0.00361633,\n",
      "         0.00717163],\n",
      "        [0.0043335, -0.000686646, 0.0147095, ..., -0.000180244,\n",
      "         0.0072937, 0.00282288],\n",
      "        [0.0012207, 0.0111694, -0.00491333, ..., -0.00860596,\n",
      "         -0.00909424, 0.00283813]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00415039, -0.00134277, -0.00189972, ..., -0.00366211,\n",
      "        -0.00107574, 0.0043335],\n",
      "       [-0.00744629, 0.00726318, 0.00897217, ..., -0.00308228,\n",
      "        0.000663757, 0.00537109],\n",
      "       [0.0150757, -0.0078125, -0.00244141, ..., -0.00817871,\n",
      "        -0.00775146, -0.00631714],\n",
      "       ...,\n",
      "       [-0.00402832, -0.0148926, -0.0030365, ..., 0.00756836, -0.0161133,\n",
      "        -0.00457764],\n",
      "       [-0.00692749, -0.00289917, -0.0108032, ..., 0.00891113,\n",
      "        -0.00732422, -0.00613403],\n",
      "       [0.0161133, -0.00332642, 0.00631714, ..., 0.00497437, 0.00384521,\n",
      "        -0.00491333]], dtype=bfloat16), a=Array([[-0.00584595, -0.00180545, -0.00662199, ..., -0.0220709 ,\n",
      "        -0.00569964, -0.00861686],\n",
      "       [ 0.00151854, -0.00964406,  0.00366633, ...,  0.00940564,\n",
      "        -0.00930284,  0.00364371]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0136108, -0.150391, -0.020874, ..., -0.355469, -0.0186768,\n",
      "       -0.425781], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.0888672, 0.0622559, 0.12793, ..., -0.00866699, 0.337891,\n",
      "       0.0756836], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.490234, 0.255859, 0.330078, ..., 0.367188, -0.0544434, 0.046875],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.388672, 0.382812, 0.402344, ..., 0.597656, -0.0415039, 0.236328],      dtype=bfloat16)}}, 'layer_6': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.0103149, 0.000452042, -0.0153809, ..., -0.00915527,\n",
      "         0.0106201, 0.00836182],\n",
      "        [-0.00848389, 0.0072937, 0.000648499, ..., -0.00823975,\n",
      "         0.010437, 0.0090332],\n",
      "        [0.00927734, -0.00402832, -0.00141907, ..., -0.00317383,\n",
      "         0.0161133, 0.00418091],\n",
      "        ...,\n",
      "        [0.0145874, 0.0222168, 0.00640869, ..., 0.00817871, -0.0137329,\n",
      "         -0.0114746],\n",
      "        [-0.00668335, 0.00195312, 0.00424194, ..., -0.00133514,\n",
      "         0.000226974, 0.0030365],\n",
      "        [-0.00195312, 0.00558472, -0.020752, ..., 0.00830078,\n",
      "         -0.0014801, 0.00341797]],\n",
      "\n",
      "       [[-0.00139618, 0.000881195, -0.0119019, ..., 0.0112305,\n",
      "         -0.00799561, -0.0140381],\n",
      "        [0.0164795, -0.0131226, 0.00582886, ..., 0.000228882,\n",
      "         -0.00772095, -0.00708008],\n",
      "        [0.00170135, 0.00753784, -0.00842285, ..., 0.00558472,\n",
      "         0.00601196, -0.00221252],\n",
      "        ...,\n",
      "        [-0.00509644, 0.00665283, 0.0127563, ..., -0.00933838,\n",
      "         0.0127563, -0.000141144],\n",
      "        [-0.0123901, -0.0179443, 0.0045166, ..., -0.00765991,\n",
      "         0.00133514, 0.00390625],\n",
      "        [0.00202942, -0.00221252, 0.00424194, ..., 0.00567627,\n",
      "         -0.00515747, 0.0050354]],\n",
      "\n",
      "       [[0.000213623, 0.000831604, -0.00720215, ..., -0.00933838,\n",
      "         0.00186157, -0.00527954],\n",
      "        [0.0113525, 0.00405884, -0.00585938, ..., -0.00253296,\n",
      "         0.00497437, 0.0174561],\n",
      "        [0.00136566, 0.00189972, 0.00570679, ..., -0.00704956,\n",
      "         0.00174713, -0.00358582],\n",
      "        ...,\n",
      "        [0.0130005, 3.40939e-05, 0.0153198, ..., 0.00112915,\n",
      "         -0.00247192, -0.0131226],\n",
      "        [-0.00646973, -0.0108643, 0.00628662, ..., 0.00312805,\n",
      "         0.00244141, -0.00848389],\n",
      "        [-0.00915527, 0.00836182, 0.000206947, ..., -0.013916,\n",
      "         -0.0111694, -0.00512695]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.000766754, 0.00285339, -0.0065918, ..., -0.0184326,\n",
      "         -0.00286865, 0.00170898],\n",
      "        [-0.000185966, -0.0106201, 0.0113525, ..., 0.00747681,\n",
      "         -0.0127563, 0.0106812],\n",
      "        [0.0137329, -0.00848389, -0.00120544, ..., 0.00320435,\n",
      "         0.00723267, 0.00897217],\n",
      "        ...,\n",
      "        [0.00897217, -0.00102997, -0.0257568, ..., -0.00686646,\n",
      "         -0.00753784, 0.0133057],\n",
      "        [0.00848389, -0.00141907, 0.0270996, ..., 0.00219727, 0.0145874,\n",
      "         0.000261307],\n",
      "        [0.000204086, -0.00363159, -0.0090332, ..., -0.00198364,\n",
      "         0.00509644, -0.0154419]],\n",
      "\n",
      "       [[0.00147247, -0.00531006, -0.00402832, ..., -0.00970459,\n",
      "         -0.00613403, 0.0113525],\n",
      "        [-0.000453949, 0.026001, -0.00872803, ..., -0.00136566,\n",
      "         -0.000320435, -0.000239372],\n",
      "        [-0.0256348, 0.00075531, -0.017334, ..., 0.00897217, -0.0238037,\n",
      "         0.0200195],\n",
      "        ...,\n",
      "        [-0.00592041, -0.00314331, -0.00317383, ..., -0.0189209,\n",
      "         -0.00540161, -0.0119629],\n",
      "        [-0.0131226, 0.0118408, -0.0125122, ..., 0.00273132, 0.00506592,\n",
      "         -0.00811768],\n",
      "        [0.0192871, 0.00479126, -0.0145874, ..., 0.0119629, 0.00408936,\n",
      "         0.0240479]],\n",
      "\n",
      "       [[0.0143433, 0.0111084, 0.0145874, ..., 0.0169678, 0.00964355,\n",
      "         -0.0144653],\n",
      "        [-0.00552368, -0.020752, -0.00296021, ..., 0.000173569,\n",
      "         0.00692749, -0.00939941],\n",
      "        [0.00643921, 0.00335693, 0.0230713, ..., 0.00567627, 0.00473022,\n",
      "         -0.0140381],\n",
      "        ...,\n",
      "        [0.0194092, -0.0213623, -0.00799561, ..., -0.00506592,\n",
      "         -0.0227051, 0.0147705],\n",
      "        [0.00509644, 0.000545502, 0.00180054, ..., -0.000682831,\n",
      "         -0.0162354, 0.00823975],\n",
      "        [-0.0132446, -0.0142212, 0.00799561, ..., -0.0128784,\n",
      "         -0.00352478, 0.00427246]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.000455856, 0.0103149, 0.00732422, ..., -0.000148773,\n",
      "          0.00927734, -0.00491333],\n",
      "         [0.00102997, 0.0098877, -0.00289917, ..., -0.0123901,\n",
      "          0.0214844, -0.0014801],\n",
      "         [-0.00241089, -0.00753784, 0.00866699, ..., -0.0126953,\n",
      "          -0.00445557, -0.00531006],\n",
      "         ...,\n",
      "         [-0.0113525, -0.00476074, 0.00805664, ..., -0.00701904,\n",
      "          0.00149536, -0.0150757],\n",
      "         [0.00291443, -0.00144196, -0.00248718, ..., -0.0127563,\n",
      "          0.00787354, 0.00860596],\n",
      "         [-0.00491333, -0.0284424, -0.00473022, ..., -0.0027771,\n",
      "          0.0148926, -0.036377]],\n",
      "\n",
      "        [[-0.000293732, 0.0032959, -0.00772095, ..., 0.00653076,\n",
      "          0.0252686, -0.0090332],\n",
      "         [0.00537109, -0.00390625, -0.0071106, ..., -0.0101318,\n",
      "          0.0175781, 0.0109253],\n",
      "         [0.00364685, -0.00331116, -0.00143433, ..., 0.00521851,\n",
      "          -0.0212402, 0.0103149],\n",
      "         ...,\n",
      "         [-0.00209045, -0.000530243, -0.00294495, ..., -2.36034e-05,\n",
      "          0.0162354, -0.019043],\n",
      "         [-0.00506592, -0.00823975, 0.00640869, ..., -0.0103149,\n",
      "          -0.00860596, 0.0249023],\n",
      "         [-0.00546265, 0.00424194, 0.0067749, ..., -0.00125885,\n",
      "          0.00708008, -0.0262451]],\n",
      "\n",
      "        [[0.0105591, 0.00686646, -0.00466919, ..., 0.00305176,\n",
      "          0.00189972, -0.0249023],\n",
      "         [-0.0205078, 0.00360107, -0.00245667, ..., -0.00592041,\n",
      "          -0.00291443, -0.0115356],\n",
      "         [0.00370789, 0.00735474, -0.001297, ..., -0.0100098,\n",
      "          -0.0131226, 0.0205078],\n",
      "         ...,\n",
      "         [-0.00982666, -0.0019455, -0.010437, ..., 0.0102539,\n",
      "          -0.00343323, 0.00436401],\n",
      "         [0.00732422, 0.00485229, -0.00686646, ..., -0.0137939,\n",
      "          -0.0257568, 0.0151978],\n",
      "         [0.0071106, -1.80006e-05, 0.00952148, ..., -0.012085,\n",
      "          -0.0131836, 0.0078125]],\n",
      "\n",
      "        [[-0.0126343, 0.00325012, 0.0142212, ..., 0.00141144,\n",
      "          0.00305176, -0.00305176],\n",
      "         [0.00169373, 0.00543213, -0.00280762, ..., -0.00227356,\n",
      "          0.0112915, -0.0206299],\n",
      "         [0.000404358, 0.00021553, -0.0057373, ..., -0.0122681,\n",
      "          -0.00689697, 0.00460815],\n",
      "         ...,\n",
      "         [0.0126953, -0.00762939, -0.00289917, ..., 0.0013504,\n",
      "          0.00952148, 0.00028801],\n",
      "         [-0.00933838, 0.000434875, 0.00897217, ..., -0.0016861,\n",
      "          -0.00872803, -0.00689697],\n",
      "         [-0.00769043, 0.00216675, 0.0039978, ..., -0.00732422,\n",
      "          0.0101929, -0.00488281]]],\n",
      "\n",
      "\n",
      "       [[[0.0169678, 0.0133057, -0.00382996, ..., -0.0045166,\n",
      "          0.00396729, -0.00375366],\n",
      "         [0.00306702, -0.0106201, 0.00506592, ..., -0.0151978,\n",
      "          -0.0195312, -0.0144043],\n",
      "         [0.00933838, -0.00732422, 0.00561523, ..., -0.00769043,\n",
      "          0.00219727, 0.0233154],\n",
      "         ...,\n",
      "         [0.00150299, 0.00390625, 0.00485229, ..., -0.0098877,\n",
      "          -0.0010376, -0.00692749],\n",
      "         [-0.00137329, -0.00047493, -0.00680542, ..., 0.0151367,\n",
      "          -0.0136719, -0.00270081],\n",
      "         [-7.43866e-05, -0.0111084, -0.00136566, ..., 0.0130005,\n",
      "          -0.0016861, -0.00521851]],\n",
      "\n",
      "        [[0.000530243, -0.00982666, -0.00209045, ..., 0.0055542,\n",
      "          0.00958252, -0.0108643],\n",
      "         [0.00952148, -4.86374e-05, 0.0100098, ..., 0.0111084,\n",
      "          -0.012085, 0.0124512],\n",
      "         [0.00178528, 0.00854492, -0.00309753, ..., 0.00680542,\n",
      "          -0.00193787, 0.000576019],\n",
      "         ...,\n",
      "         [-0.0231934, 0.0222168, -0.0140991, ..., -0.0112915,\n",
      "          0.0137329, -0.0142212],\n",
      "         [0.00014782, 0.00350952, 0.0011673, ..., 0.000656128,\n",
      "          -0.00540161, -0.00939941],\n",
      "         [0.0119019, -0.00411987, -0.0139771, ..., 0.00338745,\n",
      "          0.00595093, 0.00124359]],\n",
      "\n",
      "        [[-0.00436401, 0.00735474, -0.00476074, ..., 0.0153198,\n",
      "          0.00787354, -0.00982666],\n",
      "         [-0.000188828, -0.0385742, 0.00534058, ..., -0.010498,\n",
      "          -0.00671387, 0.00643921],\n",
      "         [-0.00759888, 0.0118408, 0.0224609, ..., 0.0130005,\n",
      "          -0.0131226, -0.00038147],\n",
      "         ...,\n",
      "         [0.0158691, 0.0115967, 0.0100098, ..., 0.0170898, -0.00476074,\n",
      "          -0.00415039],\n",
      "         [0.0122681, 0.00233459, -0.0057373, ..., 0.00326538,\n",
      "          -0.0027771, -0.0107422],\n",
      "         [-0.0118408, 0.00346375, 0.000219345, ..., 0.0126953,\n",
      "          -0.00338745, 0.0299072]],\n",
      "\n",
      "        [[0.00305176, 0.00279236, 0.0185547, ..., 0.0025177,\n",
      "          0.00601196, -0.020752],\n",
      "         [0.00424194, -0.0354004, 0.0198975, ..., 0.00689697,\n",
      "          -0.00350952, 0.00238037],\n",
      "         [0.0114746, -0.0184326, 0.034668, ..., 0.00744629, 0.0227051,\n",
      "          0.0137329],\n",
      "         ...,\n",
      "         [0.00567627, 0.010437, 0.00114441, ..., 0.0100098, 0.0133057,\n",
      "          -0.0177002],\n",
      "         [0.00537109, -0.000709534, 0.0102539, ..., 0.00421143,\n",
      "          -0.00830078, -0.0122681],\n",
      "         [-0.0134888, 0.0140381, -0.0150146, ..., 0.00601196,\n",
      "          0.0192871, -0.0090332]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.0222168, -0.0038147, -0.00323486, ..., 0.00360107,\n",
      "         0.0177002, 0.00436401],\n",
      "        [-0.0290527, -0.00921631, 0.0100708, ..., -0.0203857,\n",
      "         0.00300598, -0.00132751],\n",
      "        [0.00343323, 0.00311279, 0.000858307, ..., -0.0071106,\n",
      "         -0.00448608, 0.00787354],\n",
      "        ...,\n",
      "        [0.00173187, -0.0106201, -0.00485229, ..., 0.00546265,\n",
      "         0.0050354, -0.000135422],\n",
      "        [0.00382996, 0.0151978, 0.00439453, ..., -0.00369263,\n",
      "         -0.00946045, -0.0043335],\n",
      "        [-0.0130615, -0.00692749, -0.00402832, ..., -0.00271606,\n",
      "         0.0134888, -0.013855]],\n",
      "\n",
      "       [[-0.00326538, -0.00286865, -0.0071106, ..., 0.00704956,\n",
      "         0.0125732, 0.00878906],\n",
      "        [-0.00976562, -0.00282288, -0.00113678, ..., 0.00485229,\n",
      "         0.000238419, 0.00750732],\n",
      "        [0.00150299, -0.00927734, -0.0057373, ..., -0.022583,\n",
      "         -0.000999451, -0.0102539],\n",
      "        ...,\n",
      "        [0.00182343, -0.00138855, -0.00921631, ..., -0.00469971,\n",
      "         0.00531006, 0.0137939],\n",
      "        [-0.00933838, 0.00244141, 0.00227356, ..., 0.000919342,\n",
      "         -0.0133057, -0.0200195],\n",
      "        [-0.0038147, 0.0150757, -0.00109863, ..., -0.03125, -0.022583,\n",
      "         -0.029541]],\n",
      "\n",
      "       [[0.00747681, -0.00485229, -0.00646973, ..., 0.00224304,\n",
      "         0.010376, -0.00799561],\n",
      "        [0.000141144, 0.00921631, -0.000892639, ..., 0.000322342,\n",
      "         -0.00308228, 0.00210571],\n",
      "        [-0.00686646, 0.00305176, 0.00552368, ..., 0.000675201,\n",
      "         0.00379944, -0.00427246],\n",
      "        ...,\n",
      "        [-0.00643921, 0.00442505, 0.00175476, ..., 0.000134468,\n",
      "         0.0045166, -0.00793457],\n",
      "        [0.00300598, -0.00616455, 0.00460815, ..., 0.000312805,\n",
      "         0.00302124, -0.0101318],\n",
      "        [0.00976562, 0.00756836, -0.00260925, ..., -0.00376892,\n",
      "         -0.00364685, 0.00260925]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00341797, -0.0178223, -0.00263977, ..., -0.0050354,\n",
      "         -0.00256348, -0.00253296],\n",
      "        [0.00524902, 0.0103149, 0.0269775, ..., 0.00267029, -0.00753784,\n",
      "         -0.00415039],\n",
      "        [-0.0119019, -0.00469971, -0.00793457, ..., 0.00915527,\n",
      "         0.00854492, 0.00762939],\n",
      "        ...,\n",
      "        [-0.00439453, 0.0129395, -0.00427246, ..., -0.00674438,\n",
      "         0.00775146, 0.00909424],\n",
      "        [0.00515747, 0.0032196, 0.0117798, ..., 0.0170898, -0.00352478,\n",
      "         -0.0050354],\n",
      "        [-0.00500488, -0.00717163, -0.00297546, ..., -0.0203857,\n",
      "         -0.0115967, 0.0153198]],\n",
      "\n",
      "       [[0.0142212, -0.00180817, 0.0267334, ..., 0.00585938,\n",
      "         3.86238e-05, -0.00527954],\n",
      "        [0.0144043, 0.00242615, -0.0022583, ..., -0.0164795, 0.00509644,\n",
      "         -0.000171661],\n",
      "        [0.0071106, -0.00224304, 0.00415039, ..., -0.019165, -0.0152588,\n",
      "         0.0122681],\n",
      "        ...,\n",
      "        [0.0212402, 0.0167236, -0.0139771, ..., 0.00204468, 0.00564575,\n",
      "         -0.012207],\n",
      "        [-0.00286865, 0.00202942, 0.00476074, ..., -0.0131836,\n",
      "         8.53539e-05, -0.00136566],\n",
      "        [-0.0130005, 0.00653076, -0.00497437, ..., -0.0153809,\n",
      "         -0.0105591, -0.000511169]],\n",
      "\n",
      "       [[0.00946045, 0.0224609, 0.00149536, ..., 0.00680542,\n",
      "         -0.00233459, -0.000579834],\n",
      "        [0.00564575, -0.00680542, 0.0214844, ..., -0.00314331,\n",
      "         0.0267334, 0.00921631],\n",
      "        [-0.00897217, 0.00701904, 0.00325012, ..., 0.0114746, 0.0117188,\n",
      "         0.0281982],\n",
      "        ...,\n",
      "        [-0.0103149, 0.00854492, -0.0134277, ..., 0.00439453,\n",
      "         -0.0151978, -0.000740051],\n",
      "        [0.0101929, 0.000904083, 0.00921631, ..., 0.00299072,\n",
      "         -0.0177002, -0.0187988],\n",
      "        [0.000965118, -8.39233e-05, -0.00202942, ..., 5.50747e-05,\n",
      "         0.0045166, -0.00463867]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00227356, -0.00634766, 0.00634766, ..., 0.00701904,\n",
      "         -0.00534058, -0.010437],\n",
      "        [-0.00436401, 0.00524902, 0.010498, ..., -0.0154419, 0.00756836,\n",
      "         8.34465e-05],\n",
      "        [0.0131836, 0.00268555, -0.00683594, ..., -0.0106201, 0.0062561,\n",
      "         0.0111694],\n",
      "        ...,\n",
      "        [0.00276184, -0.00314331, 0.00430298, ..., 0.00805664,\n",
      "         0.00512695, -0.00231934],\n",
      "        [-0.00445557, -0.00280762, 0.00332642, ..., -0.000785828,\n",
      "         0.0057373, -0.00325012],\n",
      "        [0.00164795, -0.00454712, 0.00165558, ..., 0.00631714,\n",
      "         -0.015564, 0.00375366]],\n",
      "\n",
      "       [[-0.012207, -0.00622559, 0.00708008, ..., -0.00509644,\n",
      "         -0.00747681, 0.00708008],\n",
      "        [0.000263214, 0.00325012, 0.0228271, ..., -0.00393677,\n",
      "         0.00662231, -0.00650024],\n",
      "        [-0.0136108, 0.0100098, 0.00157928, ..., -0.00756836,\n",
      "         0.00402832, 0.00125122],\n",
      "        ...,\n",
      "        [0.0112915, 0.00143433, 0.00512695, ..., 0.00671387, 0.00279236,\n",
      "         0.0142212],\n",
      "        [-0.00765991, -0.00976562, -0.00114441, ..., -0.00665283,\n",
      "         -0.003479, -0.0107422],\n",
      "        [0.00534058, -0.013916, 0.00494385, ..., -0.00126648,\n",
      "         0.00259399, 0.00302124]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.0153198, -0.00793457, -0.0203857, ..., 0.0152588, -0.00891113,\n",
      "        0.00259399],\n",
      "       [-0.0142212, 0.0132446, 0.00976562, ..., 0.0123291, 0.00534058,\n",
      "        -0.00445557],\n",
      "       [0.00244141, 0.00318909, -0.0145264, ..., -0.000740051,\n",
      "        -0.00265503, -0.00405884],\n",
      "       ...,\n",
      "       [-0.0153198, 0.00187683, -0.00402832, ..., 0.00842285, -0.0174561,\n",
      "        0.00157928],\n",
      "       [0.0014801, 0.0045166, -0.00524902, ..., -0.0020752, -0.0114136,\n",
      "        -0.00146484],\n",
      "       [0.00230408, -0.0117188, -0.00201416, ..., 0.00970459, -0.019043,\n",
      "        -0.00352478]], dtype=bfloat16), a=Array([[-0.0155806 , -0.01371003, -0.01509875, ...,  0.01296713,\n",
      "         0.00798594,  0.00760426],\n",
      "       [-0.00061655,  0.01749108, -0.01459254, ...,  0.01223726,\n",
      "        -0.01537374,  0.00116413]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0039978, -0.124512, -0.0678711, ..., -0.241211, 0.00665283,\n",
      "       -0.359375], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.106934, 0.0874023, 0.219727, ..., 0.0168457, 0.365234, 0.10498],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([1.10156, 0.796875, 0.84375, ..., 0.988281, 0.0463867, 0.369141],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.435547, 0.447266, 0.443359, ..., 0.636719, -0.0673828, 0.363281],      dtype=bfloat16)}}, 'layer_7': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0178223, 0.00132751, -0.00531006, ..., 0.00689697,\n",
      "         -0.00561523, -0.00982666],\n",
      "        [-0.00958252, 0.0183105, -0.00515747, ..., 0.00263977,\n",
      "         -0.0137329, 0.00741577],\n",
      "        [0.000368118, -0.0192871, -0.0109253, ..., -0.0161133,\n",
      "         -0.0101318, -0.00698853],\n",
      "        ...,\n",
      "        [-0.013916, 0.00430298, -0.0222168, ..., 0.012207, -0.0014267,\n",
      "         -0.0120239],\n",
      "        [0.0148926, 0.0256348, 0.00123596, ..., 0.00317383, 0.00466919,\n",
      "         -0.00753784],\n",
      "        [0.0072937, -0.00842285, 0.0294189, ..., -0.0128784,\n",
      "         -0.00473022, -0.0011673]],\n",
      "\n",
      "       [[-0.003479, 0.0122681, 0.00640869, ..., 0.00193787, -0.0123291,\n",
      "         0.00357056],\n",
      "        [0.00473022, 0.00558472, -0.00219727, ..., -0.00323486,\n",
      "         0.006073, 0.0209961],\n",
      "        [0.00512695, 0.0111694, 0.0202637, ..., 0.0144653, 0.00309753,\n",
      "         -0.012146],\n",
      "        ...,\n",
      "        [0.00119781, 0.00276184, -0.0175781, ..., 0.00291443,\n",
      "         0.00485229, 0.00222778],\n",
      "        [0.00202942, -0.00506592, 0.000371933, ..., 0.00122833,\n",
      "         0.00982666, 0.000289917],\n",
      "        [0.00482178, -0.00283813, 0.0124512, ..., -0.000366211,\n",
      "         -0.000431061, 0.000459671]],\n",
      "\n",
      "       [[0.00561523, 0.00195312, 0.00946045, ..., -0.017334, -0.0109253,\n",
      "         0.00720215],\n",
      "        [-0.00279236, 0.0131836, 0.0019989, ..., -0.0088501,\n",
      "         -0.00515747, -0.000488281],\n",
      "        [-0.0145874, 0.0166016, -0.00340271, ..., 0.0134277, 0.00668335,\n",
      "         0.0136108],\n",
      "        ...,\n",
      "        [0.00939941, 0.0111084, -0.0119019, ..., 0.0152588, 0.00708008,\n",
      "         0.00460815],\n",
      "        [-0.0251465, 0.00286865, -0.0132446, ..., -0.0241699,\n",
      "         -0.00201416, 0.0144043],\n",
      "        [-0.00271606, 0.0169678, -0.0164795, ..., -0.00570679,\n",
      "         0.00230408, 0.00202942]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.0133667, -0.00288391, 0.00558472, ..., -0.0107422,\n",
      "         -0.0145264, -0.017334],\n",
      "        [-0.00236511, 0.00396729, 0.00756836, ..., 0.00177765,\n",
      "         -0.00209045, -0.00915527],\n",
      "        [-0.0120239, 0.0245361, 0.0170898, ..., -0.00430298,\n",
      "         -0.00759888, -0.00427246],\n",
      "        ...,\n",
      "        [-0.0170898, -0.0217285, -0.00692749, ..., -0.0114746,\n",
      "         -0.0246582, 0.00576782],\n",
      "        [0.0158691, 0.0055542, -0.00793457, ..., 0.0162354, -0.0145874,\n",
      "         -0.00698853],\n",
      "        [0.0062561, -0.00585938, -0.00787354, ..., 0.00933838,\n",
      "         -0.026123, 0.0288086]],\n",
      "\n",
      "       [[-0.00793457, -0.00921631, -0.00382996, ..., -2.03848e-05,\n",
      "         0.00524902, -0.00964355],\n",
      "        [-0.0197754, 0.00185394, -0.00558472, ..., 0.0071106,\n",
      "         -0.0187988, 0.00512695],\n",
      "        [0.00952148, -0.0161133, 0.00842285, ..., -0.0150146,\n",
      "         -0.00309753, -0.00830078],\n",
      "        ...,\n",
      "        [-0.0014801, 0.0142822, 0.0101929, ..., -0.0032196, 0.0327148,\n",
      "         0.00595093],\n",
      "        [-0.00427246, 0.00915527, -0.0161133, ..., -0.00692749,\n",
      "         0.0125732, 0.0112305],\n",
      "        [0.0132446, -0.00823975, 0.012146, ..., -0.0247803, -0.00909424,\n",
      "         -0.00604248]],\n",
      "\n",
      "       [[-0.00842285, 0.00579834, -0.00121307, ..., 0.00442505,\n",
      "         -0.0157471, 0.00104523],\n",
      "        [-0.0142822, -0.00132751, -0.0123901, ..., -0.010437,\n",
      "         0.00576782, -0.0144043],\n",
      "        [-0.0144653, -0.00260925, 0.00946045, ..., -0.00643921,\n",
      "         -0.00224304, 0.00402832],\n",
      "        ...,\n",
      "        [0.00567627, -0.00145721, 0.00469971, ..., -0.0062561, 0.001297,\n",
      "         -0.00291443],\n",
      "        [-0.00188446, -0.00259399, 0.00184631, ..., -0.0174561,\n",
      "         -0.0153198, -0.00958252],\n",
      "        [-0.00582886, -0.00753784, -0.0124512, ..., 0.00793457,\n",
      "         0.0148926, -0.0220947]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0001688, -0.00723267, 0.00915527, ..., 0.0118408,\n",
      "          0.00854492, -0.00842285],\n",
      "         [0.00793457, 0.00396729, 0.0098877, ..., 0.00653076,\n",
      "          -0.00101471, -0.0290527],\n",
      "         [0.00491333, 0.00127411, 0.00561523, ..., 0.0136108,\n",
      "          -0.00494385, 0.00482178],\n",
      "         ...,\n",
      "         [6.38962e-05, 0.0155029, 0.00897217, ..., 0.00698853,\n",
      "          -0.00363159, 0.0078125],\n",
      "         [-0.0123291, 0.00317383, 0.00384521, ..., -0.0145874,\n",
      "          -0.00386047, 0.000656128],\n",
      "         [0.00180054, 0.0011673, 0.00720215, ..., 3.86238e-05,\n",
      "          0.00248718, -0.00424194]],\n",
      "\n",
      "        [[0.00546265, -0.00854492, -0.000201225, ..., -0.00534058,\n",
      "          -0.0192871, 0.0155029],\n",
      "         [-0.00491333, 0.00897217, -0.00315857, ..., -0.0067749,\n",
      "          -0.0163574, -0.00817871],\n",
      "         [-0.0130005, 0.00167084, 0.000907898, ..., 0.000413895,\n",
      "          -0.00323486, 0.0116577],\n",
      "         ...,\n",
      "         [-0.0195312, 0.0022583, 0.000411987, ..., 0.0147095,\n",
      "          -0.0126953, -0.0368652],\n",
      "         [-0.00601196, -0.00367737, 0.0067749, ..., 0.00488281,\n",
      "          0.0118408, 0.0203857],\n",
      "         [0.00292969, -0.0130005, -0.00488281, ..., -0.027832,\n",
      "          -0.010376, -0.0134888]],\n",
      "\n",
      "        [[-0.00811768, -0.00448608, 0.0113525, ..., 0.00427246,\n",
      "          -0.022583, 0.0140381],\n",
      "         [-0.00191498, -0.00256348, -0.00267029, ..., -0.0136108,\n",
      "          0.00332642, -0.00439453],\n",
      "         [-0.00582886, 0.00601196, 0.00448608, ..., -0.000675201,\n",
      "          -0.00311279, 0.00260925],\n",
      "         ...,\n",
      "         [0.00616455, 0.00836182, -0.0127563, ..., -0.00306702,\n",
      "          0.0101929, -0.00421143],\n",
      "         [0.000278473, -0.00201416, -0.0216064, ..., 0.0090332,\n",
      "          -0.0306396, 0.00714111],\n",
      "         [-0.00473022, -0.0027771, 0.0106812, ..., -0.00552368,\n",
      "          -0.00297546, -0.0123291]],\n",
      "\n",
      "        [[0.0050354, -0.00952148, -0.0114136, ..., 0.0119629,\n",
      "          -0.0288086, 0.012146],\n",
      "         [-0.0123291, -0.0145874, 0.000686646, ..., 0.00921631,\n",
      "          -0.00842285, 0.012085],\n",
      "         [0.00234985, 0.00375366, -0.00476074, ..., -0.0288086,\n",
      "          0.010498, -0.00350952],\n",
      "         ...,\n",
      "         [-0.00146484, -0.00390625, -0.0115967, ..., 0.0349121,\n",
      "          -0.0336914, -0.00582886],\n",
      "         [-0.00897217, 0.00177002, -0.00537109, ..., 0.00500488,\n",
      "          0.0098877, 0.0378418],\n",
      "         [0.00793457, -0.0043335, -0.00720215, ..., 0.0371094,\n",
      "          0.0180664, -0.0177002]]],\n",
      "\n",
      "\n",
      "       [[[0.0020752, -0.00927734, -0.00436401, ..., -0.00244141,\n",
      "          0.00537109, 0.0120239],\n",
      "         [0.00765991, 0.0172119, 0.00952148, ..., 0.00408936,\n",
      "          0.0158691, 0.00360107],\n",
      "         [0.00178528, -0.00454712, -0.00445557, ..., -0.0126953,\n",
      "          -0.00411987, 0.0106812],\n",
      "         ...,\n",
      "         [0.00314331, 0.00588989, -0.00238037, ..., 0.00331116,\n",
      "          -0.0128174, -0.0114746],\n",
      "         [-0.00173187, -0.00939941, -0.00854492, ..., -0.00369263,\n",
      "          0.0145874, 0.00393677],\n",
      "         [-0.0126343, 0.00424194, 0.000432968, ..., -0.00842285,\n",
      "          -0.0103149, -0.00106049]],\n",
      "\n",
      "        [[0.0163574, 0.00860596, 0.0072937, ..., -0.0289307,\n",
      "          -0.0279541, 0.0181885],\n",
      "         [-0.0151367, 0.0234375, -0.0128784, ..., 0.0186768,\n",
      "          -0.00576782, -0.0196533],\n",
      "         [0.00811768, 0.00567627, 0.00224304, ..., -6.00815e-05,\n",
      "          -0.0194092, -0.0139771],\n",
      "         ...,\n",
      "         [-0.00946045, -0.00717163, 0.00753784, ..., 0.0230713,\n",
      "          0.00196838, -0.00136566],\n",
      "         [0.0122681, -0.00872803, -0.00653076, ..., 0.00613403,\n",
      "          0.00836182, -0.00442505],\n",
      "         [-0.0157471, -0.00387573, 0.00354004, ..., 0.0088501,\n",
      "          0.0236816, 0.0134888]],\n",
      "\n",
      "        [[0.00396729, -0.000349045, -0.00476074, ..., -0.00393677,\n",
      "          0.00811768, 0.00695801],\n",
      "         [-0.0114136, -0.0170898, 0.00518799, ..., -0.0115967,\n",
      "          0.0140991, 0.0105591],\n",
      "         [-0.00482178, 0.0183105, -0.0105591, ..., -0.00588989,\n",
      "          -0.00619507, 0.00488281],\n",
      "         ...,\n",
      "         [-0.0192871, -0.0130005, 0.00369263, ..., -0.00311279,\n",
      "          0.00723267, 0.00354004],\n",
      "         [0.00524902, 0.0110474, -0.00793457, ..., -0.0134277,\n",
      "          -0.00236511, -0.00292969],\n",
      "         [-0.0119629, 0.00069809, 0.00537109, ..., 0.0212402,\n",
      "          0.0185547, 0.0065918]],\n",
      "\n",
      "        [[-0.0178223, 0.0233154, -0.00238037, ..., -0.00198364,\n",
      "          -0.0149536, -0.00576782],\n",
      "         [0.0174561, -0.0127563, 0.000299454, ..., -0.0169678,\n",
      "          -0.0110474, 0.00114441],\n",
      "         [0.0178223, -0.00552368, -0.00069809, ..., 0.0231934,\n",
      "          0.0013504, 0.0145874],\n",
      "         ...,\n",
      "         [-0.00305176, -0.0172119, -0.0043335, ..., -0.00546265,\n",
      "          -0.00704956, 0.0155029],\n",
      "         [-0.00674438, -0.00576782, 0.00120544, ..., -0.010376,\n",
      "          0.00193024, -0.00854492],\n",
      "         [0.00598145, 0.0127563, 0.000957489, ..., 0.00494385,\n",
      "          -0.0045166, -0.00506592]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00174713, 0.00315857, 0.00646973, ..., -0.00830078,\n",
      "         -0.0164795, -0.0107422],\n",
      "        [0.0146484, -0.00439453, 0.00212097, ..., -0.00793457,\n",
      "         -0.00891113, -0.0119629],\n",
      "        [-0.00915527, 0.00119781, 0.0194092, ..., 0.0167236, 0.0203857,\n",
      "         0.00135803],\n",
      "        ...,\n",
      "        [-0.0217285, -0.0108032, 0.0167236, ..., 0.010498, -0.00069046,\n",
      "         -0.0217285],\n",
      "        [0.0213623, 0.00952148, -0.0233154, ..., -0.00598145, 0.0192871,\n",
      "         0.00436401],\n",
      "        [0.00187683, -0.00317383, -0.0197754, ..., 0.0112305,\n",
      "         0.00212097, 0.0142212]],\n",
      "\n",
      "       [[0.000545502, 0.00564575, 0.0067749, ..., 0.0100708,\n",
      "         -0.00154114, -0.00958252],\n",
      "        [0.0158691, 0.00221252, -0.00805664, ..., 0.0137329, 0.0072937,\n",
      "         0.0336914],\n",
      "        [0.00047493, 0.00346375, 0.00115204, ..., 0.00105286, 0.0245361,\n",
      "         0.00285339],\n",
      "        ...,\n",
      "        [-0.00195312, 0.00248718, 0.00488281, ..., 0.00866699,\n",
      "         0.0241699, 0.015625],\n",
      "        [0.0111694, 0.000534058, -0.013916, ..., 0.0050354, 0.00463867,\n",
      "         -0.0150757],\n",
      "        [-0.00439453, -0.0134888, 0.0211182, ..., -0.0169678,\n",
      "         -0.0105591, 0.00343323]],\n",
      "\n",
      "       [[0.0050354, 0.0065918, -0.00352478, ..., 0.0112305, -0.013916,\n",
      "         0.0272217],\n",
      "        [0.00296021, 0.00805664, -0.00842285, ..., -0.0118408,\n",
      "         0.00491333, -0.0422363],\n",
      "        [0.00291443, -0.000136375, 0.00793457, ..., 0.0269775,\n",
      "         0.00939941, -0.00124359],\n",
      "        ...,\n",
      "        [0.00106812, -0.000511169, -0.00245667, ..., -0.00300598,\n",
      "         0.024292, -0.0159912],\n",
      "        [0.00387573, -0.0111084, 0.00549316, ..., 0.00242615, 0.0148315,\n",
      "         -0.0016098],\n",
      "        [-0.00570679, -0.00634766, 0.00836182, ..., -0.00640869,\n",
      "         0.00582886, 0.000598907]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00158691, -0.000705719, -0.0133057, ..., -0.00518799,\n",
      "         -0.0145874, -0.0263672],\n",
      "        [-0.000762939, 0.00439453, -0.00686646, ..., -0.0213623,\n",
      "         -0.0270996, -0.0227051],\n",
      "        [0.000392914, -0.000177383, 0.00216675, ..., -0.0124512,\n",
      "         -0.00254822, -0.0137939],\n",
      "        ...,\n",
      "        [-0.00139618, -0.000862122, 0.00604248, ..., -0.0290527,\n",
      "         -0.0134277, -0.0127563],\n",
      "        [-0.00405884, 0.00141144, 0.0148315, ..., -0.00263977,\n",
      "         -0.00628662, 0.0319824],\n",
      "        [-0.00320435, 0.000419617, -0.00357056, ..., -0.00227356,\n",
      "         -0.0109863, -0.0200195]],\n",
      "\n",
      "       [[0.000257492, -0.0015564, 0.00631714, ..., 0.0147095, -0.003479,\n",
      "         -0.00418091],\n",
      "        [-0.0108643, 0.00343323, -0.00616455, ..., 0.00466919,\n",
      "         -0.0219727, 0.00236511],\n",
      "        [-0.000459671, 0.00113678, 0.0111084, ..., -0.0289307,\n",
      "         0.00714111, -0.000705719],\n",
      "        ...,\n",
      "        [0.00213623, 0.00415039, 0.00488281, ..., 0.0145264, 0.0186768,\n",
      "         -0.0133057],\n",
      "        [-0.000167847, -0.00274658, -0.00288391, ..., -0.0189209,\n",
      "         0.00485229, -0.0247803],\n",
      "        [-0.00113678, 0.000400543, -0.00366211, ..., 0.0371094,\n",
      "         -0.00878906, 0.00610352]],\n",
      "\n",
      "       [[-7.62939e-05, -0.00531006, -0.0117798, ..., -0.00151825,\n",
      "         0.000682831, 0.00793457],\n",
      "        [-0.0147705, -0.00390625, 0.000541687, ..., 0.00346375,\n",
      "         0.000907898, 0.00665283],\n",
      "        [-0.0134277, 0.00386047, -0.00909424, ..., -0.00126648,\n",
      "         0.000114918, 0.00186157],\n",
      "        ...,\n",
      "        [0.000930786, 0.00354004, 0.00370789, ..., -0.000839233,\n",
      "         0.00378418, -0.00411987],\n",
      "        [-0.00143433, 0.00212097, 0.0139771, ..., 0.00151062,\n",
      "         -0.00352478, -0.00842285],\n",
      "        [-0.0100098, -0.00332642, -0.010498, ..., 0.00121307,\n",
      "         0.00488281, 0.00579834]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00805664, 0.00595093, -0.00527954, ..., -0.00494385,\n",
      "         0.00338745, -0.00314331],\n",
      "        [0.00177002, 0.00775146, 0.00445557, ..., 0.00582886,\n",
      "         -0.0100098, 0.00274658],\n",
      "        [-0.00442505, -0.001297, 0.00769043, ..., -0.0072937,\n",
      "         -0.0119629, -0.000591278],\n",
      "        ...,\n",
      "        [0.000999451, 0.00866699, 0.00552368, ..., 0.00622559,\n",
      "         0.000141144, -0.00296021],\n",
      "        [0.00265503, 0.000149727, 0.00063324, ..., -0.00588989,\n",
      "         0.0106812, -0.00585938],\n",
      "        [-0.00172424, 0.00872803, -0.0126953, ..., -0.0145874,\n",
      "         -0.00393677, -0.000652313]],\n",
      "\n",
      "       [[-0.00756836, -0.00750732, -0.00772095, ..., -0.00387573,\n",
      "         -0.00213623, 0.013916],\n",
      "        [-0.000450134, 0.00109863, 0.00282288, ..., 0.00189972,\n",
      "         -0.00436401, -0.00375366],\n",
      "        [0.0110474, -0.00592041, 0.00268555, ..., 0.00318909,\n",
      "         0.00285339, -0.012146],\n",
      "        ...,\n",
      "        [-0.0153198, -0.00494385, 0.00482178, ..., 0.00288391,\n",
      "         -0.00509644, -0.000701904],\n",
      "        [-0.000358582, 0.00527954, -0.00610352, ..., 0.0111084,\n",
      "         -0.0110474, -0.00509644],\n",
      "        [0.000164986, -0.00830078, -0.000337601, ..., -0.00151062,\n",
      "         -0.00337219, -0.015625]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00817871, 0.00157166, -0.00389099, ..., 0.00769043,\n",
      "        -0.00836182, -0.00286865],\n",
      "       [-0.0159912, -0.00500488, 0.0167236, ..., -0.00582886, -0.0011673,\n",
      "        0.0090332],\n",
      "       [-0.00311279, 0.00689697, -0.00259399, ..., 0.00604248,\n",
      "        -0.000442505, -0.0050354],\n",
      "       ...,\n",
      "       [-0.00227356, -0.00193787, 0.00653076, ..., 0.00244141,\n",
      "        -0.00352478, -0.00579834],\n",
      "       [0.00427246, 0.00866699, -0.0050354, ..., 0.00952148,\n",
      "        -0.000450134, -0.00107574],\n",
      "       [0.015564, 0.000236511, -0.00159454, ..., 0.00164795, 0.00415039,\n",
      "        -0.00570679]], dtype=bfloat16), a=Array([[-0.00536764,  0.01348992, -0.00598283, ..., -0.01268126,\n",
      "        -0.01520117, -0.01440818],\n",
      "       [ 0.00239141,  0.01290342,  0.00408962, ...,  0.00013094,\n",
      "         0.00600098, -0.00192806]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0143433, -0.0620117, 0.0375977, ..., -0.0898438, 0.110352,\n",
      "       -0.135742], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.191406, 0.195312, 0.308594, ..., 0.118164, 0.625, 0.196289],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.726562, 0.589844, 0.59375, ..., 0.789062, -0.155273, 0.455078],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.542969, 0.582031, 0.550781, ..., 0.742188, -0.00248718, 0.455078],      dtype=bfloat16)}}, 'layer_8': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.0039978, 0.0115967, 0.000343323, ..., 0.032959, 0.00454712,\n",
      "         0.00701904],\n",
      "        [-0.00799561, 0.0169678, 0.0223389, ..., -0.0151367, 0.00018692,\n",
      "         1.24574e-05],\n",
      "        [0.00411987, 0.00619507, 0.000823975, ..., -0.000961304,\n",
      "         -0.00460815, 0.0205078],\n",
      "        ...,\n",
      "        [0.00159454, 0.0268555, -0.0100098, ..., 0.00210571, 0.0189209,\n",
      "         -0.0238037],\n",
      "        [-0.00306702, -0.0134277, -0.0220947, ..., -0.0272217,\n",
      "         0.00585938, -0.00421143],\n",
      "        [-0.027832, -0.0111694, 0.0055542, ..., -0.012146, 0.0239258,\n",
      "         0.00747681]],\n",
      "\n",
      "       [[0.00227356, -0.00762939, -0.00976562, ..., -0.0174561,\n",
      "         -0.0130005, -0.00497437],\n",
      "        [-0.00212097, -0.0150146, -0.00482178, ..., 0.00964355,\n",
      "         0.0027771, 0.000915527],\n",
      "        [-0.000471115, -0.0122681, -0.0101318, ..., -0.00976562,\n",
      "         0.00234985, -0.0035553],\n",
      "        ...,\n",
      "        [-0.00276184, -0.0177002, 0.000115395, ..., -0.00191498,\n",
      "         -0.013916, 0.0118408],\n",
      "        [0.0016861, 0.00946045, 0.015625, ..., 0.0178223, -0.00921631,\n",
      "         0.00778198],\n",
      "        [0.0134888, 0.00915527, -0.00427246, ..., 0.0078125, -0.0249023,\n",
      "         -0.0109253]],\n",
      "\n",
      "       [[-0.0118408, 0.0203857, -0.00166321, ..., 0.0174561, 0.00144196,\n",
      "         0.00201416],\n",
      "        [-0.000522614, 0.0187988, 0.0147095, ..., -0.00497437,\n",
      "         0.00469971, 0.00106049],\n",
      "        [0.0192871, 0.0177002, 0.00543213, ..., -0.00878906,\n",
      "         0.000545502, 0.00245667],\n",
      "        ...,\n",
      "        [0.00613403, -0.0112305, 0.000965118, ..., -0.0203857,\n",
      "         -0.00186157, 0.0011673],\n",
      "        [0.00805664, -0.00479126, 0.00860596, ..., -0.00263977,\n",
      "         0.0184326, 0.000270844],\n",
      "        [-0.00631714, -0.00747681, -3.21865e-05, ..., 0.00421143,\n",
      "         -0.00323486, -0.00665283]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.0168457, 0.0106201, -0.00738525, ..., -0.0168457, 0.00921631,\n",
      "         -0.0118408],\n",
      "        [0.00927734, -0.0168457, -0.00753784, ..., -0.000354767,\n",
      "         -0.0227051, -0.0039978],\n",
      "        [0.0111694, 0.00021553, 0.00337219, ..., 0.00946045, 0.0236816,\n",
      "         0.0179443],\n",
      "        ...,\n",
      "        [-0.0229492, -0.00436401, 0.0131836, ..., -0.0101929,\n",
      "         0.00842285, 0.0371094],\n",
      "        [-0.00842285, 0.0107422, 0.00994873, ..., -0.00148773,\n",
      "         -0.0290527, -0.00157928],\n",
      "        [-0.00343323, 0.0148315, 0.0015564, ..., -0.0118408,\n",
      "         -0.00112915, -0.0336914]],\n",
      "\n",
      "       [[0.00340271, 0.00576782, 0.00671387, ..., -0.00457764,\n",
      "         -0.00242615, -0.00259399],\n",
      "        [0.0172119, -0.00115204, 0.0020752, ..., -0.0016098, 0.00430298,\n",
      "         -0.00619507],\n",
      "        [0.00332642, 0.00537109, 0.00174713, ..., -0.00521851,\n",
      "         -0.00121307, -0.00159454],\n",
      "        ...,\n",
      "        [-0.00136566, 0.00527954, 0.000740051, ..., 0.00720215,\n",
      "         -0.0118408, 0.000572205],\n",
      "        [-0.00364685, 0.000272751, 0.00279236, ..., -0.000202179,\n",
      "         -0.00133514, 0.00239563],\n",
      "        [0.00149536, -0.0119019, 0.00582886, ..., 0.00674438,\n",
      "         -0.00848389, 0.0103149]],\n",
      "\n",
      "       [[-0.0153198, -0.0013504, -0.0130005, ..., -0.00622559,\n",
      "         0.0130615, -0.0212402],\n",
      "        [-0.00408936, 0.0112915, 0.00650024, ..., -0.00352478,\n",
      "         0.0192871, -0.0142212],\n",
      "        [0.00248718, 0.0168457, -0.0234375, ..., 0.00276184, 0.00744629,\n",
      "         0.00854492],\n",
      "        ...,\n",
      "        [0.00946045, -0.006073, -6.67572e-05, ..., 0.0043335,\n",
      "         -0.00110626, -0.0205078],\n",
      "        [-0.0178223, -0.0134277, -0.012085, ..., 0.00830078, 0.0108032,\n",
      "         -0.010437],\n",
      "        [-0.00393677, -0.017334, 0.000652313, ..., 0.00585938,\n",
      "         -0.00531006, 0.0153809]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00772095, -0.00479126, 0.000606537, ..., -0.00552368,\n",
      "          0.0109863, -0.0022583],\n",
      "         [0.00195312, -0.000682831, 0.00379944, ..., 0.00402832,\n",
      "          -0.0111084, 0.0125732],\n",
      "         [0.00717163, -0.00939941, -0.0151978, ..., -0.00143433,\n",
      "          -0.00665283, -0.0167236],\n",
      "         ...,\n",
      "         [5.81741e-05, -0.00564575, -0.00312805, ..., 0.00579834,\n",
      "          0.0123291, 0.00112915],\n",
      "         [-0.00101471, 0.00698853, -0.00115967, ..., -0.0216064,\n",
      "          -0.00531006, 0.0292969],\n",
      "         [-0.0050354, 0.0088501, -0.000732422, ..., -0.00396729,\n",
      "          -0.0078125, -0.00463867]],\n",
      "\n",
      "        [[-0.00500488, 0.00384521, -0.00088501, ..., 0.00294495,\n",
      "          -0.0263672, -0.0167236],\n",
      "         [-0.00778198, 0.00393677, -0.0137939, ..., 0.00805664,\n",
      "          -0.00138855, 0.0197754],\n",
      "         [-0.00357056, -0.00695801, 0.00460815, ..., -0.00479126,\n",
      "          0.00860596, -0.00488281],\n",
      "         ...,\n",
      "         [0.0161133, -0.00126648, -0.00047493, ..., 0.00151062,\n",
      "          0.00646973, 0.00265503],\n",
      "         [-0.0100098, 0.00595093, -0.0035553, ..., 0.0332031,\n",
      "          -0.00126648, -0.0236816],\n",
      "         [0.00224304, 0.0126953, 0.000984192, ..., 0.0166016,\n",
      "          -0.000965118, -0.00364685]],\n",
      "\n",
      "        [[0.0119019, -0.00125885, -0.00201416, ..., 0.0159912,\n",
      "          -0.00897217, -0.0113525],\n",
      "         [-0.00162506, -0.00141144, 0.00534058, ..., 0.000530243,\n",
      "          -0.000436783, -0.00247192],\n",
      "         [-0.00344849, 0.0018692, 0.00158691, ..., 0.00537109,\n",
      "          -0.00427246, 0.00891113],\n",
      "         ...,\n",
      "         [-0.00408936, -0.00296021, -0.000188828, ..., 0.0013504,\n",
      "          0.00958252, -0.0149536],\n",
      "         [0.00250244, 0.00271606, -0.00265503, ..., -0.00772095,\n",
      "          -0.0147705, 0.0098877],\n",
      "         [-0.0100098, 0.00442505, 0.0045166, ..., -0.00436401,\n",
      "          -0.00653076, -0.0137329]],\n",
      "\n",
      "        [[0.00872803, 0.00427246, 0.000448227, ..., -0.0167236,\n",
      "          -0.0133057, -0.00656128],\n",
      "         [-0.010437, 0.000720978, -0.00421143, ..., 0.00485229,\n",
      "          -0.019043, -0.00561523],\n",
      "         [0.00619507, 0.00135803, 0.00346375, ..., 0.000453949,\n",
      "          0.00260925, 0.0108032],\n",
      "         ...,\n",
      "         [-0.00113678, 3.12328e-05, -0.012085, ..., -0.000165939,\n",
      "          0.00415039, 0.00842285],\n",
      "         [0.00326538, -0.000976562, 0.00689697, ..., -0.0324707,\n",
      "          -0.00964355, -0.00221252],\n",
      "         [0.00430298, -0.00119019, -0.00317383, ..., 0.00427246,\n",
      "          -0.0145874, 0.0212402]]],\n",
      "\n",
      "\n",
      "       [[[-0.00650024, 0.000227928, -0.00245667, ..., -0.00939941,\n",
      "          0.00540161, 0.0280762],\n",
      "         [-0.000564575, 0.0131836, -0.0197754, ..., 0.00854492,\n",
      "          0.0153809, 0.0108032],\n",
      "         [-0.00107574, -0.000900269, -0.0216064, ..., 0.00753784,\n",
      "          -0.00326538, 0.000482559],\n",
      "         ...,\n",
      "         [-0.0125732, -0.0114746, -0.00160217, ..., 0.000221252,\n",
      "          0.00297546, 0.0131226],\n",
      "         [-0.00485229, -0.0145874, 9.53674e-05, ..., -0.00241089,\n",
      "          0.00320435, 0.001091],\n",
      "         [-0.000888824, -0.0062561, 0.00244141, ..., 0.00216675,\n",
      "          0.00415039, -0.00140381]],\n",
      "\n",
      "        [[0.0125732, -0.0157471, 0.00494385, ..., 0.0147095,\n",
      "          0.00982666, 0.00300598],\n",
      "         [-0.00159454, -0.00479126, 0.00210571, ..., -0.0117798,\n",
      "          0.00491333, -0.00909424],\n",
      "         [-0.0106201, 0.00231934, 0.0229492, ..., -0.0115967,\n",
      "          0.000709534, 0.0301514],\n",
      "         ...,\n",
      "         [-0.00386047, -0.00579834, -0.00408936, ..., -0.0175781,\n",
      "          -0.013916, 0.019165],\n",
      "         [0.00193787, -0.00236511, -0.000328064, ..., -0.006073,\n",
      "          0.012085, -0.00170135],\n",
      "         [-0.0131226, -0.0133667, 0.0175781, ..., 0.0155029,\n",
      "          -0.0113525, -0.00576782]],\n",
      "\n",
      "        [[-0.0179443, -0.0240479, 0.0108643, ..., 0.0267334, 0.0205078,\n",
      "          -0.00686646],\n",
      "         [-0.003479, 0.0145264, -0.0109863, ..., 0.0238037, -0.0158691,\n",
      "          -0.0174561],\n",
      "         [0.0151978, 0.00726318, 0.00860596, ..., -0.00263977,\n",
      "          0.00360107, 0.00442505],\n",
      "         ...,\n",
      "         [0.00704956, -0.00970459, -0.000255585, ..., 0.0175781,\n",
      "          -0.00738525, 0.00537109],\n",
      "         [-0.00872803, 0.0253906, -0.0117188, ..., -0.00744629,\n",
      "          0.0283203, -0.00233459],\n",
      "         [0.0167236, -0.00842285, -0.0105591, ..., -0.0427246,\n",
      "          -0.00205994, 0.0385742]],\n",
      "\n",
      "        [[0.0100098, 0.00891113, 0.00610352, ..., -0.0170898,\n",
      "          -0.000328064, 0.00897217],\n",
      "         [-0.00582886, 0.00747681, 0.0194092, ..., 0.00263977,\n",
      "          -0.000919342, -0.0157471],\n",
      "         [-0.0050354, 0.00518799, -0.0324707, ..., 0.00215149,\n",
      "          0.00314331, -0.00463867],\n",
      "         ...,\n",
      "         [-0.0201416, -0.00939941, -0.0119629, ..., 0.0234375,\n",
      "          -0.00897217, 0.0109253],\n",
      "         [0.000170708, 0.000854492, 0.00216675, ..., -0.0217285,\n",
      "          0.0108032, -0.000938416],\n",
      "         [-0.019165, -0.00476074, -0.00259399, ..., -0.00518799,\n",
      "          0.0126343, 0.010376]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00328064, -0.00860596, -0.00848389, ..., -0.00259399,\n",
      "         0.00836182, 0.00817871],\n",
      "        [0.00982666, -0.00631714, -0.00151062, ..., 0.00141144,\n",
      "         -0.012085, -0.00430298],\n",
      "        [0.00411987, 0.00248718, -0.00257874, ..., -0.00378418,\n",
      "         0.00793457, -0.0067749],\n",
      "        ...,\n",
      "        [0.00543213, 0.00382996, 0.00506592, ..., -0.00292969,\n",
      "         0.00698853, -0.00379944],\n",
      "        [0.0136108, 0.00276184, -0.0161133, ..., 0.00180054,\n",
      "         0.000492096, 0.00247192],\n",
      "        [0.00582886, -0.0014801, -0.0114136, ..., -0.00204468,\n",
      "         0.00445557, -0.00650024]],\n",
      "\n",
      "       [[0.0131226, -0.0124512, -0.0112915, ..., 0.00180817, 0.010376,\n",
      "         0.00473022],\n",
      "        [0.00817871, -0.00549316, -0.00622559, ..., -0.00622559,\n",
      "         -0.0209961, -0.0211182],\n",
      "        [-0.00166321, 0.00946045, 0.0112915, ..., 0.00143433,\n",
      "         -0.00564575, -0.00131226],\n",
      "        ...,\n",
      "        [-0.000720978, 0.00604248, 0.00326538, ..., 0.0240479,\n",
      "         0.0088501, 0.000188828],\n",
      "        [0.00186157, 0.00454712, -0.00262451, ..., 0.010376,\n",
      "         0.000172615, -0.00222778],\n",
      "        [-0.0035553, -0.00233459, -0.00183105, ..., -0.00854492,\n",
      "         -0.0197754, -0.0186768]],\n",
      "\n",
      "       [[-0.00228882, 0.00122833, 0.00186157, ..., -0.00448608,\n",
      "         -0.0238037, -0.0117798],\n",
      "        [-0.00695801, 0.00582886, 0.00138092, ..., 0.0184326,\n",
      "         -0.00405884, 0.00848389],\n",
      "        [-0.00270081, -0.00396729, 0.000946045, ..., -0.00263977,\n",
      "         0.00946045, 0.0162354],\n",
      "        ...,\n",
      "        [-0.00958252, -0.0144653, -0.015625, ..., 0.0166016, -0.0175781,\n",
      "         0.00159454],\n",
      "        [0.00360107, -0.00105286, 0.0098877, ..., 0.0202637, 0.0205078,\n",
      "         -0.00271606],\n",
      "        [0.00518799, -0.0111694, 0.0039978, ..., -0.0183105, -0.0167236,\n",
      "         0.00369263]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00366211, 0.00939941, 0.0135498, ..., -0.00196838,\n",
      "         -0.000793457, -0.00646973],\n",
      "        [-0.0105591, 0.006073, 0.00866699, ..., -0.00671387, 0.00970459,\n",
      "         0.00891113],\n",
      "        [-0.00811768, 0.0170898, -0.00750732, ..., -0.000808716,\n",
      "         -0.0220947, 0.00836182],\n",
      "        ...,\n",
      "        [-0.0109253, 0.00576782, -0.00111389, ..., -0.00775146,\n",
      "         -0.0179443, 0.00497437],\n",
      "        [0.000591278, -0.00460815, -0.0039978, ..., 0.00619507,\n",
      "         -0.0022583, -0.00019455],\n",
      "        [-0.0127563, 0.00139618, 0.00187683, ..., 0.00245667, 0.013855,\n",
      "         -0.00205994]],\n",
      "\n",
      "       [[-0.003479, 0.00379944, -0.0145874, ..., 0.0244141, -0.036377,\n",
      "         -0.00408936],\n",
      "        [0.00872803, 0.0189209, -0.00141144, ..., -0.00692749,\n",
      "         0.0368652, -0.00970459],\n",
      "        [-0.0105591, -0.0150757, -0.00643921, ..., -0.0324707,\n",
      "         -0.0123901, -0.0272217],\n",
      "        ...,\n",
      "        [-0.00970459, 0.00469971, -0.00695801, ..., -0.00878906,\n",
      "         -0.0135498, 0.0354004],\n",
      "        [-0.00506592, 0.0150757, 0.00982666, ..., -0.00946045,\n",
      "         0.0186768, 0.000396729],\n",
      "        [0.00939941, 0.00521851, 0.0090332, ..., -0.00921631,\n",
      "         0.00717163, -0.0227051]],\n",
      "\n",
      "       [[0.015564, 0.00759888, 0.00056076, ..., 0.0317383, 0.0109253,\n",
      "         0.00927734],\n",
      "        [0.00344849, -0.00799561, 0.00897217, ..., 0.00289917,\n",
      "         0.0272217, -0.0439453],\n",
      "        [0.0137329, 0.0167236, 0.0167236, ..., -0.015625, 0.00063324,\n",
      "         0.00799561],\n",
      "        ...,\n",
      "        [-0.00231934, -0.00139618, 0.00411987, ..., -0.0153198,\n",
      "         -6.24657e-05, 0.0228271],\n",
      "        [0.00149536, 0.00753784, -0.00262451, ..., -0.000463486,\n",
      "         0.0214844, -0.00126648],\n",
      "        [0.0016861, 0.00708008, 0.0144043, ..., -0.00521851, 0.0132446,\n",
      "         -0.000434875]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.0115967, 0.00300598, -0.000114441, ..., 0.0032196,\n",
      "         0.0067749, -0.00665283],\n",
      "        [0.00396729, 0.00364685, -0.00799561, ..., 0.000915527,\n",
      "         0.00762939, 0.00891113],\n",
      "        [-0.00136566, 0.0105591, 0.0177002, ..., 0.00242615,\n",
      "         -0.000865936, -0.00848389],\n",
      "        ...,\n",
      "        [0.0101318, -0.00512695, -0.00218201, ..., -0.0123901,\n",
      "         -0.00106049, 0.000450134],\n",
      "        [-0.00466919, 0.00762939, 0.0110474, ..., 0.0100098,\n",
      "         -0.000679016, -0.0228271],\n",
      "        [0.00357056, 0.00445557, -0.00291443, ..., -0.00239563,\n",
      "         -0.00408936, -0.00921631]],\n",
      "\n",
      "       [[0.0065918, 0.00747681, 0.0105591, ..., -0.0106201, 0.000743866,\n",
      "         0.00512695],\n",
      "        [0.0100708, -0.00637817, -0.00141907, ..., -0.00424194,\n",
      "         0.00427246, -0.00408936],\n",
      "        [-0.00982666, 0.00549316, -0.00830078, ..., -0.00619507,\n",
      "         0.00637817, 0.00415039],\n",
      "        ...,\n",
      "        [0.00909424, -0.00952148, -0.0107422, ..., -0.00631714,\n",
      "         0.00280762, 0.00063324],\n",
      "        [-0.00836182, 0.00854492, 0.00604248, ..., -0.0105591,\n",
      "         -0.0153809, -0.00280762],\n",
      "        [-0.0120239, 0.00305176, -0.00811768, ..., 0.0147095,\n",
      "         0.00921631, 0.00668335]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.010376, -0.00247192, 0.00189972, ..., 0.0128174, -0.00787354,\n",
      "        -0.00527954],\n",
      "       [0.00102997, -0.010498, 0.00263977, ..., 0.000743866, -0.00367737,\n",
      "        -0.000455856],\n",
      "       [0.0102539, -0.0137329, -0.0224609, ..., -0.00289917, 0.00334167,\n",
      "        -0.0108643],\n",
      "       ...,\n",
      "       [-0.0017395, -0.00028038, -0.00494385, ..., 0.000900269,\n",
      "        -0.0107422, -0.00817871],\n",
      "       [-0.00396729, -0.00650024, 0.00276184, ..., -0.00747681,\n",
      "        0.0062561, 0.00360107],\n",
      "       [0.00616455, 0.00631714, 0.0216064, ..., -0.00488281, 0.0030365,\n",
      "        0.00160217]], dtype=bfloat16), a=Array([[-0.00295627, -0.00559398, -0.00677068, ...,  0.01155958,\n",
      "        -0.01056946, -0.01427677],\n",
      "       [ 0.02465803,  0.01395147, -0.01297336, ..., -0.0011971 ,\n",
      "        -0.00226062, -0.00428502]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.120117, 0.132812, 0.211914, ..., 0.0247803, 0.125977, 0.0432129],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.277344, 0.273438, 0.369141, ..., 0.199219, 0.644531, 0.271484],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([1.14062, 1.02344, 1.03906, ..., 1.14062, 0.0703125, 0.894531],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.601562, 0.675781, 0.648438, ..., 0.785156, 0.0917969, 0.589844],      dtype=bfloat16)}}, 'layer_9': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00379944, 0.000249863, -0.0267334, ..., -0.0148315,\n",
      "         0.000656128, -0.00650024],\n",
      "        [-0.0100708, 0.00460815, 0.0133057, ..., 0.0071106, 0.00482178,\n",
      "         -0.00735474],\n",
      "        [-0.00534058, -0.00628662, -0.00349426, ..., -0.00195312,\n",
      "         0.0115356, 0.015625],\n",
      "        ...,\n",
      "        [0.000203133, 0.00854492, -0.00823975, ..., -0.00686646,\n",
      "         -0.0103149, 0.00723267],\n",
      "        [0.0241699, 0.00389099, 0.00860596, ..., 0.000999451,\n",
      "         -0.00227356, -0.00500488],\n",
      "        [0.0216064, 0.015564, -0.00817871, ..., -0.00125122, 0.00671387,\n",
      "         -0.0212402]],\n",
      "\n",
      "       [[0.00805664, 0.0144653, -0.0108032, ..., 0.00384521,\n",
      "         0.000621796, -0.012146],\n",
      "        [-0.0140991, -0.0016098, -0.0175781, ..., -0.015564,\n",
      "         -0.00720215, -0.00210571],\n",
      "        [4.36306e-05, -0.0111084, -0.0101929, ..., 0.000413895,\n",
      "         0.0130615, -0.0154419],\n",
      "        ...,\n",
      "        [-0.0161133, -0.00215149, -0.00848389, ..., 0.00817871,\n",
      "         -0.00494385, -0.00405884],\n",
      "        [0.0166016, -0.00112152, 0.00546265, ..., 0.00872803,\n",
      "         0.00193787, 0.00817871],\n",
      "        [-0.0122681, -0.034668, -0.00473022, ..., 0.0169678, 0.00738525,\n",
      "         -0.0187988]],\n",
      "\n",
      "       [[0.00823975, -0.0101929, 0.0102539, ..., -0.00222778,\n",
      "         -0.00335693, -0.0169678],\n",
      "        [0.0146484, -0.00933838, -0.00570679, ..., 0.00291443,\n",
      "         -0.00144958, 0.00177002],\n",
      "        [0.00309753, 0.0238037, -0.0341797, ..., 0.00473022, 0.0109863,\n",
      "         -0.00138092],\n",
      "        ...,\n",
      "        [-0.00178528, 0.00396729, -0.00228882, ..., 0.00144196,\n",
      "         -0.012207, -0.00738525],\n",
      "        [0.0327148, 0.00921631, -0.0015564, ..., 0.00179291,\n",
      "         -0.00540161, 0.0132446],\n",
      "        [-0.00891113, 0.00866699, 0.00387573, ..., 0.000190735,\n",
      "         -0.0144653, 0.0102539]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00497437, 0.00274658, -0.00170135, ..., 0.00485229,\n",
      "         -0.00726318, 0.0164795],\n",
      "        [0.019043, -0.00778198, 0.00921631, ..., -0.00335693, 0.0133057,\n",
      "         -0.00970459],\n",
      "        [-0.0267334, -0.0194092, -0.0022583, ..., 0.0157471, -0.0108643,\n",
      "         0.0109253],\n",
      "        ...,\n",
      "        [-0.00653076, 0.0144653, 0.0100708, ..., -0.0349121, 0.00209045,\n",
      "         -0.000991821],\n",
      "        [-0.0140381, 0.00239563, -0.00113678, ..., -0.00172424,\n",
      "         -0.0174561, 0.0112305],\n",
      "        [-0.0145874, 0.0192871, 0.00982666, ..., 0.00466919,\n",
      "         -0.00592041, -0.00689697]],\n",
      "\n",
      "       [[0.0185547, 0.00283813, 0.00619507, ..., -0.00308228, 0.0142212,\n",
      "         0.00427246],\n",
      "        [-0.00341797, -0.0163574, 0.00723267, ..., -0.00500488,\n",
      "         -0.00177765, -0.00552368],\n",
      "        [-0.012207, 0.00280762, 0.0198975, ..., -0.0178223, -0.00479126,\n",
      "         -0.0088501],\n",
      "        ...,\n",
      "        [0.00387573, -0.0209961, -0.0120239, ..., 0.00402832,\n",
      "         0.00306702, 0.0139771],\n",
      "        [-3.48091e-05, -0.00224304, 0.00915527, ..., 0.0144043, 0.03125,\n",
      "         -0.0161133],\n",
      "        [-0.0105591, -0.00286865, 0.001091, ..., -0.0187988, 0.00860596,\n",
      "         -0.0212402]],\n",
      "\n",
      "       [[-0.0177002, -0.00231934, 0.0050354, ..., 0.0108643,\n",
      "         -0.00698853, -0.000463486],\n",
      "        [0.0115967, 0.0019989, -0.000238419, ..., -0.00317383,\n",
      "         3.60608e-06, 0.00750732],\n",
      "        [-0.0131226, 0.00411987, 0.0119019, ..., -0.00848389,\n",
      "         0.00720215, -0.0118408],\n",
      "        ...,\n",
      "        [-0.0128174, 0.0185547, 0.0213623, ..., 0.0168457, -0.015625,\n",
      "         -0.0103149],\n",
      "        [-0.0238037, 0.00274658, 0.00598145, ..., 0.00866699,\n",
      "         -0.00878906, 0.00349426],\n",
      "        [0.00473022, -0.0055542, -0.00610352, ..., 0.00500488,\n",
      "         -0.00805664, 0.00732422]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
      "        [-0.00643921, -0.0130615],\n",
      "        [-0.00396729, -0.000341415],\n",
      "        ...,\n",
      "        [-0.0174561, 0.0014267],\n",
      "        [-0.00152588, -0.00854492],\n",
      "        [0.0148315, 0.00283813]],\n",
      "\n",
      "       [[-0.0050354, 0.00366211],\n",
      "        [0.00344849, -0.0195312],\n",
      "        [0.00680542, 0.000835419],\n",
      "        ...,\n",
      "        [-0.00692749, -0.0195312],\n",
      "        [-0.00375366, -0.00375366],\n",
      "        [0.000246048, 0.0101929]],\n",
      "\n",
      "       [[0.00732422, -0.0130615],\n",
      "        [0.0251465, 0.0119629],\n",
      "        [-0.000341415, 0.00325012],\n",
      "        ...,\n",
      "        [-0.000146866, -0.00598145],\n",
      "        [-0.0125732, -0.00273132],\n",
      "        [-0.00375366, -0.000341415]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.00897217, -0.00741577],\n",
      "        [-0.00312805, -0.00460815],\n",
      "        [-0.00482178, 0.00325012],\n",
      "        ...,\n",
      "        [0.00897217, -0.00273132],\n",
      "        [0.0115967, -0.00334167],\n",
      "        [-0.0114136, 0.00515747]],\n",
      "\n",
      "       [[0.0162354, -0.0166016],\n",
      "        [0.00408936, 0.0018158],\n",
      "        [-0.0166016, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00668335, -0.00769043],\n",
      "        [0.0119629, -0.00878906],\n",
      "        [0.0124512, -0.0100098]],\n",
      "\n",
      "       [[-0.00668335, -0.00854492],\n",
      "        [0.0078125, -0.0211182],\n",
      "        [-0.00692749, 0.0078125],\n",
      "        ...,\n",
      "        [-0.00460815, 0.000246048],\n",
      "        [0.00122833, 0.00610352],\n",
      "        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00346375, -0.00686646, -0.00793457, ..., 0.00878906,\n",
      "          -0.00860596, 0.0113525],\n",
      "         [0.0146484, 0.00338745, -0.00762939, ..., -0.000379562,\n",
      "          0.0167236, -0.0162354],\n",
      "         [-0.0102539, 0.00476074, 0.0116577, ..., -0.0111694,\n",
      "          0.0134277, 0.00113678],\n",
      "         ...,\n",
      "         [-0.00167847, 0.00823975, 0.00778198, ..., -0.00939941,\n",
      "          0.0004673, 0.0246582],\n",
      "         [-0.00994873, 0.00650024, -0.00570679, ..., 0.00378418,\n",
      "          -0.00897217, 0.00671387],\n",
      "         [-0.00164795, 0.00976562, 0.0045166, ..., -0.010498,\n",
      "          0.0180664, 0.00411987]],\n",
      "\n",
      "        [[0.00167847, -0.00337219, -0.00744629, ..., 0.00637817,\n",
      "          -0.00982666, 0.00180817],\n",
      "         [0.00479126, 0.00427246, 0.00175476, ..., 0.00634766,\n",
      "          -0.000831604, -0.0201416],\n",
      "         [0.000705719, 0.00408936, 0.00515747, ..., -0.00184631,\n",
      "          -0.00933838, -0.0123901],\n",
      "         ...,\n",
      "         [-0.00144196, 0.00927734, -0.00102997, ..., 0.0149536,\n",
      "          0.0268555, 0.00878906],\n",
      "         [-0.00253296, 0.00219727, 0.0111694, ..., 0.0233154,\n",
      "          -0.0144653, 0.00257874],\n",
      "         [-0.00579834, 0.0016861, 0.00163269, ..., -0.0148926,\n",
      "          0.00230408, 0.0158691]],\n",
      "\n",
      "        [[0.015625, -0.000459671, 0.00101471, ..., 0.0131836,\n",
      "          -0.060791, -0.0124512],\n",
      "         [-0.00866699, 0.0184326, 0.00570679, ..., 0.0158691,\n",
      "          -0.0158691, 0.00769043],\n",
      "         [0.00331116, 0.00628662, -0.00534058, ..., 0.00250244,\n",
      "          -0.019043, 0.000896454],\n",
      "         ...,\n",
      "         [-0.000339508, -0.000663757, -0.0115356, ..., 0.00306702,\n",
      "          -0.00311279, 0.0148926],\n",
      "         [-0.00714111, -0.00179291, -0.00958252, ..., -0.00567627,\n",
      "          0.00860596, 0.0402832],\n",
      "         [-0.00982666, 0.00439453, -0.00216675, ..., -0.0117188,\n",
      "          0.0220947, -0.000514984]],\n",
      "\n",
      "        [[0.00561523, 0.000648499, -0.00866699, ..., 0.00927734,\n",
      "          -0.00897217, -0.0117188],\n",
      "         [0.00585938, 0.00411987, 0.00147247, ..., 0.00610352,\n",
      "          0.00488281, 0.00402832],\n",
      "         [0.00107574, -0.00370789, -0.00515747, ..., 0.0139771,\n",
      "          0.0106201, -0.000747681],\n",
      "         ...,\n",
      "         [0.0043335, 0.00686646, 0.0088501, ..., -0.0043335, 0.0166016,\n",
      "          -0.0126343],\n",
      "         [-0.00479126, -0.00436401, -0.00069809, ..., 0.0301514,\n",
      "          -0.0154419, 0.00540161],\n",
      "         [0.00156403, 3.33786e-05, -0.00187683, ..., 0.00619507,\n",
      "          -0.00427246, 0.0664062]]],\n",
      "\n",
      "\n",
      "       [[[0.00915527, -0.0126343, 0.0205078, ..., -0.00701904,\n",
      "          0.0142212, -0.000843048],\n",
      "         [0.0256348, -0.0114136, -0.0196533, ..., 0.0196533,\n",
      "          0.00231934, -0.0131836],\n",
      "         [-0.00094223, -0.012085, -0.00390625, ..., -0.00317383,\n",
      "          -0.00463867, -0.00352478],\n",
      "         ...,\n",
      "         [0.0043335, -0.0112915, 0.00476074, ..., -0.0012207,\n",
      "          -0.00497437, 0.0236816],\n",
      "         [0.00366211, -0.00212097, -0.00476074, ..., 0.00628662,\n",
      "          -0.00958252, -0.00561523],\n",
      "         [-0.00543213, -0.0032959, -0.00134277, ..., -0.00915527,\n",
      "          -0.0238037, 0.00509644]],\n",
      "\n",
      "        [[0.00680542, -0.00415039, 0.0222168, ..., 0.0106812,\n",
      "          0.0150757, -0.0067749],\n",
      "         [-0.0187988, -0.0115356, 0.0307617, ..., 0.0183105,\n",
      "          0.00567627, 0.00891113],\n",
      "         [0.00982666, -0.000425339, -0.0150146, ..., 0.00750732,\n",
      "          -0.00726318, -0.0130615],\n",
      "         ...,\n",
      "         [0.0110474, 0.0145874, 0.0262451, ..., -0.00102234, 0.001297,\n",
      "          -0.0140991],\n",
      "         [0.0142212, -0.00135803, 0.00228882, ..., -0.00154114,\n",
      "          0.00665283, -0.00778198],\n",
      "         [0.0090332, 0.00848389, -0.0390625, ..., -0.0154419,\n",
      "          0.000375748, 0.0164795]],\n",
      "\n",
      "        [[0.00653076, 0.0147095, -0.00524902, ..., 0.00866699,\n",
      "          -0.00552368, 0.0022583],\n",
      "         [0.0062561, -0.00128937, -0.00637817, ..., 0.019043,\n",
      "          -0.0116577, 0.0157471],\n",
      "         [0.000137329, 0.0125732, -0.00708008, ..., 0.0286865,\n",
      "          0.00213623, -0.00866699],\n",
      "         ...,\n",
      "         [0.0163574, 0.0148315, -0.0143433, ..., -0.0217285, 0.0110474,\n",
      "          -0.00933838],\n",
      "         [0.0111084, -0.00701904, -0.00176239, ..., -0.00238037,\n",
      "          0.00769043, 0.00616455],\n",
      "         [0.00714111, -0.000247955, 0.00166321, ..., -0.00216675,\n",
      "          0.00933838, -0.00209045]],\n",
      "\n",
      "        [[4.95911e-05, -0.00897217, -0.00141144, ..., 0.00296021,\n",
      "          -0.00328064, -0.0322266],\n",
      "         [0.0115356, 0.00466919, 0.00769043, ..., -0.00537109,\n",
      "          -0.00970459, -0.0119629],\n",
      "         [0.0111694, 0.000385284, -0.00494385, ..., 0.00830078,\n",
      "          0.0124512, 0.000198364],\n",
      "         ...,\n",
      "         [0.00518799, -0.0222168, -0.000595093, ..., 0.0250244,\n",
      "          -0.00430298, 0.0114136],\n",
      "         [-0.00195312, -0.00306702, -0.00747681, ..., -0.00291443,\n",
      "          -0.019165, 0.0108643],\n",
      "         [-0.00970459, 0.0263672, -0.000204086, ..., -0.0078125,\n",
      "          -0.0103149, 0.010437]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
      "         [0.00866699, 0.0045166],\n",
      "         [-0.0289307, 0.0133057],\n",
      "         ...,\n",
      "         [0.00262451, -0.00439453],\n",
      "         [-0.00622559, 0.0119629],\n",
      "         [0.0203857, -0.00273132]],\n",
      "\n",
      "        [[-0.00334167, 0.00202942],\n",
      "         [-0.0117798, 0.00122833],\n",
      "         [0.0045166, -0.00823975],\n",
      "         ...,\n",
      "         [0.0124512, 0.0108643],\n",
      "         [-0.000934601, -0.00909424],\n",
      "         [0.00387573, 0.00366211]],\n",
      "\n",
      "        [[0.00430298, -0.00231934],\n",
      "         [0.00162506, 0.00262451],\n",
      "         [0.0178223, -0.000146866],\n",
      "         ...,\n",
      "         [0.00897217, -0.00552368],\n",
      "         [0.0128174, -0.00970459],\n",
      "         [-0.00132751, -0.00172424]],\n",
      "\n",
      "        [[-0.0050354, 0.0155029],\n",
      "         [0.00585938, -0.00552368],\n",
      "         [-0.000341415, -0.000541687],\n",
      "         ...,\n",
      "         [0.00634766, -0.00622559],\n",
      "         [0.00561523, -0.00396729],\n",
      "         [-0.00692749, -0.0140991]]],\n",
      "\n",
      "\n",
      "       [[[0.0133057, 0.0119629],\n",
      "         [0.000246048, -0.0211182],\n",
      "         [-0.00112915, 0.0115967],\n",
      "         ...,\n",
      "         [0.0189209, 0.000835419],\n",
      "         [0.00430298, 0.00515747],\n",
      "         [-0.00769043, 0.0148315]],\n",
      "\n",
      "        [[-0.00823975, -0.0146484],\n",
      "         [-0.00334167, 0.00344849],\n",
      "         [0.00732422, -0.0025177],\n",
      "         ...,\n",
      "         [0.00610352, -0.0117798],\n",
      "         [0.00387573, -0.00439453],\n",
      "         [0.00473022, -0.00172424]],\n",
      "\n",
      "        [[-0.00292969, -0.00799561],\n",
      "         [-0.0107422, -0.00552368],\n",
      "         [-0.00273132, -0.0233154],\n",
      "         ...,\n",
      "         [-0.00396729, -0.00854492],\n",
      "         [-0.00769043, -0.00482178],\n",
      "         [0.00325012, -0.0050354]],\n",
      "\n",
      "        [[0.000246048, 0.000637054],\n",
      "         [-0.00334167, 0.000637054],\n",
      "         [0.0112305, -0.00439453],\n",
      "         ...,\n",
      "         [0.0128174, 0.00927734],\n",
      "         [0.0030365, -0.00643921],\n",
      "         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00595093, 0.00854492, 0.00390625, ..., 0.00741577, 0.0112305,\n",
      "         -0.0043335],\n",
      "        [-0.00534058, 0.00878906, -0.0113525, ..., 0.00202942,\n",
      "         -0.00604248, -0.00248718],\n",
      "        [-0.00897217, 0.00241089, -0.0128174, ..., -0.00860596,\n",
      "         -0.00683594, 0.010498],\n",
      "        ...,\n",
      "        [0.0162354, 0.00823975, 0.00872803, ..., -0.00610352, 0.0126953,\n",
      "         -0.0057373],\n",
      "        [0.0183105, 0.00030899, 0.0125122, ..., 0.00860596, -0.0123291,\n",
      "         0.000785828],\n",
      "        [0.000976562, 0.00390625, -0.00994873, ..., 0.0205078,\n",
      "         0.00418091, -0.0131836]],\n",
      "\n",
      "       [[-0.00153351, 0.0202637, 0.0187988, ..., -0.000274658,\n",
      "         0.0125732, -0.000457764],\n",
      "        [-0.00521851, -0.00872803, -0.00138092, ..., -0.0140991,\n",
      "         0.012146, -0.00331116],\n",
      "        [-0.00738525, -0.00127411, -0.0126953, ..., -0.0349121,\n",
      "         -0.0050354, -0.0065918],\n",
      "        ...,\n",
      "        [0.00317383, -0.00714111, -0.0149536, ..., 0.0130615,\n",
      "         0.00793457, -0.0246582],\n",
      "        [0.010437, -0.0167236, 0.00335693, ..., 0.00854492, -0.0366211,\n",
      "         -0.0220947],\n",
      "        [0.0118408, -0.00708008, 0.00241089, ..., -0.00375366,\n",
      "         -0.0184326, 0.00787354]],\n",
      "\n",
      "       [[0.00842285, -0.00119781, 0.00170135, ..., -0.0133667,\n",
      "         -0.00640869, -0.0143433],\n",
      "        [-0.0164795, -0.00637817, -0.0172119, ..., -0.00340271,\n",
      "         0.00309753, 0.000778198],\n",
      "        [0.000411987, -3.40939e-05, -0.00186157, ..., -0.0147705,\n",
      "         0.0155029, -0.0235596],\n",
      "        ...,\n",
      "        [-0.00524902, 0.00662231, 0.00393677, ..., -0.00256348,\n",
      "         0.000732422, -0.00799561],\n",
      "        [-0.00112152, -0.0200195, -0.0057373, ..., -0.00521851,\n",
      "         0.0214844, -0.0148926],\n",
      "        [0.00994873, -0.0135498, -0.00177002, ..., -0.0217285,\n",
      "         -0.015625, 0.00616455]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00765991, 0.00340271, -0.00738525, ..., -0.00360107,\n",
      "         -0.0130615, -0.0103149],\n",
      "        [0.00515747, -0.0134888, 0.00479126, ..., -0.00106049,\n",
      "         -0.00320435, -0.00598145],\n",
      "        [-0.00982666, 0.0217285, -0.00778198, ..., 0.00689697,\n",
      "         -0.0213623, 0.00527954],\n",
      "        ...,\n",
      "        [-0.00518799, 0.00315857, 0.00683594, ..., -0.0142212,\n",
      "         0.00300598, -0.00872803],\n",
      "        [-0.0141602, 0.00549316, 0.0101929, ..., 0.0109863, 0.0170898,\n",
      "         0.00233459],\n",
      "        [0.00964355, 0.00671387, -0.000545502, ..., 0.000333786,\n",
      "         0.00389099, -0.00457764]],\n",
      "\n",
      "       [[-0.00772095, 0.00564575, -0.0105591, ..., -0.00970459,\n",
      "         -4.8399e-05, -0.0098877],\n",
      "        [-0.0108032, 0.000499725, 0.000667572, ..., 0.00640869,\n",
      "         0.0109253, 0.00430298],\n",
      "        [-0.00218201, -0.0114746, 0.0126953, ..., 0.0168457,\n",
      "         -0.00866699, 0.0185547],\n",
      "        ...,\n",
      "        [-0.00274658, -0.00285339, -0.00427246, ..., 0.006073,\n",
      "         0.0098877, 0.0120239],\n",
      "        [0.0098877, 0.0196533, -0.0186768, ..., 0.0109253, 0.00509644,\n",
      "         0.0187988],\n",
      "        [0.0118408, 0.00634766, -0.00854492, ..., -0.00408936,\n",
      "         0.000398636, 0.0195312]],\n",
      "\n",
      "       [[-0.00549316, 0.00436401, 0.00848389, ..., 0.00312805,\n",
      "         0.0113525, 0.00445557],\n",
      "        [-0.00512695, -0.00732422, 0.00772095, ..., 0.0194092,\n",
      "         0.0108032, -0.00341797],\n",
      "        [0.00546265, -0.00241089, 0.000572205, ..., -0.00256348,\n",
      "         0.000213623, 0.012085],\n",
      "        ...,\n",
      "        [-0.00479126, -0.00382996, -0.00262451, ..., -0.00662231,\n",
      "         0.0201416, -0.00418091],\n",
      "        [0.00613403, 0.0125122, -0.00558472, ..., -0.00637817,\n",
      "         -0.0192871, -0.00769043],\n",
      "        [0.000234604, 0.00280762, -0.00567627, ..., -0.0136719,\n",
      "         -0.00457764, 0.026123]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
      "        [0.00866699, 0.0045166],\n",
      "        [-0.0289307, 0.0133057],\n",
      "        ...,\n",
      "        [0.00262451, -0.00439453],\n",
      "        [-0.00622559, 0.0119629],\n",
      "        [0.0203857, -0.00273132]],\n",
      "\n",
      "       [[-0.00334167, 0.00202942],\n",
      "        [-0.0117798, 0.00122833],\n",
      "        [0.0045166, -0.00823975],\n",
      "        ...,\n",
      "        [0.0124512, 0.0108643],\n",
      "        [-0.000934601, -0.00909424],\n",
      "        [0.00387573, 0.00366211]],\n",
      "\n",
      "       [[0.00430298, -0.00231934],\n",
      "        [0.00162506, 0.00262451],\n",
      "        [0.0178223, -0.000146866],\n",
      "        ...,\n",
      "        [0.00897217, -0.00552368],\n",
      "        [0.0128174, -0.00970459],\n",
      "        [-0.00132751, -0.00172424]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.00823975, -0.0146484],\n",
      "        [-0.00334167, 0.00344849],\n",
      "        [0.00732422, -0.0025177],\n",
      "        ...,\n",
      "        [0.00610352, -0.0117798],\n",
      "        [0.00387573, -0.00439453],\n",
      "        [0.00473022, -0.00172424]],\n",
      "\n",
      "       [[-0.00292969, -0.00799561],\n",
      "        [-0.0107422, -0.00552368],\n",
      "        [-0.00273132, -0.0233154],\n",
      "        ...,\n",
      "        [-0.00396729, -0.00854492],\n",
      "        [-0.00769043, -0.00482178],\n",
      "        [0.00325012, -0.0050354]],\n",
      "\n",
      "       [[0.000246048, 0.000637054],\n",
      "        [-0.00334167, 0.000637054],\n",
      "        [0.0112305, -0.00439453],\n",
      "        ...,\n",
      "        [0.0128174, 0.00927734],\n",
      "        [0.0030365, -0.00643921],\n",
      "        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00107574, -0.0137939, 0.013916, ..., 0.0205078, 0.000705719,\n",
      "         -0.000926971],\n",
      "        [0.000843048, 0.0109863, -0.00476074, ..., -0.00411987,\n",
      "         -0.00427246, 0.00138855],\n",
      "        [-0.00469971, 0.0162354, 0.00312805, ..., 0.000133514,\n",
      "         0.00408936, -0.00280762],\n",
      "        ...,\n",
      "        [-0.00196838, 0.000606537, 0.00445557, ..., -0.0109253,\n",
      "         -0.0115356, 0.00113678],\n",
      "        [0.00799561, 0.00598145, -0.00436401, ..., 0.00543213,\n",
      "         0.00390625, -0.0150146],\n",
      "        [-0.0100098, 0.012207, -0.00418091, ..., -3.71933e-05,\n",
      "         0.00317383, -0.00762939]],\n",
      "\n",
      "       [[0.0131226, 0.00756836, 0.00860596, ..., 0.00970459, -0.0107422,\n",
      "         -0.000591278],\n",
      "        [-0.00762939, -0.00680542, 0.00692749, ..., -0.00337219,\n",
      "         0.00616455, 0.00830078],\n",
      "        [6.07967e-05, -0.00848389, 0.00683594, ..., 0.0144043,\n",
      "         0.00964355, 0.00494385],\n",
      "        ...,\n",
      "        [0.00427246, -0.012146, 0.0186768, ..., 0.00158691, -0.00759888,\n",
      "         0.000240326],\n",
      "        [0.00218201, 0.0078125, 0.0145874, ..., -0.00799561, 0.00384521,\n",
      "         0.00933838],\n",
      "        [0.00811768, -0.00424194, -0.00317383, ..., 0.003479,\n",
      "         -0.00289917, 0.00296021]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
      "        [0.0014267, -0.00720215],\n",
      "        [0.00708008, 0.0142822],\n",
      "        ...,\n",
      "        [-0.000341415, 0.00408936],\n",
      "        [-0.00439453, 0.0108643],\n",
      "        [0.0220947, 0.0203857]],\n",
      "\n",
      "       [[-0.00527954, 0.00283813],\n",
      "        [0.0101929, 0.00927734],\n",
      "        [0.00836182, -0.0211182],\n",
      "        ...,\n",
      "        [-0.000341415, -0.000341415],\n",
      "        [0.00221252, 0.0078125],\n",
      "        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00128937, -0.0125732, -0.0032196, ..., 0.00576782, 0.00156403,\n",
      "        0.00473022],\n",
      "       [0.0037384, 0.000239372, 0.00402832, ..., 0.000394821,\n",
      "        -0.000530243, 0.010376],\n",
      "       [0.00817871, 0.00106812, 0.00132751, ..., 0.00848389, -0.00289917,\n",
      "        -0.00491333],\n",
      "       ...,\n",
      "       [-0.00891113, -0.00646973, 0.0057373, ..., -0.00320435,\n",
      "        -0.0106812, 0.00619507],\n",
      "       [-0.00558472, -0.00738525, -0.0100708, ..., 0.0043335, 0.00579834,\n",
      "        0.00738525],\n",
      "       [0.00341797, -0.0169678, -0.0038147, ..., 0.00439453, 0.00817871,\n",
      "        0.0125732]], dtype=bfloat16), a=Array([[-0.0046731 ,  0.00286664,  0.00511242, ...,  0.01160862,\n",
      "        -0.00942933, -0.01301723],\n",
      "       [ 0.0052865 ,  0.00223007, -0.01150817, ..., -0.00929926,\n",
      "        -0.01117802,  0.00230565]], dtype=float32), b=Array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       ...,\n",
      "       [0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.107422, 0.113281, 0.164062, ..., 0.0292969, 0.0986328,\n",
      "       -0.0441895], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.484375, 0.488281, 0.539062, ..., 0.390625, 0.65625, 0.408203],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.953125, 0.917969, 0.871094, ..., 1.10156, 0.15918, 0.871094],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.267578, 0.339844, 0.296875, ..., 0.400391, -0.120117, 0.251953],      dtype=bfloat16)}}}}\n"
     ]
    }
   ],
   "source": [
    "print(lora_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = lorax.lora(model.apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print params after applying LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: prepare the dataset\n",
    "\n",
    "For this project, we're utilizing the refined **Alpaca dataset**, curated by yahma. This dataset is a carefully filtered selection of 52,000 entries from the original Alpaca collection. Feel free to substitute this section with your own data preparation code if you prefer.\n",
    "\n",
    "It's crucial to include the EOS_TOKEN (End of Sequence Token) in your tokenized output. Failing to do so may result in endless generation loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    token=HUGGINGFACE_TOKEN\n",
    ")\n",
    "if not tokenizer.pad_token:\n",
    "    print(\"Tokenizer doesn't have a pad token.\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(*, tokenizer, batch_size=1, max_length=25, debug_mode=True):\n",
    "    # Define Alpaca prompt template\n",
    "    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "    \n",
    "    ### Instruction: {}\n",
    "    \n",
    "    ### Input: {}\n",
    "    \n",
    "    ### Response: {}\"\"\"\n",
    "    \n",
    "    EOS_TOKEN = tokenizer.eos_token\n",
    "    \n",
    "    # Define formatting function.\n",
    "    def _format_prompts(examples):\n",
    "        instructions = examples[\"instruction\"]\n",
    "        inputs = examples[\"input\"]\n",
    "        outputs = examples[\"output\"]\n",
    "        texts = []\n",
    "        for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "            text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "            texts.append(text)\n",
    "        return {\"text\": texts}\n",
    "\n",
    "    def _tokenize(examples, max_length=None):\n",
    "        tokenized = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=25+1 if not max_length else max_length+1)\n",
    "        tokenized['input_ids'] = [input_id[:-1] for input_id in tokenized['input_ids']]\n",
    "        return {\n",
    "            'input_tokens': tokenized['input_ids'],\n",
    "            'target_mask': tokenized['attention_mask']\n",
    "        }\n",
    "\n",
    "    def _custom_collate_fn(batch):\n",
    "        \"\"\"Applies default_collate_fn from transformers and converts to JAX NumPy arrays.\"\"\"\n",
    "        batch = default_data_collator(batch)\n",
    "        jax_batch = {}\n",
    "        for key, value in batch.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                jax_batch[key] = jnp.array(value.numpy())\n",
    "            else:\n",
    "                jax_batch[key] = value\n",
    "        \n",
    "        return jax_batch\n",
    "\n",
    "    # Load and preprocess the dataset.\n",
    "    dataset = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\")\n",
    "    if debug_mode:\n",
    "        dataset = dataset.select(range(32)) # Use just 32 exampfor faster iteration\n",
    "    dataset = dataset.map(_format_prompts, batched=True)\n",
    "\n",
    "    # Create train and test dataset.\n",
    "    ds = dataset.train_test_split(test_size=0.15)\n",
    "    ds['train'] = ds['train'].map(_tokenize, batched=True, remove_columns=dataset.column_names)\n",
    "    ds['test'] = ds['test'].map(_tokenize, batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        ds['train'],\n",
    "        shuffle=True,\n",
    "        batch_size=1 if not batch_size else batch_size,\n",
    "        collate_fn=_custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        ds['test'],\n",
    "        shuffle=True,\n",
    "        batch_size=1 if not batch_size else batch_size,\n",
    "        collate_fn=_custom_collate_fn\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Test Dataset\n",
    "# train_dataloader, _ = get_dataset(tokenizer=tokenizer)\n",
    "# for i, batch in enumerate(train_dataloader):\n",
    "#     if i>10:\n",
    "#         break\n",
    "#     input_ids, attention_mask = (\n",
    "#         batch[\"input_tokens\"],\n",
    "#         batch[\"target_mask\"],\n",
    "        \n",
    "#     )\n",
    "#     print(input_ids)\n",
    "#     print()\n",
    "#     print(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cellView": "form",
    "id": "iEcV0XEEEcoZ"
   },
   "outputs": [],
   "source": [
    "def forward_and_loss_fn(params,\n",
    "                        *,\n",
    "                        lora_model,\n",
    "                        input_tokens: jax.Array,            # Shape [B, L]\n",
    "                        input_mask: jax.Array,              # Shape [B, L]\n",
    "                        positions: jax.Array,               # Shape [B, L]\n",
    "                        attention_mask: jax.Array,          # [B, L, L]\n",
    "                        ) -> jax.Array:\n",
    "  \"\"\"Forward pass and loss function.\n",
    "\n",
    "  Args:\n",
    "    params: model's input parameters.\n",
    "    model: gemma transformer model to call.\n",
    "    input_tokens: input tokens sequence, shape [B, L].\n",
    "    input_mask: tokens to ignore when computing the loss, shape [B, L].\n",
    "    positions: relative position of each token, shape [B, L].\n",
    "    attention_mask: input attention mask, shape [B, L].\n",
    "\n",
    "  Returns:\n",
    "    Softmax cross-entropy loss for the next-token prediction task.\n",
    "  \"\"\"\n",
    "\n",
    "  # Forward pass on the input data.\n",
    "  # No attention cache is needed here.\n",
    "  logits, _ = lora_model(\n",
    "        params,\n",
    "        input_tokens,\n",
    "        positions,\n",
    "        None,              # Attention cache is None.\n",
    "        attention_mask,\n",
    "    )\n",
    "\n",
    "  # Exclude the last step as it does not appear in the targets.\n",
    "  logits = logits[:, :-1]\n",
    "\n",
    "\n",
    "  # Similarly, the first token cannot be predicteds.\n",
    "  target_tokens = input_tokens[:, 1:]\n",
    "  target_mask = input_mask[:, 1:]\n",
    "\n",
    "  # Convert the target labels into one-hot encoded vectors.\n",
    "  target_mask = target_mask[...,1:] # TODO\n",
    "  one_hot = jax.nn.one_hot(target_tokens, logits.shape[-1])\n",
    "\n",
    "  # Don't update on unwanted tokens.\n",
    "  one_hot = one_hot * target_mask.astype(one_hot.dtype)[..., None]\n",
    "\n",
    "  # Normalisation factor.\n",
    "  norm_factor = 1 / (jnp.sum(target_mask) + 1e-8)\n",
    "\n",
    "  # Return the nll loss.\n",
    "  return -jnp.sum(jax.nn.log_softmax(logits) * one_hot) * norm_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y83DimpjEcoZ"
   },
   "source": [
    "The Gemma transformer requires an attention mask and position vector alongside each input. We can conveniently generate these using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cellView": "form",
    "id": "cbWfdHf0EcoZ"
   },
   "outputs": [],
   "source": [
    "def get_attention_mask_and_positions(example: jax.Array,\n",
    "                                     pad_id : int,\n",
    "                                     )-> tuple[jax.Array, jax.Array]:\n",
    "  \"\"\"Builds the position and attention mask vectors from the given tokens.\"\"\"\n",
    "  pad_mask = example != pad_id\n",
    "  current_token_position = transformer_lib.build_positions_from_mask(pad_mask)\n",
    "  attention_mask = transformer_lib.make_causal_attn_mask(pad_mask)\n",
    "  return current_token_position, attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbxYMMWLEcoZ"
   },
   "source": [
    "We can now build the train_step function which performs the backward pass and updates the model's parameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cellView": "form",
    "id": "cPSfp7ZUEcoZ"
   },
   "outputs": [],
   "source": [
    "def train_step(lora_model,\n",
    "               params,\n",
    "               optimizer: optax.GradientTransformation,\n",
    "               opt_state: optax.OptState,\n",
    "               pad_id: int,\n",
    "               example):\n",
    "  \"\"\"Train step.\n",
    "\n",
    "  Args:\n",
    "    model: gemma transformer model.\n",
    "    params: model's input parameters.\n",
    "    optimizer: optax optimizer to use.\n",
    "    opt_state: input optimizer's state.\n",
    "    pad_id: id of the pad token.\n",
    "    example: input batch.\n",
    "\n",
    "  Returns:\n",
    "    Training loss, updated parameters, updated optimizer state.\n",
    "  \"\"\"\n",
    "  # Build the position and attention mask vectors.\n",
    "  positions, attention_mask = get_attention_mask_and_positions(example['input_tokens'], pad_id)\n",
    "\n",
    "\n",
    "  # Forward and backward passes\n",
    "  train_loss, grads = jax.value_and_grad(forward_and_loss_fn)(params,\n",
    "                                                             lora_model=lora_model,\n",
    "                                                             input_tokens=example['input_tokens'],\n",
    "                                                             input_mask=example['target_mask'],\n",
    "                                                             positions=positions,\n",
    "                                                             attention_mask=attention_mask)\n",
    "  # Update the parameters\n",
    "  updates, opt_state = optimizer.update(grads, opt_state)\n",
    "  params = optax.apply_updates(params, updates)\n",
    "\n",
    "  return train_loss, params, opt_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2QXp116EcoZ"
   },
   "source": [
    "Similarly, we build a `validation_step` function without backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6g6LFWJbEcoa"
   },
   "source": [
    "And now the training loop itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "cellView": "form",
    "id": "xT4bAqNLEcoa"
   },
   "outputs": [],
   "source": [
    "@chex.dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "  learning_rate: float\n",
    "  num_epochs: int\n",
    "  eval_every_n: int\n",
    "  batch_size: int\n",
    "  max_steps: int | None = None\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "    lora_model,\n",
    "    params,\n",
    "    train_dataloader,\n",
    "    tokenizer,\n",
    "    training_cfg: TrainingConfig,\n",
    "    lora_spec):\n",
    "\n",
    "\n",
    "  compiled_train_step = train_step# , static_argnames=['lora_model', 'optimizer'])\n",
    "  optimizer = optax.sgd(training_cfg.learning_rate)\n",
    "  optimizer = lorax.wrap_optimizer(optimizer, lora_spec)\n",
    "  opt_state = optimizer.init(params)\n",
    "\n",
    "  n_steps = 0\n",
    "  avg_loss=0\n",
    "\n",
    "  for i, train_example in enumerate(train_dataloader):\n",
    "    train_loss, params, opt_state = train_step(lora_model=lora_model,\n",
    "                                                        params=params,\n",
    "                                                        optimizer=optimizer,\n",
    "                                                        opt_state=opt_state,\n",
    "                                                        pad_id=tokenizer.pad_token_id,\n",
    "                                                        example=train_example)\n",
    "    n_steps += 1\n",
    "    avg_loss += train_loss\n",
    "    print(f\"train_loss {train_loss}\")\n",
    "    if training_cfg.max_steps is not None and n_steps > training_cfg.max_steps:\n",
    "      break\n",
    "  return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muwkf_ZgEcoa"
   },
   "source": [
    "We can fine-tune our model on a limited number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedder': {'input_embedding': Array([[0.0351562, -0.0229492, 0.081543, ..., 0.0211182, 0.0527344,\n",
       "          -0.0351562],\n",
       "         [-0.0200195, 0.0522461, -0.0302734, ..., 0.0027771, -0.0240479,\n",
       "          -0.017334],\n",
       "         [-0.000164032, -0.00592041, 0.0222168, ..., 0.0151978,\n",
       "          -0.00735474, -0.0119019],\n",
       "         ...,\n",
       "         [0.0227051, -0.0375977, 0.0356445, ..., 0.0402832, 0.0117798,\n",
       "          -0.0308838],\n",
       "         [0.0319824, -0.0368652, 0.0410156, ..., 0.0385742, 0.0196533,\n",
       "          -0.0270996],\n",
       "         [0.0203857, -0.0405273, 0.0368652, ..., 0.0400391, 0.0180664,\n",
       "          -0.0306396]], dtype=bfloat16)},\n",
       " 'final_norm': {'scale': Array([2.32812, 2.34375, 2.28125, ..., 4.65625, 2.53125, 2.4375],      dtype=bfloat16)},\n",
       " 'layer_0': {'attn': {'attn_vec_einsum': {'w': Array([[[0.0090332, 0.0100708, 0.0155029, ..., 0.00256348, -0.00537109,\n",
       "             0.00848389],\n",
       "            [0.0114136, 0.0202637, 0.00952148, ..., -0.000166893, 0.0108032,\n",
       "             0.0124512],\n",
       "            [0.00543213, -0.000261307, 0.000991821, ..., 0.0150146,\n",
       "             0.0119019, 0.00424194],\n",
       "            ...,\n",
       "            [0.00188446, 0.00346375, -0.00598145, ..., 0.0195312,\n",
       "             -0.00405884, -0.00738525],\n",
       "            [-0.0111694, 0.00515747, 0.00306702, ..., -0.00750732,\n",
       "             0.00389099, -0.0107422],\n",
       "            [-0.00230408, 0.0202637, 0.00167084, ..., -0.0123901,\n",
       "             0.00787354, 0.00236511]],\n",
       "    \n",
       "           [[0.012207, -0.00169373, -0.0222168, ..., -0.0055542,\n",
       "             -0.00891113, -0.0150146],\n",
       "            [0.00546265, -0.00872803, -0.00112915, ..., 0.00854492,\n",
       "             -0.0110474, 0.0131836],\n",
       "            [0.00294495, 0.00230408, 0.00650024, ..., 0.0011673,\n",
       "             -0.00598145, 0.0131226],\n",
       "            ...,\n",
       "            [-0.00714111, -0.00848389, -0.00340271, ..., -0.000105381,\n",
       "             0.0118408, 0.00469971],\n",
       "            [0.00231934, -0.00115967, 0.0078125, ..., -0.00512695,\n",
       "             -0.00579834, 0.000249863],\n",
       "            [0.0045166, 0.00982666, 0.0105591, ..., 0.00479126, -0.00915527,\n",
       "             -0.00872803]],\n",
       "    \n",
       "           [[-0.0114136, -0.0194092, 0.00334167, ..., 0.0055542,\n",
       "             -0.00952148, 0.0133057],\n",
       "            [-0.00958252, 0.00224304, 0.000499725, ..., 0.0216064,\n",
       "             0.00268555, -0.000448227],\n",
       "            [0.00195312, -0.0214844, -0.00341797, ..., 0.00265503,\n",
       "             -0.00430298, 0.0169678],\n",
       "            ...,\n",
       "            [0.00320435, -0.00222778, 0.0111694, ..., -0.0151367,\n",
       "             -0.00994873, -0.0116577],\n",
       "            [-0.00187683, 0.00616455, 0.000991821, ..., 0.0168457,\n",
       "             0.00299072, -0.00149536],\n",
       "            [-0.00836182, 0.00772095, -0.00671387, ..., 0.00860596,\n",
       "             -0.000370026, -0.0116577]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00738525, -0.00878906, -0.0100708, ..., 0.00848389,\n",
       "             0.0108032, -0.0223389],\n",
       "            [0.0126343, -0.0055542, 0.0020752, ..., 0.0151367, 0.00741577,\n",
       "             0.00564575],\n",
       "            [0.0179443, -0.006073, 0.0152588, ..., -0.00552368, -0.0151978,\n",
       "             -0.0184326],\n",
       "            ...,\n",
       "            [-0.00364685, -0.0162354, 0.00897217, ..., -0.0114136,\n",
       "             -0.0234375, -0.0178223],\n",
       "            [0.0129395, -0.0134888, -0.0109253, ..., -0.0233154, 0.00335693,\n",
       "             -0.0144043],\n",
       "            [0.00482178, -0.0142822, 0.00370789, ..., 0.00473022,\n",
       "             0.00946045, 0.0132446]],\n",
       "    \n",
       "           [[0.0140381, 0.00576782, -0.0126953, ..., 0.00215149, -0.0015564,\n",
       "             -0.0118408],\n",
       "            [0.00335693, -0.0055542, 0.00872803, ..., 0.0145874, 0.0238037,\n",
       "             -0.0159912],\n",
       "            [-0.00601196, 0.0214844, -0.0140991, ..., 0.00460815, 0.0155029,\n",
       "             -0.00231934],\n",
       "            ...,\n",
       "            [-0.0127563, 0.0090332, -0.0126953, ..., -0.00842285,\n",
       "             -0.000185013, -0.00897217],\n",
       "            [-0.000663757, 4.91738e-06, -0.000220299, ..., -0.006073,\n",
       "             -0.00402832, 0.00114441],\n",
       "            [0.00634766, -0.0201416, -0.000180244, ..., -0.00494385,\n",
       "             -0.0183105, -0.00375366]],\n",
       "    \n",
       "           [[0.0167236, -0.00463867, 0.00646973, ..., 0.00082016,\n",
       "             0.00811768, -0.00338745],\n",
       "            [-0.0125732, -0.00860596, -0.00811768, ..., -0.00769043,\n",
       "             0.00473022, -0.00335693],\n",
       "            [-0.00105286, 0.0231934, 0.00216675, ..., 0.00646973,\n",
       "             -0.00331116, -0.0201416],\n",
       "            ...,\n",
       "            [0.00442505, 0.00927734, -0.0037384, ..., 0.00588989,\n",
       "             -0.0039978, -0.00131989],\n",
       "            [-0.00268555, -0.0032196, 0.00640869, ..., -0.00756836,\n",
       "             0.000105858, -0.00227356],\n",
       "            [-0.00102234, 0.00927734, 0.0174561, ..., 0.013855, -0.0142822,\n",
       "             0.0163574]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.0055542, -0.00469971, 0.00686646, ..., -0.00312805,\n",
       "              -0.0183105, 0.0264893],\n",
       "             [0.00479126, -0.0022583, 0.00549316, ..., -0.00119781,\n",
       "              0.00958252, -0.00558472],\n",
       "             [-0.0192871, 0.00210571, 0.00720215, ..., 0.00128174,\n",
       "              0.00799561, 0.0136108],\n",
       "             ...,\n",
       "             [0.0120239, -0.00173187, -0.0088501, ..., 0.00296021,\n",
       "              0.0136719, -0.0144653],\n",
       "             [-0.00518799, 0.00744629, 0.00014019, ..., -0.000934601,\n",
       "              0.0106812, 0.010437],\n",
       "             [0.0126953, -0.00698853, -0.0113525, ..., 0.027832,\n",
       "              0.00921631, 0.00994873]],\n",
       "    \n",
       "            [[-0.00110626, -0.00497437, 0.0147095, ..., 0.0172119,\n",
       "              0.00714111, -0.00354004],\n",
       "             [0.0163574, -0.00386047, 0.0189209, ..., 0.0136108, 0.0192871,\n",
       "              -0.0257568],\n",
       "             [-0.0105591, -0.0100708, 0.0134277, ..., 0.0112915, 0.0152588,\n",
       "              -0.00302124],\n",
       "             ...,\n",
       "             [-0.0152588, -0.00537109, -0.00148773, ..., -0.0306396,\n",
       "              -0.0019455, 0.0206299],\n",
       "             [0.00714111, 0.00549316, 0.00396729, ..., -0.00122833,\n",
       "              0.00500488, 0.0157471],\n",
       "             [0.0101318, 0.00173187, -0.0100708, ..., -0.00604248,\n",
       "              0.00506592, 0.00830078]],\n",
       "    \n",
       "            [[0.00509644, 0.0194092, 0.00094223, ..., 0.0159912, 0.0120239,\n",
       "              0.00244141],\n",
       "             [0.0035553, -0.00753784, -0.0128174, ..., -0.0038147,\n",
       "              -0.00958252, -0.0162354],\n",
       "             [0.00352478, -0.00842285, -0.00564575, ..., 0.046875,\n",
       "              0.00286865, 0.0126343],\n",
       "             ...,\n",
       "             [-0.00927734, -0.0088501, -0.0114136, ..., 0.00933838,\n",
       "              0.0220947, -0.0124512],\n",
       "             [0.000629425, -0.0067749, 0.000930786, ..., 0.00720215,\n",
       "              -0.0228271, -0.0025177],\n",
       "             [0.00534058, 0.0152588, 0.00427246, ..., -0.0275879,\n",
       "              -0.0123901, 0.00145721]],\n",
       "    \n",
       "            [[0.000911713, 0.0195312, -0.00546265, ..., 0.0136108,\n",
       "              0.0017395, 0.0038147],\n",
       "             [0.00509644, 0.000364304, 0.000488281, ..., 0.00552368,\n",
       "              -0.00872803, 0.013855],\n",
       "             [0.00337219, -0.00216675, -0.00150299, ..., -0.020752,\n",
       "              0.0153198, -0.00183868],\n",
       "             ...,\n",
       "             [0.00494385, -0.00686646, -0.0014801, ..., -0.00830078,\n",
       "              0.00817871, 0.015625],\n",
       "             [-0.0211182, -0.00860596, 0.0180664, ..., -0.0133667,\n",
       "              0.00537109, -0.00257874],\n",
       "             [0.00500488, 0.00811768, -0.00765991, ..., -0.0120239,\n",
       "              -0.00778198, -0.00346375]]],\n",
       "    \n",
       "    \n",
       "           [[[0.00735474, 0.00170135, -0.00234985, ..., -0.0192871,\n",
       "              -0.0101929, -0.00209045],\n",
       "             [0.0105591, 0.0145874, 0.0067749, ..., -0.0050354, 0.00613403,\n",
       "              0.00531006],\n",
       "             [0.0213623, -0.00442505, -0.00418091, ..., 0.00396729,\n",
       "              0.00479126, -0.00543213],\n",
       "             ...,\n",
       "             [-0.00268555, -0.0088501, -0.0108032, ..., -0.0108643,\n",
       "              -0.0184326, -0.0157471],\n",
       "             [-0.00376892, 0.000387192, 0.00732422, ..., 0.00172424,\n",
       "              -0.00619507, 0.000286102],\n",
       "             [0.00260925, 0.00927734, -0.0218506, ..., -0.0102539,\n",
       "              -0.00183105, -0.00424194]],\n",
       "    \n",
       "            [[-0.00115204, 0.024292, 0.0072937, ..., -0.0122681,\n",
       "              -0.0241699, 0.00653076],\n",
       "             [-0.00689697, -0.0240479, -0.00196838, ..., -0.0032196,\n",
       "              -0.00570679, -0.00315857],\n",
       "             [0.00866699, -0.000195503, 0.00408936, ..., -0.000595093,\n",
       "              -0.00111389, 0.00349426],\n",
       "             ...,\n",
       "             [-0.0162354, 0.00325012, 0.000671387, ..., -0.0105591,\n",
       "              0.0106201, -0.0189209],\n",
       "             [0.0140381, -0.0145874, 0.0019455, ..., 0.0062561,\n",
       "              7.24792e-05, -0.0124512],\n",
       "             [0.00692749, 0.0108032, -0.00308228, ..., -0.00628662,\n",
       "              -0.00166321, 0.00358582]],\n",
       "    \n",
       "            [[0.00154114, 0.0030365, -0.00567627, ..., -0.00430298,\n",
       "              0.0120239, -0.00106049],\n",
       "             [0.0266113, -0.00588989, -0.00124359, ..., -0.00128937,\n",
       "              -0.00491333, -0.00104523],\n",
       "             [0.0141602, -0.00463867, 0.00402832, ..., -0.00744629,\n",
       "              0.00585938, 0.00680542],\n",
       "             ...,\n",
       "             [-0.00732422, 0.0172119, 0.0112915, ..., -0.0088501,\n",
       "              -0.010376, 0.0022583],\n",
       "             [0.00445557, 0.0032196, 0.00970459, ..., 0.0116577,\n",
       "              -0.0112915, 0.0106812],\n",
       "             [-0.00344849, -0.00640869, -0.00241089, ..., 0.0184326,\n",
       "              -0.00314331, 0.0129395]],\n",
       "    \n",
       "            [[0.0126953, 0.0267334, 0.00668335, ..., -0.00268555,\n",
       "              -0.00897217, -0.00176239],\n",
       "             [-0.0116577, -0.0045166, -0.0181885, ..., 0.0189209,\n",
       "              -0.00811768, 0.00439453],\n",
       "             [-0.00772095, -0.0078125, 0.0146484, ..., -0.0105591,\n",
       "              -0.00263977, -0.0118408],\n",
       "             ...,\n",
       "             [0.0153198, -0.0114746, -0.0217285, ..., 0.00357056,\n",
       "              0.0117798, 0.000226974],\n",
       "             [-0.00274658, -0.00306702, 0.010376, ..., -0.00305176,\n",
       "              0.0128784, -0.0088501],\n",
       "             [0.00613403, -0.00866699, 0.00491333, ..., -0.00848389,\n",
       "              -0.00512695, -0.00350952]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00701904, -0.00222778, 0.00172424, ..., 0.00131989,\n",
       "             0.00759888, 0.00173187],\n",
       "            [0.0148926, 0.015564, 0.00344849, ..., -0.00527954, 0.00524902,\n",
       "             -0.000448227],\n",
       "            [-0.0192871, -0.0253906, 0.00622559, ..., -0.00582886,\n",
       "             0.000656128, -0.013855],\n",
       "            ...,\n",
       "            [0.0147705, 0.0205078, -0.000892639, ..., 0.00747681,\n",
       "             0.00512695, -0.000797272],\n",
       "            [-0.027832, -0.0100098, 0.0136108, ..., -0.000249863,\n",
       "             -0.0112915, -0.0116577],\n",
       "            [0.00866699, 0.00494385, -0.00124359, ..., -0.0127563,\n",
       "             -0.000556946, 0.00515747]],\n",
       "    \n",
       "           [[-0.00497437, 0.00296021, 0.00723267, ..., -0.0065918,\n",
       "             -0.0189209, 0.0212402],\n",
       "            [-0.0038147, 0.00357056, 0.00236511, ..., 0.0100708, 0.00360107,\n",
       "             0.0153198],\n",
       "            [-0.00137329, -2.94447e-05, -0.00198364, ..., 0.0055542,\n",
       "             0.000164986, 0.00799561],\n",
       "            ...,\n",
       "            [0.0065918, -0.00180817, -0.00494385, ..., 0.00561523,\n",
       "             0.0314941, -0.0133057],\n",
       "            [0.00909424, 0.000522614, -0.00247192, ..., 9.58443e-05,\n",
       "             0.0228271, 0.0136108],\n",
       "            [0.00704956, -0.00379944, -0.00320435, ..., 0.0283203,\n",
       "             0.0143433, 0.0267334]],\n",
       "    \n",
       "           [[-0.00817871, 0.00317383, 0.010376, ..., -0.0124512, -0.0161133,\n",
       "             0.00695801],\n",
       "            [0.0177002, 0.00689697, -0.00662231, ..., -0.00830078,\n",
       "             0.0153198, -4.55379e-05],\n",
       "            [0.00500488, 0.00282288, -0.00592041, ..., 0.00379944,\n",
       "             0.0170898, -0.0043335],\n",
       "            ...,\n",
       "            [-0.00552368, -0.0050354, 0.012146, ..., 0.00708008,\n",
       "             -0.00219727, 0.020874],\n",
       "            [-0.000272751, -0.00393677, 0.000801086, ..., 0.010437,\n",
       "             -0.00817871, 0.0267334],\n",
       "            [-0.0197754, 6.4373e-05, -0.00927734, ..., 0.0039978,\n",
       "             -0.0169678, -0.00762939]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00176239, 0.0280762, 0.00958252, ..., 0.0253906, 0.00405884,\n",
       "             -0.0103149],\n",
       "            [-0.00830078, 0.0157471, 0.00405884, ..., -0.00753784,\n",
       "             0.0157471, 0.00364685],\n",
       "            [0.000482559, -0.0168457, -0.0189209, ..., 0.00564575,\n",
       "             0.00273132, -0.0219727],\n",
       "            ...,\n",
       "            [-0.0147095, 0.0137939, 0.000431061, ..., 0.0134888, 0.00195312,\n",
       "             0.0134888],\n",
       "            [-0.0035553, -0.0163574, 0.015564, ..., -0.00177002, -0.020752,\n",
       "             -0.00830078],\n",
       "            [-0.00221252, -0.00111389, 0.00866699, ..., -0.00123596,\n",
       "             -0.0220947, 0.0164795]],\n",
       "    \n",
       "           [[-0.000701904, 0.000305176, -0.00564575, ..., 0.0170898,\n",
       "             -0.00769043, 0.00793457],\n",
       "            [-0.00604248, -0.0133057, -0.00014782, ..., -0.013855,\n",
       "             0.0216064, 0.013916],\n",
       "            [0.00141907, -0.00622559, -0.00521851, ..., -0.00811768,\n",
       "             -0.00317383, 0.0133667],\n",
       "            ...,\n",
       "            [0.00466919, -0.0133667, 0.0220947, ..., -0.0198975,\n",
       "             -0.00909424, -0.00628662],\n",
       "            [-0.00263977, -0.00227356, -0.00592041, ..., -0.00518799,\n",
       "             -0.00720215, -0.00964355],\n",
       "            [-0.00704956, -0.010498, -0.0105591, ..., 0.00318909,\n",
       "             0.00306702, -0.00108337]],\n",
       "    \n",
       "           [[-0.000785828, -0.00302124, -0.00518799, ..., 0.0030365,\n",
       "             0.00415039, -0.0100098],\n",
       "            [0.00115967, 0.0045166, 0.0268555, ..., 0.0275879, -0.00248718,\n",
       "             -0.0110474],\n",
       "            [-0.000383377, 0.00564575, -0.00389099, ..., 0.00872803,\n",
       "             0.00549316, 0.0213623],\n",
       "            ...,\n",
       "            [0.00379944, 0.012085, -0.0219727, ..., 0.0174561, 0.00698853,\n",
       "             -0.0152588],\n",
       "            [0.0144653, -0.00476074, -0.0035553, ..., -0.0113525,\n",
       "             0.000263214, 0.0339355],\n",
       "            [0.0141602, 0.0151367, -0.0126953, ..., -0.00133514, 0.00598145,\n",
       "             -0.0184326]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.0027771, -0.00335693, -0.00897217, ..., 0.0078125,\n",
       "            -0.00592041, 0.0115356],\n",
       "           [-0.0178223, -0.00717163, 0.0169678, ..., -0.000892639,\n",
       "            -0.00102234, 0.00619507],\n",
       "           [-0.00344849, -0.0055542, 0.00110626, ..., 0.00692749,\n",
       "            -0.00527954, -0.010376],\n",
       "           ...,\n",
       "           [0.00698853, -0.000255585, -0.006073, ..., -0.00726318,\n",
       "            -0.00897217, -0.0106812],\n",
       "           [0.00543213, -0.00732422, 0.00288391, ..., -0.0098877,\n",
       "            0.0101929, -0.00909424],\n",
       "           [0.00698853, -0.0126953, 0.0032196, ..., -0.00772095,\n",
       "            -0.00714111, 0.0125122]],\n",
       "   \n",
       "          [[0.00817871, 0.0162354, 0.00274658, ..., -0.0105591,\n",
       "            -0.00811768, 0.00230408],\n",
       "           [-0.013855, -0.00346375, -0.00506592, ..., -0.00732422,\n",
       "            -0.00167847, 0.00552368],\n",
       "           [-0.00662231, 0.0125732, -0.0037384, ..., 0.00241089,\n",
       "            -0.00927734, -0.00946045],\n",
       "           ...,\n",
       "           [0.00674438, -0.0100098, -0.000713348, ..., -0.0116577,\n",
       "            -0.00037384, 0.00720215],\n",
       "           [-0.00622559, -0.00299072, -0.000191689, ..., 0.00576782,\n",
       "            -0.00424194, 0.00393677],\n",
       "           [0.000265121, -0.0195312, 0.00735474, ..., 0.00653076,\n",
       "            0.000455856, 0.0102539]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.000249863, 0.00778198, 0.0151978, ..., -0.00805664,\n",
       "           -0.00162506, -0.0137329],\n",
       "          [0.0143433, 0.00692749, 0.0136108, ..., -0.0235596, 0.00010252,\n",
       "           -0.00921631],\n",
       "          [0.00221252, 0.00842285, -0.00308228, ..., 0.000200272,\n",
       "           -0.00546265, -0.00994873],\n",
       "          ...,\n",
       "          [-0.000102043, -0.00230408, 0.00367737, ..., 0.0244141, 0.0109863,\n",
       "           -0.00683594],\n",
       "          [-0.00860596, 0.00357056, -0.006073, ..., -0.00616455,\n",
       "           -0.00698853, 0.00454712],\n",
       "          [-0.00708008, 0.00341797, 0.00242615, ..., 0.00189209,\n",
       "           -0.00402832, 0.00933838]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([-0.53125, -0.515625, -0.490234, ..., -0.53125, 1.42188, -0.519531],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([-0.229492, -0.189453, -0.194336, ..., -0.361328, 0.441406,\n",
       "          -0.162109], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.116699, 0.134766, 0.192383, ..., 0.636719, 0.0402832, 0.243164],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.227539, 0.208008, 0.208008, ..., 0.992188, 2.15625, 0.197266],      dtype=bfloat16)}},\n",
       " 'layer_1': {'attn': {'attn_vec_einsum': {'w': Array([[[0.00360107, 0.00775146, 0.0117798, ..., 0.00494385, -0.0147705,\n",
       "             -0.020752],\n",
       "            [0.00273132, -0.00309753, -0.00151825, ..., 0.00239563,\n",
       "             -0.00279236, -0.00411987],\n",
       "            [-0.0223389, -0.00183868, -0.0153198, ..., 0.00276184,\n",
       "             0.0239258, -0.0167236],\n",
       "            ...,\n",
       "            [0.0015564, 0.000617981, 0.00854492, ..., -0.00494385,\n",
       "             0.00331116, 0.00113678],\n",
       "            [-0.00389099, -0.00576782, -0.0159912, ..., 0.0119019,\n",
       "             -0.0410156, -0.0134277],\n",
       "            [-0.00018692, -0.0219727, 0.000747681, ..., -0.00274658,\n",
       "             -0.0114136, 0.00145721]],\n",
       "    \n",
       "           [[-0.00946045, -0.0118408, -0.00891113, ..., 0.00927734,\n",
       "             0.019165, -0.0142212],\n",
       "            [-0.00169373, -0.00482178, 0.00134277, ..., 0.00476074,\n",
       "             -0.00153351, -0.000442505],\n",
       "            [0.00204468, -0.0224609, 0.00595093, ..., -0.00866699,\n",
       "             -0.0163574, -0.00964355],\n",
       "            ...,\n",
       "            [0.003479, -0.00109863, -0.00860596, ..., 0.0037384, 0.0163574,\n",
       "             0.034668],\n",
       "            [0.0181885, -0.00104523, -0.00454712, ..., 0.0168457,\n",
       "             -0.0200195, 0.00787354],\n",
       "            [-0.00262451, 0.0161133, -0.00662231, ..., -0.00970459,\n",
       "             0.00695801, -0.00106812]],\n",
       "    \n",
       "           [[-0.0119019, -0.00598145, 0.00897217, ..., 0.00909424,\n",
       "             -0.0134277, 0.0162354],\n",
       "            [-0.00518799, 0.0168457, -0.00312805, ..., -0.00126648,\n",
       "             -0.00366211, -0.0149536],\n",
       "            [-0.00050354, 0.00125885, -0.0118408, ..., 0.00595093,\n",
       "             0.00637817, -0.00842285],\n",
       "            ...,\n",
       "            [-0.00714111, 0.0140991, -0.00479126, ..., -0.00165558,\n",
       "             -0.00273132, 0.019043],\n",
       "            [-0.00408936, -0.00144196, -0.0090332, ..., -0.0119019,\n",
       "             -0.00811768, 0.00524902],\n",
       "            [-0.00115204, -0.0230713, 0.00357056, ..., 0.0123901,\n",
       "             -0.00695801, 0.00860596]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00775146, 0.00799561, 0.0120239, ..., 0.0107422, -0.00811768,\n",
       "             -0.00952148],\n",
       "            [0.00744629, 0.0088501, 0.00567627, ..., 0.0126343, 0.0078125,\n",
       "             -0.0205078],\n",
       "            [0.0195312, -0.0112305, -0.0112915, ..., 0.0159912, -0.00799561,\n",
       "             0.0307617],\n",
       "            ...,\n",
       "            [0.0174561, 0.00405884, -0.00698853, ..., 0.000484467,\n",
       "             -0.0140381, 0.00830078],\n",
       "            [-0.00346375, -0.0141602, -0.0113525, ..., 0.00689697,\n",
       "             0.0272217, 0.00418091],\n",
       "            [-0.00927734, 0.0118408, -0.013855, ..., -0.00125122,\n",
       "             0.00952148, 0.000349045]],\n",
       "    \n",
       "           [[-0.0157471, -0.00564575, 0.0019989, ..., 0.00296021,\n",
       "             -0.00230408, -0.00279236],\n",
       "            [-0.00576782, 0.013855, -0.0115967, ..., -0.00842285, 0.010376,\n",
       "             -0.00476074],\n",
       "            [-0.0137939, -0.0108032, 0.00717163, ..., 0.00958252,\n",
       "             -0.00897217, -0.00662231],\n",
       "            ...,\n",
       "            [0.0209961, 0.0177002, -0.00592041, ..., -0.0131226, 0.00732422,\n",
       "             -0.012085],\n",
       "            [-0.0109863, 0.00830078, -0.000545502, ..., -0.00759888,\n",
       "             -0.00811768, -0.00787354],\n",
       "            [0.0187988, -0.00921631, 0.0148926, ..., 0.0043335, 0.00854492,\n",
       "             0.0159912]],\n",
       "    \n",
       "           [[-0.0100098, 0.00213623, 0.00836182, ..., 0.0043335, -0.0129395,\n",
       "             -0.00393677],\n",
       "            [0.00793457, 0.00579834, 0.00665283, ..., -0.00148773,\n",
       "             0.0110474, -0.0133667],\n",
       "            [0.00488281, -0.00466919, -0.0100708, ..., 0.0013504,\n",
       "             -0.00163269, -0.0123291],\n",
       "            ...,\n",
       "            [-0.0032959, -0.00415039, -0.0169678, ..., 0.00328064,\n",
       "             -0.00421143, -0.00109863],\n",
       "            [-0.0143433, -0.00247192, -0.00527954, ..., -0.00582886,\n",
       "             0.00162506, -0.00744629],\n",
       "            [0.0110474, -0.0263672, -0.00964355, ..., 0.00466919,\n",
       "             -0.0111084, -0.00909424]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.0013504, -0.00108337, -0.00610352, ..., -0.0088501,\n",
       "              0.0020752, 0.0113525],\n",
       "             [0.00227356, 0.00799561, 0.00518799, ..., -0.00836182,\n",
       "              -0.00282288, -0.00564575],\n",
       "             [-0.00631714, 0.000492096, 7.92742e-06, ..., 0.0202637,\n",
       "              -0.0100098, 0.0124512],\n",
       "             ...,\n",
       "             [0.00245667, 0.00239563, 0.00082016, ..., 0.00178528,\n",
       "              0.0198975, 0.0238037],\n",
       "             [-0.00247192, 0.0206299, 0.00112152, ..., 0.043457,\n",
       "              1.43051e-05, 0.0150757],\n",
       "             [0.00112915, -0.0016098, 0.0025177, ..., 0.00720215,\n",
       "              0.0196533, -0.00775146]],\n",
       "    \n",
       "            [[-0.00701904, 0.00878906, -0.00842285, ..., -0.00320435,\n",
       "              0.0175781, -0.0111694],\n",
       "             [-0.00145721, -0.00389099, -0.0128174, ..., 0.00704956,\n",
       "              -0.0158691, -0.0162354],\n",
       "             [-0.00695801, -0.00616455, -0.0109253, ..., -0.0341797,\n",
       "              0.000155449, 0.0110474],\n",
       "             ...,\n",
       "             [-0.019165, 0.0258789, 0.000396729, ..., 0.0159912, 0.0131226,\n",
       "              0.013855],\n",
       "             [0.00020504, 0.00756836, -0.00708008, ..., 0.00891113,\n",
       "              -0.00933838, 0.00384521],\n",
       "             [-0.00723267, -0.00297546, -0.00063324, ..., 0.00228882,\n",
       "              0.0212402, 0.0148926]],\n",
       "    \n",
       "            [[-0.0118408, 0.00110626, 0.00177765, ..., 0.0019455,\n",
       "              -0.00379944, -0.0135498],\n",
       "             [-0.00137329, 0.00180054, -0.0117188, ..., 0.00160217,\n",
       "              0.027832, 0.000109673],\n",
       "             [-0.0155029, -0.00299072, 0.0103149, ..., 0.000865936,\n",
       "              -0.0172119, -0.0102539],\n",
       "             ...,\n",
       "             [-0.0168457, 0.00312805, 0.0361328, ..., -0.00427246,\n",
       "              0.0189209, 0.00952148],\n",
       "             [0.0125122, -0.0017395, 0.00531006, ..., -0.00817871,\n",
       "              -0.00402832, 0.00704956],\n",
       "             [0.00106812, -0.00457764, -0.0258789, ..., -0.00165558,\n",
       "              -0.0200195, -0.0131226]],\n",
       "    \n",
       "            [[-0.00497437, 0.00726318, -0.012085, ..., -0.0112305,\n",
       "              -0.0184326, -0.00811768],\n",
       "             [0.00460815, 0.0123291, 0.0043335, ..., -0.0103149,\n",
       "              -0.0280762, -0.032959],\n",
       "             [0.00296021, 0.00366211, -0.0134888, ..., -0.0108032,\n",
       "              0.00154877, 0.00622559],\n",
       "             ...,\n",
       "             [-0.00158691, 0.0100708, -0.0118408, ..., -0.0124512,\n",
       "              -0.0101929, 0.0432129],\n",
       "             [-0.003479, -0.015625, -0.00473022, ..., -0.010437, -0.027832,\n",
       "              -0.0270996],\n",
       "             [-0.00119781, -0.00282288, 0.0090332, ..., 0.0174561,\n",
       "              -0.00473022, -0.00102234]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00271606, -0.0164795, -0.00101471, ..., 0.0108032,\n",
       "              0.0334473, 0.00101471],\n",
       "             [-0.0249023, -0.000164032, -0.00582886, ..., -0.0050354,\n",
       "              0.00939941, -0.00479126],\n",
       "             [-0.00427246, 0.0088501, 0.00866699, ..., -0.0106201,\n",
       "              0.0126343, -0.00994873],\n",
       "             ...,\n",
       "             [-0.017334, 0.00393677, -0.00161743, ..., 0.00537109,\n",
       "              0.0116577, 0.00952148],\n",
       "             [0.0152588, -0.000926971, -0.00747681, ..., 0.00363159,\n",
       "              0.00369263, 0.00354004],\n",
       "             [-0.00842285, 0.000244141, -0.0166016, ..., 0.0045166,\n",
       "              -0.00273132, -0.00848389]],\n",
       "    \n",
       "            [[-0.0213623, -0.00268555, -0.00157928, ..., -0.00337219,\n",
       "              -0.0132446, -0.00509644],\n",
       "             [-0.000679016, 0.0117188, 0.00842285, ..., -0.0102539,\n",
       "              0.00485229, -0.00552368],\n",
       "             [-0.00262451, 0.00842285, 0.00364685, ..., -0.00552368,\n",
       "              0.0139771, -0.000999451],\n",
       "             ...,\n",
       "             [0.0105591, -0.00927734, 0.0286865, ..., 0.00370789,\n",
       "              -0.0179443, 0.00466919],\n",
       "             [0.012085, -0.00386047, 0.00756836, ..., 0.00300598,\n",
       "              -0.0020752, 0.00133514],\n",
       "             [0.015564, -0.0108032, -0.0209961, ..., 0.0151367, 0.00793457,\n",
       "              0.00372314]],\n",
       "    \n",
       "            [[-0.00379944, -0.00933838, 0.00805664, ..., 0.00848389,\n",
       "              -0.00209045, 0.00891113],\n",
       "             [-0.0170898, -0.0102539, -0.0111084, ..., -0.00488281,\n",
       "              0.00787354, 0.0134888],\n",
       "             [-0.0106201, -0.000972748, -0.0137939, ..., -0.00759888,\n",
       "              -0.00512695, -0.0100098],\n",
       "             ...,\n",
       "             [-0.001297, 0.00188446, 0.00897217, ..., 0.0170898,\n",
       "              -0.00151825, -0.00994873],\n",
       "             [-0.00921631, 0.00582886, 0.00363159, ..., -0.00337219,\n",
       "              -0.010376, -0.00909424],\n",
       "             [0.00445557, 0.00192261, 0.00604248, ..., 0.00131226,\n",
       "              0.00442505, 0.00497437]],\n",
       "    \n",
       "            [[0.0050354, 0.0136108, 0.00230408, ..., -0.0202637,\n",
       "              0.00674438, 0.0108032],\n",
       "             [-0.00854492, 0.0172119, -0.00848389, ..., 0.00460815,\n",
       "              0.00753784, 0.00378418],\n",
       "             [-0.013916, -0.00540161, -0.0113525, ..., 0.00210571,\n",
       "              0.00537109, 0.00224304],\n",
       "             ...,\n",
       "             [0.00787354, -0.000789642, -0.00671387, ..., -0.00726318,\n",
       "              0.00402832, 0.00125122],\n",
       "             [0.0169678, -0.00531006, -0.00509644, ..., 0.0155029,\n",
       "              0.00631714, 0.0100098],\n",
       "             [0.0088501, 0.0098877, -0.015625, ..., -0.0334473, -0.0201416,\n",
       "              0.0137329]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.000261307, -0.000207901, 0.0110474, ..., -0.0218506,\n",
       "             -0.0184326, -0.00034523],\n",
       "            [0.00430298, -0.00628662, -0.00927734, ..., 0.0112305,\n",
       "             0.00518799, 0.0131836],\n",
       "            [0.0112305, -0.00312805, -0.0062561, ..., -0.00334167,\n",
       "             0.00405884, 0.00576782],\n",
       "            ...,\n",
       "            [-0.00111389, 0.000934601, -0.010498, ..., 0.0136719,\n",
       "             -0.00805664, 0.00714111],\n",
       "            [0.0050354, -0.0147095, -0.00219727, ..., 0.0273438, 0.024292,\n",
       "             -0.0187988],\n",
       "            [-0.00326538, 0.0119629, 0.00909424, ..., 0.00717163,\n",
       "             -0.0153198, -0.00216675]],\n",
       "    \n",
       "           [[-0.00340271, -0.00613403, 0.0067749, ..., -0.0206299,\n",
       "             -0.00463867, 0.00546265],\n",
       "            [0.00382996, -0.00231934, -0.00714111, ..., -0.010376,\n",
       "             -0.00094986, -0.00354004],\n",
       "            [-0.00104523, -4.43459e-05, -0.003479, ..., -0.00765991,\n",
       "             0.0175781, -0.00595093],\n",
       "            ...,\n",
       "            [-0.00604248, -0.00735474, -0.00723267, ..., 0.0310059,\n",
       "             -0.00854492, 0.026123],\n",
       "            [0.0196533, -0.00601196, -0.00872803, ..., 0.00250244,\n",
       "             -0.00509644, 0.0111694],\n",
       "            [0.00231934, -0.00762939, -0.00343323, ..., 0.0112305,\n",
       "             0.00616455, -0.0108643]],\n",
       "    \n",
       "           [[0.0088501, 0.0118408, 0.00823975, ..., 0.00386047, 0.006073,\n",
       "             -0.0119629],\n",
       "            [0.00805664, -0.0114746, -0.0127563, ..., 0.00765991, 0.0136108,\n",
       "             0.00558472],\n",
       "            [-0.00338745, -0.0132446, 0.00836182, ..., 0.0133667,\n",
       "             -0.00601196, 0.00872803],\n",
       "            ...,\n",
       "            [-0.00283813, -0.00297546, 0.0130005, ..., -0.0213623,\n",
       "             -0.0117798, 0.00325012],\n",
       "            [0.0180664, -0.00158691, -0.00201416, ..., -0.0101318,\n",
       "             -0.00463867, 0.0037384],\n",
       "            [-0.00337219, -0.00744629, -0.0187988, ..., -0.00872803,\n",
       "             0.00288391, -0.0012207]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0185547, -0.0125122, -0.012085, ..., 0.00185394, -0.00714111,\n",
       "             -0.0159912],\n",
       "            [-0.00613403, -0.00582886, 0.00601196, ..., 0.00331116,\n",
       "             -0.0112305, -0.0161133],\n",
       "            [0.00689697, 0.0098877, -0.0107422, ..., 0.00285339, -0.0090332,\n",
       "             0.00350952],\n",
       "            ...,\n",
       "            [0.00741577, -0.0178223, 0.00427246, ..., -0.00662231,\n",
       "             0.00753784, -0.012146],\n",
       "            [-0.0197754, -0.00982666, 0.0065918, ..., 0.0163574,\n",
       "             -0.00576782, 0.00723267],\n",
       "            [-0.00582886, 0.019165, -0.000728607, ..., 0.00227356,\n",
       "             0.0113525, 0.0272217]],\n",
       "    \n",
       "           [[0.000717163, -0.00512695, 0.000724792, ..., -0.0159912,\n",
       "             -0.0155029, -0.00958252],\n",
       "            [0.00445557, -0.00250244, -0.00159454, ..., 0.00311279,\n",
       "             -0.00543213, -0.0180664],\n",
       "            [0.000235558, 0.00363159, 0.000339508, ..., 0.0106201,\n",
       "             0.00952148, 0.001091],\n",
       "            ...,\n",
       "            [-0.00244141, -0.00704956, 0.00476074, ..., -0.0534668,\n",
       "             -0.00582886, -0.0228271],\n",
       "            [0.0020752, 0.0124512, -0.00921631, ..., -0.0351562, -0.0495605,\n",
       "             -0.0103149],\n",
       "            [0.00215149, 0.00215149, 0.000904083, ..., 0.0133667,\n",
       "             0.00335693, -0.00108337]],\n",
       "    \n",
       "           [[0.00271606, -0.0090332, 0.0240479, ..., 0.019043, -0.00230408,\n",
       "             -0.0123901],\n",
       "            [-0.00286865, 0.00680542, -0.00144958, ..., 0.0197754,\n",
       "             -0.00276184, -0.00717163],\n",
       "            [0.00769043, 0.00227356, -0.00915527, ..., 0.000222206,\n",
       "             0.000717163, -0.012085],\n",
       "            ...,\n",
       "            [-0.00164795, 0.000495911, 0.0119629, ..., -0.0281982,\n",
       "             -0.0137939, -0.0159912],\n",
       "            [-0.00357056, 0.0178223, -0.00442505, ..., -0.00056076,\n",
       "             -0.00878906, -0.0184326],\n",
       "            [-0.00411987, 0.00123596, -0.00259399, ..., -0.000724792,\n",
       "             0.00958252, 0.0164795]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.0139771, 0.0163574, 0.0174561, ..., -0.00169373, 0.00854492,\n",
       "            -0.0071106],\n",
       "           [-0.00231934, -0.0141602, 0.00576782, ..., -0.00494385,\n",
       "            -0.010437, 0.00291443],\n",
       "           [-0.00075531, 0.00628662, 0.0078125, ..., 0.000728607,\n",
       "            0.00117493, 0.0101318],\n",
       "           ...,\n",
       "           [0.0114746, -0.00521851, 0.000671387, ..., -0.00726318,\n",
       "            -0.00830078, -0.0019455],\n",
       "           [-0.00778198, 0.00527954, 0.0174561, ..., 0.00139618,\n",
       "            -0.0166016, -0.00897217],\n",
       "           [-0.00543213, -0.0240479, -0.00119781, ..., -0.00897217,\n",
       "            -0.0136719, -0.00482178]],\n",
       "   \n",
       "          [[1.57356e-05, -0.0124512, 0.010498, ..., 0.00263977, 0.00396729,\n",
       "            -0.0078125],\n",
       "           [-0.00610352, -0.00257874, -0.00267029, ..., 0.00823975,\n",
       "            0.00732422, 0.00619507],\n",
       "           [-0.00122833, -0.00509644, -0.00726318, ..., -0.0112305,\n",
       "            0.00332642, 0.013916],\n",
       "           ...,\n",
       "           [-0.0098877, -0.00463867, -0.000675201, ..., -0.0055542,\n",
       "            -0.015564, 0.00616455],\n",
       "           [0.000265121, -0.00506592, -0.00549316, ..., 0.00738525,\n",
       "            -0.00300598, 0.000930786],\n",
       "           [4.12464e-05, -0.000762939, -0.00276184, ..., -0.0153198,\n",
       "            0.00215149, 0.00515747]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.00463867, 0.00128174, 0.00817871, ..., 0.00216675, 0.0055542,\n",
       "           0.00386047],\n",
       "          [-0.00854492, -0.00830078, -0.00212097, ..., -0.00860596,\n",
       "           -0.00668335, 0.00466919],\n",
       "          [0.0016861, -0.0114136, 0.00842285, ..., -0.00976562, -0.00537109,\n",
       "           0.00144958],\n",
       "          ...,\n",
       "          [-0.00927734, 0.0125732, -0.0014267, ..., -0.00454712, 0.00576782,\n",
       "           -0.00405884],\n",
       "          [-0.00521851, 0.0011673, -0.00460815, ..., 0.00318909, 0.00248718,\n",
       "           -0.00146484],\n",
       "          [-0.0196533, 0.00497437, 0.00393677, ..., -0.00262451,\n",
       "           -0.00927734, 0.00732422]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([-0.507812, -0.46875, -0.466797, ..., -0.503906, 0.102539,\n",
       "          -0.498047], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([-0.0354004, 0.0598145, 0.043457, ..., -0.202148, 0.308594,\n",
       "          0.113281], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.648438, 0.589844, 0.640625, ..., 1.27344, 0.229492, 0.5625],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.498047, 0.570312, 0.535156, ..., 1.22656, 0.361328, 0.462891],      dtype=bfloat16)}},\n",
       " 'layer_10': {'attn': {'attn_vec_einsum': {'w': Array([[[0.00695801, -0.00424194, 0.000801086, ..., 0.015625,\n",
       "             0.00854492, 0.0179443],\n",
       "            [-0.0110474, -0.00460815, 0.00842285, ..., -0.00708008,\n",
       "             0.0187988, -0.0118408],\n",
       "            [0.0228271, 0.0130005, 0.0062561, ..., 0.000766754, 0.0027771,\n",
       "             -0.00372314],\n",
       "            ...,\n",
       "            [0.00772095, 0.0185547, -0.00872803, ..., 0.0100098, 0.00860596,\n",
       "             0.00500488],\n",
       "            [0.0100708, 0.00439453, 0.0123291, ..., 0.00958252, 0.00656128,\n",
       "             -0.0133057],\n",
       "            [0.00732422, 0.0090332, 0.0167236, ..., 0.00343323, 0.0111694,\n",
       "             -0.00653076]],\n",
       "    \n",
       "           [[-0.000923157, -0.00344849, -0.00476074, ..., 0.0111694,\n",
       "             -0.0140381, -0.0224609],\n",
       "            [0.0256348, 0.0132446, 0.00668335, ..., 0.00488281, 0.0103149,\n",
       "             -0.0144653],\n",
       "            [0.00337219, -0.0115967, -0.029541, ..., -0.00634766,\n",
       "             -0.00418091, 0.00292969],\n",
       "            ...,\n",
       "            [-0.0143433, -0.00698853, -0.00872803, ..., -0.0098877,\n",
       "             -0.0327148, 0.0142212],\n",
       "            [-0.00364685, 0.00585938, 0.00686646, ..., 0.00221252,\n",
       "             0.00842285, 0.00897217],\n",
       "            [-0.0262451, -0.0274658, 0.00500488, ..., -0.00872803,\n",
       "             -0.015625, 0.000396729]],\n",
       "    \n",
       "           [[-0.0245361, -0.00127411, -0.00680542, ..., -0.00424194,\n",
       "             0.000900269, -0.00370789],\n",
       "            [-0.0057373, -0.00273132, -0.00178528, ..., 0.0106812,\n",
       "             0.0137939, 0.00860596],\n",
       "            [0.0124512, 0.00610352, 0.0090332, ..., -0.00257874, 0.00390625,\n",
       "             -0.00393677],\n",
       "            ...,\n",
       "            [-0.00463867, -0.0180664, -0.0108643, ..., 0.0162354,\n",
       "             -0.0130615, 0.00952148],\n",
       "            [0.00482178, 0.0245361, -0.0180664, ..., 0.027832, -0.0217285,\n",
       "             -0.0202637],\n",
       "            [0.00118256, -0.000305176, 0.00315857, ..., -0.00442505,\n",
       "             0.0170898, 0.00164795]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00622559, 0.00775146, 0.0043335, ..., -0.0152588, 0.0032196,\n",
       "             0.00643921],\n",
       "            [-0.00224304, 0.0122681, 0.00650024, ..., -0.0212402,\n",
       "             -0.00488281, -0.0078125],\n",
       "            [0.0114746, -0.0148315, -0.00909424, ..., 0.00805664,\n",
       "             0.000831604, -0.00909424],\n",
       "            ...,\n",
       "            [-0.00582886, 0.00213623, 0.0090332, ..., -0.00143433,\n",
       "             0.00241089, 0.00288391],\n",
       "            [0.00448608, -0.000545502, -0.00312805, ..., 0.00424194,\n",
       "             -0.00460815, 0.0142212],\n",
       "            [-0.000389099, 0.0195312, -0.00518799, ..., 0.00390625,\n",
       "             -0.00823975, 0.0306396]],\n",
       "    \n",
       "           [[-0.00646973, -0.000934601, -0.000629425, ..., -0.00427246,\n",
       "             -0.00576782, -0.0170898],\n",
       "            [-0.00107574, -0.00518799, 0.00242615, ..., -0.0161133,\n",
       "             0.0126953, -0.000610352],\n",
       "            [-0.019165, -0.0169678, -7.82013e-05, ..., -0.00396729,\n",
       "             -0.00379944, 0.00485229],\n",
       "            ...,\n",
       "            [0.0174561, 0.00695801, 0.00500488, ..., 0.00276184, -0.0137939,\n",
       "             -0.00982666],\n",
       "            [-0.0030365, -0.000789642, 0.00180817, ..., 0.0177002,\n",
       "             0.00897217, -0.00958252],\n",
       "            [0.00701904, 0.00521851, 0.0136108, ..., 0.0106812, -0.00830078,\n",
       "             -0.00665283]],\n",
       "    \n",
       "           [[-0.00595093, -0.00294495, -0.00613403, ..., -0.00448608,\n",
       "             -0.00250244, -0.0112915],\n",
       "            [-0.00231934, -0.010376, -0.0111084, ..., -0.00430298,\n",
       "             0.0194092, 0.00309753],\n",
       "            [-0.00769043, 0.00540161, 0.00370789, ..., -0.0134277,\n",
       "             0.0132446, 0.0108032],\n",
       "            ...,\n",
       "            [0.0106812, -0.00124359, -0.00564575, ..., 0.0145874,\n",
       "             -0.0172119, -0.0229492],\n",
       "            [-0.0167236, -0.00326538, -0.0106812, ..., 0.00488281,\n",
       "             0.0078125, 0.0201416],\n",
       "            [-0.0142212, -0.00488281, -0.0128174, ..., -0.0122681,\n",
       "             0.0134888, 0.0109253]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.000888824, -0.00115204, -0.000119209, ..., -0.00598145,\n",
       "              -0.00704956, 0.0197754],\n",
       "             [-0.00139618, 0.0198975, -0.00424194, ..., -0.00946045,\n",
       "              -0.00634766, 0.00515747],\n",
       "             [0.00215149, -0.000652313, 0.00964355, ..., 0.0142822,\n",
       "              -0.000282288, 0.00376892],\n",
       "             ...,\n",
       "             [0.00561523, -0.00582886, 0.00585938, ..., -0.00387573,\n",
       "              0.00805664, 0.00720215],\n",
       "             [-3.3617e-05, -0.00149536, -0.0098877, ..., 0.00952148,\n",
       "              0.00982666, -0.0148315],\n",
       "             [0.00927734, 0.0018692, -0.00598145, ..., -0.00402832,\n",
       "              -0.00405884, 0.00306702]],\n",
       "    \n",
       "            [[-0.00250244, 0.00183868, 0.000999451, ..., 0.0185547,\n",
       "              -0.0132446, 0.00564575],\n",
       "             [-0.00579834, 0.0150146, -0.0102539, ..., 0.0148926,\n",
       "              0.0184326, 0.0109863],\n",
       "             [-0.00346375, -0.00491333, -0.0148315, ..., 0.00216675,\n",
       "              0.0159912, 0.0118408],\n",
       "             ...,\n",
       "             [0.0106812, -0.00173187, -0.0045166, ..., 0.0114746,\n",
       "              -0.0281982, 0.00622559],\n",
       "             [0.00215149, -0.0157471, 0.0111084, ..., 0.000747681,\n",
       "              -0.000208855, 0.0183105],\n",
       "             [0.012207, -0.000537872, -0.0122681, ..., -0.019043,\n",
       "              -0.0088501, 0.00274658]],\n",
       "    \n",
       "            [[-0.00680542, -0.000667572, 0.00147247, ..., 0.0233154,\n",
       "              -0.0105591, -0.0136108],\n",
       "             [0.00102997, -0.000371933, -0.000156403, ..., -0.00671387,\n",
       "              -0.012207, -0.00579834],\n",
       "             [-0.00174713, 0.00285339, -0.0109863, ..., 0.00173187,\n",
       "              -0.0030365, -0.00588989],\n",
       "             ...,\n",
       "             [0.00588989, 0.00421143, -0.00695801, ..., -0.0220947,\n",
       "              0.00692749, -0.00209045],\n",
       "             [-0.00148773, -0.00680542, 0.00331116, ..., -0.0174561,\n",
       "              -0.0128174, 0.00595093],\n",
       "             [-0.00497437, 0.00405884, -0.00349426, ..., 0.00958252,\n",
       "              0.000218391, -2.31266e-05]],\n",
       "    \n",
       "            [[-0.00592041, -0.00367737, -0.00209045, ..., 0.0373535,\n",
       "              -0.0126953, 0.0240479],\n",
       "             [-0.00389099, -0.0015564, 0.00177765, ..., -0.006073,\n",
       "              0.00102234, 0.0222168],\n",
       "             [0.00753784, 0.00314331, -0.00708008, ..., 0.0163574,\n",
       "              -0.0129395, -0.00823975],\n",
       "             ...,\n",
       "             [-0.0108643, 0.00601196, 0.00283813, ..., 0.0120239,\n",
       "              -0.0228271, 0.0361328],\n",
       "             [0.00291443, -0.00253296, 0.00561523, ..., 0.0279541,\n",
       "              0.0147095, -0.022583],\n",
       "             [-0.0102539, -0.00582886, -0.0172119, ..., 0.00393677,\n",
       "              0.00463867, 0.0118408]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00241089, -0.0262451, -0.00878906, ..., 0.00750732,\n",
       "              -0.00376892, 0.0220947],\n",
       "             [-0.00102997, 0.00338745, 0.00891113, ..., 0.000117302,\n",
       "              -0.00540161, 0.0185547],\n",
       "             [0.00708008, -0.00567627, 0.0354004, ..., -0.00588989,\n",
       "              -0.00830078, -0.0214844],\n",
       "             ...,\n",
       "             [-0.00848389, 0.000541687, 0.0332031, ..., 0.00982666,\n",
       "              -0.00376892, 0.0187988],\n",
       "             [0.0133057, 0.00769043, -0.0214844, ..., 0.0184326, 0.0019989,\n",
       "              0.00854492],\n",
       "             [0.0272217, 0.0114746, -0.00708008, ..., -0.0219727,\n",
       "              0.0090332, -0.00872803]],\n",
       "    \n",
       "            [[0.00775146, -0.00241089, -0.00799561, ..., 0.0116577,\n",
       "              0.00442505, -0.0209961],\n",
       "             [-0.0224609, 0.00732422, 1.50204e-05, ..., -0.0170898,\n",
       "              0.0184326, 0.0247803],\n",
       "             [0.00610352, 0.0100098, 0.0297852, ..., 0.0178223, 0.00811768,\n",
       "              0.00976562],\n",
       "             ...,\n",
       "             [0.0159912, -0.00683594, -0.00909424, ..., 0.00454712,\n",
       "              0.00817871, 0.0078125],\n",
       "             [-0.00361633, 0.00576782, -0.00159454, ..., -0.0222168,\n",
       "              -0.0212402, -0.0147705],\n",
       "             [-0.000720978, -0.00509644, -0.00283813, ..., -0.00500488,\n",
       "              -0.00263977, 0.00726318]],\n",
       "    \n",
       "            [[0.00732422, -0.00195312, 0.00349426, ..., 0.0140381,\n",
       "              0.000766754, -0.0158691],\n",
       "             [0.00854492, 0.00396729, 0.00689697, ..., 0.00228882,\n",
       "              -0.00309753, -0.00178528],\n",
       "             [0.0168457, 0.02771, -0.00346375, ..., -0.00171661,\n",
       "              -0.0211182, -0.00805664],\n",
       "             ...,\n",
       "             [0.0272217, -0.0118408, 0.010498, ..., 0.000434875,\n",
       "              0.00190735, 0.00564575],\n",
       "             [-0.0039978, 0.0106812, -0.00402832, ..., 0.00209045,\n",
       "              -0.0168457, -0.00178528],\n",
       "             [-0.0098877, -0.0246582, -0.0354004, ..., -0.0206299,\n",
       "              0.00897217, 0.0172119]],\n",
       "    \n",
       "            [[-0.0136108, 0.00723267, -0.0159912, ..., -4.43459e-05,\n",
       "              -1.2219e-05, 0.00527954],\n",
       "             [-0.0134277, 0.0050354, 0.0151367, ..., 0.0212402,\n",
       "              -0.00320435, -0.0170898],\n",
       "             [0.0114746, -0.00674438, 0.00457764, ..., -0.00137329,\n",
       "              -0.00848389, -0.00170135],\n",
       "             ...,\n",
       "             [-0.00038147, -0.00759888, -0.00570679, ..., 0.00288391,\n",
       "              -0.010498, 0.00247192],\n",
       "             [0.00836182, 0.0119019, 0.012207, ..., -0.00982666,\n",
       "              0.00107574, -0.00738525],\n",
       "             [0.00234985, 0.00878906, 0.000202179, ..., 0.00540161,\n",
       "              0.00753784, -0.0129395]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.0137329, 0.0100708, -0.00680542, ..., -0.0101929, 0.00154114,\n",
       "             -0.00592041],\n",
       "            [-0.000583649, 0.0131836, -0.00335693, ..., 0.0147705,\n",
       "             0.00411987, 0.00376892],\n",
       "            [0.00830078, -0.0103149, -0.00598145, ..., -0.0155029,\n",
       "             -0.00616455, -0.00817871],\n",
       "            ...,\n",
       "            [0.0109253, -0.000679016, -0.0152588, ..., -0.000354767,\n",
       "             -0.0145874, 0.00390625],\n",
       "            [-0.00387573, -0.00141907, 0.00161743, ..., -0.001091,\n",
       "             -0.015625, 0.0100098],\n",
       "            [-0.00259399, 0.00230408, 0.00427246, ..., -0.000469208,\n",
       "             -0.00866699, -0.00439453]],\n",
       "    \n",
       "           [[0.00933838, 0.00170898, 9.05991e-05, ..., 0.0100098,\n",
       "             0.00747681, 0.0116577],\n",
       "            [0.00848389, 0.00732422, -0.00720215, ..., 0.00262451,\n",
       "             -0.0186768, 0.0067749],\n",
       "            [-0.00254822, 0.00527954, 0.00218201, ..., 0.020874, 0.00265503,\n",
       "             0.0065918],\n",
       "            ...,\n",
       "            [-0.0043335, -0.000183105, 0.00759888, ..., -0.00405884,\n",
       "             -3.30806e-06, -0.00448608],\n",
       "            [0.013916, -0.00209045, -0.00448608, ..., 0.00927734,\n",
       "             0.00241089, 0.0113525],\n",
       "            [-0.00393677, -0.00376892, 0.00576782, ..., -0.000740051,\n",
       "             0.00817871, 0.00823975]],\n",
       "    \n",
       "           [[0.0057373, 0.0240479, 0.0174561, ..., -0.0125732, -0.00302124,\n",
       "             -0.0115356],\n",
       "            [-0.0100708, -0.000305176, 0.00518799, ..., 0.00585938,\n",
       "             -0.00662231, 0.00221252],\n",
       "            [-0.00248718, 0.0161133, 0.000222206, ..., 0.000610352,\n",
       "             0.000530243, -0.00131989],\n",
       "            ...,\n",
       "            [0.00138855, -0.00291443, -0.00546265, ..., 0.00250244,\n",
       "             0.017334, -0.0032196],\n",
       "            [0.032959, -0.00692749, -0.0022583, ..., 0.0218506, -0.00692749,\n",
       "             -0.00154114],\n",
       "            [-0.0163574, 0.00408936, -0.00811768, ..., -0.0136719,\n",
       "             0.000583649, -0.0114746]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00723267, 0.000976562, -0.00463867, ..., 0.00610352,\n",
       "             -0.00259399, -0.024292],\n",
       "            [0.0030365, 0.00405884, -0.0112305, ..., 0.00610352, -0.0336914,\n",
       "             -0.0354004],\n",
       "            [-0.00231934, 0.000267029, -0.00344849, ..., 0.00946045,\n",
       "             -0.0120239, -0.00300598],\n",
       "            ...,\n",
       "            [-0.00128174, -0.00604248, -0.00579834, ..., 0.0020752,\n",
       "             -0.00056839, -0.0344238],\n",
       "            [-0.0057373, 0.00221252, -0.00408936, ..., 0.0180664, -0.032959,\n",
       "             0.000202179],\n",
       "            [0.00915527, -0.00769043, -0.00149536, ..., -0.0111084,\n",
       "             -0.00196838, -0.0110474]],\n",
       "    \n",
       "           [[0.0106201, -0.000976562, 0.00958252, ..., 0.00732422,\n",
       "             -0.00848389, 0.0103149],\n",
       "            [-0.00744629, 0.000915527, -0.00775146, ..., 0.0154419,\n",
       "             0.00759888, 0.0395508],\n",
       "            [-0.000602722, -0.00506592, 0.00427246, ..., -0.000242233,\n",
       "             0.0162354, 0.0245361],\n",
       "            ...,\n",
       "            [-0.00421143, 0.00750732, 0.00616455, ..., 0.03125, -0.00515747,\n",
       "             0.00121307],\n",
       "            [-0.00128174, 0.00643921, 0.00157928, ..., 0.00811768,\n",
       "             0.0123291, -0.0332031],\n",
       "            [0.00138092, -0.00387573, -0.00262451, ..., 0.00341797,\n",
       "             0.034668, -0.0349121]],\n",
       "    \n",
       "           [[0.00314331, -0.00454712, 0.00147247, ..., 0.0120239, -0.020752,\n",
       "             -0.0111694],\n",
       "            [0.0258789, -0.0181885, -0.0090332, ..., 0.0123291, -0.017334,\n",
       "             0.0214844],\n",
       "            [0.00439453, -0.00408936, -0.00291443, ..., 0.0103149,\n",
       "             -0.0101929, -0.00178528],\n",
       "            ...,\n",
       "            [0.00469971, 0.00753784, 0.0175781, ..., 0.0202637, 0.00421143,\n",
       "             0.0230713],\n",
       "            [-0.0235596, 0.00141907, 0.0131226, ..., 0.0137939, -0.00153351,\n",
       "             -0.0167236],\n",
       "            [0.00616455, 0.0177002, 0.0111084, ..., -0.0219727, -0.00354004,\n",
       "             -0.0117798]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00218201, 0.00506592, -0.00318909, ..., 0.0202637,\n",
       "            0.00619507, 0.010376],\n",
       "           [-0.00244141, 0.00582886, 0.00346375, ..., -0.000448227,\n",
       "            0.00137329, -0.0037384],\n",
       "           [-0.0022583, -0.00604248, -0.00805664, ..., 0.0140991,\n",
       "            0.000572205, -0.0071106],\n",
       "           ...,\n",
       "           [-0.0155029, -0.0098877, -1.42306e-06, ..., -0.00787354,\n",
       "            -0.00848389, -0.00393677],\n",
       "           [0.00248718, -0.00512695, 0.0114136, ..., 0.00592041,\n",
       "            -0.00283813, -0.00646973],\n",
       "           [-0.00364685, 0.0101318, 0.0057373, ..., 0.00601196,\n",
       "            -0.00062561, -0.00466919]],\n",
       "   \n",
       "          [[0.0136108, -0.00836182, 0.00720215, ..., -0.00811768,\n",
       "            0.0100708, -0.00167084],\n",
       "           [-0.00643921, -0.00262451, -0.00138855, ..., -0.00260925,\n",
       "            -0.0019455, 0.0130615],\n",
       "           [0.00735474, 0.00454712, 0.00595093, ..., 0.00579834,\n",
       "            0.00527954, -0.00491333],\n",
       "           ...,\n",
       "           [-0.00454712, 0.0144043, 0.00221252, ..., -0.0020752, 0.0105591,\n",
       "            -0.00592041],\n",
       "           [-0.0100708, -0.00717163, 0.010376, ..., 0.00112152, 0.0032196,\n",
       "            0.00270081],\n",
       "           [0.00445557, 0.00842285, -0.0100098, ..., -0.0090332,\n",
       "            0.00744629, 0.0139771]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.0102539, 0.0057373, -0.00534058, ..., 0.0134277, 0.00075531,\n",
       "           0.00314331],\n",
       "          [1.01924e-05, 0.0125732, -0.00222778, ..., -0.00314331,\n",
       "           -0.00213623, 0.0057373],\n",
       "          [0.00482178, -0.0131836, 0.000274658, ..., 0.00952148, 0.00640869,\n",
       "           -0.00909424],\n",
       "          ...,\n",
       "          [-0.00463867, -0.0183105, 0.00750732, ..., 0.00221252, 0.0090332,\n",
       "           -0.0150146],\n",
       "          [0.00631714, -0.00842285, 0.00151825, ..., 0.0027771, 0.000957489,\n",
       "           -0.00196838],\n",
       "          [-0.0111694, 0.0111084, 0.00415039, ..., -0.00241089, -2.2769e-05,\n",
       "           0.00497437]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.244141, 0.330078, 0.421875, ..., 0.183594, 0.165039, 0.129883],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.496094, 0.535156, 0.570312, ..., 0.429688, 0.511719, 0.371094],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.699219, 0.773438, 0.65625, ..., 0.820312, 0.0186768, 0.671875],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.12793, 0.229492, 0.152344, ..., 0.227539, -0.212891, 0.125977],      dtype=bfloat16)}},\n",
       " 'layer_11': {'attn': {'attn_vec_einsum': {'w': Array([[[0.0011673, -0.0067749, -0.00610352, ..., 0.0169678, -0.0100098,\n",
       "             0.0117188],\n",
       "            [0.0145874, -0.00564575, -0.0162354, ..., -0.0152588,\n",
       "             0.00692749, 0.0102539],\n",
       "            [-0.0109863, -0.00247192, -0.0133057, ..., 0.00268555,\n",
       "             0.00598145, -0.00787354],\n",
       "            ...,\n",
       "            [0.0275879, -0.000671387, -0.0110474, ..., -0.0108643,\n",
       "             -0.0098877, 0.0137939],\n",
       "            [0.0100708, 0.0010376, -0.00230408, ..., 0.00267029, 0.00460815,\n",
       "             -0.00653076],\n",
       "            [0.00588989, 0.0012207, 0.010376, ..., 0.00439453, 0.00613403,\n",
       "             0.0114746]],\n",
       "    \n",
       "           [[-0.0151367, 0.00233459, -0.0105591, ..., 0.000762939,\n",
       "             -0.00720215, 0.0201416],\n",
       "            [-0.0126343, 0.0133667, -0.0169678, ..., 0.00436401, 0.00325012,\n",
       "             0.00848389],\n",
       "            [0.00509644, -0.0043335, 0.0269775, ..., 0.00509644, 0.00540161,\n",
       "             0.00164795],\n",
       "            ...,\n",
       "            [0.00756836, 0.012207, -0.0133057, ..., -0.000736237,\n",
       "             -0.00976562, -0.00750732],\n",
       "            [-0.0101318, 0.00363159, -0.0219727, ..., -0.0179443,\n",
       "             0.00946045, 0.0238037],\n",
       "            [-0.00872803, 0.0186768, 0.0114136, ..., -0.0354004,\n",
       "             -0.000720978, 0.00338745]],\n",
       "    \n",
       "           [[-0.00063324, -0.0170898, 0.00616455, ..., -0.0142822,\n",
       "             0.0004673, -0.00335693],\n",
       "            [0.0149536, 0.00564575, -0.00375366, ..., 0.0144653, 0.00546265,\n",
       "             -0.00772095],\n",
       "            [-0.00476074, -0.00933838, 0.0157471, ..., 0.0103149, 0.0107422,\n",
       "             0.0169678],\n",
       "            ...,\n",
       "            [-0.00357056, 0.00354004, -0.000579834, ..., 0.00631714,\n",
       "             0.00952148, 0.0098877],\n",
       "            [-0.00552368, -0.00212097, 0.00466919, ..., 0.00289917,\n",
       "             0.00138855, 0.000522614],\n",
       "            [0.0111084, 0.000406265, 0.00370789, ..., 0.00265503,\n",
       "             0.00173187, 0.00653076]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00708008, 0.0113525, -0.0205078, ..., 0.000201225,\n",
       "             0.0201416, -0.00540161],\n",
       "            [0.0037384, 0.00094986, 0.0131836, ..., -0.00424194, 0.015625,\n",
       "             -0.00848389],\n",
       "            [-0.00897217, -0.00297546, 0.00421143, ..., -0.00704956,\n",
       "             0.00254822, -0.00769043],\n",
       "            ...,\n",
       "            [0.0014801, -0.0170898, -0.00411987, ..., 0.00933838,\n",
       "             0.00726318, 0.00043869],\n",
       "            [0.0116577, 0.00224304, 0.0151978, ..., 0.00209045, 0.0161133,\n",
       "             -0.00970459],\n",
       "            [-0.00315857, 0.0124512, -0.00515747, ..., 0.00227356,\n",
       "             -0.0146484, 0.00201416]],\n",
       "    \n",
       "           [[-0.0128784, 0.000854492, 0.00188446, ..., -0.0045166,\n",
       "             -0.00288391, 0.0115356],\n",
       "            [-0.0101929, -0.00521851, -0.00167847, ..., 0.00714111,\n",
       "             0.0115356, -0.0164795],\n",
       "            [0.00866699, -0.00424194, -0.00314331, ..., -0.00117493,\n",
       "             0.00549316, -0.0107422],\n",
       "            ...,\n",
       "            [-0.015625, 0.00772095, 9.25064e-05, ..., -0.00854492,\n",
       "             0.000720978, -0.00668335],\n",
       "            [-0.0213623, -0.00352478, 0.0129395, ..., -0.00964355,\n",
       "             -0.00793457, -0.00787354],\n",
       "            [-0.0198975, 0.00830078, -0.00245667, ..., -0.00646973,\n",
       "             0.00015831, -0.0164795]],\n",
       "    \n",
       "           [[0.000434875, -0.000946045, -0.00209045, ..., -0.0114746,\n",
       "             -0.0113525, -0.00698853],\n",
       "            [0.0108032, -0.0169678, 0.006073, ..., 0.0129395, 0.00297546,\n",
       "             0.00897217],\n",
       "            [0.00202942, 0.0112305, -0.000598907, ..., -0.00601196,\n",
       "             -0.0195312, -0.00253296],\n",
       "            ...,\n",
       "            [0.0145874, 0.000534058, 0.0178223, ..., 0.0107422, 0.0100708,\n",
       "             0.0192871],\n",
       "            [-0.00762939, 0.00430298, 0.00756836, ..., -0.00241089,\n",
       "             -0.0268555, 0.0142212],\n",
       "            [0.0071106, 0.00140381, 0.000144958, ..., -0.00668335,\n",
       "             0.00643921, 0.000705719]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.00527954, -0.0098877, -0.0153809, ..., 0.00271606,\n",
       "              0.00152588, -0.00772095],\n",
       "             [0.00215149, -0.00830078, 0.00683594, ..., -0.00527954,\n",
       "              0.0202637, 0.00567627],\n",
       "             [-0.00964355, 0.00689697, 0.00286865, ..., 0.012146,\n",
       "              -0.0157471, -0.00769043],\n",
       "             ...,\n",
       "             [0.00318909, 0.000247955, 0.00897217, ..., -0.0429688,\n",
       "              0.00564575, -7.53403e-05],\n",
       "             [-0.0071106, -0.00253296, 0.00515747, ..., -0.0134277,\n",
       "              0.0196533, 0.0109253],\n",
       "             [0.00521851, -0.0159912, 0.00112152, ..., -0.000356674,\n",
       "              -0.0142822, 0.000455856]],\n",
       "    \n",
       "            [[0.00296021, 0.000417709, 0.00402832, ..., -0.00427246,\n",
       "              -0.0088501, 0.00297546],\n",
       "             [0.00247192, -0.00302124, 0.000368118, ..., -0.00393677,\n",
       "              -0.00485229, 0.00811768],\n",
       "             [0.00157166, -0.00799561, 0.00408936, ..., -0.00141144,\n",
       "              -0.00442505, 0.0279541],\n",
       "             ...,\n",
       "             [0.00087738, -0.00370789, 0.00640869, ..., 0.00479126,\n",
       "              0.000518799, -0.019165],\n",
       "             [-0.00218201, -0.00405884, -0.0133057, ..., 0.00521851,\n",
       "              -0.00445557, -0.00634766],\n",
       "             [-0.00634766, 0.000486374, -0.00213623, ..., -0.0098877,\n",
       "              -0.0224609, -0.0130005]],\n",
       "    \n",
       "            [[-0.0014267, 0.00744629, 0.00389099, ..., -0.00976562,\n",
       "              0.0105591, -0.0132446],\n",
       "             [0.000169754, 0.00245667, 0.00312805, ..., 0.00331116,\n",
       "              0.000366211, -0.00854492],\n",
       "             [-0.0130005, -0.00769043, -0.00340271, ..., -0.000606537,\n",
       "              -0.0131226, 0.0133667],\n",
       "             ...,\n",
       "             [-0.013855, 0.00158691, -0.00376892, ..., 0.00970459,\n",
       "              -0.00326538, -0.00402832],\n",
       "             [-0.0166016, -0.00375366, -0.013855, ..., -0.00683594,\n",
       "              -0.00704956, -0.00640869],\n",
       "             [0.00958252, -0.00830078, 0.0230713, ..., -0.0108643,\n",
       "              -0.0147705, -0.0194092]],\n",
       "    \n",
       "            [[-0.00352478, -0.000984192, -0.000356674, ..., 0.0108643,\n",
       "              -0.0230713, 0.00756836],\n",
       "             [0.000827789, 0.00561523, 0.00393677, ..., -0.0549316,\n",
       "              -0.00315857, 0.00439453],\n",
       "             [-0.00131226, 0.00567627, -0.00653076, ..., -0.0170898,\n",
       "              0.015625, -0.0170898],\n",
       "             ...,\n",
       "             [0.00289917, -0.0115967, -0.00352478, ..., 0.0166016,\n",
       "              0.0137329, 0.00396729],\n",
       "             [-0.0137329, 0.00263977, 0.0043335, ..., -0.0349121,\n",
       "              -0.0373535, 0.0201416],\n",
       "             [-0.00170898, -0.000427246, -0.0013504, ..., -0.0236816,\n",
       "              0.00282288, 0.0055542]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00897217, -0.0170898, -0.000888824, ..., 0.00170898,\n",
       "              -0.0119019, 0.0174561],\n",
       "             [0.0101929, -0.00174713, 0.0114746, ..., 0.00674438,\n",
       "              0.00445557, 0.0128784],\n",
       "             [-0.0038147, 0.0189209, 0.019043, ..., 0.00588989,\n",
       "              -0.00485229, -0.000919342],\n",
       "             ...,\n",
       "             [-0.000175476, -0.00646973, 0.00726318, ..., -0.00248718,\n",
       "              0.00506592, -0.0249023],\n",
       "             [-0.00582886, -0.00860596, -0.00854492, ..., 0.00375366,\n",
       "              -0.0144653, 0.00382996],\n",
       "             [0.0203857, -0.0299072, 0.0322266, ..., -0.00382996,\n",
       "              -0.00473022, 0.0213623]],\n",
       "    \n",
       "            [[0.0115356, 0.0151978, 0.0035553, ..., -0.00628662, 0.0150146,\n",
       "              0.00613403],\n",
       "             [0.00909424, -0.00221252, 0.0101929, ..., -0.010376,\n",
       "              0.00230408, -0.00628662],\n",
       "             [0.0108032, 0.0227051, 0.00592041, ..., 0.00120544,\n",
       "              -0.0181885, -0.000579834],\n",
       "             ...,\n",
       "             [-0.00537109, -0.00540161, 0.0105591, ..., 0.00582886,\n",
       "              0.0118408, 0.00114441],\n",
       "             [-0.000705719, 0.00185394, 0.0222168, ..., -0.00592041,\n",
       "              -0.00421143, -0.0136108],\n",
       "             [-0.00497437, -0.0098877, 0.00946045, ..., -0.00271606,\n",
       "              0.0105591, 0.0108643]],\n",
       "    \n",
       "            [[0.00650024, 0.0139771, -0.0115967, ..., 0.012146, 0.0213623,\n",
       "              -0.0159912],\n",
       "             [0.0270996, -0.0106812, -0.00762939, ..., -0.0262451,\n",
       "              -0.00994873, 0.00735474],\n",
       "             [-0.0239258, 0.00686646, 0.0238037, ..., -0.015564, 0.0209961,\n",
       "              -0.0140991],\n",
       "             ...,\n",
       "             [-0.00285339, -0.0122681, -0.00604248, ..., -0.000541687,\n",
       "              -0.0098877, 0.00430298],\n",
       "             [0.00430298, 0.0220947, -0.000368118, ..., -0.0296631,\n",
       "              0.00683594, -0.0039978],\n",
       "             [0.0120239, -0.020874, -0.0129395, ..., -0.00878906,\n",
       "              -0.0217285, -0.0131836]],\n",
       "    \n",
       "            [[-0.000991821, -0.00872803, 0.0133057, ..., -0.00698853,\n",
       "              -0.0306396, -0.0124512],\n",
       "             [0.0090332, -0.00276184, 0.0110474, ..., 0.010376,\n",
       "              -0.00224304, 0.000134468],\n",
       "             [-0.000968933, -0.0071106, -0.000621796, ..., -0.00138855,\n",
       "              0.00671387, 0.00628662],\n",
       "             ...,\n",
       "             [-0.0157471, 0.0183105, 0.012207, ..., -0.0219727, 0.00241089,\n",
       "              -0.00448608],\n",
       "             [0.00270081, -0.0213623, 0.00297546, ..., -0.0168457,\n",
       "              -0.013916, 0.00854492],\n",
       "             [-0.00102234, 0.00164795, 0.000843048, ..., 0.0264893,\n",
       "              -0.0255127, 0.0130615]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00720215, 0.00402832, -0.00344849, ..., -0.0120239,\n",
       "             0.00436401, 0.0136108],\n",
       "            [-0.00476074, -0.00328064, -0.0050354, ..., -0.0107422,\n",
       "             0.0122681, -0.00233459],\n",
       "            [-0.00735474, -0.00799561, -0.00482178, ..., 0.00741577,\n",
       "             -0.00701904, 0.00236511],\n",
       "            ...,\n",
       "            [-0.0030365, -0.000530243, 0.0043335, ..., -0.0252686,\n",
       "             -0.019165, -0.017334],\n",
       "            [-0.00262451, 0.00909424, 0.00317383, ..., -0.00927734,\n",
       "             -0.0227051, 0.00738525],\n",
       "            [-0.010498, 0.00358582, -0.00227356, ..., -0.0240479, 0.0205078,\n",
       "             0.000444412]],\n",
       "    \n",
       "           [[0.00491333, -0.00405884, 0.00692749, ..., -0.0038147,\n",
       "             0.00138092, 0.00372314],\n",
       "            [0.00430298, -0.00909424, -0.0149536, ..., 0.00184631, 0.020874,\n",
       "             0.00585938],\n",
       "            [-0.0101318, 0.00107574, -0.00662231, ..., 0.0186768,\n",
       "             -0.00497437, -0.00509644],\n",
       "            ...,\n",
       "            [0.00482178, 0.0140991, -0.0113525, ..., -0.00279236,\n",
       "             -0.00270081, -0.0045166],\n",
       "            [-0.0113525, -0.00842285, -0.0216064, ..., 0.0155029,\n",
       "             -0.00927734, 0.0256348],\n",
       "            [-0.00415039, 0.00196838, -0.00210571, ..., 0.00469971,\n",
       "             0.019043, 0.0294189]],\n",
       "    \n",
       "           [[-0.000709534, 0.00524902, 0.00442505, ..., -0.0189209,\n",
       "             -0.00683594, 0.000387192],\n",
       "            [0.00933838, 0.0088501, 0.0072937, ..., -0.00619507, 0.00726318,\n",
       "             -0.00169373],\n",
       "            [0.00408936, -0.00518799, 0.00442505, ..., -0.0137329,\n",
       "             0.0146484, 0.00653076],\n",
       "            ...,\n",
       "            [0.00952148, 0.00167847, 0.0192871, ..., -0.00915527,\n",
       "             0.00909424, -0.00309753],\n",
       "            [-0.00601196, -0.0153198, -0.00221252, ..., 0.015564,\n",
       "             0.00418091, 0.00318909],\n",
       "            [0.00430298, 0.010498, 0.00198364, ..., -0.000534058,\n",
       "             0.00604248, 0.00227356]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00346375, -0.0105591, 0.00256348, ..., -0.00457764,\n",
       "             -0.00424194, -0.00683594],\n",
       "            [0.0142212, 0.00823975, -0.000892639, ..., -0.00747681,\n",
       "             -0.0112915, 0.0001688],\n",
       "            [0.00162506, -0.0119629, -0.00239563, ..., 0.0067749,\n",
       "             -0.0153809, -0.00384521],\n",
       "            ...,\n",
       "            [0.000417709, -0.00692749, 0.000587463, ..., -0.0129395,\n",
       "             -0.00570679, 0.0222168],\n",
       "            [-0.000117779, -0.0158691, 0.00408936, ..., 0.00488281,\n",
       "             0.00552368, -0.00799561],\n",
       "            [-0.00326538, 0.0125732, 0.0233154, ..., -0.0228271, 0.00714111,\n",
       "             0.0202637]],\n",
       "    \n",
       "           [[-0.0100708, 0.00125885, -0.00248718, ..., 0.0233154,\n",
       "             -0.0463867, 0.0162354],\n",
       "            [-0.0100708, -0.00349426, -0.00769043, ..., -0.0127563,\n",
       "             0.0196533, 0.00497437],\n",
       "            [-0.000843048, -5.29289e-05, -0.00631714, ..., -0.0177002,\n",
       "             -0.00312805, -0.00741577],\n",
       "            ...,\n",
       "            [0.00982666, 0.00346375, 0.00830078, ..., -0.0366211, 0.0112305,\n",
       "             -0.00817871],\n",
       "            [0.0144653, -0.00357056, 0.00106812, ..., -0.0134277,\n",
       "             -0.0297852, -0.00909424],\n",
       "            [0.006073, 0.00964355, 0.0108032, ..., 0.0228271, 0.00442505,\n",
       "             -0.0291748]],\n",
       "    \n",
       "           [[0.0123901, 0.00723267, -0.00393677, ..., -0.000968933,\n",
       "             -0.00964355, 0.0253906],\n",
       "            [0.00946045, -0.00646973, 0.00506592, ..., -0.0281982,\n",
       "             0.00701904, 0.0111694],\n",
       "            [0.00448608, -0.012085, 0.00518799, ..., -0.0532227, -0.0258789,\n",
       "             -0.00268555],\n",
       "            ...,\n",
       "            [0.00156403, 0.00732422, 0.000583649, ..., 0.00546265, 0.020752,\n",
       "             0.0169678],\n",
       "            [0.013916, -0.000276566, 0.000934601, ..., 0.0219727,\n",
       "             -0.0246582, 0.00762939],\n",
       "            [0.00343323, -0.00337219, -0.00695801, ..., -0.00262451,\n",
       "             0.0179443, -0.0286865]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.0114746, -0.0014267, -0.00331116, ..., -0.00162506,\n",
       "            -0.0117188, 0.00370789],\n",
       "           [0.00326538, 0.00159454, -0.000766754, ..., -0.00460815,\n",
       "            -0.00561523, -9.77516e-06],\n",
       "           [-0.0123291, 0.0072937, -0.00274658, ..., -0.000173569,\n",
       "            0.00113678, -0.00646973],\n",
       "           ...,\n",
       "           [-0.000463486, 0.00427246, -0.0148315, ..., -0.00793457,\n",
       "            0.0151367, -0.0132446],\n",
       "           [-0.00549316, 0.00357056, -0.00915527, ..., 0.00372314,\n",
       "            -0.0471191, -0.001091],\n",
       "           [-0.00357056, -0.00219727, -0.0103149, ..., 9.39369e-05,\n",
       "            -0.00439453, -0.00125885]],\n",
       "   \n",
       "          [[0.0163574, 0.0035553, 0.00442505, ..., -0.0231934, -0.00723267,\n",
       "            0.0136108],\n",
       "           [0.00131989, 0.00976562, -0.00257874, ..., 0.013916,\n",
       "            -0.00271606, -0.0203857],\n",
       "           [-0.00732422, -0.00279236, -0.00860596, ..., -0.00479126,\n",
       "            -0.00473022, 0.00352478],\n",
       "           ...,\n",
       "           [0.0142822, -0.0112305, 0.00653076, ..., -0.00300598,\n",
       "            -0.00613403, 0.00280762],\n",
       "           [-0.0090332, 0.00312805, -0.00524902, ..., 0.00328064,\n",
       "            0.0130615, 0.0111694],\n",
       "           [0.000770569, 0.00646973, 0.0128174, ..., 4.8399e-05,\n",
       "            0.00592041, 0.0154419]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.0050354, 0.000976562, -0.00619507, ..., 0.0118408, -0.00799561,\n",
       "           -0.00179291],\n",
       "          [-0.0106812, -0.0114136, -0.00436401, ..., 0.00364685,\n",
       "           -0.00361633, -0.00372314],\n",
       "          [-0.00674438, 0.00170135, 0.00136566, ..., 0.000915527,\n",
       "           -0.00927734, 0.00415039],\n",
       "          ...,\n",
       "          [0.00335693, -0.00331116, 0.00463867, ..., 0.0010376, 0.0016861,\n",
       "           -0.00564575],\n",
       "          [0.0025177, -0.000295639, 0.000284195, ..., 0.00075531,\n",
       "           -0.00854492, -0.00244141],\n",
       "          [0.000148773, -0.0090332, -0.00650024, ..., -0.00686646,\n",
       "           0.0159912, 0.0155029]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.417969, 0.449219, 0.496094, ..., 0.236328, 0.0996094, 0.226562],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.570312, 0.636719, 0.699219, ..., 0.523438, 0.554688, 0.421875],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.648438, 0.875, 0.738281, ..., 0.773438, -0.0170898, 0.667969],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.074707, 0.15625, 0.0830078, ..., 0.185547, -0.205078, 0.0991211],      dtype=bfloat16)}},\n",
       " 'layer_12': {'attn': {'attn_vec_einsum': {'w': Array([[[0.0123291, 0.00909424, -0.001091, ..., 0.0146484, -0.000839233,\n",
       "             0.0090332],\n",
       "            [-0.00273132, 0.000862122, -0.00531006, ..., 0.0108032,\n",
       "             0.00160217, -0.00114441],\n",
       "            [0.00561523, 0.00665283, 0.00364685, ..., -0.0120239, 0.013855,\n",
       "             -0.00842285],\n",
       "            ...,\n",
       "            [-0.0336914, -0.0148315, -0.0022583, ..., -0.00204468,\n",
       "             0.00497437, 0.00309753],\n",
       "            [-0.0137939, -0.00276184, 0.000127792, ..., 0.0212402,\n",
       "             0.00488281, -0.00469971],\n",
       "            [-0.00239563, 0.00128174, 0.00592041, ..., -0.0129395,\n",
       "             -0.00262451, -0.00311279]],\n",
       "    \n",
       "           [[0.00799561, -0.0144653, 0.00285339, ..., -0.00302124,\n",
       "             -0.000644684, 0.012146],\n",
       "            [0.00424194, -0.0019455, 0.00787354, ..., -0.00741577,\n",
       "             -0.00695801, -0.00335693],\n",
       "            [-0.0125732, -0.00976562, -0.00561523, ..., -0.00210571,\n",
       "             -0.00958252, 0.0134888],\n",
       "            ...,\n",
       "            [0.0245361, 0.00579834, 0.00344849, ..., 0.00726318,\n",
       "             -0.00775146, 0.00379944],\n",
       "            [0.00430298, 0.00866699, -0.00349426, ..., 0.00308228,\n",
       "             -0.00793457, 0.0018692],\n",
       "            [-0.00124359, -0.000320435, 0.00640869, ..., 0.00411987,\n",
       "             0.0117798, 0.00891113]],\n",
       "    \n",
       "           [[-0.0200195, 0.00230408, 0.0246582, ..., -0.0205078, 0.0128174,\n",
       "             0.00762939],\n",
       "            [0.0189209, 0.00933838, -0.00708008, ..., 0.00418091, 0.0175781,\n",
       "             0.0136719],\n",
       "            [-0.012146, -0.00915527, 0.0164795, ..., 0.00564575, 0.00756836,\n",
       "             0.0174561],\n",
       "            ...,\n",
       "            [0.0133057, -0.0240479, -0.00891113, ..., 0.019165, 0.00494385,\n",
       "             0.0220947],\n",
       "            [0.00497437, 0.00744629, 0.010437, ..., 0.000926971, -0.0247803,\n",
       "             0.0169678],\n",
       "            [0.0249023, -0.00708008, -0.00546265, ..., 0.0166016,\n",
       "             -0.0202637, 0.00866699]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00153351, 0.0118408, -0.0019989, ..., -0.0102539,\n",
       "             -0.00169373, 0.00897217],\n",
       "            [-0.00872803, -0.0119019, 0.00656128, ..., -0.00297546,\n",
       "             -0.0205078, -0.000659943],\n",
       "            [-0.0106201, 0.000210762, 0.0133057, ..., -0.00442505,\n",
       "             -0.00738525, 0.0125122],\n",
       "            ...,\n",
       "            [-0.0111084, 0.000452042, -0.00915527, ..., -0.00387573,\n",
       "             -0.0117798, 0.000762939],\n",
       "            [-0.00723267, -0.00126648, -0.00169373, ..., -0.00872803,\n",
       "             1.32918e-05, 0.0148315],\n",
       "            [-0.00273132, 0.00109863, -0.00720215, ..., 0.0231934,\n",
       "             0.00390625, -0.0115967]],\n",
       "    \n",
       "           [[0.0164795, -0.00162506, -0.00219727, ..., -0.00933838,\n",
       "             0.0011673, 0.00069809],\n",
       "            [0.0181885, -0.00576782, 0.00466919, ..., 0.000514984,\n",
       "             0.00260925, 0.00376892],\n",
       "            [0.0098877, 0.00337219, -0.0043335, ..., 0.00909424, 0.00469971,\n",
       "             -0.00964355],\n",
       "            ...,\n",
       "            [-0.00637817, 0.00759888, -0.000324249, ..., -0.000352859,\n",
       "             -0.000770569, 0.0145264],\n",
       "            [0.00411987, 0.0181885, 0.000854492, ..., -0.00558472,\n",
       "             -0.00102997, -0.0101318],\n",
       "            [0.0101929, -0.00662231, 0.0206299, ..., -0.010498, 0.0108643,\n",
       "             -0.0136108]],\n",
       "    \n",
       "           [[-0.0115356, -0.000915527, 0.00341797, ..., -0.00150299,\n",
       "             -0.00717163, 0.00598145],\n",
       "            [-0.0157471, -0.0109253, -0.0117188, ..., 0.0109253, 0.00408936,\n",
       "             -0.00271606],\n",
       "            [-0.00793457, -0.00337219, -0.0037384, ..., 0.00234985,\n",
       "             0.00769043, 0.0112305],\n",
       "            ...,\n",
       "            [0.000957489, 0.000873566, -0.0117798, ..., 0.00164032,\n",
       "             -0.00500488, -0.0032196],\n",
       "            [0.000694275, -0.0185547, 0.00723267, ..., -0.00170135,\n",
       "             -0.00741577, 0.0109253],\n",
       "            [-0.00402832, 0.000999451, -0.0231934, ..., 0.00848389,\n",
       "             -0.00177765, 0.0130615]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.00343323, 0.00543213, 0.0010376, ..., 0.0194092,\n",
       "              -0.0289307, 0.00854492],\n",
       "             [0.00335693, -0.000406265, -0.000614166, ..., -0.0223389,\n",
       "              -0.0181885, -0.0213623],\n",
       "             [0.0110474, -0.00549316, 0.000406265, ..., -0.0035553,\n",
       "              -0.00457764, 0.0284424],\n",
       "             ...,\n",
       "             [-0.0126343, 0.00759888, -0.00273132, ..., -0.00799561,\n",
       "              -0.00756836, -0.00378418],\n",
       "             [0.00364685, 0.00156403, 0.00567627, ..., 0.00558472,\n",
       "              -0.00909424, 0.00915527],\n",
       "             [0.00970459, -0.00213623, -0.000476837, ..., -0.0334473,\n",
       "              -0.00958252, -0.0162354]],\n",
       "    \n",
       "            [[-0.000766754, -0.00704956, 0.00424194, ..., -0.010498,\n",
       "              -0.019165, -0.00775146],\n",
       "             [0.00595093, 0.0111084, -0.00457764, ..., -0.0145874,\n",
       "              -0.0019455, 0.000892639],\n",
       "             [0.000255585, -0.00408936, 0.00312805, ..., 0.0244141,\n",
       "              -0.0106201, -0.017334],\n",
       "             ...,\n",
       "             [-0.00585938, -0.00366211, -0.00265503, ..., -0.00897217,\n",
       "              -0.0114746, -0.00328064],\n",
       "             [1.2517e-05, 0.00592041, 0.000459671, ..., 0.00408936,\n",
       "              -0.0147705, 0.00244141],\n",
       "             [0.00094223, 0.0018158, -0.0010376, ..., 0.010437, 0.0280762,\n",
       "              0.0088501]],\n",
       "    \n",
       "            [[0.00897217, 0.0078125, -0.00196838, ..., 0.00179291,\n",
       "              0.00156403, 0.00357056],\n",
       "             [-0.00173187, -0.00153351, -0.00598145, ..., -0.00982666,\n",
       "              0.00263977, -0.0120239],\n",
       "             [-0.00201416, -0.00494385, 0.00224304, ..., -0.00823975,\n",
       "              -0.00442505, -0.0273438],\n",
       "             ...,\n",
       "             [-0.00218201, 0.00111389, -0.00216675, ..., -0.00939941,\n",
       "              -0.00466919, -0.00946045],\n",
       "             [0.0039978, -0.00427246, -0.00747681, ..., -0.0159912,\n",
       "              -0.0322266, 0.0419922],\n",
       "             [0.00231934, -0.000358582, 0.00567627, ..., 0.00476074,\n",
       "              0.00448608, 0.00595093]],\n",
       "    \n",
       "            [[-0.00274658, 0.0132446, -0.00205994, ..., -0.00848389,\n",
       "              -0.00430298, -0.00245667],\n",
       "             [0.00726318, 0.00111389, 0.00267029, ..., 0.000595093,\n",
       "              -0.0157471, -0.00408936],\n",
       "             [-0.00897217, -8.86917e-05, 0.0072937, ..., -0.00396729,\n",
       "              0.000717163, 0.00279236],\n",
       "             ...,\n",
       "             [-0.00364685, -0.00671387, 0.00024128, ..., -0.0050354,\n",
       "              0.00735474, -0.00640869],\n",
       "             [0.00408936, 8.58307e-05, 0.00897217, ..., 0.000915527,\n",
       "              0.0112915, -0.0122681],\n",
       "             [-0.00592041, -0.00241089, -0.00872803, ..., 0.0205078,\n",
       "              -0.00337219, -8.82149e-05]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00527954, 0.00213623, -0.00387573, ..., 0.000329971,\n",
       "              0.00113678, 0.00315857],\n",
       "             [-0.00689697, 0.00610352, -0.0174561, ..., -0.0117798,\n",
       "              0.00141907, -0.00634766],\n",
       "             [0.0169678, -0.019165, -0.0185547, ..., 0.00915527,\n",
       "              0.00909424, -0.00958252],\n",
       "             ...,\n",
       "             [-0.0150757, -0.00270081, 0.0181885, ..., 3.19481e-05,\n",
       "              -0.00842285, 0.0146484],\n",
       "             [-0.00750732, -0.0216064, -0.003479, ..., -0.00723267,\n",
       "              0.0114746, 0.000545502],\n",
       "             [0.00346375, -0.0334473, 0.00361633, ..., 0.000919342,\n",
       "              -0.0116577, -0.00570679]],\n",
       "    \n",
       "            [[0.0135498, -0.0057373, 0.0128784, ..., -0.00674438,\n",
       "              0.000232697, -0.015564],\n",
       "             [-0.0194092, -0.000595093, 0.0117798, ..., 0.0212402,\n",
       "              -0.0177002, 0.0164795],\n",
       "             [-0.0247803, 0.00408936, -0.0153809, ..., 0.00765991,\n",
       "              -0.00376892, 0.00653076],\n",
       "             ...,\n",
       "             [0.00765991, -0.00457764, 0.0168457, ..., -0.0234375,\n",
       "              -0.0179443, -0.012085],\n",
       "             [-0.000953674, 0.00595093, 0.0119019, ..., -0.00588989,\n",
       "              0.0167236, 0.000192642],\n",
       "             [0.00506592, -0.00402832, 0.00328064, ..., -0.0195312,\n",
       "              -0.00175476, -0.0167236]],\n",
       "    \n",
       "            [[0.0240479, 0.0250244, -0.00466919, ..., -0.00140381,\n",
       "              0.00387573, 0.00479126],\n",
       "             [-0.0216064, 0.00366211, -0.00744629, ..., 0.0145874,\n",
       "              -0.00364685, -0.0181885],\n",
       "             [0.0144043, -0.00561523, -0.00616455, ..., -0.00534058,\n",
       "              -0.00312805, -0.00167847],\n",
       "             ...,\n",
       "             [0.00158691, 0.00265503, -0.00231934, ..., 0.00552368,\n",
       "              -0.00506592, 0.000976562],\n",
       "             [-0.0125732, 0.0162354, -0.00119019, ..., -0.00315857,\n",
       "              0.0145874, -0.00147247],\n",
       "             [-0.0123901, -0.0218506, 0.00500488, ..., 0.00531006,\n",
       "              -0.0101929, -0.00540161]],\n",
       "    \n",
       "            [[-0.00909424, -0.0184326, 0.00262451, ..., -0.00352478,\n",
       "              -0.0166016, -0.00500488],\n",
       "             [0.0022583, 0.00558472, -0.00296021, ..., -0.0137329,\n",
       "              -0.0294189, -0.0020752],\n",
       "             [0.0113525, -0.00549316, 0.0157471, ..., -0.00378418,\n",
       "              -0.00512695, -0.0119629],\n",
       "             ...,\n",
       "             [0.00640869, -0.00158691, -0.0055542, ..., -0.00137329,\n",
       "              0.0128784, 0.0090332],\n",
       "             [9.44138e-05, -0.00787354, -0.000178337, ..., -0.00128937,\n",
       "              0.0164795, -0.00854492],\n",
       "             [-0.000364304, 0.00056839, 0.00326538, ..., -0.0167236,\n",
       "              0.00123596, 0.0122681]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00866699, -0.000282288, -0.00335693, ..., 0.00732422,\n",
       "             -0.0071106, -0.0164795],\n",
       "            [0.00315857, -0.00297546, -0.00753784, ..., -0.00527954,\n",
       "             -0.00927734, -0.00349426],\n",
       "            [-0.010498, -0.0107422, -0.0129395, ..., -0.0223389, 0.0057373,\n",
       "             -0.00747681],\n",
       "            ...,\n",
       "            [0.00588989, -0.00308228, -0.00318909, ..., 0.000679016,\n",
       "             -0.000337601, -0.00515747],\n",
       "            [-0.00585938, -0.00592041, 0.0222168, ..., -0.00273132,\n",
       "             0.00320435, -0.0110474],\n",
       "            [0.000331879, 0.00167847, -0.00515747, ..., 0.0098877,\n",
       "             0.0016861, 0.0200195]],\n",
       "    \n",
       "           [[0.000492096, -0.00396729, -0.000984192, ..., 0.0222168,\n",
       "             0.0202637, -0.00585938],\n",
       "            [-0.00564575, -0.0119629, -0.0131836, ..., -0.032959,\n",
       "             -0.0169678, 0.0153809],\n",
       "            [-0.0155029, -0.00921631, 0.000724792, ..., -0.0177002,\n",
       "             -0.00430298, 0.000751495],\n",
       "            ...,\n",
       "            [0.0016098, -0.00674438, 0.00488281, ..., 0.00367737,\n",
       "             0.00106049, -0.0157471],\n",
       "            [0.0116577, -0.000326157, -0.0211182, ..., 0.0115356, 0.0101318,\n",
       "             0.000812531],\n",
       "            [0.00323486, 0.0157471, -0.00418091, ..., 0.00231934, 0.0257568,\n",
       "             0.0339355]],\n",
       "    \n",
       "           [[0.00823975, -0.00424194, -0.00317383, ..., 0.00534058,\n",
       "             0.0105591, -0.00267029],\n",
       "            [-0.00531006, 0.000789642, -0.00515747, ..., 0.010437,\n",
       "             -0.00817871, -0.00389099],\n",
       "            [-0.00668335, -0.000461578, -0.00631714, ..., 0.0158691,\n",
       "             0.0012207, 0.00668335],\n",
       "            ...,\n",
       "            [0.00418091, -0.000274658, 0.000398636, ..., -0.0252686,\n",
       "             -0.00866699, 0.00958252],\n",
       "            [-0.00933838, -0.000934601, 0.026001, ..., -0.0067749,\n",
       "             -0.00219727, -0.00909424],\n",
       "            [0.00212097, -2.75671e-06, -0.00460815, ..., 0.00668335,\n",
       "             -0.00186157, 0.0136719]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00488281, -0.00262451, 0.00250244, ..., 0.00897217,\n",
       "             0.00778198, 0.0332031],\n",
       "            [0.000770569, -0.00088501, 0.00830078, ..., -0.0067749,\n",
       "             -0.0169678, -0.00982666],\n",
       "            [-0.00320435, 0.00518799, -0.00506592, ..., -0.0180664,\n",
       "             0.00897217, -0.0119019],\n",
       "            ...,\n",
       "            [0.00540161, 0.00485229, 0.00288391, ..., -0.00735474,\n",
       "             0.0119629, -0.013855],\n",
       "            [-0.00497437, 0.0035553, -0.000398636, ..., -0.019165,\n",
       "             -0.00823975, -0.0111694],\n",
       "            [-0.00402832, -0.00242615, -0.00108337, ..., -0.00933838,\n",
       "             -0.00119019, -0.0240479]],\n",
       "    \n",
       "           [[-0.000526428, -0.0107422, 0.000923157, ..., -0.0088501,\n",
       "             -0.00970459, -0.0088501],\n",
       "            [-0.00878906, -0.0109253, -0.00860596, ..., -0.0143433,\n",
       "             0.00466919, -4.62532e-05],\n",
       "            [0.0071106, -0.00346375, -0.00741577, ..., 0.00540161,\n",
       "             -0.00964355, -0.00152588],\n",
       "            ...,\n",
       "            [-0.0039978, -0.00976562, 0.00976562, ..., -0.0107422,\n",
       "             0.0174561, -0.00897217],\n",
       "            [0.00671387, -0.00830078, 0.00156403, ..., -0.0150146,\n",
       "             -0.00805664, 0.00250244],\n",
       "            [0.00160217, -0.0120239, -0.00817871, ..., 0.00564575,\n",
       "             -0.00309753, 0.00393677]],\n",
       "    \n",
       "           [[-0.00848389, 0.00222778, 0.00360107, ..., 0.00405884,\n",
       "             -0.00708008, -0.00769043],\n",
       "            [-0.00136566, -6.7234e-05, -0.00384521, ..., -0.0062561,\n",
       "             -0.00463867, -0.00631714],\n",
       "            [0.00112915, 0.0045166, 0.00726318, ..., -0.0108032,\n",
       "             -0.00183868, -0.00344849],\n",
       "            ...,\n",
       "            [-0.00482178, -0.00497437, 0.00161743, ..., 0.00534058,\n",
       "             -0.00415039, 0.010376],\n",
       "            [0.00424194, 0.0181885, 0.00485229, ..., -0.00344849,\n",
       "             -0.00457764, 0.00665283],\n",
       "            [0.00680542, 0.00482178, -0.0065918, ..., 0.00190735,\n",
       "             0.00302124, 0.010498]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00946045, 0.00714111, 0.0112305, ..., -0.00205994,\n",
       "            -0.0202637, 0.000368118],\n",
       "           [-0.000888824, 0.0150757, -0.00897217, ..., -0.00485229,\n",
       "            0.0143433, -0.0109863],\n",
       "           [0.00260925, 0.0198975, 0.0281982, ..., -0.012146, -0.00842285,\n",
       "            -0.00115967],\n",
       "           ...,\n",
       "           [-0.00616455, -0.03125, 0.00933838, ..., -0.00448608,\n",
       "            -0.0126953, 0.010437],\n",
       "           [0.00056076, -0.00312805, -0.00305176, ..., -0.00210571,\n",
       "            0.0131226, 0.010376],\n",
       "           [0.006073, -0.0106201, -0.000105858, ..., 0.00952148,\n",
       "            -0.00579834, -0.00756836]],\n",
       "   \n",
       "          [[-0.00775146, -0.00375366, -0.00421143, ..., -0.00224304,\n",
       "            -0.00344849, -0.00537109],\n",
       "           [-0.00125122, 0.000541687, -0.00369263, ..., 0.00982666,\n",
       "            0.0120239, -0.00367737],\n",
       "           [-0.00131989, -0.00866699, 0.0114136, ..., -0.0194092,\n",
       "            0.00183868, 0.00650024],\n",
       "           ...,\n",
       "           [-0.0140991, -0.00665283, -0.00604248, ..., 0.00267029,\n",
       "            0.00279236, -0.00396729],\n",
       "           [-0.00454712, -0.00331116, 0.0132446, ..., 0.00564575,\n",
       "            -0.00726318, 0.000785828],\n",
       "           [0.00643921, 0.0039978, 0.010376, ..., -0.000938416,\n",
       "            -0.00112152, 0.000827789]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.012085, 0.00479126, -0.00488281, ..., -0.00848389, -0.010376,\n",
       "           0.0062561],\n",
       "          [0.00113678, -0.00708008, -0.00592041, ..., 0.0145264, 0.00271606,\n",
       "           0.00308228],\n",
       "          [0.00156403, -0.00921631, 0.019043, ..., 0.00686646, -0.00364685,\n",
       "           -0.00259399],\n",
       "          ...,\n",
       "          [-0.00331116, 0.00233459, -0.00970459, ..., 0.00915527,\n",
       "           0.00689697, 0.00241089],\n",
       "          [-0.0181885, 0.00753784, 0.00424194, ..., 0.00253296, -0.0117188,\n",
       "           0.00289917],\n",
       "          [-0.00418091, -0.00244141, 0.00854492, ..., 0.00213623,\n",
       "           -0.00506592, 0.00424194]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.416016, 0.648438, 0.589844, ..., 0.335938, 0.133789, 0.298828],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.644531, 0.695312, 0.757812, ..., 0.589844, 0.589844, 0.507812],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.933594, 1.07812, 0.972656, ..., 0.863281, 0.0952148, 0.957031],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.0192871, 0.0976562, 0.0195312, ..., 0.10498, -0.239258,\n",
       "          0.0118408], dtype=bfloat16)}},\n",
       " 'layer_13': {'attn': {'attn_vec_einsum': {'w': Array([[[0.0135498, 0.00506592, -0.00741577, ..., 0.00358582,\n",
       "             -0.00222778, -0.00854492],\n",
       "            [-0.0125122, -0.00457764, 0.00662231, ..., -0.0090332,\n",
       "             0.00787354, -0.00112152],\n",
       "            [0.00087738, 0.0088501, 0.0039978, ..., -0.00241089, 0.00187683,\n",
       "             -0.0103149],\n",
       "            ...,\n",
       "            [0.0050354, 0.00866699, -0.00946045, ..., 0.0150146, 0.00311279,\n",
       "             0.00274658],\n",
       "            [0.00558472, 0.00158691, 0.000904083, ..., 0.00537109,\n",
       "             -0.0224609, -0.00247192],\n",
       "            [-9.67979e-05, 0.00213623, 0.00337219, ..., -0.00640869,\n",
       "             0.0162354, -0.0246582]],\n",
       "    \n",
       "           [[-0.00378418, 0.0144043, -0.00680542, ..., 0.00817871,\n",
       "             -0.00357056, 0.00750732],\n",
       "            [0.00772095, 0.00296021, 0.00344849, ..., -0.0137939,\n",
       "             -0.00349426, 0.00549316],\n",
       "            [0.00897217, 0.00585938, -0.00300598, ..., -0.0206299,\n",
       "             0.000231743, -0.00361633],\n",
       "            ...,\n",
       "            [0.0129395, -0.00741577, 0.00631714, ..., 0.00762939, 0.0122681,\n",
       "             0.00485229],\n",
       "            [0.00637817, -0.00454712, -0.00193024, ..., 0.00268555,\n",
       "             -0.00952148, -0.000486374],\n",
       "            [-0.0050354, -0.00982666, 0.00376892, ..., 0.0045166,\n",
       "             0.00263977, -0.0025177]],\n",
       "    \n",
       "           [[0.0201416, 0.00872803, -0.00201416, ..., 0.0151367,\n",
       "             -0.00094223, -0.00415039],\n",
       "            [0.00598145, -0.0187988, 0.0112915, ..., 0.0117798, 0.0071106,\n",
       "             0.00148773],\n",
       "            [-0.00205994, 0.00933838, 0.00878906, ..., 0.0090332,\n",
       "             0.00564575, 0.00120544],\n",
       "            ...,\n",
       "            [0.00683594, -0.00793457, -0.012085, ..., 0.0168457,\n",
       "             -0.00150299, 0.0078125],\n",
       "            [-0.00349426, 0.0112915, 0.00361633, ..., -0.0115356,\n",
       "             0.00897217, -0.0252686],\n",
       "            [0.00512695, -0.00585938, -0.0128174, ..., -0.000459671,\n",
       "             0.020752, 0.0170898]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0141602, 0.0146484, -0.0205078, ..., 0.00265503, 0.00933838,\n",
       "             0.0299072],\n",
       "            [-0.0235596, 0.0172119, -0.00349426, ..., -0.00576782,\n",
       "             -0.00799561, 0.00314331],\n",
       "            [-0.013916, 0.0200195, -0.00860596, ..., -0.0269775,\n",
       "             0.000448227, -0.0107422],\n",
       "            ...,\n",
       "            [-0.0128174, -0.00921631, -0.00842285, ..., -0.000125885,\n",
       "             -0.00131226, -0.00250244],\n",
       "            [0.00482178, 0.0181885, 0.0189209, ..., -0.00239563, 0.0322266,\n",
       "             -0.0016098],\n",
       "            [0.00138855, -0.00328064, -0.0222168, ..., -0.0102539, 0.022583,\n",
       "             0.019043]],\n",
       "    \n",
       "           [[-0.0235596, 0.0108643, -0.0132446, ..., 0.00491333, 0.00982666,\n",
       "             -0.0244141],\n",
       "            [-0.00531006, -0.017334, -0.00579834, ..., -0.0166016,\n",
       "             -0.00643921, -0.0102539],\n",
       "            [0.00836182, 0.00537109, 0.00180054, ..., 0.0115967, 0.0239258,\n",
       "             -0.00543213],\n",
       "            ...,\n",
       "            [0.00485229, -0.00860596, 0.00160217, ..., 0.00222778,\n",
       "             -0.000507355, -0.0150146],\n",
       "            [0.00561523, -0.0143433, 0.00460815, ..., -0.00156403,\n",
       "             0.000846863, 0.010376],\n",
       "            [0.00909424, -0.00218201, -0.0162354, ..., 0.0140381,\n",
       "             -0.00668335, -0.0175781]],\n",
       "    \n",
       "           [[-0.017334, -0.00854492, 0.0183105, ..., 0.0088501, -0.00518799,\n",
       "             0.00598145],\n",
       "            [-0.00692749, -0.0130005, 0.00692749, ..., 0.0103149, 0.0157471,\n",
       "             -0.00387573],\n",
       "            [0.0122681, -0.0114746, -0.012207, ..., -0.0136719, -0.00494385,\n",
       "             0.00424194],\n",
       "            ...,\n",
       "            [0.000333786, 0.00247192, 0.0090332, ..., 0.000265121,\n",
       "             -0.0202637, 0.0263672],\n",
       "            [-0.00534058, 0.00958252, -0.00662231, ..., -0.0152588,\n",
       "             -0.0103149, 0.00579834],\n",
       "            [-0.00686646, 0.0045166, 0.0183105, ..., -0.00683594, 0.0128784,\n",
       "             0.0045166]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.000892639, 0.00201416, -0.00775146, ..., 0.000904083,\n",
       "              0.0071106, 0.00558472],\n",
       "             [-0.00891113, -0.00157166, 8.4877e-05, ..., -0.00939941,\n",
       "              0.0145264, -0.0100098],\n",
       "             [-0.00177765, -0.00106812, 0.00613403, ..., 0.0136108,\n",
       "              0.019043, -0.00375366],\n",
       "             ...,\n",
       "             [0.0067749, -0.000537872, -0.00546265, ..., 0.0090332,\n",
       "              -0.00445557, 0.0101318],\n",
       "             [-0.0218506, -0.0145874, 0.00244141, ..., -0.010498,\n",
       "              0.00127411, 0.00476074],\n",
       "             [-0.00364685, -0.000553131, 0.00390625, ..., -0.0184326,\n",
       "              0.0163574, -0.0163574]],\n",
       "    \n",
       "            [[-0.00619507, 0.000919342, -0.0022583, ..., -0.027832,\n",
       "              0.0132446, 0.0241699],\n",
       "             [0.00164032, -0.000831604, -0.000235558, ..., 0.00958252,\n",
       "              0.0118408, 0.0107422],\n",
       "             [-0.00430298, 0.00650024, -0.00656128, ..., -0.0118408,\n",
       "              -0.00280762, 0.0140991],\n",
       "             ...,\n",
       "             [0.00245667, -0.00169373, 0.00198364, ..., -0.00701904,\n",
       "              -0.0117188, -0.00082016],\n",
       "             [0.00335693, 0.0164795, 0.00104523, ..., -0.0147705,\n",
       "              0.0148926, -0.00328064],\n",
       "             [0.000257492, 0.000400543, -0.00280762, ..., -0.0120239,\n",
       "              0.0196533, -0.0158691]],\n",
       "    \n",
       "            [[0.00540161, -0.00411987, -8.82149e-05, ..., 0.0109253,\n",
       "              -0.0117798, 0.0201416],\n",
       "             [0.000103474, 0.00405884, 0.0098877, ..., 0.0106201, 0.017334,\n",
       "              0.0186768],\n",
       "             [-0.00830078, 0.00595093, 0.0071106, ..., -0.0118408,\n",
       "              0.00491333, 0.00543213],\n",
       "             ...,\n",
       "             [0.00665283, -0.00787354, 0.00170898, ..., -0.0258789,\n",
       "              0.00616455, 0.0111694],\n",
       "             [2.76566e-05, 0.00482178, 0.00234985, ..., 0.0112305,\n",
       "              0.00159454, 0.0145264],\n",
       "             [-0.00436401, 0.00343323, 0.00305176, ..., 0.0180664,\n",
       "              0.0181885, -0.0234375]],\n",
       "    \n",
       "            [[0.00549316, -0.00238037, 0.00151062, ..., 0.0177002,\n",
       "              0.000762939, 0.00270081],\n",
       "             [-0.00424194, -0.00306702, 0.00543213, ..., 0.00436401,\n",
       "              0.00500488, -0.00698853],\n",
       "             [0.00494385, 0.00775146, 0.00147247, ..., 0.00744629,\n",
       "              -0.0249023, 0.0043335],\n",
       "             ...,\n",
       "             [0.00653076, 0.00325012, -0.00701904, ..., -0.00872803,\n",
       "              -0.0088501, -0.00915527],\n",
       "             [0.00430298, 0.000637054, -0.00282288, ..., 0.0218506,\n",
       "              0.0241699, -0.0209961],\n",
       "             [-0.00604248, 0.00378418, -0.00469971, ..., 0.00726318,\n",
       "              -1.44839e-05, 0.00897217]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00866699, -0.00228882, 0.00964355, ..., 0.00418091,\n",
       "              0.00592041, 0.00341797],\n",
       "             [0.000333786, -0.00811768, 0.0100098, ..., 0.00372314,\n",
       "              0.00592041, 0.0114136],\n",
       "             [0.00701904, 0.00463867, 0.00756836, ..., 0.00854492,\n",
       "              -0.0088501, -0.00325012],\n",
       "             ...,\n",
       "             [0.0108643, -0.00854492, -0.0222168, ..., 0.00418091,\n",
       "              0.00173187, 0.00799561],\n",
       "             [-0.00534058, 0.00616455, 0.0251465, ..., -0.0100098,\n",
       "              -0.0111084, 0.0102539],\n",
       "             [0.000507355, 0.00289917, -0.00421143, ..., -0.00805664,\n",
       "              -0.0018158, 0.00259399]],\n",
       "    \n",
       "            [[0.000793457, -0.00221252, -0.00119019, ..., 0.00848389,\n",
       "              0.0105591, -0.00769043],\n",
       "             [0.00650024, 0.00982666, 0.00279236, ..., -0.00643921,\n",
       "              0.00628662, 0.00173187],\n",
       "             [-0.0252686, -0.00367737, 0.0100708, ..., 0.00125122,\n",
       "              0.019043, 0.0107422],\n",
       "             ...,\n",
       "             [-0.00230408, 0.00604248, 0.00848389, ..., 0.00909424,\n",
       "              -0.0185547, 0.00256348],\n",
       "             [-0.00872803, -0.00897217, -0.00509644, ..., -0.0101929,\n",
       "              0.0174561, 0.00506592],\n",
       "             [0.00387573, 0.0109863, -0.0224609, ..., 0.00805664,\n",
       "              -0.0090332, -0.0141602]],\n",
       "    \n",
       "            [[0.0283203, -0.0112305, -0.00714111, ..., 0.0222168,\n",
       "              -0.00183868, 0.0115967],\n",
       "             [0.0109253, 0.0289307, 0.015564, ..., -0.0130005, -0.00326538,\n",
       "              -0.00561523],\n",
       "             [0.00842285, 0.0109863, 0.000160217, ..., 0.00169373,\n",
       "              -0.0139771, 0.00518799],\n",
       "             ...,\n",
       "             [-0.00494385, -0.00244141, 0.0105591, ..., 0.00180054,\n",
       "              0.00405884, -0.0264893],\n",
       "             [0.0038147, -0.00927734, -0.00537109, ..., -0.0142822,\n",
       "              0.0110474, 0.0230713],\n",
       "             [0.00558472, -0.00198364, 0.0202637, ..., -0.00270081,\n",
       "              -0.0169678, 0.00494385]],\n",
       "    \n",
       "            [[-0.0109253, -0.00689697, 0.012085, ..., -0.0180664,\n",
       "              0.00125122, -0.0158691],\n",
       "             [-0.00534058, -0.0131226, -0.00665283, ..., -0.00325012,\n",
       "              0.020874, 0.00637817],\n",
       "             [-0.00564575, -0.017334, 0.0268555, ..., -0.00367737,\n",
       "              -0.000583649, -0.0107422],\n",
       "             ...,\n",
       "             [0.0111084, -0.00701904, 0.00836182, ..., -0.0147095,\n",
       "              -0.000888824, 0.00176239],\n",
       "             [0.0505371, -0.0151367, 0.0128784, ..., 0.00695801,\n",
       "              -0.00256348, 0.00445557],\n",
       "             [0.00842285, -0.0065918, -0.00540161, ..., -0.0127563,\n",
       "              0.00588989, -0.0247803]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.000207901, -0.00448608, -0.00363159, ..., 0.00964355,\n",
       "             0.00598145, -0.000116825],\n",
       "            [0.0103149, 0.0078125, -0.0137329, ..., -0.000747681,\n",
       "             0.00915527, -0.0141602],\n",
       "            [-0.00411987, 8.15392e-05, 0.000804901, ..., 0.000675201,\n",
       "             0.00567627, 0.0043335],\n",
       "            ...,\n",
       "            [0.00231934, -0.00101471, 0.000232697, ..., 0.00772095,\n",
       "             0.00171661, -0.0129395],\n",
       "            [0.000103951, -0.0269775, 0.00613403, ..., 0.00668335,\n",
       "             0.00370789, -0.0128784],\n",
       "            [-0.00454712, -0.00842285, -0.00704956, ..., -0.000341415,\n",
       "             -0.00726318, -0.0119629]],\n",
       "    \n",
       "           [[-0.00186157, 0.00299072, -0.0030365, ..., 0.000368118,\n",
       "             -0.00588989, 0.0192871],\n",
       "            [0.00497437, 0.000667572, -0.00622559, ..., -0.0400391,\n",
       "             0.0128174, 0.0118408],\n",
       "            [-0.00151062, -0.00234985, -0.00318909, ..., -0.00604248,\n",
       "             0.0205078, 0.00256348],\n",
       "            ...,\n",
       "            [0.000450134, 0.00138855, -0.00302124, ..., 0.0262451,\n",
       "             0.0018158, 0.0131226],\n",
       "            [0.00854492, -0.0143433, -0.00506592, ..., -0.000518799,\n",
       "             0.0123291, 0.0133057],\n",
       "            [4.98295e-05, 0.00156403, -0.0101318, ..., -0.0236816,\n",
       "             -0.0014801, -0.00166321]],\n",
       "    \n",
       "           [[0.00738525, 0.0181885, 0.00473022, ..., 0.000499725,\n",
       "             -0.00964355, -0.00570679],\n",
       "            [0.0123291, 0.00390625, 0.00213623, ..., 0.0263672, 0.0228271,\n",
       "             -0.000892639],\n",
       "            [-0.00619507, -0.00439453, -0.00138855, ..., 0.0194092,\n",
       "             -0.0137329, -0.000541687],\n",
       "            ...,\n",
       "            [-0.00175476, -0.00915527, 0.00561523, ..., 0.00231934,\n",
       "             -0.015625, 0.00674438],\n",
       "            [0.0030365, -0.00927734, 0.00778198, ..., -0.00640869,\n",
       "             -0.0130615, 0.029541],\n",
       "            [-0.0072937, -0.00306702, -0.00537109, ..., 0.0122681,\n",
       "             0.00787354, -0.0358887]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0124512, -0.000469208, -0.00135803, ..., 0.0184326,\n",
       "             -0.0187988, -0.0162354],\n",
       "            [0.00183105, 0.00527954, -0.0202637, ..., 0.0236816,\n",
       "             -0.000782013, -0.00158691],\n",
       "            [-0.00509644, -0.019165, 0.0100708, ..., -0.0130615, 0.0161133,\n",
       "             0.00787354],\n",
       "            ...,\n",
       "            [-0.0124512, 0.00163269, -0.00588989, ..., -0.0334473,\n",
       "             -0.0114746, 0.000595093],\n",
       "            [0.00848389, -0.00515747, 0.0147095, ..., 0.00340271,\n",
       "             -0.00939941, 0.0267334],\n",
       "            [0.00215149, 0.000640869, 0.00976562, ..., -0.0152588, 0.015564,\n",
       "             -0.00723267]],\n",
       "    \n",
       "           [[0.00367737, -0.0001688, 0.00402832, ..., -0.00982666,\n",
       "             0.0153198, 0.00267029],\n",
       "            [0.0122681, 0.00344849, -0.00671387, ..., -0.000534058,\n",
       "             0.0134888, -0.0180664],\n",
       "            [0.00439453, 0.00927734, -0.00137329, ..., 0.0332031, 0.0115967,\n",
       "             0.00585938],\n",
       "            ...,\n",
       "            [-0.000640869, -8.49366e-07, -0.0100098, ..., -0.00512695,\n",
       "             0.0181885, 0.0141602],\n",
       "            [0.00107574, -0.00204468, 0.00360107, ..., 0.0108643,\n",
       "             0.00338745, 0.0168457],\n",
       "            [0.010376, -0.00518799, 0.00153351, ..., -0.0140991, -0.0168457,\n",
       "             0.000663757]],\n",
       "    \n",
       "           [[-0.00595093, -0.00396729, 0.00445557, ..., 0.00192261,\n",
       "             -0.0106201, -0.0015564],\n",
       "            [-0.0055542, 0.00830078, 0.00488281, ..., 0.0078125, 0.00145721,\n",
       "             0.000461578],\n",
       "            [-0.00128937, 0.00738525, 0.00215149, ..., 0.00805664,\n",
       "             0.00153351, -0.00172424],\n",
       "            ...,\n",
       "            [0.00537109, -0.00622559, -0.00817871, ..., -0.000184059,\n",
       "             0.000843048, -0.0088501],\n",
       "            [-0.0022583, -0.00325012, -0.00306702, ..., 0.00239563,\n",
       "             0.0149536, 0.0300293],\n",
       "            [-0.00193787, 0.00534058, 0.00524902, ..., 0.000556946,\n",
       "             0.0159912, 0.00866699]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.00717163, -0.00282288, -0.00683594, ..., -0.00196838,\n",
       "            -0.0148315, 0.0126343],\n",
       "           [0.00964355, -0.00750732, -0.0146484, ..., -0.00218201,\n",
       "            0.0102539, 0.000999451],\n",
       "           [-0.000774384, 0.00622559, 0.0106812, ..., -0.00842285,\n",
       "            -0.00631714, -0.00234985],\n",
       "           ...,\n",
       "           [0.00210571, -0.00141144, -0.00491333, ..., -0.00683594,\n",
       "            -0.0120239, 0.00891113],\n",
       "           [0.00224304, 0.00177765, -0.00637817, ..., -0.00189209,\n",
       "            -0.00171661, -0.0112915],\n",
       "           [-0.00276184, -0.00543213, -0.00415039, ..., -0.00741577,\n",
       "            0.00473022, -0.00759888]],\n",
       "   \n",
       "          [[-0.00823975, -0.00427246, 0.00817871, ..., -0.00088501,\n",
       "            0.0149536, 0.00375366],\n",
       "           [0.00747681, -0.0131836, 0.00421143, ..., -0.00183105,\n",
       "            -0.00958252, -0.00704956],\n",
       "           [-0.00126648, 0.00159454, -0.00836182, ..., 0.00439453,\n",
       "            -0.00288391, 0.0032196],\n",
       "           ...,\n",
       "           [-0.0101318, 0.017334, 0.000652313, ..., 0.00396729,\n",
       "            -0.000402451, 0.0117798],\n",
       "           [-0.0100708, -0.00674438, 0.0045166, ..., 0.00958252,\n",
       "            -0.0115356, -0.0011673],\n",
       "           [0.000629425, 0.00153351, -0.00119781, ..., 0.00653076,\n",
       "            0.00738525, -0.00463867]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00756836, -0.00531006, 0.00567627, ..., 0.00282288,\n",
       "           -0.0016098, -0.00387573],\n",
       "          [-0.00376892, -0.00121307, -0.00210571, ..., -0.00518799,\n",
       "           -0.00102997, 0.00302124],\n",
       "          [0.0157471, 0.0133667, -0.00637817, ..., 0.00382996, 0.00543213,\n",
       "           0.012085],\n",
       "          ...,\n",
       "          [-0.000934601, -0.00527954, -0.0100098, ..., -0.00309753,\n",
       "           0.0010376, -0.0126953],\n",
       "          [0.0169678, -0.0200195, -0.00241089, ..., -0.0050354, -0.00270081,\n",
       "           0.00854492],\n",
       "          [0.0103149, 0.00836182, 0.00531006, ..., 0.00616455, -1.87159e-05,\n",
       "           -0.00134277]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.742188, 0.71875, 0.671875, ..., 0.597656, 0.515625, 0.494141],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.875, 0.867188, 0.953125, ..., 0.859375, 0.839844, 0.679688],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.722656, 0.894531, 0.761719, ..., 0.726562, 0.0529785, 0.789062],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.126953, -0.0751953, -0.126953, ..., -0.0358887, -0.269531,\n",
       "          -0.0932617], dtype=bfloat16)}},\n",
       " 'layer_14': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.00366211, 0.00842285, -0.0114746, ..., 0.0151367,\n",
       "             0.000350952, -0.00479126],\n",
       "            [-0.00025177, 0.0019455, 0.000900269, ..., 0.00250244, 0.010376,\n",
       "             -0.00442505],\n",
       "            [-0.0155029, -0.010437, 0.00148773, ..., -0.00286865,\n",
       "             0.00579834, -0.0035553],\n",
       "            ...,\n",
       "            [0.0098877, -0.00233459, -0.00723267, ..., -0.00830078,\n",
       "             0.0147095, -0.000432968],\n",
       "            [0.00473022, 0.000396729, 0.00927734, ..., -0.0137939,\n",
       "             -0.00331116, 0.0177002],\n",
       "            [0.0133667, -0.0142822, 0.00595093, ..., -0.00692749,\n",
       "             0.00747681, 0.00799561]],\n",
       "    \n",
       "           [[0.0071106, -0.00479126, -0.00182343, ..., -0.00114441,\n",
       "             0.00430298, -0.012085],\n",
       "            [-0.00154114, 0.0109253, -0.00927734, ..., -0.0103149,\n",
       "             -0.00823975, -0.00115204],\n",
       "            [-0.0147705, 0.000961304, 0.000155449, ..., 0.00631714,\n",
       "             0.00318909, 0.00276184],\n",
       "            ...,\n",
       "            [-0.00242615, -0.00198364, 0.0145264, ..., 0.0194092,\n",
       "             -0.00285339, -0.00457764],\n",
       "            [-0.00190735, 0.0130615, -0.00445557, ..., 0.0163574,\n",
       "             -0.0103149, -0.00491333],\n",
       "            [-0.00436401, 0.00588989, -0.0113525, ..., 0.0163574,\n",
       "             -0.0103149, -0.00585938]],\n",
       "    \n",
       "           [[-0.00570679, 0.00227356, -0.00128174, ..., -0.0108032,\n",
       "             -0.0154419, 0.00921631],\n",
       "            [-0.00866699, 0.00509644, -0.0129395, ..., -0.00248718,\n",
       "             -0.00402832, 0.00970459],\n",
       "            [-0.0158691, 0.00156403, 0.00665283, ..., -0.00442505,\n",
       "             -0.0115356, 0.000518799],\n",
       "            ...,\n",
       "            [-0.00352478, 0.00595093, 9.53674e-05, ..., 0.000263214,\n",
       "             0.0101318, -0.000320435],\n",
       "            [-0.00866699, 0.000682831, 0.0133667, ..., 0.0101318,\n",
       "             -0.00210571, 0.00396729],\n",
       "            [-0.012207, 0.00747681, -0.019165, ..., 0.0194092, -0.0103149,\n",
       "             0.000305176]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0106201, 0.00228882, 0.00714111, ..., 0.00579834,\n",
       "             0.00897217, -0.00518799],\n",
       "            [0.0130005, 0.010376, 0.0286865, ..., 0.00320435, 0.0161133,\n",
       "             0.0139771],\n",
       "            [0.00306702, 0.0103149, -0.0109863, ..., 0.0189209, 0.010498,\n",
       "             -0.0200195],\n",
       "            ...,\n",
       "            [0.00147247, -0.0238037, -0.00527954, ..., -0.00315857,\n",
       "             -0.00212097, -0.00915527],\n",
       "            [-0.000865936, 0.00741577, 0.00430298, ..., 0.00120544,\n",
       "             -0.00897217, -0.00823975],\n",
       "            [0.00775146, -0.00463867, -0.00964355, ..., 0.00294495,\n",
       "             -0.00022316, 0.00145721]],\n",
       "    \n",
       "           [[-0.0174561, -0.0239258, 0.00315857, ..., -0.0101318,\n",
       "             -0.0137329, -0.00216675],\n",
       "            [-0.00653076, 0.00222778, 0.00108337, ..., -0.00805664,\n",
       "             -0.00872803, -0.0125122],\n",
       "            [0.00285339, -0.0038147, -0.00909424, ..., -0.000785828,\n",
       "             0.00325012, 7.00951e-05],\n",
       "            ...,\n",
       "            [-0.0101929, 0.0150146, -0.0043335, ..., 0.00340271, 0.0090332,\n",
       "             0.00738525],\n",
       "            [0.019165, -0.026123, 0.00921631, ..., -0.0134277, -0.0180664,\n",
       "             0.0039978],\n",
       "            [0.0014267, 0.00170135, 0.00738525, ..., 0.00823975, 0.0107422,\n",
       "             0.00120544]],\n",
       "    \n",
       "           [[0.00671387, 0.00854492, -0.00279236, ..., 0.0159912,\n",
       "             0.00927734, 0.00765991],\n",
       "            [0.00994873, 0.00811768, -0.00101471, ..., 0.0114136,\n",
       "             0.000606537, -0.0108643],\n",
       "            [-0.00285339, -0.00891113, 0.00653076, ..., 0.0148926,\n",
       "             -0.00242615, -0.0108643],\n",
       "            ...,\n",
       "            [0.0126343, -0.00921631, 0.0067749, ..., 0.0072937, -0.0164795,\n",
       "             -0.00753784],\n",
       "            [-0.0128784, 0.00656128, -0.010498, ..., -0.00585938, 0.0144653,\n",
       "             -0.0128784],\n",
       "            [0.000198364, -0.0186768, -0.0108643, ..., 0.00247192,\n",
       "             -0.00592041, 0.00262451]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.00674438, -0.00939941, 0.00112915, ..., 0.0203857,\n",
       "              0.0305176, -0.0172119],\n",
       "             [-0.00524902, -0.00127411, -0.000530243, ..., 0.0108643,\n",
       "              -0.00466919, -0.0246582],\n",
       "             [0.010376, 0.00631714, -0.0027771, ..., -0.00674438,\n",
       "              -0.00799561, -0.0102539],\n",
       "             ...,\n",
       "             [0.00122833, -0.00402832, -0.00463867, ..., -0.0218506,\n",
       "              -0.00674438, -0.0169678],\n",
       "             [-0.00430298, 0.0158691, 0.000427246, ..., -0.0294189,\n",
       "              -0.0150757, 0.00604248],\n",
       "             [-0.0109863, 0.00442505, -0.00222778, ..., -0.0107422,\n",
       "              -0.0148926, 0.0186768]],\n",
       "    \n",
       "            [[0.00337219, -0.000486374, -0.0088501, ..., 0.00762939,\n",
       "              -0.00402832, 0.0108643],\n",
       "             [-0.00244141, 0.00387573, 0.0030365, ..., -0.00344849,\n",
       "              -0.00680542, -0.0130615],\n",
       "             [0.00643921, 0.00616455, 0.00161743, ..., 0.0100708,\n",
       "              0.0103149, -0.00454712],\n",
       "             ...,\n",
       "             [-0.00386047, 0.0114746, -0.00744629, ..., -0.0088501,\n",
       "              0.00631714, -0.0159912],\n",
       "             [0.00177002, -0.00726318, -0.00494385, ..., 0.0281982,\n",
       "              -0.0115967, -0.00805664],\n",
       "             [0.000930786, 0.00125885, 0.00133514, ..., 0.00167847,\n",
       "              -0.00552368, 0.00396729]],\n",
       "    \n",
       "            [[-0.00102234, -0.00332642, -0.00708008, ..., 0.00823975,\n",
       "              0.0114136, -0.0198975],\n",
       "             [-0.00662231, -0.000305176, 0.00457764, ..., -0.0126953,\n",
       "              -0.000295639, -0.00274658],\n",
       "             [-0.00124359, -0.00379944, -0.0115967, ..., -0.00933838,\n",
       "              0.00291443, 0.0119019],\n",
       "             ...,\n",
       "             [-0.00244141, -0.00201416, -0.00436401, ..., 0.000804901,\n",
       "              -0.000679016, -0.000991821],\n",
       "             [-0.00778198, 0.00509644, -0.000511169, ..., -0.00164795,\n",
       "              0.0292969, -0.00363159],\n",
       "             [0.00439453, 0.00628662, 0.0012207, ..., 0.0239258,\n",
       "              -0.00927734, 0.0150757]],\n",
       "    \n",
       "            [[0.00778198, 0.00231934, 0.000440598, ..., -0.00187683,\n",
       "              0.00970459, -0.00708008],\n",
       "             [-0.000854492, -0.00570679, -0.00144958, ..., -0.0157471,\n",
       "              0.00242615, 0.00732422],\n",
       "             [7.18236e-06, 0.00305176, -0.000663757, ..., -0.00698853,\n",
       "              -0.00668335, 0.00396729],\n",
       "             ...,\n",
       "             [-0.00340271, -0.00296021, -0.00180054, ..., -0.00202942,\n",
       "              0.00219727, 0.0062561],\n",
       "             [0.00114441, 0.013855, -0.00430298, ..., 0.00982666,\n",
       "              0.0102539, -0.00127411],\n",
       "             [-0.00297546, 0.0055542, -0.000511169, ..., -0.0126953,\n",
       "              0.0126953, 0.000762939]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0123291, -0.019043, -0.000938416, ..., -0.012085,\n",
       "              -0.00598145, -0.0270996],\n",
       "             [-0.00466919, 0.00361633, -0.0106201, ..., -0.00704956,\n",
       "              0.00216675, 0.00595093],\n",
       "             [-0.00830078, -0.0166016, 0.00970459, ..., -0.00958252,\n",
       "              0.00500488, 0.00222778],\n",
       "             ...,\n",
       "             [0.00283813, 0.00418091, -0.013855, ..., 0.00769043,\n",
       "              -0.00460815, 0.0140991],\n",
       "             [0.0249023, 0.00836182, 0.0174561, ..., 0.00897217,\n",
       "              0.00994873, 0.00585938],\n",
       "             [-0.00350952, -0.00653076, 0.00184631, ..., -0.00119019,\n",
       "              -0.000522614, 0.000268936]],\n",
       "    \n",
       "            [[-0.0356445, -0.00549316, 0.00640869, ..., -0.00897217,\n",
       "              0.0236816, -0.0217285],\n",
       "             [0.00805664, 0.0100098, -0.00952148, ..., 0.00213623,\n",
       "              -0.00436401, 0.00759888],\n",
       "             [0.010498, 0.00735474, 0.0197754, ..., 0.00665283, 0.00543213,\n",
       "              0.0150146],\n",
       "             ...,\n",
       "             [-0.0111694, 0.00759888, -0.006073, ..., -0.0078125,\n",
       "              0.0131836, 0.00732422],\n",
       "             [0.0140991, -0.00793457, -0.000534058, ..., 0.000839233,\n",
       "              -0.000360489, 0.0101929],\n",
       "             [-0.00946045, 0.00323486, 0.00561523, ..., 0.00189209,\n",
       "              -0.00799561, 0.0134277]],\n",
       "    \n",
       "            [[0.00364685, -0.00891113, -0.0019989, ..., -0.0065918,\n",
       "              -0.00793457, -0.013916],\n",
       "             [-0.0114136, -0.00267029, -0.00186157, ..., 0.0175781,\n",
       "              -0.017334, -0.0195312],\n",
       "             [-0.00340271, -0.0125732, 0.00405884, ..., 0.0187988,\n",
       "              -0.00415039, 0.0107422],\n",
       "             ...,\n",
       "             [-0.00759888, -0.00188446, -0.013855, ..., 0.00241089,\n",
       "              0.000835419, 0.010498],\n",
       "             [-0.00610352, -0.0108032, -0.00122833, ..., -0.00110626,\n",
       "              0.0130005, 0.00259399],\n",
       "             [0.00866699, -0.00695801, 0.00643921, ..., -0.00262451,\n",
       "              0.0197754, -0.000831604]],\n",
       "    \n",
       "            [[0.00537109, -0.000865936, 0.0159912, ..., 0.00854492,\n",
       "              -0.00567627, 0.00119781],\n",
       "             [8.67844e-05, -0.0153198, 0.00169373, ..., 0.00759888,\n",
       "              0.00921631, -0.0244141],\n",
       "             [-0.0195312, -0.00909424, 0.0108643, ..., 0.0220947,\n",
       "              -0.00631714, 0.00352478],\n",
       "             ...,\n",
       "             [0.00927734, 0.0202637, 0.0117798, ..., -0.000455856,\n",
       "              0.00113678, 0.0098877],\n",
       "             [-0.00274658, -0.0112915, -0.000400543, ..., -0.0116577,\n",
       "              0.0201416, 0.000113487],\n",
       "             [0.00161743, -0.0112915, -0.0184326, ..., -0.0039978,\n",
       "              -0.00665283, 0.013916]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00778198, -0.00485229, 0.003479, ..., 0.0324707, 0.0151367,\n",
       "             0.0219727],\n",
       "            [-0.00166321, -0.00233459, 0.00817871, ..., 0.00318909,\n",
       "             0.0375977, 0.0115356],\n",
       "            [-0.00616455, 0.00466919, 0.00662231, ..., -0.00631714,\n",
       "             0.00361633, -0.00369263],\n",
       "            ...,\n",
       "            [-0.000177383, -0.00402832, 0.00665283, ..., -0.0227051,\n",
       "             0.0105591, -0.0251465],\n",
       "            [0.00994873, -0.0038147, -0.00872803, ..., -0.017334,\n",
       "             -0.00138092, 0.0163574],\n",
       "            [-0.00598145, -0.0020752, 0.00296021, ..., -0.024292,\n",
       "             -0.00387573, 0.010498]],\n",
       "    \n",
       "           [[-0.00799561, 0.00952148, -0.0043335, ..., 0.019165,\n",
       "             -0.00558472, 0.0039978],\n",
       "            [0.00189972, -0.00110626, -0.00457764, ..., 0.00221252,\n",
       "             0.020752, 0.0088501],\n",
       "            [-0.0163574, 0.00946045, 0.00289917, ..., 0.00289917,\n",
       "             0.00105286, 0.00106049],\n",
       "            ...,\n",
       "            [-0.000778198, -0.00294495, 0.00958252, ..., 0.00056076,\n",
       "             0.00637817, -0.0463867],\n",
       "            [0.0239258, -0.0043335, -0.0150757, ..., -0.0127563,\n",
       "             -6.96182e-05, -0.0140381],\n",
       "            [-0.00500488, 0.00250244, -0.00390625, ..., -0.0327148,\n",
       "             0.000206947, 0.0088501]],\n",
       "    \n",
       "           [[-0.00488281, 0.00671387, 0.00118256, ..., 0.0175781, 0.0300293,\n",
       "             -0.0106812],\n",
       "            [-0.00157166, -0.0126343, 0.00273132, ..., 0.000253677,\n",
       "             0.000637054, 0.00062561],\n",
       "            [-0.00101471, -0.00619507, -0.000482559, ..., -0.0341797,\n",
       "             -0.00878906, 0.0272217],\n",
       "            ...,\n",
       "            [0.0057373, 0.00389099, -0.00674438, ..., -0.0127563,\n",
       "             0.00346375, 0.0198975],\n",
       "            [0.0128174, 0.00836182, 0.0103149, ..., -0.00121307,\n",
       "             -0.00106049, 0.0158691],\n",
       "            [0.00271606, 0.000720978, 0.0016098, ..., -0.00366211,\n",
       "             -0.0395508, 0.0167236]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00671387, -0.000911713, -0.0136108, ..., -0.0098877,\n",
       "             0.0032196, -0.000701904],\n",
       "            [-0.00234985, -0.00231934, -0.010437, ..., -0.00469971,\n",
       "             -0.0120239, -0.00267029],\n",
       "            [-0.00717163, 0.00139618, -0.00640869, ..., -0.00119781,\n",
       "             0.00384521, -0.00158691],\n",
       "            ...,\n",
       "            [0.00756836, 0.0133057, -0.00592041, ..., -0.00634766,\n",
       "             0.00117493, 0.00216675],\n",
       "            [-0.00402832, 0.00775146, -0.00872803, ..., -0.00634766,\n",
       "             0.00352478, -0.00811768],\n",
       "            [-0.0022583, -0.0055542, -0.0203857, ..., 0.00473022,\n",
       "             0.00479126, 0.0180664]],\n",
       "    \n",
       "           [[-0.00173187, -0.0186768, -0.0128784, ..., -0.00250244,\n",
       "             -0.0202637, -0.0175781],\n",
       "            [-0.00848389, 0.00680542, 0.00460815, ..., -0.0262451,\n",
       "             0.0153198, -0.0071106],\n",
       "            [-0.00294495, 0.00176239, 0.00219727, ..., 0.000984192,\n",
       "             -0.0147705, -0.00854492],\n",
       "            ...,\n",
       "            [-0.00370789, 0.00656128, 0.00346375, ..., 0.0030365,\n",
       "             -0.0012207, 0.0101929],\n",
       "            [-0.00216675, -0.00531006, -9.65595e-06, ..., 0.0144653,\n",
       "             -0.00386047, -0.0120239],\n",
       "            [-0.00958252, 0.00279236, 0.00854492, ..., -0.00445557,\n",
       "             0.0270996, -0.00257874]],\n",
       "    \n",
       "           [[0.00133514, 0.00344849, 0.00378418, ..., 0.00921631, 0.0231934,\n",
       "             0.000178337],\n",
       "            [0.0137939, 0.00402832, -0.00288391, ..., -0.0119629, 0.0141602,\n",
       "             0.00787354],\n",
       "            [-0.000329971, 0.00411987, -0.00567627, ..., 0.0175781,\n",
       "             -0.00378418, 0.00300598],\n",
       "            ...,\n",
       "            [0.00576782, -0.00112152, -0.0088501, ..., -0.00698853,\n",
       "             0.0164795, 0.00506592],\n",
       "            [0.00564575, -0.00286865, 0.010376, ..., 0.0314941, -0.0150146,\n",
       "             -0.00866699],\n",
       "            [0.000617981, 7.77245e-05, 0.0101318, ..., 0.0169678,\n",
       "             0.00308228, 0.00891113]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.0110474, -0.00537109, 0.00787354, ..., 0.00279236,\n",
       "            -0.00376892, -0.00744629],\n",
       "           [0.012085, 0.000492096, 0.0119629, ..., -0.00466919, 0.012146,\n",
       "            -0.00171661],\n",
       "           [-0.00149536, -0.00811768, -0.000320435, ..., -0.0163574,\n",
       "            -0.00117493, 0.00952148],\n",
       "           ...,\n",
       "           [0.0105591, -0.00221252, 0.00518799, ..., -0.00506592,\n",
       "            -0.0078125, 0.00292969],\n",
       "           [-0.00994873, -0.00805664, 0.00418091, ..., -0.000709534,\n",
       "            -0.00823975, 0.000770569],\n",
       "           [-0.00421143, 0.00585938, 0.010437, ..., -0.000850677,\n",
       "            -0.00915527, -0.00823975]],\n",
       "   \n",
       "          [[0.00183868, -0.00198364, -0.00527954, ..., 0.00866699,\n",
       "            -0.00148773, -0.00239563],\n",
       "           [-0.00152588, 0.00976562, 0.00631714, ..., -0.000274658,\n",
       "            -0.0139771, -0.0090332],\n",
       "           [0.00512695, -0.00448608, -0.00224304, ..., -0.00793457,\n",
       "            0.00280762, -0.00411987],\n",
       "           ...,\n",
       "           [0.013916, -0.00714111, -0.00141144, ..., -0.0118408,\n",
       "            0.00379944, 0.00787354],\n",
       "           [-0.00224304, -0.00946045, -0.000938416, ..., -0.00250244,\n",
       "            -0.000972748, 0.0168457],\n",
       "           [-0.00402832, 0.00289917, 0.0022583, ..., -0.00723267,\n",
       "            0.00650024, -0.00430298]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.00448608, -0.00750732, 0.000961304, ..., -0.00720215,\n",
       "           -0.00308228, -0.00463867],\n",
       "          [0.0072937, -0.0126953, 0.00170898, ..., 0.00762939, 0.00668335,\n",
       "           -0.00415039],\n",
       "          [0.00726318, -0.00241089, -0.00753784, ..., 0.00952148,\n",
       "           0.00256348, -0.000511169],\n",
       "          ...,\n",
       "          [-0.00393677, -0.00762939, -0.010437, ..., -0.0071106,\n",
       "           -0.00775146, -0.00108337],\n",
       "          [0.00836182, -0.00994873, -0.00283813, ..., -0.00386047,\n",
       "           0.00262451, 0.00759888],\n",
       "          [-0.0126953, -0.00424194, 0.0045166, ..., 0.00787354, 0.0133057,\n",
       "           -0.00854492]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.882812, 0.957031, 0.742188, ..., 0.757812, 0.648438, 0.628906],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([1.14844, 1.125, 1.20312, ..., 1.07031, 1.04688, 0.898438],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.878906, 1.07812, 0.859375, ..., 0.964844, 0.373047, 0.929688],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.185547, -0.140625, -0.193359, ..., -0.111328, -0.271484,\n",
       "          -0.130859], dtype=bfloat16)}},\n",
       " 'layer_15': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.0168457, -0.00282288, -0.00848389, ..., -0.000402451,\n",
       "             0.00836182, 0.00297546],\n",
       "            [-0.000614166, -0.00144196, -0.0137329, ..., 0.0151978,\n",
       "             -0.0101318, -0.00854492],\n",
       "            [-0.0120239, -0.000213623, 0.0101318, ..., 0.0107422,\n",
       "             -0.00123596, 0.00125122],\n",
       "            ...,\n",
       "            [0.00402832, -8.44002e-05, -0.00552368, ..., -0.00778198,\n",
       "             0.0175781, 0.0107422],\n",
       "            [-0.000610352, 0.00182343, 0.00952148, ..., -0.00363159,\n",
       "             -0.0035553, 0.00653076],\n",
       "            [0.00115204, 0.00149536, 0.00094223, ..., 0.000331879,\n",
       "             -0.00921631, -0.0115967]],\n",
       "    \n",
       "           [[0.00964355, 0.00242615, 0.0151367, ..., -0.000629425,\n",
       "             0.0194092, -0.010437],\n",
       "            [0.00637817, -0.0272217, 0.00279236, ..., 0.00326538,\n",
       "             0.00588989, 8.05855e-05],\n",
       "            [0.0366211, -0.012207, -0.0181885, ..., 0.00311279, -0.00558472,\n",
       "             -0.00257874],\n",
       "            ...,\n",
       "            [0.012207, -0.00418091, -0.00692749, ..., -0.0189209,\n",
       "             0.000314713, -0.0322266],\n",
       "            [0.00848389, -0.00180817, 0.00202942, ..., -0.00561523,\n",
       "             -0.0185547, -0.0117188],\n",
       "            [-0.000291824, -0.0101318, 0.00212097, ..., -0.0181885,\n",
       "             0.0168457, 0.0027771]],\n",
       "    \n",
       "           [[-0.0294189, -0.017334, -0.0128784, ..., 0.00878906,\n",
       "             -0.00260925, 0.0148926],\n",
       "            [-0.000396729, -0.0090332, 0.0127563, ..., -0.0164795,\n",
       "             -0.00476074, -0.00689697],\n",
       "            [0.0030365, 0.0119629, -0.00891113, ..., 0.00854492,\n",
       "             -0.00178528, 0.00817871],\n",
       "            ...,\n",
       "            [-0.00112152, 0.000385284, 0.0012207, ..., 0.0174561,\n",
       "             -0.0101929, -0.0123901],\n",
       "            [-0.00195312, 0.0170898, -0.0115356, ..., 0.0123901, -0.0206299,\n",
       "             0.00714111],\n",
       "            [-0.020874, -0.00610352, -0.00704956, ..., -0.00130463,\n",
       "             -0.0114746, -0.0154419]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.000160217, 0.00378418, -0.00205994, ..., -0.0115356,\n",
       "             -0.00546265, 0.000394821],\n",
       "            [0.000583649, -0.00378418, -0.0238037, ..., -0.0062561,\n",
       "             -0.000118732, 0.0108643],\n",
       "            [-0.0158691, -0.019043, -0.00595093, ..., -0.00259399,\n",
       "             0.0192871, 0.00299072],\n",
       "            ...,\n",
       "            [-0.0114746, 0.00939941, -0.00909424, ..., -0.0103149,\n",
       "             -0.00100708, 0.0146484],\n",
       "            [0.012085, 0.0106201, -0.0164795, ..., -0.0213623, 0.00344849,\n",
       "             -0.00439453],\n",
       "            [-0.00756836, 0.00210571, 0.0174561, ..., 0.000762939, 0.010498,\n",
       "             -0.00174713]],\n",
       "    \n",
       "           [[0.00650024, -0.0157471, -0.00491333, ..., 0.00576782,\n",
       "             -0.0112305, 0.0142822],\n",
       "            [-0.00750732, -0.00418091, -0.00151062, ..., 0.00854492,\n",
       "             0.0119019, 0.00772095],\n",
       "            [0.000701904, 0.00153351, 0.00354004, ..., -0.00708008,\n",
       "             0.000659943, -0.0027771],\n",
       "            ...,\n",
       "            [0.0131226, 0.00128174, -0.00595093, ..., 0.00527954,\n",
       "             -0.0168457, -0.00643921],\n",
       "            [-0.000240326, -0.00805664, -0.0112305, ..., 0.00952148,\n",
       "             -0.00744629, -0.00817871],\n",
       "            [0.0195312, 0.00105286, 0.0105591, ..., 0.0164795, -0.0114136,\n",
       "             0.000831604]],\n",
       "    \n",
       "           [[-0.0111694, 0.0155029, 0.00958252, ..., -0.00132751, 0.0262451,\n",
       "             -0.0183105],\n",
       "            [0.00361633, 0.012085, -0.00445557, ..., -0.0174561, -0.0140991,\n",
       "             -0.0101929],\n",
       "            [-0.00546265, 0.00640869, 0.00332642, ..., 0.0133667,\n",
       "             0.00149536, 0.00162506],\n",
       "            ...,\n",
       "            [-0.00927734, -0.00698853, -0.00805664, ..., 0.00842285,\n",
       "             0.0115967, 0.015564],\n",
       "            [0.0185547, 0.00113678, 0.0134888, ..., -0.00811768, 0.00891113,\n",
       "             0.0218506],\n",
       "            [-0.0115356, 0.00744629, -0.0175781, ..., -0.000427246,\n",
       "             0.00393677, 0.0115356]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.00140381, -0.00793457, -0.0098877, ..., 0.00331116,\n",
       "              -0.0317383, 0.0133667],\n",
       "             [0.0025177, 0.00622559, -0.00466919, ..., 0.0270996,\n",
       "              -0.00500488, -0.0158691],\n",
       "             [0.00543213, 0.00257874, -0.0139771, ..., 0.00561523,\n",
       "              -0.0177002, -0.00506592],\n",
       "             ...,\n",
       "             [0.00521851, 6.91414e-05, 0.00297546, ..., 0.0257568,\n",
       "              0.0149536, -0.0114136],\n",
       "             [-0.00285339, -0.00704956, -0.00491333, ..., 0.000789642,\n",
       "              0.0239258, 0.0136719],\n",
       "             [-0.00640869, 0.00297546, 0.00335693, ..., -0.0230713,\n",
       "              0.0157471, 0.00848389]],\n",
       "    \n",
       "            [[-0.00714111, -0.00170135, -0.00370789, ..., -0.00292969,\n",
       "              -0.0194092, 0.0212402],\n",
       "             [-0.00619507, -0.0107422, 0.00166321, ..., 0.00170898,\n",
       "              -0.0090332, 0.000923157],\n",
       "             [0.00524902, -0.00787354, -0.010498, ..., -0.00185394,\n",
       "              -0.017334, -0.00233459],\n",
       "             ...,\n",
       "             [0.00811768, -0.00765991, 0.0039978, ..., -0.00151825,\n",
       "              0.00193787, 0.00933838],\n",
       "             [0.00616455, -0.0065918, 0.00285339, ..., -0.00540161,\n",
       "              -0.0112305, -0.012207],\n",
       "             [0.00637817, -0.00643921, -0.00552368, ..., 0.00405884,\n",
       "              -0.00695801, -0.0013504]],\n",
       "    \n",
       "            [[0.00396729, -0.0071106, 0.00131226, ..., -0.0266113,\n",
       "              0.0129395, -0.00921631],\n",
       "             [-0.0117798, -0.00102997, -0.00939941, ..., 0.0166016,\n",
       "              -0.017334, -0.0189209],\n",
       "             [-0.00656128, -0.0123901, -0.000701904, ..., 0.00279236,\n",
       "              0.0203857, 0.0144043],\n",
       "             ...,\n",
       "             [-0.00656128, -0.00592041, -0.00167084, ..., -0.0230713,\n",
       "              0.00202942, -0.00631714],\n",
       "             [-0.00110626, 0.010376, -0.00650024, ..., -0.000541687,\n",
       "              0.0262451, -0.0327148],\n",
       "             [0.00268555, -0.00405884, -0.0144653, ..., 0.0126953,\n",
       "              0.0219727, -0.00186157]],\n",
       "    \n",
       "            [[-0.00193787, -0.00332642, -0.00141144, ..., -0.0227051,\n",
       "              -0.019165, -0.00735474],\n",
       "             [0.00753784, -0.000900269, 0.00686646, ..., 0.00153351,\n",
       "              -0.0019455, -0.0256348],\n",
       "             [0.00114441, -0.00747681, -0.0183105, ..., -0.00665283,\n",
       "              0.020752, 0.000352859],\n",
       "             ...,\n",
       "             [-0.00366211, 0.00704956, 0.0194092, ..., -0.0124512,\n",
       "              0.0112305, 0.00970459],\n",
       "             [-0.00210571, 0.00656128, -0.0100098, ..., -0.00274658,\n",
       "              -0.0106201, -0.00515747],\n",
       "             [-0.00190735, 0.00151825, 0.0144043, ..., 0.0181885,\n",
       "              0.00300598, -0.0183105]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00549316, -0.000341415, 0.00297546, ..., -0.0134277,\n",
       "              0.000637054, -0.0101318],\n",
       "             [-0.0123901, -0.0050354, 0.00540161, ..., 0.00836182,\n",
       "              0.00595093, -0.0101318],\n",
       "             [-0.00756836, 0.0131226, -0.000322342, ..., 0.0100708,\n",
       "              -0.00823975, -0.00248718],\n",
       "             ...,\n",
       "             [0.0183105, 0.00466919, -0.00485229, ..., 0.00326538,\n",
       "              -0.012146, 0.0142212],\n",
       "             [-0.00744629, -0.0186768, -0.00212097, ..., 0.017334,\n",
       "              0.00708008, -0.0222168],\n",
       "             [-0.00842285, -0.00534058, -0.00109863, ..., -0.00460815,\n",
       "              0.017334, -0.00087738]],\n",
       "    \n",
       "            [[-0.0166016, -0.00775146, 0.00352478, ..., -0.0125122,\n",
       "              -0.00613403, -0.00637817],\n",
       "             [-0.0219727, -0.0236816, 0.0327148, ..., -0.0088501,\n",
       "              -0.0153198, -0.0180664],\n",
       "             [-0.00466919, 0.00337219, 0.00866699, ..., -0.0116577,\n",
       "              0.0120239, 0.00558472],\n",
       "             ...,\n",
       "             [-0.000896454, -0.00153351, -0.00139618, ..., 0.00460815,\n",
       "              0.0177002, -0.0118408],\n",
       "             [-0.000135422, 0.00509644, 0.00958252, ..., -0.0203857,\n",
       "              4.29153e-05, -0.0111694],\n",
       "             [0.00939941, 0.00479126, -0.0072937, ..., 0.0129395,\n",
       "              0.0184326, -0.00151062]],\n",
       "    \n",
       "            [[0.00842285, 0.00534058, 0.0116577, ..., -0.00585938,\n",
       "              -0.00656128, -0.0057373],\n",
       "             [-0.0112915, 0.0100098, -0.0231934, ..., 0.00686646,\n",
       "              0.0115356, 0.0180664],\n",
       "             [-0.00485229, 0.00282288, 0.0218506, ..., -0.0037384,\n",
       "              -0.00619507, 0.0110474],\n",
       "             ...,\n",
       "             [-0.0166016, 0.010376, -0.00830078, ..., 0.00567627,\n",
       "              -0.00173187, 0.000255585],\n",
       "             [0.0124512, 0.006073, 0.0107422, ..., 0.0100098, 0.00104523,\n",
       "              0.0101318],\n",
       "             [-0.0175781, 0.00692749, -0.00769043, ..., -0.00921631,\n",
       "              -0.00897217, 0.000991821]],\n",
       "    \n",
       "            [[0.000105858, -0.000778198, -0.00296021, ..., -0.00613403,\n",
       "              0.00473022, -0.0202637],\n",
       "             [0.017334, 0.00811768, -0.00634766, ..., -0.000999451,\n",
       "              0.0214844, 0.00150299],\n",
       "             [0.00546265, 0.00154114, -0.0119019, ..., -0.00312805,\n",
       "              -3.86238e-05, -0.00640869],\n",
       "             ...,\n",
       "             [-0.00230408, -0.0150146, 0.0177002, ..., 0.0027771,\n",
       "              -0.0184326, -0.0180664],\n",
       "             [0.00101471, -0.0164795, -0.00289917, ..., 0.0162354,\n",
       "              0.00650024, 0.00527954],\n",
       "             [-0.0236816, -0.0136108, 0.00946045, ..., 0.00125122,\n",
       "              0.0147095, -0.00994873]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00256348, 0.00549316, 0.00212097, ..., -0.0311279,\n",
       "             -0.050293, 0.0174561],\n",
       "            [-0.00634766, 0.00346375, 0.00292969, ..., 0.00616455,\n",
       "             -0.032959, 0.0307617],\n",
       "            [0.00218201, -0.00286865, 0.00202942, ..., 0.00866699,\n",
       "             -0.00686646, -0.0062561],\n",
       "            ...,\n",
       "            [0.0032196, 0.00312805, 0.000907898, ..., 0.0311279,\n",
       "             -0.00122833, -0.00927734],\n",
       "            [0.00102997, 0.00021553, -0.00421143, ..., -0.00878906,\n",
       "             0.00964355, 0.00279236],\n",
       "            [0.00112152, 0.0032959, -0.00160217, ..., -0.00436401,\n",
       "             0.0371094, -0.0268555]],\n",
       "    \n",
       "           [[0.0116577, -0.00552368, -0.00335693, ..., 0.00497437,\n",
       "             0.00177765, 0.000587463],\n",
       "            [-0.00518799, 0.0101929, -0.000181198, ..., -0.00878906,\n",
       "             -0.012085, -0.00154877],\n",
       "            [-0.0245361, -0.00576782, 0.00897217, ..., 0.00695801,\n",
       "             -0.0022583, -0.000181198],\n",
       "            ...,\n",
       "            [0.000816345, -0.00588989, -0.00190735, ..., 0.0035553,\n",
       "             0.0111084, 0.00213623],\n",
       "            [0.00482178, 0.00558472, 0.00921631, ..., 0.00141907,\n",
       "             0.00289917, 0.000244141],\n",
       "            [0.0238037, -0.0123291, -0.0181885, ..., 0.012085, -0.00595093,\n",
       "             -0.0159912]],\n",
       "    \n",
       "           [[-0.0010376, 0.0113525, 0.00588989, ..., 0.0227051, 0.00515747,\n",
       "             0.0127563],\n",
       "            [0.00479126, 0.001297, 0.00308228, ..., 0.0187988, -0.00601196,\n",
       "             0.0072937],\n",
       "            [0.00034523, 0.0140991, 0.00631714, ..., -0.0266113, 0.00291443,\n",
       "             0.0090332],\n",
       "            ...,\n",
       "            [0.0072937, -0.0122681, -0.00286865, ..., 0.00171661,\n",
       "             0.00430298, 0.00497437],\n",
       "            [0.00118256, 0.0098877, 0.00205994, ..., 0.00656128, 0.00418091,\n",
       "             -0.0109863],\n",
       "            [0.00025177, 0.00189209, -0.0101318, ..., 0.00823975,\n",
       "             -0.000272751, 0.0239258]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00241089, 0.00402832, 0.00317383, ..., -0.0456543,\n",
       "             0.00854492, -0.0238037],\n",
       "            [-0.00170135, 0.0115356, -0.00216675, ..., 0.0505371, 0.0230713,\n",
       "             0.0183105],\n",
       "            [-0.00153351, -0.00799561, -0.00222778, ..., 0.0229492,\n",
       "             -0.0187988, 0.0422363],\n",
       "            ...,\n",
       "            [0.00188446, 0.00619507, -0.00326538, ..., -0.0598145,\n",
       "             -0.0125732, 0.00125122],\n",
       "            [4.22001e-05, -0.00245667, 0.00946045, ..., -0.000888824,\n",
       "             -0.00411987, 0.027832],\n",
       "            [-0.00154877, -0.00656128, 0.0062561, ..., 0.0183105, 0.0108032,\n",
       "             -0.0137939]],\n",
       "    \n",
       "           [[0.0170898, -0.00360107, 0.00909424, ..., -0.0106201,\n",
       "             -0.00704956, 0.00317383],\n",
       "            [-0.0119629, -0.0169678, -0.00222778, ..., 0.00102234,\n",
       "             0.0114746, -0.00958252],\n",
       "            [-0.000522614, -0.00601196, -0.0280762, ..., 0.0162354,\n",
       "             -0.00257874, 0.0100098],\n",
       "            ...,\n",
       "            [-0.0012207, 0.00994873, 0.00656128, ..., -0.00227356,\n",
       "             -0.00101471, 0.00274658],\n",
       "            [-0.00680542, 0.00396729, -0.0150757, ..., 0.0140991,\n",
       "             -0.00317383, -0.0133667],\n",
       "            [-0.00564575, -0.00387573, 0.0308838, ..., 0.00976562,\n",
       "             -0.00460815, -0.00328064]],\n",
       "    \n",
       "           [[0.00421143, 0.000881195, 0.00094986, ..., 0.0126953,\n",
       "             0.00177002, -0.0185547],\n",
       "            [-0.00616455, 0.00248718, -0.00100708, ..., 0.00296021,\n",
       "             0.0209961, -0.0461426],\n",
       "            [-0.00259399, 0.00366211, 0.000778198, ..., -0.0133057,\n",
       "             0.0110474, -0.00830078],\n",
       "            ...,\n",
       "            [-0.00154877, -0.00187683, 0.00184631, ..., -0.0172119,\n",
       "             -0.0142822, -0.0283203],\n",
       "            [0.00585938, -0.0010376, 0.00527954, ..., 0.00540161,\n",
       "             -0.00787354, -0.013916],\n",
       "            [-0.0019989, 0.00224304, -0.00396729, ..., 0.00744629,\n",
       "             -0.00343323, 0.00250244]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.0158691, -0.00306702, -0.0169678, ..., -0.00346375,\n",
       "            -0.00723267, 0.0071106],\n",
       "           [0.00154114, 0.0124512, -0.00494385, ..., -0.0050354,\n",
       "            0.00292969, 0.00830078],\n",
       "           [0.00976562, 0.0098877, 0.00415039, ..., 0.00436401, 0.00518799,\n",
       "            0.00274658],\n",
       "           ...,\n",
       "           [0.00238037, -0.00686646, -0.00427246, ..., -0.00216675,\n",
       "            -0.00653076, -0.00130463],\n",
       "           [0.0108032, -0.00337219, 0.00323486, ..., -0.00646973,\n",
       "            -0.00509644, 0.00180817],\n",
       "           [0.00248718, -0.0102539, -0.000656128, ..., 0.006073,\n",
       "            0.00549316, -0.0161133]],\n",
       "   \n",
       "          [[0.00247192, -0.000621796, 0.0150146, ..., 0.00136566,\n",
       "            -0.00390625, -0.00204468],\n",
       "           [-0.0035553, -0.00488281, -0.000709534, ..., 0.0038147,\n",
       "            0.0020752, -0.00534058],\n",
       "           [0.00165558, 0.000364304, 0.00063324, ..., -0.00494385,\n",
       "            -0.012146, -0.00248718],\n",
       "           ...,\n",
       "           [-0.0127563, -0.00415039, 0.000648499, ..., -0.00117493,\n",
       "            0.00454712, -0.00260925],\n",
       "           [-0.00787354, -0.00140381, 0.00805664, ..., 0.00994873,\n",
       "            -0.00527954, 0.00239563],\n",
       "           [-0.0130615, 0.00297546, 0.0130615, ..., -0.00296021,\n",
       "            0.00732422, 0.0103149]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.00221252, -0.00897217, -0.00634766, ..., -0.0098877,\n",
       "           0.000938416, 0.00341797],\n",
       "          [0.00756836, 0.0078125, -0.00595093, ..., 0.00372314, -0.00233459,\n",
       "           -0.00744629],\n",
       "          [0.00286865, -0.000667572, -0.00567627, ..., -0.000865936,\n",
       "           -0.00744629, 0.00106049],\n",
       "          ...,\n",
       "          [-0.000312805, 0.00146484, -4.26769e-05, ..., -0.00289917,\n",
       "           0.00549316, -0.0110474],\n",
       "          [-0.00363159, 0.000465393, -0.00878906, ..., 0.00512695,\n",
       "           -0.0153198, -0.00315857],\n",
       "          [-0.00222778, 0.0050354, -0.000159264, ..., 0.000162125,\n",
       "           -0.00457764, -0.00518799]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([1.125, 1.09375, 1.17969, ..., 1.22656, 0.921875, 0.847656],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([1.42188, 1.45312, 1.50781, ..., 1.46094, 1.53125, 1.23438],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.589844, 0.570312, 0.498047, ..., 0.628906, 0.259766, 0.570312],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.176758, -0.133789, -0.176758, ..., -0.145508, -0.251953,\n",
       "          -0.133789], dtype=bfloat16)}},\n",
       " 'layer_16': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.00282288, -0.00491333, 0.00744629, ..., -0.013855,\n",
       "             -0.0124512, 0.00215149],\n",
       "            [-0.00564575, 0.00302124, 0.00509644, ..., -0.00497437,\n",
       "             -0.00494385, 0.0125122],\n",
       "            [0.0194092, -0.017334, -0.0115967, ..., -0.006073, -0.000450134,\n",
       "             0.00485229],\n",
       "            ...,\n",
       "            [-0.00531006, 0.00254822, 0.00154114, ..., 0.00196838,\n",
       "             -0.00180054, -0.00136566],\n",
       "            [-0.00259399, -0.0110474, 0.0270996, ..., 0.0019989, 0.0102539,\n",
       "             -0.0157471],\n",
       "            [0.00411987, -0.0177002, 0.00878906, ..., -0.000873566,\n",
       "             -0.0050354, 0.00320435]],\n",
       "    \n",
       "           [[-0.00143433, -0.00588989, 0.00817871, ..., -0.00421143,\n",
       "             -0.00512695, -0.0218506],\n",
       "            [0.00524902, -0.00442505, 0.00817871, ..., 0.00163269,\n",
       "             -0.00509644, 0.00558472],\n",
       "            [-0.00939941, -0.012207, 0.0101318, ..., 0.00460815, 0.00267029,\n",
       "             -0.00497437],\n",
       "            ...,\n",
       "            [0.00567627, 0.0126953, -0.00714111, ..., -0.0122681, 0.0314941,\n",
       "             -0.00326538],\n",
       "            [0.0151978, 0.00338745, -0.00497437, ..., 0.00830078,\n",
       "             -0.000114918, 0.0129395],\n",
       "            [0.00698853, 0.0189209, 0.000946045, ..., 0.00233459,\n",
       "             0.00976562, 0.0116577]],\n",
       "    \n",
       "           [[-0.0131836, 0.020874, 0.0127563, ..., -0.00842285, -0.043457,\n",
       "             0.0125122],\n",
       "            [-0.00585938, 0.00543213, -0.00250244, ..., -0.00878906,\n",
       "             0.00811768, -0.00179291],\n",
       "            [0.00897217, 0.0322266, -0.0128784, ..., -0.0249023, -0.0395508,\n",
       "             0.00479126],\n",
       "            ...,\n",
       "            [0.017334, -0.017334, -0.00921631, ..., -0.0115967, 0.00117493,\n",
       "             0.0137939],\n",
       "            [-0.00515747, 0.0117188, 0.00643921, ..., -0.0098877,\n",
       "             -0.0178223, 0.00735474],\n",
       "            [0.0349121, 0.0117798, -0.0339355, ..., -0.00183105, 0.00245667,\n",
       "             -0.0153198]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00193787, 0.00515747, 0.0117188, ..., -0.0144653,\n",
       "             -0.00613403, 0.0192871],\n",
       "            [0.00518799, 0.00744629, 0.00231934, ..., -0.00909424,\n",
       "             -0.0230713, -0.0112915],\n",
       "            [-0.00222778, 0.00460815, 0.0135498, ..., 0.0150757, 0.00231934,\n",
       "             -0.00358582],\n",
       "            ...,\n",
       "            [-0.00500488, 0.00720215, 0.017334, ..., -0.00994873,\n",
       "             -0.0158691, 0.0098877],\n",
       "            [-0.012146, 0.00671387, 0.00982666, ..., -0.0267334,\n",
       "             -0.00148773, -0.000459671],\n",
       "            [-0.00799561, -0.00622559, 0.000614166, ..., 0.0137329,\n",
       "             0.00665283, -0.00921631]],\n",
       "    \n",
       "           [[0.00117493, 0.00332642, -0.00921631, ..., 0.00982666,\n",
       "             0.00192261, 0.00106812],\n",
       "            [-0.0172119, 0.00393677, 0.00695801, ..., 0.0105591, 0.0020752,\n",
       "             0.000473022],\n",
       "            [-0.012146, -0.0144043, 0.00328064, ..., 0.0178223, 0.00897217,\n",
       "             0.00221252],\n",
       "            ...,\n",
       "            [0.0030365, -0.000972748, -0.000484467, ..., 0.00643921,\n",
       "             0.00994873, 0.00952148],\n",
       "            [-0.00668335, 0.00747681, 0.0286865, ..., -0.0038147,\n",
       "             -0.0128784, -0.00306702],\n",
       "            [0.00491333, 0.00222778, 0.00616455, ..., -0.0129395, 0.0119019,\n",
       "             0.00982666]],\n",
       "    \n",
       "           [[-0.0157471, -0.0125122, -0.00671387, ..., -0.00466919,\n",
       "             0.0111084, 0.0144043],\n",
       "            [0.00190735, 0.00411987, 0.0039978, ..., 0.000326157,\n",
       "             -0.00102997, 0.0220947],\n",
       "            [-0.00637817, 0.00656128, 0.0111694, ..., -0.00976562,\n",
       "             -0.00408936, -0.0157471],\n",
       "            ...,\n",
       "            [-0.00650024, 0.015625, -0.000671387, ..., 0.00720215,\n",
       "             -9.77516e-06, -0.00872803],\n",
       "            [-0.00202942, -0.000404358, -0.0201416, ..., 0.00650024,\n",
       "             -0.000720978, -0.0175781],\n",
       "            [0.00595093, -0.00958252, -0.0264893, ..., 0.00215149,\n",
       "             -0.00653076, 0.017334]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.00704956, -0.000284195, 0.00430298, ..., 0.0123901,\n",
       "              -0.000141144, -0.0114746],\n",
       "             [-0.00708008, -0.00482178, 0.00476074, ..., 0.0172119,\n",
       "              0.0106812, 0.00723267],\n",
       "             [0.00726318, 0.000553131, 0.00622559, ..., 0.0166016,\n",
       "              0.00811768, -0.00124359],\n",
       "             ...,\n",
       "             [-0.000476837, -0.000751495, 0.00970459, ..., 0.0110474,\n",
       "              -0.00360107, -0.034668],\n",
       "             [0.00276184, 0.00101471, 0.00370789, ..., -0.00848389,\n",
       "              -0.0205078, -0.00662231],\n",
       "             [0.00242615, -0.000389099, 0.00601196, ..., -0.0159912,\n",
       "              -0.00442505, -0.0192871]],\n",
       "    \n",
       "            [[-0.00245667, 0.00866699, -0.00540161, ..., -0.00145721,\n",
       "              0.00454712, -0.00120544],\n",
       "             [-0.000175476, -0.00390625, 0.00744629, ..., 0.0123901,\n",
       "              0.0140381, 0.0039978],\n",
       "             [0.00817871, 0.00476074, -0.003479, ..., 0.0159912,\n",
       "              -0.00436401, 0.0203857],\n",
       "             ...,\n",
       "             [0.0016098, 0.0039978, 0.00756836, ..., -0.00549316,\n",
       "              0.00405884, -0.000831604],\n",
       "             [-0.00778198, -0.00656128, -0.00500488, ..., -0.00848389,\n",
       "              0.00238037, -0.00318909],\n",
       "             [-0.00187683, 0.00558472, 0.0043335, ..., -0.00274658,\n",
       "              0.00473022, -0.00309753]],\n",
       "    \n",
       "            [[0.0101318, 0.00640869, 0.00442505, ..., 0.0222168, 0.020752,\n",
       "              0.00616455],\n",
       "             [-0.00558472, -0.00683594, 0.00334167, ..., -0.0155029,\n",
       "              -0.00762939, 0.00582886],\n",
       "             [0.000717163, -0.00173187, -0.00613403, ..., 0.00860596,\n",
       "              0.00239563, -0.0110474],\n",
       "             ...,\n",
       "             [0.00334167, 0.00151062, -0.00445557, ..., 0.0144043,\n",
       "              0.0123901, 0.00488281],\n",
       "             [-0.00759888, 0.00105286, -0.00179291, ..., -0.0170898,\n",
       "              0.00157928, -0.00204468],\n",
       "             [0.0018158, -0.00358582, 0.000831604, ..., 0.006073,\n",
       "              0.0043335, -0.0106812]],\n",
       "    \n",
       "            [[-0.00075531, 0.00386047, -0.000291824, ..., 0.0132446,\n",
       "              0.00546265, -0.0206299],\n",
       "             [0.000185966, -0.0109253, 0.00159454, ..., -0.0214844,\n",
       "              -0.0129395, 0.00195312],\n",
       "             [0.00187683, 0.00132751, 0.00144958, ..., -0.0198975,\n",
       "              -0.0157471, 0.0126953],\n",
       "             ...,\n",
       "             [0.00830078, 0.0016861, -0.00170135, ..., -0.0151367,\n",
       "              0.0220947, -0.0252686],\n",
       "             [-0.00271606, 0.00411987, -0.00102234, ..., -0.00106812,\n",
       "              -0.0228271, 0.0198975],\n",
       "             [-0.00382996, 0.000243187, -0.0101318, ..., 0.00579834,\n",
       "              0.0114136, 0.00102997]]],\n",
       "    \n",
       "    \n",
       "           [[[0.000991821, -0.0109253, 0.0150757, ..., -0.00259399,\n",
       "              0.00674438, 0.00927734],\n",
       "             [-0.00233459, -0.00285339, -0.00393677, ..., 0.00769043,\n",
       "              -0.0151367, -0.00622559],\n",
       "             [-0.00185394, 0.0189209, -0.00254822, ..., -0.00680542,\n",
       "              0.00386047, 0.0187988],\n",
       "             ...,\n",
       "             [-0.00723267, 0.0114136, 0.00976562, ..., -0.00537109,\n",
       "              0.0126343, 0.0112915],\n",
       "             [-0.019043, -0.00622559, -0.00521851, ..., 0.00193787,\n",
       "              -0.0032959, -0.000301361],\n",
       "             [-0.0227051, -0.0105591, 0.0050354, ..., 0.00457764,\n",
       "              0.00628662, 0.0108032]],\n",
       "    \n",
       "            [[-0.000839233, -0.00549316, 0.00153351, ..., -0.00735474,\n",
       "              0.00341797, -0.0142212],\n",
       "             [-0.0107422, -0.0117188, -0.00230408, ..., -0.0187988,\n",
       "              -0.0150757, -0.00823975],\n",
       "             [-0.0195312, -0.00132751, 0.00476074, ..., 0.00186157,\n",
       "              0.0125122, 0.0189209],\n",
       "             ...,\n",
       "             [-0.00634766, 0.0158691, 0.00257874, ..., 0.0106201,\n",
       "              0.0137939, -0.0246582],\n",
       "             [0.0142822, -0.0111694, 0.00439453, ..., -0.00358582,\n",
       "              0.00830078, 0.00268555],\n",
       "             [-0.00224304, 0.0202637, 0.00302124, ..., -0.0172119,\n",
       "              -0.000915527, 0.00689697]],\n",
       "    \n",
       "            [[-0.00454712, -0.00282288, -0.00366211, ..., 0.00552368,\n",
       "              -0.00337219, -0.00427246],\n",
       "             [-0.00256348, 0.0103149, 0.00775146, ..., 0.0098877,\n",
       "              0.00631714, -0.0144043],\n",
       "             [-0.000759125, 0.00662231, 1.61678e-06, ..., -0.00506592,\n",
       "              0.0108643, 0.00312805],\n",
       "             ...,\n",
       "             [-0.0150146, -0.00585938, 0.012207, ..., -0.00254822,\n",
       "              -0.0148315, 0.0106812],\n",
       "             [-0.00509644, -0.0270996, 0.00778198, ..., -0.0050354,\n",
       "              -0.00872803, 0.0203857],\n",
       "             [0.00382996, 0.00024128, 0.00866699, ..., -0.0174561,\n",
       "              0.0115356, -0.00173187]],\n",
       "    \n",
       "            [[-0.0106812, -0.00576782, -0.00564575, ..., 0.00308228,\n",
       "              -0.00747681, 0.0130615],\n",
       "             [-0.0217285, -0.00244141, -0.00640869, ..., 0.010437,\n",
       "              0.000126839, -0.000383377],\n",
       "             [0.0146484, -0.00144958, 0.0111694, ..., -0.00176239,\n",
       "              -0.00291443, -0.0114746],\n",
       "             ...,\n",
       "             [0.00244141, 0.00311279, -0.00141907, ..., -0.00231934,\n",
       "              -0.00619507, 0.00421143],\n",
       "             [-0.00202942, 0.0172119, -0.000196457, ..., 0.0161133,\n",
       "              -0.00619507, -0.00909424],\n",
       "             [0.0167236, 0.0112305, -0.00836182, ..., -0.00588989,\n",
       "              -0.00714111, 0.00491333]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00270081, -0.0148926, 0.013916, ..., 0.00193024, 0.0117798,\n",
       "             0.0299072],\n",
       "            [0.010376, -0.00279236, -0.00582886, ..., -0.0109863, 0.0164795,\n",
       "             -0.0249023],\n",
       "            [-0.00576782, -0.00265503, 0.00540161, ..., 0.0234375,\n",
       "             0.00732422, -0.0114136],\n",
       "            ...,\n",
       "            [0.00775146, -0.000617981, -0.000740051, ..., 0.0142822,\n",
       "             0.0339355, 0.0218506],\n",
       "            [0.00209045, -0.00174713, 0.00188446, ..., -0.0200195,\n",
       "             -0.0012207, 0.012207],\n",
       "            [0.012207, 0.00205994, 0.00613403, ..., 0.00343323, 0.0114746,\n",
       "             0.00848389]],\n",
       "    \n",
       "           [[-0.00830078, -8.10623e-05, 0.0101929, ..., -0.00747681,\n",
       "             0.00631714, 0.0177002],\n",
       "            [0.00915527, -0.00598145, -0.00964355, ..., -0.0166016,\n",
       "             0.0205078, -0.0358887],\n",
       "            [-0.00662231, 0.00585938, 0.001297, ..., 0.0154419, 0.0153198,\n",
       "             -0.0192871],\n",
       "            ...,\n",
       "            [0.00714111, 0.00769043, -0.00180054, ..., 0.017334, 0.0100098,\n",
       "             0.0227051],\n",
       "            [-0.0155029, -0.00497437, 0.0247803, ..., -0.0112915,\n",
       "             0.00169373, 0.000591278],\n",
       "            [0.00994873, -0.00152588, 0.000804901, ..., 0.00300598,\n",
       "             0.0019455, -0.00836182]],\n",
       "    \n",
       "           [[-0.00683594, 0.0025177, 0.00325012, ..., -0.00735474,\n",
       "             -0.0123291, -0.0153198],\n",
       "            [0.00302124, -0.00765991, -0.0016098, ..., 0.013916,\n",
       "             -0.00473022, 0.0172119],\n",
       "            [0.00291443, -0.00601196, -0.0109253, ..., 0.0132446,\n",
       "             -0.00662231, -0.00759888],\n",
       "            ...,\n",
       "            [0.00112152, -0.00186157, 0.00775146, ..., 0.019043, 0.0016861,\n",
       "             -0.0233154],\n",
       "            [-0.0038147, -0.00389099, -0.00540161, ..., 0.0090332,\n",
       "             -0.000778198, 0.00187683],\n",
       "            [-0.00239563, 0.00328064, -0.00799561, ..., -0.0111694,\n",
       "             -0.00866699, 0.0128784]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.000705719, 0.0032196, 0.00668335, ..., 0.0239258,\n",
       "             -0.00741577, 0.00108337],\n",
       "            [0.00595093, -0.0234375, 0.0124512, ..., -0.00680542,\n",
       "             -0.00762939, 0.0169678],\n",
       "            [0.00714111, -0.00320435, 0.00866699, ..., -0.0288086, 0.013916,\n",
       "             0.0187988],\n",
       "            ...,\n",
       "            [-0.00174713, 0.0055542, 0.00619507, ..., -0.00154877,\n",
       "             0.00631714, -0.00063324],\n",
       "            [0.00671387, -0.000444412, -0.0018692, ..., -0.00598145,\n",
       "             -0.0166016, 0.0166016],\n",
       "            [0.00415039, 0.00720215, -0.000312805, ..., -0.00512695,\n",
       "             0.0055542, -0.019043]],\n",
       "    \n",
       "           [[-0.015625, 0.00430298, 0.00805664, ..., 0.024292, -0.0214844,\n",
       "             -0.00765991],\n",
       "            [0.00588989, 0.00369263, -0.0110474, ..., -0.0354004,\n",
       "             0.00799561, -0.0194092],\n",
       "            [0.00387573, 0.00164795, 0.0109253, ..., -0.000648499,\n",
       "             -0.0291748, 0.00759888],\n",
       "            ...,\n",
       "            [-0.012146, 0.00750732, -0.00280762, ..., 0.00714111,\n",
       "             -0.00312805, 0.00750732],\n",
       "            [0.00210571, -0.000339508, 0.0101929, ..., 0.00622559,\n",
       "             -0.00350952, -0.00479126],\n",
       "            [-0.00662231, 0.000377655, -0.00101471, ..., -0.0142822,\n",
       "             0.0235596, 0.001091]],\n",
       "    \n",
       "           [[-0.0078125, 0.00811768, 0.00311279, ..., 0.00328064,\n",
       "             -0.0522461, -0.029541],\n",
       "            [-0.0110474, 0.0152588, -0.000161171, ..., -0.0167236,\n",
       "             -0.0143433, -0.0122681],\n",
       "            [0.000170708, 0.00405884, 0.000545502, ..., 0.000583649,\n",
       "             -0.0272217, 0.0130615],\n",
       "            ...,\n",
       "            [-0.0145874, 0.00396729, 0.000488281, ..., -0.0112305,\n",
       "             0.0038147, -0.00448608],\n",
       "            [0.0116577, 0.00285339, 0.00130463, ..., -0.00325012, 0.029541,\n",
       "             -0.0187988],\n",
       "            [-0.0133667, 0.0126343, 0.019165, ..., -0.0169678, 0.0198975,\n",
       "             -0.013916]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.00106049, -0.0136108, -0.00315857, ..., 0.00205994,\n",
       "            0.0202637, -0.00112915],\n",
       "           [-0.00866699, 0.00778198, 0.00350952, ..., 0.00312805,\n",
       "            -0.00454712, 0.012146],\n",
       "           [0.00958252, -0.00154877, -0.0101318, ..., 0.00415039,\n",
       "            -0.00650024, 0.00376892],\n",
       "           ...,\n",
       "           [-0.0108643, -0.00299072, 0.012085, ..., 0.00637817,\n",
       "            -0.00457764, 0.00167084],\n",
       "           [0.0065918, 0.0032196, 0.00130463, ..., 0.00878906, -0.00418091,\n",
       "            0.0067749],\n",
       "           [0.00309753, -0.0119629, -0.00732422, ..., -0.00280762,\n",
       "            0.00454712, 0.000349045]],\n",
       "   \n",
       "          [[0.00952148, -0.0090332, 0.0032196, ..., -0.00366211,\n",
       "            -0.00823975, 0.00186157],\n",
       "           [0.00927734, -0.000930786, 0.0142822, ..., 0.00188446,\n",
       "            0.00306702, -0.0157471],\n",
       "           [-0.00341797, -0.00379944, -0.00598145, ..., 0.00582886,\n",
       "            0.0147095, -0.00708008],\n",
       "           ...,\n",
       "           [0.0016861, 0.00259399, -0.000118732, ..., -0.00289917,\n",
       "            -0.00476074, -0.00382996],\n",
       "           [-0.00741577, -0.003479, 0.000694275, ..., 0.00209045,\n",
       "            -0.00299072, 0.0122681],\n",
       "           [-0.00836182, -0.0144043, 0.00823975, ..., -0.00540161,\n",
       "            -0.00982666, 0.00424194]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00172424, -0.00161743, -0.00848389, ..., -0.00291443,\n",
       "           0.00527954, 0.00119019],\n",
       "          [-0.00860596, -0.00769043, -0.00497437, ..., 0.0038147,\n",
       "           0.00157166, -0.0187988],\n",
       "          [0.00671387, 0.00686646, -0.0110474, ..., 0.00595093,\n",
       "           -0.000713348, 0.000938416],\n",
       "          ...,\n",
       "          [-0.00582886, 0.0067749, 0.00124359, ..., -0.00720215,\n",
       "           -0.00762939, -0.0102539],\n",
       "          [-0.00579834, 0.00897217, 0.0119629, ..., 0.00188446, 0.00151825,\n",
       "           0.00209045],\n",
       "          [0.00674438, 0.00418091, 0.00909424, ..., 0.0129395, 0.00224304,\n",
       "           -0.000789642]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([1.25781, 1.17969, 1.125, ..., 0.96875, 1.0625, 0.910156], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([1.8125, 1.82812, 1.90625, ..., 1.71094, 1.84375, 1.57031],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.871094, 0.992188, 0.765625, ..., 0.648438, 0.5625, 0.960938],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.108398, -0.0561523, -0.0947266, ..., -0.074707, -0.150391,\n",
       "          -0.0505371], dtype=bfloat16)}},\n",
       " 'layer_17': {'attn': {'attn_vec_einsum': {'w': Array([[[0.0317383, 0.0122681, 0.00708008, ..., -0.00114441, -0.0109863,\n",
       "             -0.0137329],\n",
       "            [-0.0032196, 0.00421143, -0.00300598, ..., -0.00148773,\n",
       "             0.022583, 0.00244141],\n",
       "            [-0.0183105, 0.0147095, 0.0153809, ..., 0.00364685, -0.00582886,\n",
       "             0.0088501],\n",
       "            ...,\n",
       "            [-0.012085, 0.00151825, -0.00445557, ..., -0.00270081,\n",
       "             -0.0141602, -0.00202942],\n",
       "            [-0.00415039, 0.0164795, -0.00891113, ..., -0.00759888,\n",
       "             0.0157471, 0.0017395],\n",
       "            [-0.013916, -0.0183105, 0.0150146, ..., -0.00158691, 0.00245667,\n",
       "             0.00976562]],\n",
       "    \n",
       "           [[-0.0118408, -0.00198364, 0.00976562, ..., -0.000541687,\n",
       "             0.0178223, -0.00332642],\n",
       "            [-0.0109253, 0.00325012, -0.0285645, ..., -0.00891113,\n",
       "             -0.0111084, 0.0119629],\n",
       "            [0.0088501, -0.0219727, 0.0115967, ..., -0.00891113, 0.015625,\n",
       "             0.00427246],\n",
       "            ...,\n",
       "            [-0.00350952, 0.0212402, -0.0180664, ..., -0.00561523,\n",
       "             0.00939941, -0.00276184],\n",
       "            [0.00473022, 0.019043, -0.00772095, ..., 0.0123291, 0.00110626,\n",
       "             -0.00352478],\n",
       "            [0.0101929, 0.0319824, 0.0158691, ..., 0.0143433, 0.0107422,\n",
       "             0.0162354]],\n",
       "    \n",
       "           [[0.00582886, -0.00970459, -0.00854492, ..., 0.00878906,\n",
       "             0.00570679, 0.0113525],\n",
       "            [0.0114136, 0.000610352, -0.0090332, ..., 0.0247803, -0.0090332,\n",
       "             0.00454712],\n",
       "            [-8.53539e-05, 0.0194092, 0.00233459, ..., -0.0137939,\n",
       "             0.00567627, -0.0209961],\n",
       "            ...,\n",
       "            [0.00958252, 0.00674438, 0.00337219, ..., -0.00294495, 0.012146,\n",
       "             -0.00352478],\n",
       "            [0.00753784, -0.00872803, -0.00469971, ..., -0.0143433,\n",
       "             0.00732422, 0.0125732],\n",
       "            [-0.017334, 0.0196533, -0.00891113, ..., -0.0115356, 0.00259399,\n",
       "             -0.00927734]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0125122, -0.00297546, -0.0196533, ..., 0.00482178,\n",
       "             0.0117188, 0.0150146],\n",
       "            [-0.00836182, -0.00866699, 0.0142212, ..., 0.00756836,\n",
       "             -0.0251465, -0.00109863],\n",
       "            [-0.00366211, -0.00415039, 0.0230713, ..., 0.0071106,\n",
       "             0.000556946, -0.0106812],\n",
       "            ...,\n",
       "            [0.0145874, 0.0196533, 0.0196533, ..., 0.0238037, 0.0216064,\n",
       "             -0.00463867],\n",
       "            [0.00157166, -0.00334167, 0.013855, ..., -0.00436401,\n",
       "             0.00297546, -0.00154877],\n",
       "            [-0.00482178, -0.000984192, 0.00152588, ..., -0.000324249,\n",
       "             0.0136719, -0.000839233]],\n",
       "    \n",
       "           [[-0.0027771, -0.0115356, 0.00367737, ..., 0.00125885, 0.0101929,\n",
       "             -0.000766754],\n",
       "            [0.00976562, -0.0267334, -0.00469971, ..., 0.0233154,\n",
       "             0.00209045, 0.0175781],\n",
       "            [-0.000938416, -0.000587463, -0.00491333, ..., 0.0222168,\n",
       "             0.00552368, -0.0134277],\n",
       "            ...,\n",
       "            [0.0125732, 0.00872803, 0.0194092, ..., 0.0011673, -0.006073,\n",
       "             0.00891113],\n",
       "            [-0.00268555, -0.00352478, 0.00366211, ..., 0.00164032,\n",
       "             0.0213623, -0.00640869],\n",
       "            [0.0134888, -0.00772095, -0.0172119, ..., 0.00196838,\n",
       "             -0.00367737, 0.00479126]],\n",
       "    \n",
       "           [[0.00952148, 0.0117188, -0.00805664, ..., 0.0117798,\n",
       "             -0.00405884, -0.00314331],\n",
       "            [-0.00360107, 0.0174561, -0.00491333, ..., -0.0281982,\n",
       "             -0.00358582, -0.0181885],\n",
       "            [-0.00933838, -0.00212097, 0.000314713, ..., -0.0175781,\n",
       "             -0.00421143, 0.017334],\n",
       "            ...,\n",
       "            [0.000135422, -0.0018692, -0.0158691, ..., -0.00408936,\n",
       "             0.00457764, 0.0108032],\n",
       "            [-0.000572205, -0.00271606, -0.0101318, ..., 0.00878906,\n",
       "             -0.019165, -0.000774384],\n",
       "            [-0.00585938, 0.00531006, 0.000314713, ..., -6.94394e-06,\n",
       "             0.00479126, -0.00190735]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.0192871, 0.00017643, 0.0133667, ..., 0.00613403,\n",
       "              0.0174561, 0.00860596],\n",
       "             [0.00372314, 0.0108643, 0.00494385, ..., -0.00488281,\n",
       "              -0.00485229, 0.00616455],\n",
       "             [-0.00564575, -0.00165558, -0.00241089, ..., 0.000965118,\n",
       "              -0.000172615, 0.0109863],\n",
       "             ...,\n",
       "             [0.00650024, 0.00958252, -0.0100708, ..., -0.0322266,\n",
       "              -0.00756836, -0.00494385],\n",
       "             [-0.0123901, 0.00540161, 0.00897217, ..., 0.00878906,\n",
       "              -0.0142212, 0.000303268],\n",
       "             [5.93662e-05, 0.0157471, -0.00799561, ..., -0.0149536,\n",
       "              -0.0106812, -0.0250244]],\n",
       "    \n",
       "            [[-0.00756836, -0.00488281, 0.0124512, ..., -0.00946045,\n",
       "              -0.00576782, 0.00289917],\n",
       "             [-9.82285e-05, 0.0011673, 0.00028801, ..., 0.00640869,\n",
       "              0.0111084, 0.00674438],\n",
       "             [0.00506592, 0.000450134, -0.00448608, ..., -0.00119781,\n",
       "              0.000888824, -0.00257874],\n",
       "             ...,\n",
       "             [-0.00361633, 0.00439453, 0.0050354, ..., 0.00704956,\n",
       "              -0.00430298, -0.0202637],\n",
       "             [0.00674438, -0.00454712, -0.00830078, ..., 0.00221252,\n",
       "              0.00939941, -0.00222778],\n",
       "             [0.00363159, -0.00534058, -0.00265503, ..., -0.00628662,\n",
       "              -0.0148315, 0.0185547]],\n",
       "    \n",
       "            [[-0.00668335, 0.00610352, 0.00341797, ..., -0.00662231,\n",
       "              0.00747681, -0.00970459],\n",
       "             [-0.00726318, -0.00151825, -0.00445557, ..., 0.000142097,\n",
       "              -0.000349045, -0.0125122],\n",
       "             [0.00302124, -0.000762939, 0.00145721, ..., -0.00115967,\n",
       "              -0.00671387, -0.00500488],\n",
       "             ...,\n",
       "             [-0.00028801, -0.00158691, -0.00518799, ..., -0.00282288,\n",
       "              -0.00224304, 0.0152588],\n",
       "             [0.00127411, 0.00196838, -0.00482178, ..., -0.0108643,\n",
       "              -0.0141602, 0.00134277],\n",
       "             [0.0018692, -0.00137329, 0.00424194, ..., -0.00161743,\n",
       "              0.00933838, -0.00744629]],\n",
       "    \n",
       "            [[-0.00723267, -0.00704956, -0.00787354, ..., 0.0213623,\n",
       "              0.0012207, -0.00133514],\n",
       "             [-0.00488281, -0.00241089, 0.00430298, ..., -0.00285339,\n",
       "              -0.00245667, 0.00872803],\n",
       "             [-0.00878906, 0.00300598, 0.0098877, ..., 0.0150757,\n",
       "              0.00183105, 0.000364304],\n",
       "             ...,\n",
       "             [0.0136719, -0.00866699, -0.00241089, ..., 0.0125122,\n",
       "              0.0172119, 0.0178223],\n",
       "             [-0.0108032, 0.0057373, -0.00708008, ..., -0.00111389,\n",
       "              0.00166321, -0.00131226],\n",
       "             [-0.00427246, 0.0163574, -0.00204468, ..., -0.0177002,\n",
       "              0.0062561, 0.0213623]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00601196, 0.0183105, 0.00151825, ..., -0.00418091,\n",
       "              0.0288086, 0.00558472],\n",
       "             [-0.00118256, -0.0030365, -0.00317383, ..., 0.00418091,\n",
       "              0.00915527, 0.0129395],\n",
       "             [0.00228882, 0.00289917, 0.015564, ..., -0.000640869,\n",
       "              -0.000185013, 0.0161133],\n",
       "             ...,\n",
       "             [-0.00643921, -0.0303955, 0.010376, ..., -0.0152588,\n",
       "              -0.00165558, 0.00610352],\n",
       "             [0.0250244, 0.0141602, 0.00671387, ..., 0.00537109,\n",
       "              0.00994873, -0.000679016],\n",
       "             [-0.00958252, -0.0032196, 0.00921631, ..., -0.000295639,\n",
       "              -0.00735474, 0.0197754]],\n",
       "    \n",
       "            [[0.012146, 0.00765991, 0.00309753, ..., 0.00376892, 0.0102539,\n",
       "              0.0101929],\n",
       "             [0.0151367, 0.00860596, 0.0151978, ..., 0.00952148,\n",
       "              0.00579834, -0.000602722],\n",
       "             [0.012146, -0.00424194, 0.00279236, ..., 0.00582886,\n",
       "              0.0234375, -0.013855],\n",
       "             ...,\n",
       "             [0.00915527, 0.0090332, -0.0115356, ..., -0.00680542,\n",
       "              0.0189209, 0.00454712],\n",
       "             [0.0187988, -0.0155029, -0.0115967, ..., 0.0149536, 0.0196533,\n",
       "              0.0107422],\n",
       "             [-0.0125732, 0.00224304, -0.000415802, ..., 0.0195312,\n",
       "              0.00315857, -0.0100098]],\n",
       "    \n",
       "            [[0.00312805, -0.010498, 0.00149536, ..., 0.0090332,\n",
       "              -0.00323486, -0.00708008],\n",
       "             [0.00263977, 0.00430298, -1.38879e-05, ..., 0.000553131,\n",
       "              0.0112305, 0.00927734],\n",
       "             [0.003479, 0.000839233, -0.00216675, ..., 0.00288391,\n",
       "              0.00320435, 0.00952148],\n",
       "             ...,\n",
       "             [0.00588989, 0.00860596, 0.00360107, ..., 0.0231934,\n",
       "              -0.000398636, 0.0244141],\n",
       "             [0.020752, -0.00253296, -0.00543213, ..., 0.00848389,\n",
       "              -0.0116577, 0.00756836],\n",
       "             [-0.0110474, -0.022583, -0.00994873, ..., 0.0187988,\n",
       "              0.00393677, 0.00448608]],\n",
       "    \n",
       "            [[0.0324707, -0.0140381, 0.00110626, ..., -0.0122681,\n",
       "              0.00170898, -0.0126953],\n",
       "             [0.00909424, 0.0281982, 0.00382996, ..., -0.00604248,\n",
       "              -0.00236511, 0.00361633],\n",
       "             [-0.0178223, -0.00439453, 0.00720215, ..., -0.0253906,\n",
       "              0.0043335, 0.0107422],\n",
       "             ...,\n",
       "             [-0.00836182, -0.0245361, -0.022583, ..., -0.00323486,\n",
       "              0.0153809, -0.00151825],\n",
       "             [-0.00656128, 0.00366211, -0.00866699, ..., 0.0065918,\n",
       "              -0.0252686, 0.00512695],\n",
       "             [-0.00689697, -0.0197754, 0.0317383, ..., -0.0020752,\n",
       "              0.00823975, -0.00512695]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00518799, -0.00567627, -0.00671387, ..., -0.00190735,\n",
       "             -0.000797272, 0.0127563],\n",
       "            [-0.00300598, 0.00149536, -0.00622559, ..., -0.0444336,\n",
       "             0.026001, -0.03125],\n",
       "            [-0.00244141, 0.0112915, -0.00848389, ..., 0.0180664, 0.0197754,\n",
       "             0.017334],\n",
       "            ...,\n",
       "            [0.00601196, 0.00402832, 0.0163574, ..., 0.00265503, 0.00650024,\n",
       "             -0.019165],\n",
       "            [0.00309753, -0.00500488, -0.00224304, ..., -0.0131226,\n",
       "             0.0123291, -0.00314331],\n",
       "            [-0.00415039, 0.0055542, 0.00317383, ..., 0.00241089,\n",
       "             -0.0280762, -0.0170898]],\n",
       "    \n",
       "           [[0.0062561, -0.00698853, -0.0107422, ..., -0.00817871,\n",
       "             -0.00139618, -0.00271606],\n",
       "            [0.0014801, 0.0163574, 0.00964355, ..., -0.00153351, 0.00376892,\n",
       "             -0.00299072],\n",
       "            [-0.00236511, 0.00811768, 0.00415039, ..., 0.00166321,\n",
       "             0.00311279, 0.0201416],\n",
       "            ...,\n",
       "            [0.0252686, -0.00595093, 0.00482178, ..., 0.00509644,\n",
       "             -0.00656128, -0.0147705],\n",
       "            [0.00128937, -0.0169678, -0.00552368, ..., 0.013916,\n",
       "             -0.00601196, 0.0111694],\n",
       "            [0.00346375, 0.00137329, -0.00315857, ..., -0.00567627,\n",
       "             -0.00270081, -0.00970459]],\n",
       "    \n",
       "           [[0.00257874, -0.00204468, -3.6478e-05, ..., 0.010376,\n",
       "             0.00160217, 0.0273438],\n",
       "            [-0.0136108, 0.00393677, -0.00982666, ..., 0.000972748,\n",
       "             0.00262451, -0.012146],\n",
       "            [-0.00369263, -0.00604248, -0.00619507, ..., -0.00393677,\n",
       "             0.00177002, 0.00028038],\n",
       "            ...,\n",
       "            [-0.00543213, 0.00473022, 0.000663757, ..., -0.0032196,\n",
       "             0.0240479, -0.0020752],\n",
       "            [0.00646973, 0.0142212, 0.00328064, ..., -0.0111084, -0.0133057,\n",
       "             -0.00344849],\n",
       "            [-0.0119019, -0.000999451, 0.0038147, ..., 0.00121307,\n",
       "             -0.0150757, 0.00497437]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.000214577, 0.00283813, -0.00328064, ..., 0.00430298,\n",
       "             0.00221252, -0.00265503],\n",
       "            [0.00485229, 0.00389099, 0.00552368, ..., -0.000307083,\n",
       "             0.0110474, 0.00122833],\n",
       "            [0.0189209, -0.0189209, 0.0236816, ..., 0.00939941, -0.00113678,\n",
       "             -0.00592041],\n",
       "            ...,\n",
       "            [-0.00598145, 0.00640869, -0.0212402, ..., -0.00088501,\n",
       "             -0.00387573, 0.000171661],\n",
       "            [0.0111694, -0.0106201, 0.0098877, ..., -0.003479, -5.72205e-05,\n",
       "             -0.00418091],\n",
       "            [-0.000234604, 0.00927734, -0.0245361, ..., 0.00408936,\n",
       "             0.00262451, 0.00325012]],\n",
       "    \n",
       "           [[-0.00291443, -0.0035553, 0.0101318, ..., 0.0106812, 0.00588989,\n",
       "             0.0170898],\n",
       "            [0.00460815, 0.00231934, 0.00245667, ..., 0.00527954, 0.0065918,\n",
       "             0.0134888],\n",
       "            [0.0067749, 0.00445557, 0.0137329, ..., 0.00382996, 0.0126953,\n",
       "             -0.00634766],\n",
       "            ...,\n",
       "            [-0.00227356, 0.00527954, 0.0110474, ..., 0.00750732, 0.0016861,\n",
       "             0.0218506],\n",
       "            [-0.00570679, 0.00338745, 0.017334, ..., -0.00405884,\n",
       "             -0.0100098, 0.00628662],\n",
       "            [-0.00772095, -0.00622559, -0.0105591, ..., -0.0168457,\n",
       "             0.0065918, 0.0147095]],\n",
       "    \n",
       "           [[0.000831604, 0.0102539, -0.0020752, ..., 0.00588989, 0.0161133,\n",
       "             -0.0098877],\n",
       "            [-0.00138855, 0.00509644, 0.00946045, ..., 0.00439453,\n",
       "             -0.00370789, 0.00613403],\n",
       "            [-0.00946045, -0.00558472, -0.00521851, ..., 0.0115967,\n",
       "             0.0065918, 0.0114746],\n",
       "            ...,\n",
       "            [-0.00842285, 0.000572205, -0.00144196, ..., 0.00689697,\n",
       "             0.00524902, 0.0148315],\n",
       "            [-0.00946045, -0.00314331, -0.00665283, ..., 0.00497437,\n",
       "             0.010376, 0.00656128],\n",
       "            [-0.00665283, -0.00527954, -0.0078125, ..., -0.0195312,\n",
       "             -0.0106812, 0.0128784]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.000762939, 0.000923157, 0.0124512, ..., 0.0088501,\n",
       "            -0.00473022, -0.00534058],\n",
       "           [-0.00778198, -0.00637817, -0.00735474, ..., 0.00604248,\n",
       "            0.00136566, 0.00665283],\n",
       "           [0.00897217, 0.000124931, -0.000396729, ..., 0.0118408,\n",
       "            -0.00245667, -0.000808716],\n",
       "           ...,\n",
       "           [0.00805664, 0.00159454, 0.00805664, ..., -0.00488281,\n",
       "            0.00570679, -0.0102539],\n",
       "           [0.00643921, -0.00396729, -0.00704956, ..., 0.00271606,\n",
       "            -0.0198975, 0.00637817],\n",
       "           [-0.0126953, 0.00253296, -0.00190735, ..., -0.00170135,\n",
       "            0.00411987, 0.0100708]],\n",
       "   \n",
       "          [[-0.00891113, -0.00860596, 0.00540161, ..., 0.00170135,\n",
       "            0.00665283, -0.00180817],\n",
       "           [-0.0130615, 0.00717163, 0.0109863, ..., -0.00312805,\n",
       "            0.00164795, 0.00747681],\n",
       "           [5.29289e-05, -0.0050354, -0.00424194, ..., -0.00144958,\n",
       "            0.00274658, -0.0252686],\n",
       "           ...,\n",
       "           [-0.00805664, 0.006073, 0.000946045, ..., -0.00299072,\n",
       "            0.00460815, 0.00393677],\n",
       "           [-0.00982666, 0.00111389, -0.00509644, ..., -0.00683594,\n",
       "            -0.00112152, 0.00717163],\n",
       "           [-0.00289917, 0.0169678, 0.000934601, ..., 0.00732422,\n",
       "            0.0143433, 0.00704956]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00213623, -0.00421143, -0.000114918, ..., -0.00062561,\n",
       "           -0.00126648, 0.00830078],\n",
       "          [0.0128174, 0.00976562, -0.00543213, ..., -0.00656128,\n",
       "           -0.00646973, 0.0153809],\n",
       "          [0.00427246, -0.00823975, -0.00216675, ..., 0.00115967,\n",
       "           0.00267029, 0.00753784],\n",
       "          ...,\n",
       "          [-0.010498, 0.00167847, 0.0109863, ..., -0.00778198, 0.000522614,\n",
       "           -0.000385284],\n",
       "          [-0.00634766, -0.0045166, -0.00172424, ..., -0.00308228,\n",
       "           0.00230408, 0.0115967],\n",
       "          [0.00367737, 0.00604248, -0.0290527, ..., -0.00247192, 0.00361633,\n",
       "           0.00732422]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([1.17188, 1.17188, 1.03125, ..., 1.05469, 0.980469, 1.01562],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([2.125, 2.04688, 2.1875, ..., 2, 2.15625, 1.875], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.535156, 0.675781, 0.472656, ..., 0.484375, 0.423828, 0.667969],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.0554199, -0.00891113, -0.0585938, ..., -0.0483398, -0.0942383,\n",
       "          -0.000480652], dtype=bfloat16)}},\n",
       " 'layer_18': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.00476074, -0.00531006, 0.0158691, ..., -0.00159454,\n",
       "             -0.00141144, 0.00190735],\n",
       "            [-0.0219727, 0.010376, -0.00674438, ..., -0.0142822, 0.00604248,\n",
       "             -0.0180664],\n",
       "            [-0.0105591, 0.000965118, 0.00817871, ..., 0.00358582,\n",
       "             -0.00759888, -0.0233154],\n",
       "            ...,\n",
       "            [0.0159912, 0.0162354, -0.00531006, ..., -0.00830078,\n",
       "             -0.000839233, -0.00909424],\n",
       "            [-0.0275879, 0.0137329, 0.0078125, ..., 0.0062561, 0.00366211,\n",
       "             -0.0115967],\n",
       "            [0.0119019, 0.00939941, 0.000579834, ..., 0.00219727,\n",
       "             -0.00309753, 0.010498]],\n",
       "    \n",
       "           [[0.0116577, -0.020752, 0.000831604, ..., -0.00305176,\n",
       "             -0.00306702, 0.00102997],\n",
       "            [-0.00154877, 0.00171661, 0.000991821, ..., -0.00233459,\n",
       "             0.0137939, -0.00469971],\n",
       "            [-0.0251465, 1.86265e-06, -0.0179443, ..., -0.0253906,\n",
       "             0.0118408, -0.0025177],\n",
       "            ...,\n",
       "            [0.00592041, -0.0220947, 0.00491333, ..., -0.00689697, 0.015625,\n",
       "             0.0112915],\n",
       "            [-0.00212097, 0.0141602, -0.0131836, ..., -0.0209961,\n",
       "             -0.00964355, 0.0224609],\n",
       "            [-0.00543213, 0.000159264, 0.00340271, ..., 0.0209961,\n",
       "             0.0136108, -0.0164795]],\n",
       "    \n",
       "           [[0.00427246, 0.00927734, 0.0111084, ..., 0.0118408, -0.0272217,\n",
       "             0.00891113],\n",
       "            [0.00138855, -0.019043, 0.0130005, ..., 0.0349121, 0.00442505,\n",
       "             0.00289917],\n",
       "            [-0.00188446, 0.0126953, 0.00323486, ..., -0.00153351,\n",
       "             -0.006073, 0.00952148],\n",
       "            ...,\n",
       "            [-0.0157471, -0.00497437, 0.00224304, ..., 0.00209045,\n",
       "             0.00176239, 0.00159454],\n",
       "            [-0.00364685, -0.00396729, 0.0150146, ..., -0.00485229,\n",
       "             -0.00897217, -0.00769043],\n",
       "            [0.000461578, -0.0103149, -0.0117188, ..., -0.00143433,\n",
       "             -0.0102539, 0.00726318]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00564575, 0.00291443, 0.00210571, ..., -0.00331116,\n",
       "             0.00616455, 0.0134888],\n",
       "            [0.00088501, 0.00289917, 0.00463867, ..., -0.00274658,\n",
       "             -0.010376, 0.00271606],\n",
       "            [0.00595093, -0.0178223, -0.00259399, ..., -2.32458e-05,\n",
       "             0.0268555, -0.00769043],\n",
       "            ...,\n",
       "            [-0.00488281, 0.0180664, 0.017334, ..., 0.00379944, 0.0161133,\n",
       "             0.0117188],\n",
       "            [0.000522614, 0.0159912, -0.00408936, ..., -0.0098877,\n",
       "             0.00726318, -0.00860596],\n",
       "            [-0.000583649, -0.00384521, 0.0114136, ..., -0.00169373,\n",
       "             0.00393677, 0.0043335]],\n",
       "    \n",
       "           [[-0.00616455, -0.0022583, -0.00148773, ..., -0.00227356,\n",
       "             -0.010498, 0.000396729],\n",
       "            [0.00604248, -0.00378418, -0.00891113, ..., -0.00579834,\n",
       "             -0.0224609, -0.00167847],\n",
       "            [0.010498, 0.0209961, 0.00308228, ..., -0.00405884, -0.00387573,\n",
       "             0.00588989],\n",
       "            ...,\n",
       "            [-0.000161171, -0.0134277, 0.00540161, ..., 0.00744629,\n",
       "             0.00366211, -0.00402832],\n",
       "            [0.000881195, -0.00144196, -0.000179291, ..., -0.00299072,\n",
       "             0.0109863, -0.00331116],\n",
       "            [-0.00418091, 3.40939e-05, 0.0105591, ..., 0.0216064,\n",
       "             0.00230408, -0.0019989]],\n",
       "    \n",
       "           [[0.0067749, -0.0119019, -0.00285339, ..., 0.0019989, 0.00604248,\n",
       "             0.010437],\n",
       "            [-0.00170898, 0.00650024, 0.010376, ..., -0.00106049, 0.024292,\n",
       "             -0.00466919],\n",
       "            [-0.010437, -0.0354004, -0.0129395, ..., -0.00182343,\n",
       "             -0.000984192, -0.00537109],\n",
       "            ...,\n",
       "            [-0.00274658, 0.0118408, -0.0100098, ..., -0.0163574,\n",
       "             0.00469971, 0.013855],\n",
       "            [0.0184326, -0.00418091, -0.0148315, ..., 0.00982666,\n",
       "             -0.0148926, 0.00723267],\n",
       "            [0.00982666, 0.00256348, -0.00738525, ..., -0.0290527,\n",
       "             -0.00595093, 0.00463867]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.00123596, 0.00038147, 0.001297, ..., 0.000425339,\n",
       "              0.0184326, 0.0088501],\n",
       "             [-0.0112305, 0.00179291, -0.00723267, ..., 0.0224609,\n",
       "              0.0117798, -0.00296021],\n",
       "             [-0.0119629, 0.00326538, -0.00933838, ..., -0.022583,\n",
       "              -0.00239563, -0.00512695],\n",
       "             ...,\n",
       "             [-0.000923157, 0.00717163, 0.0120239, ..., 0.00753784,\n",
       "              0.00250244, 0.00141144],\n",
       "             [-0.00204468, -0.000526428, 0.00227356, ..., 0.0106201,\n",
       "              -0.000166893, 0.0055542],\n",
       "             [-0.00823975, 0.0014801, -0.000545502, ..., -0.0198975,\n",
       "              -0.00448608, 0.0123291]],\n",
       "    \n",
       "            [[0.00201416, -0.000640869, 0.0125122, ..., 0.00325012,\n",
       "              0.00115967, 0.00263977],\n",
       "             [-0.00830078, 0.00491333, 0.00174713, ..., -0.00082016,\n",
       "              0.00878906, -0.0236816],\n",
       "             [-0.00104523, 0.000644684, 0.0147095, ..., 0.00328064,\n",
       "              -0.00354004, 0.0238037],\n",
       "             ...,\n",
       "             [0.00848389, 0.00050354, 0.00349426, ..., 0.00909424,\n",
       "              -0.00744629, -0.00595093],\n",
       "             [-0.00656128, 0.00567627, 0.00738525, ..., -0.00245667,\n",
       "              -0.0167236, 0.00218201],\n",
       "             [-0.00665283, 0.0090332, 0.00094986, ..., -0.00253296,\n",
       "              0.00314331, 0.0105591]],\n",
       "    \n",
       "            [[-0.0118408, 0.00274658, -0.0206299, ..., -0.0255127,\n",
       "              -0.00939941, 0.0148926],\n",
       "             [-0.00952148, 0.0131836, 0.0013504, ..., 0.00332642,\n",
       "              -0.0274658, 0.00595093],\n",
       "             [-0.0050354, 0.00643921, 0.0117798, ..., 0.00683594,\n",
       "              -0.0178223, -0.0015564],\n",
       "             ...,\n",
       "             [0.00384521, -0.00592041, -0.000701904, ..., 0.000371933,\n",
       "              -0.00139618, -0.00164795],\n",
       "             [-0.000640869, -0.0178223, -0.0111694, ..., -0.0239258,\n",
       "              -0.0067749, -0.0195312],\n",
       "             [-0.00112152, 0.00723267, -0.0164795, ..., -0.0187988,\n",
       "              0.010376, -0.0175781]],\n",
       "    \n",
       "            [[0.00463867, -0.00112915, 0.0065918, ..., -0.013855,\n",
       "              -0.00585938, 0.00167084],\n",
       "             [0.00878906, -0.0161133, -0.00598145, ..., -0.000184059,\n",
       "              0.0214844, -0.00842285],\n",
       "             [0.0062561, -0.00375366, -0.00201416, ..., 0.0189209,\n",
       "              -0.003479, -0.00515747],\n",
       "             ...,\n",
       "             [-0.00891113, -0.00289917, -0.00823975, ..., -0.00242615,\n",
       "              0.00285339, -0.0112305],\n",
       "             [-0.0062561, -0.00500488, -0.00238037, ..., 0.00485229,\n",
       "              0.0197754, 0.0161133],\n",
       "             [0.00408936, 0.000163078, -0.0078125, ..., 0.00320435,\n",
       "              0.00970459, 0.0125732]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0016098, -0.0163574, -0.022583, ..., 0.0281982,\n",
       "              -0.00866699, 0.00279236],\n",
       "             [-0.0183105, 0.0101318, 0.00130463, ..., 0.0192871, 0.0236816,\n",
       "              0.0130615],\n",
       "             [0.0361328, 0.00939941, -0.00830078, ..., -0.0229492,\n",
       "              0.013916, 0.00946045],\n",
       "             ...,\n",
       "             [-0.0200195, -0.0205078, -0.000429153, ..., -0.0169678,\n",
       "              -0.00102997, 0.00579834],\n",
       "             [-0.0211182, 0.00488281, -0.00128174, ..., 0.00396729,\n",
       "              0.0161133, -0.0108643],\n",
       "             [-0.00662231, -0.013855, -0.0230713, ..., 0.0045166,\n",
       "              0.00143433, 0.00723267]],\n",
       "    \n",
       "            [[0.00765991, 0.0253906, -0.00463867, ..., 0.000134468,\n",
       "              0.0088501, -0.00144196],\n",
       "             [0.00375366, -0.0224609, 0.00271606, ..., 0.0039978,\n",
       "              0.0045166, -0.00732422],\n",
       "             [0.0209961, 0.00747681, 0.00982666, ..., 0.0279541,\n",
       "              0.000938416, -0.00921631],\n",
       "             ...,\n",
       "             [0.0159912, 0.00576782, -0.00817871, ..., 0.0126953,\n",
       "              -0.0050354, -0.00282288],\n",
       "             [-0.0251465, 0.00772095, -0.0186768, ..., 0.00799561,\n",
       "              0.00106049, -0.0198975],\n",
       "             [0.0144043, -0.0217285, 0.0185547, ..., 0.0244141, 0.00121307,\n",
       "              0.00964355]],\n",
       "    \n",
       "            [[0.00543213, -0.0088501, 0.000219345, ..., -0.00366211,\n",
       "              -0.0101318, -0.0145874],\n",
       "             [0.003479, 0.00811768, 0.00582886, ..., 0.00117493,\n",
       "              -0.0032196, 0.0115356],\n",
       "             [-0.00120544, -0.00469971, 0.0020752, ..., 0.00540161,\n",
       "              -0.0103149, -0.00271606],\n",
       "             ...,\n",
       "             [-0.00288391, -0.000701904, 0.00595093, ..., -0.00292969,\n",
       "              0.00165558, -0.0150757],\n",
       "             [0.0125122, 0.00741577, 0.0229492, ..., -0.00256348,\n",
       "              -0.00793457, -0.00576782],\n",
       "             [-0.00101471, -0.00113678, -0.0112915, ..., 0.0151978,\n",
       "              -4.41074e-05, 0.0147095]],\n",
       "    \n",
       "            [[0.0101929, -0.00300598, 0.000782013, ..., -0.00769043,\n",
       "              -0.0050354, 0.00135803],\n",
       "             [7.45058e-06, 0.000114441, -0.00479126, ..., 0.00576782,\n",
       "              -0.00028038, 0.00131226],\n",
       "             [0.00891113, 0.00509644, 0.00872803, ..., -0.0037384,\n",
       "              0.0262451, -0.00686646],\n",
       "             ...,\n",
       "             [8.58307e-06, 0.00167847, -0.00619507, ..., -0.00509644,\n",
       "              0.0067749, 0.00112915],\n",
       "             [0.00418091, 0.00476074, -0.0071106, ..., 0.0117798,\n",
       "              0.0273438, 0.0212402],\n",
       "             [0.000151634, -0.00408936, 0.00299072, ..., -0.00491333,\n",
       "              -0.00190735, 0.00970459]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00411987, -0.0011673, 0.00509644, ..., 0.00524902,\n",
       "             0.00285339, 0.00744629],\n",
       "            [0.00485229, 0.0132446, 0.0067749, ..., -0.00878906,\n",
       "             -0.00854492, 0.00656128],\n",
       "            [-0.00897217, 0.0212402, 0.00288391, ..., 0.000797272,\n",
       "             0.00050354, -0.027832],\n",
       "            ...,\n",
       "            [0.0164795, 0.00167847, -0.00326538, ..., -0.0143433,\n",
       "             0.00131989, -0.000789642],\n",
       "            [-0.00105286, -0.00671387, -0.0128784, ..., 0.0167236,\n",
       "             -0.00171661, -0.00561523],\n",
       "            [-0.0114746, 0.0111694, 0.00147247, ..., -0.00106812,\n",
       "             -0.00210571, 0.0180664]],\n",
       "    \n",
       "           [[0.00210571, -0.0115356, 0.00274658, ..., -0.015564, 0.0112915,\n",
       "             -0.0125732],\n",
       "            [0.000137329, -0.00231934, -0.00793457, ..., -0.00643921,\n",
       "             0.00191498, -0.012085],\n",
       "            [0.0030365, 0.00283813, 0.0011673, ..., -0.00515747, 0.00364685,\n",
       "             -0.000530243],\n",
       "            ...,\n",
       "            [0.0164795, 0.00161743, -0.000476837, ..., -0.00114441,\n",
       "             -0.0203857, -0.0212402],\n",
       "            [0.000583649, -0.00276184, -0.0110474, ..., 0.0214844,\n",
       "             -0.00335693, 0.0120239],\n",
       "            [-0.0114746, 0.0114136, 0.010437, ..., -0.00500488,\n",
       "             -0.000526428, -0.00185394]],\n",
       "    \n",
       "           [[0.0120239, -0.00238037, 0.00982666, ..., 0.0159912, -0.0158691,\n",
       "             0.00811768],\n",
       "            [-0.0144043, 0.0202637, 0.012207, ..., -0.0170898, -0.0123901,\n",
       "             -0.00552368],\n",
       "            [0.00233459, 0.00476074, 0.0198975, ..., 0.0172119, 0.0131836,\n",
       "             -0.0192871],\n",
       "            ...,\n",
       "            [-0.0111694, 0.00512695, -0.0018692, ..., 0.0108643, 0.00346375,\n",
       "             -0.00579834],\n",
       "            [0.00411987, -0.00221252, -0.00817871, ..., -0.0124512,\n",
       "             -0.0184326, -0.000595093],\n",
       "            [-0.00717163, -0.00357056, 0.00497437, ..., 0.0014801,\n",
       "             -0.0332031, 0.0133667]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0037384, 0.00805664, 0.0146484, ..., -0.0336914, -0.0101318,\n",
       "             0.0145264],\n",
       "            [0.0065918, 0.00102234, 0.00787354, ..., 0.0292969, 0.00318909,\n",
       "             -0.026001],\n",
       "            [0.00370789, -0.0174561, 0.0145264, ..., -0.00349426, 0.0120239,\n",
       "             0.00891113],\n",
       "            ...,\n",
       "            [0.00775146, -0.000371933, 0.00708008, ..., -0.0245361,\n",
       "             0.0407715, 0.000526428],\n",
       "            [-0.0151978, -0.00259399, -0.000728607, ..., -0.00921631,\n",
       "             0.00309753, -0.020752],\n",
       "            [-0.0022583, 0.00775146, 0.00265503, ..., -0.0101318,\n",
       "             -0.00946045, -0.0161133]],\n",
       "    \n",
       "           [[-0.000142097, 0.00286865, 0.0126343, ..., 0.00439453,\n",
       "             -0.00357056, -0.00172424],\n",
       "            [-0.00817871, 0.00518799, 0.0106201, ..., 0.0177002, 0.0157471,\n",
       "             -0.00131226],\n",
       "            [-0.00982666, -0.00878906, -0.000457764, ..., -0.0108032,\n",
       "             0.0159912, -0.0102539],\n",
       "            ...,\n",
       "            [0.0140381, 0.00546265, -0.0078125, ..., -0.00714111,\n",
       "             0.00534058, 0.00708008],\n",
       "            [0.00506592, 0.00424194, 0.000736237, ..., -0.00976562,\n",
       "             0.00735474, -0.0100708],\n",
       "            [-0.0022583, 0.0030365, 0.0107422, ..., 0.0125122, 0.0181885,\n",
       "             -0.0268555]],\n",
       "    \n",
       "           [[-0.00994873, 0.00778198, -0.00534058, ..., 0.0120239,\n",
       "             -0.0119629, 0.0136108],\n",
       "            [0.00473022, -0.0127563, -0.0032196, ..., 0.00166321,\n",
       "             0.00338745, -0.00108337],\n",
       "            [-0.00159454, -0.00379944, 0.00769043, ..., -0.00294495,\n",
       "             -0.00369263, -0.00213623],\n",
       "            ...,\n",
       "            [0.0016098, 0.00952148, -0.0192871, ..., 0.00509644,\n",
       "             -0.00189972, 0.00692749],\n",
       "            [-0.00463867, 0.0123901, 0.00454712, ..., 0.0108643, 0.00964355,\n",
       "             0.00616455],\n",
       "            [0.00570679, -0.00354004, -0.00726318, ..., 0.00726318,\n",
       "             0.00011158, 0.00439453]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00238037, 0.015625, -0.00811768, ..., 0.00692749,\n",
       "            0.00759888, 0.00279236],\n",
       "           [-0.0115967, -0.00695801, -0.0098877, ..., 0.00476074,\n",
       "            -0.000191689, 0.0125732],\n",
       "           [0.00698853, -0.00994873, 0.00366211, ..., -0.00364685,\n",
       "            0.000926971, 0.0032959],\n",
       "           ...,\n",
       "           [0.000195503, -0.0105591, -0.00463867, ..., 0.00469971,\n",
       "            -0.00671387, -0.00759888],\n",
       "           [0.00285339, 0.0129395, -0.00497437, ..., -0.00182343,\n",
       "            -0.00216675, -0.0067749],\n",
       "           [0.0137329, 0.00518799, 0.00325012, ..., 0.0101929, -0.00056839,\n",
       "            0.000640869]],\n",
       "   \n",
       "          [[-0.00704956, 0.0164795, -0.0167236, ..., -0.0130005,\n",
       "            -0.00579834, 0.00747681],\n",
       "           [0.0128784, -0.00267029, 0.00619507, ..., 0.000946045,\n",
       "            -0.0016861, 0.00427246],\n",
       "           [-0.000858307, 0.00601196, -0.0013504, ..., -0.00741577,\n",
       "            -0.00927734, 0.0115967],\n",
       "           ...,\n",
       "           [0.00982666, -0.000402451, 0.0098877, ..., 0.00891113,\n",
       "            0.00564575, -0.0050354],\n",
       "           [-0.00830078, -0.00175476, 0.00276184, ..., 0.00292969,\n",
       "            -0.0109863, 0.00405884],\n",
       "           [0.00175476, -0.0106812, -0.00378418, ..., 6.19888e-05,\n",
       "            -0.00361633, 0.0106201]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00424194, 0.00421143, -0.00646973, ..., -0.00610352,\n",
       "           -0.00107574, 0.00671387],\n",
       "          [0.00817871, 0.00123596, 0.00230408, ..., 0.00741577, -0.00878906,\n",
       "           0.00331116],\n",
       "          [-0.012085, -0.00415039, -0.0150146, ..., 0.00367737, -0.00738525,\n",
       "           -0.0032196],\n",
       "          ...,\n",
       "          [-0.00762939, 0.0129395, -0.0129395, ..., 0.00970459, 0.0116577,\n",
       "           0.00994873],\n",
       "          [-0.00241089, -0.000701904, 0.00732422, ..., 0.00280762,\n",
       "           0.000246048, 0.00210571],\n",
       "          [0.00576782, -0.00817871, 0.0120239, ..., -0.00363159, 0.00442505,\n",
       "           -0.00546265]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([1.36719, 1.41406, 1.35938, ..., 1.39062, 1.60938, 1.26562],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([2.46875, 2.42188, 2.48438, ..., 2.34375, 2.53125, 2.3125],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.443359, 0.570312, 0.347656, ..., 0.453125, 0.388672, 0.5625],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.160156, 0.269531, 0.191406, ..., 0.158203, 0.11377, 0.259766],      dtype=bfloat16)}},\n",
       " 'layer_19': {'attn': {'attn_vec_einsum': {'w': Array([[[0.00750732, -0.0223389, -0.0175781, ..., 0.00497437,\n",
       "             -0.00921631, 0.00454712],\n",
       "            [0.00891113, -0.00183868, 0.00268555, ..., 0.00430298,\n",
       "             -0.000682831, -0.0246582],\n",
       "            [-0.00296021, 0.0268555, -0.00227356, ..., 2.11e-05,\n",
       "             -0.00108337, -0.0115967],\n",
       "            ...,\n",
       "            [0.00183868, 0.0186768, 0.0125122, ..., 0.00291443, 0.00198364,\n",
       "             0.0100098],\n",
       "            [0.0014267, -0.00778198, 0.0117188, ..., -0.0055542,\n",
       "             -0.00970459, 0.00402832],\n",
       "            [0.000923157, 0.0194092, -0.0078125, ..., -0.00656128,\n",
       "             -0.0098877, 0.0175781]],\n",
       "    \n",
       "           [[-0.0230713, 0.00787354, 0.00418091, ..., -0.0014267,\n",
       "             -0.0128784, 0.0206299],\n",
       "            [-0.0334473, -0.0140381, -0.00408936, ..., 0.00376892,\n",
       "             -0.00482178, -0.0142822],\n",
       "            [0.0122681, -0.00680542, 0.00732422, ..., -0.0112305,\n",
       "             -0.0130615, -0.00598145],\n",
       "            ...,\n",
       "            [0.0183105, -0.00396729, -0.00860596, ..., -0.00396729,\n",
       "             0.00643921, -0.00121307],\n",
       "            [0.0117798, -0.0212402, -0.0203857, ..., -0.00491333,\n",
       "             0.00136566, 0.0106201],\n",
       "            [-0.0255127, 0.000686646, 0.00723267, ..., -0.00125122,\n",
       "             -0.00231934, -0.0175781]],\n",
       "    \n",
       "           [[0.02771, -0.00946045, 0.00805664, ..., -0.0241699, 0.010437,\n",
       "             0.0202637],\n",
       "            [0.00120544, 0.0100098, -0.0168457, ..., 0.00753784, -0.0117188,\n",
       "             -0.0157471],\n",
       "            [-0.00891113, 0.00213623, 0.00683594, ..., -0.00069809,\n",
       "             -0.00469971, 0.0050354],\n",
       "            ...,\n",
       "            [0.00230408, 0.00958252, -0.000648499, ..., 0.00558472,\n",
       "             0.0299072, 0.00866699],\n",
       "            [0.00787354, -0.00708008, -0.0201416, ..., -0.000511169,\n",
       "             -0.00952148, -0.019165],\n",
       "            [-0.00037384, 0.0161133, -0.00952148, ..., -0.012207,\n",
       "             -0.0179443, 0.00561523]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.019165, -0.00248718, 0.00157166, ..., -0.0025177, 0.0145874,\n",
       "             -0.00315857],\n",
       "            [-0.0236816, -0.0134888, 0.0142212, ..., 0.00695801,\n",
       "             -0.00848389, -0.00891113],\n",
       "            [-0.000518799, -0.00393677, 0.0213623, ..., 0.0167236,\n",
       "             -0.010437, -0.00561523],\n",
       "            ...,\n",
       "            [0.0126343, 0.00306702, 0.0200195, ..., -0.00909424, 0.0136108,\n",
       "             -0.0109253],\n",
       "            [-0.000797272, -0.00427246, -0.00860596, ..., -0.00491333,\n",
       "             0.00201416, 0.0145264],\n",
       "            [0.00671387, -0.0174561, -0.0134277, ..., -0.00836182,\n",
       "             -0.0174561, -0.0187988]],\n",
       "    \n",
       "           [[0.000854492, -0.0142822, -0.0130615, ..., -0.000839233,\n",
       "             -0.00363159, -0.00866699],\n",
       "            [-0.00668335, -0.00921631, 0.0113525, ..., -0.006073,\n",
       "             -9.71556e-06, 0.0032959],\n",
       "            [0.0149536, 0.00120544, 0.00325012, ..., -0.0109863,\n",
       "             -0.00775146, -0.000915527],\n",
       "            ...,\n",
       "            [-0.0294189, 0.0045166, -0.0039978, ..., -0.00343323,\n",
       "             0.00634766, -0.00720215],\n",
       "            [0.00939941, -0.00162506, 0.0154419, ..., -0.000239372,\n",
       "             -0.010437, 6.19888e-05],\n",
       "            [0.00982666, 0.0112915, 0.00579834, ..., 8.58307e-05,\n",
       "             -0.0090332, 0.00262451]],\n",
       "    \n",
       "           [[0.00340271, 0.00123596, 0.0136108, ..., 0.00515747, 0.00390625,\n",
       "             0.00811768],\n",
       "            [0.0253906, -0.0181885, -0.00634766, ..., -0.00112152,\n",
       "             0.0078125, -0.00579834],\n",
       "            [-0.0144653, -0.0142822, -0.00509644, ..., 0.0209961,\n",
       "             0.00482178, -0.0131836],\n",
       "            ...,\n",
       "            [0.0110474, -0.0105591, 0.00842285, ..., 0.0001688, 0.0119019,\n",
       "             -0.00836182],\n",
       "            [-0.0113525, -0.00646973, -0.0157471, ..., -0.0179443,\n",
       "             -0.00201416, 0.0198975],\n",
       "            [0.00408936, 0.00482178, 0.00363159, ..., 0.00267029, 0.013916,\n",
       "             -0.0098877]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.00921631, 0.0206299, 0.00215149, ..., -0.00518799,\n",
       "              -0.0263672, 0.00195312],\n",
       "             [0.00430298, 0.00476074, -0.00124359, ..., -0.00842285,\n",
       "              0.0212402, -0.00393677],\n",
       "             [-0.00309753, 0.0020752, 0.00312805, ..., 0.00291443,\n",
       "              -0.00753784, -0.000436783],\n",
       "             ...,\n",
       "             [0.00270081, 0.00358582, 0.00228882, ..., -0.0151367,\n",
       "              -0.00280762, 0.00836182],\n",
       "             [-0.00521851, -0.0103149, 0.00390625, ..., 0.000900269,\n",
       "              0.00111389, -0.00390625],\n",
       "             [0.000724792, 0.00375366, 0.00372314, ..., 0.00518799,\n",
       "              -0.0169678, 0.00215149]],\n",
       "    \n",
       "            [[-0.0113525, 0.00367737, -0.00192261, ..., -0.0162354,\n",
       "              -0.0170898, 0.00558472],\n",
       "             [-0.0117798, -0.00976562, 0.00274658, ..., 0.0106812,\n",
       "              0.0018158, 0.00946045],\n",
       "             [0.00133514, 0.00244141, -0.000157356, ..., -0.00209045,\n",
       "              0.0181885, 0.00482178],\n",
       "             ...,\n",
       "             [0.000128746, 0.0057373, -0.0119019, ..., -0.00198364,\n",
       "              0.00161743, 0.000211716],\n",
       "             [0.00288391, 0.010498, 0.0109253, ..., 0.00361633,\n",
       "              -0.00427246, -0.0189209],\n",
       "             [0.00482178, -0.00268555, -0.0106201, ..., 0.0150146,\n",
       "              -0.00662231, 0.015564]],\n",
       "    \n",
       "            [[-0.006073, -0.00389099, -0.0109863, ..., 0.0114746,\n",
       "              0.0290527, 0.00308228],\n",
       "             [-0.00714111, -0.00933838, 0.00250244, ..., 0.00927734,\n",
       "              -0.00460815, 0.0336914],\n",
       "             [0.0037384, -0.00704956, -0.000667572, ..., -0.0223389,\n",
       "              0.00717163, -0.0118408],\n",
       "             ...,\n",
       "             [0.00149536, 0.00405884, -0.00518799, ..., 0.00567627,\n",
       "              0.0249023, 0.00860596],\n",
       "             [-0.00369263, -0.00213623, 0.0115967, ..., 0.000896454,\n",
       "              0.00473022, -0.00506592],\n",
       "             [-0.00436401, -4.14848e-05, -0.000850677, ..., 0.00485229,\n",
       "              0.019043, -0.00164795]],\n",
       "    \n",
       "            [[-0.00683594, -0.0154419, -0.0166016, ..., -0.0126953,\n",
       "              0.0152588, 0.0168457],\n",
       "             [-0.00628662, 0.00741577, -0.00775146, ..., -0.00891113,\n",
       "              0.0134888, -0.000356674],\n",
       "             [-0.0140991, 0.00769043, -0.00634766, ..., -0.022583,\n",
       "              -0.00188446, 0.00717163],\n",
       "             ...,\n",
       "             [-0.00686646, 0.00588989, -0.0157471, ..., 0.00735474,\n",
       "              -0.00946045, 0.00619507],\n",
       "             [0.0032959, 0.0149536, -0.00650024, ..., 0.0142212,\n",
       "              -0.00466919, 0.00964355],\n",
       "             [-0.00056076, -0.0213623, -0.0270996, ..., -0.00506592,\n",
       "              -0.00595093, -0.0115356]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0098877, 0.00341797, -0.00494385, ..., -0.0136108,\n",
       "              -0.00245667, 0.0106812],\n",
       "             [0.00488281, 0.00494385, -0.00891113, ..., -0.00248718,\n",
       "              -0.0136108, -0.0143433],\n",
       "             [0.000720978, -0.0157471, -0.00358582, ..., -0.00759888,\n",
       "              0.0118408, -0.00247192],\n",
       "             ...,\n",
       "             [0.00402832, 0.0101318, 0.0134888, ..., -0.00549316,\n",
       "              0.0167236, 0.00034523],\n",
       "             [-0.006073, 0.00121307, -0.0177002, ..., 0.00964355,\n",
       "              -0.0117798, -0.0143433],\n",
       "             [-0.00114441, -0.00268555, -0.00585938, ..., -0.00759888,\n",
       "              -0.0137329, -0.0169678]],\n",
       "    \n",
       "            [[-0.00442505, -0.00340271, 0.00190735, ..., 0.00132751,\n",
       "              -0.000686646, -0.0132446],\n",
       "             [-0.00126648, 0.0126343, 0.0147095, ..., 0.00823975,\n",
       "              0.0126953, -0.00332642],\n",
       "             [0.0010376, 0.0146484, 0.000629425, ..., -0.00909424,\n",
       "              -0.00341797, 0.00352478],\n",
       "             ...,\n",
       "             [-0.012207, -0.00958252, -0.00300598, ..., 0.00927734,\n",
       "              0.0019989, -0.00209045],\n",
       "             [-0.0184326, 0.0136719, 0.0249023, ..., 0.00527954,\n",
       "              -0.00811768, 0.0038147],\n",
       "             [-3.47197e-06, 0.00540161, 0.00244141, ..., -0.000724792,\n",
       "              0.0151978, 0.00268555]],\n",
       "    \n",
       "            [[-0.0256348, -0.00891113, -0.00276184, ..., 0.0212402,\n",
       "              0.00588989, 0.00598145],\n",
       "             [0.00338745, 0.010498, -0.00102234, ..., 0.00509644,\n",
       "              -0.0025177, -0.0112305],\n",
       "             [0.00186157, -0.00689697, 0.0106201, ..., 0.0286865,\n",
       "              -0.00196838, -0.0162354],\n",
       "             ...,\n",
       "             [-0.0125732, 0.00186157, 0.0172119, ..., -0.0107422,\n",
       "              -0.000385284, 0.00527954],\n",
       "             [0.00242615, -0.00628662, -0.0142822, ..., 0.0030365,\n",
       "              -0.00219727, -0.0181885],\n",
       "             [-0.00393677, -0.0184326, -0.00939941, ..., -0.00817871,\n",
       "              0.000299454, -0.0128174]],\n",
       "    \n",
       "            [[0.00524902, 0.00946045, 0.0100708, ..., -0.010498,\n",
       "              -0.00190735, 0.0139771],\n",
       "             [-0.0159912, -0.0268555, -0.00631714, ..., -0.00671387,\n",
       "              -0.00335693, -0.00216675],\n",
       "             [-0.00411987, 0.00891113, -0.00367737, ..., 0.00582886,\n",
       "              0.000226021, 0.0114746],\n",
       "             ...,\n",
       "             [-0.00106049, -0.00830078, 0.0205078, ..., 0.00805664,\n",
       "              -0.017334, -4.76837e-05],\n",
       "             [-0.00527954, 0.0123291, 0.00518799, ..., 0.00872803,\n",
       "              -0.0253906, 0.00793457],\n",
       "             [0.0115356, -4.22001e-05, -0.0114136, ..., -0.0078125,\n",
       "              0.0219727, -0.0050354]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00717163, 0.00741577, -0.0159912, ..., 0.013855, -0.0158691,\n",
       "             -0.0354004],\n",
       "            [-0.00299072, 0.000965118, 0.00640869, ..., -0.00445557,\n",
       "             0.012207, -0.0200195],\n",
       "            [0.00598145, -0.00518799, 0.0100098, ..., -0.0202637,\n",
       "             0.000105858, 0.000583649],\n",
       "            ...,\n",
       "            [-0.00860596, -0.00970459, 0.006073, ..., -0.0253906,\n",
       "             -0.00891113, 0.00357056],\n",
       "            [0.015564, 0.0088501, 0.0027771, ..., -0.0115356, 0.00897217,\n",
       "             -0.0368652],\n",
       "            [-0.0123901, -0.00421143, -0.00506592, ..., 0.0144043,\n",
       "             0.00430298, 0.0507812]],\n",
       "    \n",
       "           [[0.00817871, 0.00683594, -0.0252686, ..., 0.0419922, -0.0166016,\n",
       "             0.00558472],\n",
       "            [-0.00704956, -0.00537109, 0.00127411, ..., -0.00352478,\n",
       "             0.00854492, -0.00546265],\n",
       "            [-0.0117188, -0.00349426, 0.0122681, ..., -0.0388184,\n",
       "             -0.0126343, 0.0195312],\n",
       "            ...,\n",
       "            [-0.0159912, 0.00515747, -4.33922e-05, ..., -0.0228271,\n",
       "             -0.00692749, -0.00964355],\n",
       "            [0.0126343, -0.00674438, 0.003479, ..., -0.00386047,\n",
       "             -0.000272751, 0.00242615],\n",
       "            [-0.0130005, 0.00817871, -0.00588989, ..., 0.012085, 0.0123291,\n",
       "             0.0144043]],\n",
       "    \n",
       "           [[-0.00267029, -0.00860596, 0.00436401, ..., -0.0250244,\n",
       "             -0.0437012, -0.0180664],\n",
       "            [0.00735474, -0.00430298, 0.000808716, ..., -0.032959,\n",
       "             -0.0112915, 0.00439453],\n",
       "            [-0.00506592, -0.00196838, -0.006073, ..., 0.0126343,\n",
       "             -0.0119629, -0.00946045],\n",
       "            ...,\n",
       "            [0.000720978, 0.0114746, 0.0157471, ..., -0.00830078,\n",
       "             -0.00680542, 0.000366211],\n",
       "            [0.00720215, 0.00958252, -0.00182343, ..., 0.00976562,\n",
       "             -0.0122681, -0.00778198],\n",
       "            [-0.00317383, 0.0100098, -0.00448608, ..., -0.0146484,\n",
       "             -0.00628662, 0.0444336]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00149536, -0.00405884, 0.00205994, ..., -0.00302124,\n",
       "             -0.0045166, -0.0131226],\n",
       "            [0.00567627, 0.00213623, -0.00491333, ..., 0.00738525,\n",
       "             -0.00469971, 0.00866699],\n",
       "            [-0.0062561, 0.000370026, -0.00056839, ..., 0.00239563,\n",
       "             0.00653076, 0.00778198],\n",
       "            ...,\n",
       "            [-0.00759888, -0.00268555, -2.43187e-05, ..., 0.00592041,\n",
       "             0.0224609, -0.00331116],\n",
       "            [-0.00445557, -0.00686646, -0.000709534, ..., -0.00196838,\n",
       "             -0.0174561, -0.00328064],\n",
       "            [0.00121307, -0.00436401, 0.00656128, ..., 0.026123, 0.0209961,\n",
       "             -0.00188446]],\n",
       "    \n",
       "           [[-0.00138855, -0.006073, 0.0102539, ..., -0.0234375, 0.0108032,\n",
       "             0.0334473],\n",
       "            [-0.00357056, 0.0055542, -0.00106812, ..., -0.00939941,\n",
       "             -0.00141144, 0.00424194],\n",
       "            [-0.00836182, -2.2769e-05, -0.00582886, ..., -8.63075e-05,\n",
       "             -0.00769043, 0.00253296],\n",
       "            ...,\n",
       "            [0.00805664, -0.000648499, -0.012085, ..., 0.0216064,\n",
       "             -0.0227051, 0.00915527],\n",
       "            [-0.0198975, 0.0181885, -0.00143433, ..., -0.0161133,\n",
       "             -0.00114441, 0.0127563],\n",
       "            [-0.00396729, 0.0050354, 0.000537872, ..., 0.0181885,\n",
       "             0.00408936, 0.0105591]],\n",
       "    \n",
       "           [[0.00564575, -0.026123, -0.00163269, ..., 0.0200195,\n",
       "             -0.00176239, 0.0251465],\n",
       "            [0.00323486, -0.0239258, 0.00190735, ..., -0.00683594,\n",
       "             -0.0100708, 0.0280762],\n",
       "            [0.00552368, 0.00723267, 0.00646973, ..., 0.0144043,\n",
       "             -0.00909424, -0.0200195],\n",
       "            ...,\n",
       "            [0.00148773, -0.0244141, 0.000946045, ..., 0.00328064,\n",
       "             0.0127563, -0.0107422],\n",
       "            [-0.0112305, 0.0062561, -0.0102539, ..., 0.00263977, 0.0112305,\n",
       "             0.00454712],\n",
       "            [-0.00341797, -0.0139771, -0.00537109, ..., 0.0198975,\n",
       "             0.00445557, 0.0258789]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00408936, 0.00610352, -0.00308228, ..., 0.00424194,\n",
       "            -0.00604248, -0.0163574],\n",
       "           [0.00424194, -0.00402832, 0.0131226, ..., 0.00219727,\n",
       "            -0.00704956, -0.00805664],\n",
       "           [0.00302124, 0.00546265, -0.00137329, ..., -0.00292969,\n",
       "            0.00302124, 0.00130463],\n",
       "           ...,\n",
       "           [-0.00306702, 0.000694275, -0.00509644, ..., -0.0114746,\n",
       "            -0.0107422, 0.00115967],\n",
       "           [-0.0133667, 0.00823975, -0.00133514, ..., -0.00171661,\n",
       "            -0.00386047, 0.0274658],\n",
       "           [0.000307083, 0.00482178, 0.00187683, ..., -0.00891113,\n",
       "            0.00588989, 0.00698853]],\n",
       "   \n",
       "          [[-0.0153198, -0.0194092, 0.00585938, ..., 0.00134277,\n",
       "            0.00314331, 0.00427246],\n",
       "           [0.00186157, -0.00909424, 0.00546265, ..., 0.00163269,\n",
       "            -0.0128174, 0.00549316],\n",
       "           [0.00204468, 0.0125732, 0.00592041, ..., -0.0109253, 0.0039978,\n",
       "            -0.00170135],\n",
       "           ...,\n",
       "           [-0.00402832, -0.0131226, 0.0112305, ..., 0.00866699,\n",
       "            -0.0098877, -0.00506592],\n",
       "           [0.0174561, -0.00570679, -0.0114136, ..., -0.00241089,\n",
       "            0.0144653, 0.0130615],\n",
       "           [0.00147247, -0.00063324, -0.00390625, ..., -0.00576782,\n",
       "            0.0131226, -0.0062561]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.0167236, -0.00549316, 0.012085, ..., -0.000341415, 0.00144196,\n",
       "           0.00224304],\n",
       "          [-0.0109253, -0.00775146, -0.00131226, ..., -0.0147705,\n",
       "           -0.0090332, -0.0127563],\n",
       "          [0.00320435, 0.00165558, -0.00338745, ..., -0.00567627, 0.0043335,\n",
       "           0.00250244],\n",
       "          ...,\n",
       "          [0.00169373, -2.93255e-05, 0.000782013, ..., -0.00326538,\n",
       "           -0.00546265, -0.0108032],\n",
       "          [-0.000270844, 0.00552368, 0.00241089, ..., -0.00364685,\n",
       "           0.0109863, 0.00244141],\n",
       "          [0.00204468, 0.00463867, 0.0017395, ..., -0.00337219,\n",
       "           -0.000480652, -1.07288e-05]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([1.25, 1.07812, 1.29688, ..., 1.35156, 1.29688, 1.14062], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([2.64062, 2.625, 2.73438, ..., 2.51562, 2.625, 2.3125], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.414062, 0.59375, 0.5, ..., 0.451172, 0.375, 0.554688], dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.175781, 0.236328, 0.203125, ..., 0.168945, 0.128906, 0.248047],      dtype=bfloat16)}},\n",
       " 'layer_2': {'attn': {'attn_vec_einsum': {'w': Array([[[0.0179443, -0.00765991, 0.000134468, ..., 0.00238037,\n",
       "             0.00204468, -0.00454712],\n",
       "            [-0.0106812, 0.0088501, -0.0234375, ..., 0.0123901, 0.0126953,\n",
       "             -0.00958252],\n",
       "            [-0.0106812, -0.00132751, 0.0142822, ..., 0.00848389,\n",
       "             0.00247192, -0.00479126],\n",
       "            ...,\n",
       "            [0.000219345, -0.00680542, -0.00891113, ..., 0.0174561,\n",
       "             -0.00689697, -0.00141144],\n",
       "            [0.00671387, 0.0116577, 0.0183105, ..., 0.0170898, -0.00218201,\n",
       "             0.00595093],\n",
       "            [-0.00133514, 0.00509644, 0.000167847, ..., 0.0203857,\n",
       "             0.00964355, 0.0043335]],\n",
       "    \n",
       "           [[0.00111389, -0.0143433, -0.00133514, ..., -0.00105286,\n",
       "             -0.000720978, -0.00686646],\n",
       "            [0.0197754, 0.00570679, 0.00402832, ..., 0.0039978, 0.00854492,\n",
       "             -0.0187988],\n",
       "            [-0.00769043, -0.00308228, -0.0142212, ..., 0.024292, 0.0110474,\n",
       "             -0.00297546],\n",
       "            ...,\n",
       "            [-0.00994873, -0.0161133, -0.000617981, ..., 0.0200195,\n",
       "             -0.00273132, 0.00227356],\n",
       "            [0.0123291, 0.0071106, -0.0158691, ..., -0.00842285,\n",
       "             -0.00174713, -0.00717163],\n",
       "            [-0.0236816, -0.00167084, -0.0101929, ..., -0.0045166,\n",
       "             0.0162354, -0.00723267]],\n",
       "    \n",
       "           [[-0.00136566, 0.000253677, 0.0108032, ..., -0.000656128,\n",
       "             0.0194092, -0.001091],\n",
       "            [0.0250244, 0.00592041, 0.0168457, ..., 0.0263672, -0.0256348,\n",
       "             0.0163574],\n",
       "            [-0.00512695, 0.0201416, 0.000267029, ..., -0.0102539,\n",
       "             -0.0161133, -5.50747e-05],\n",
       "            ...,\n",
       "            [0.00167847, -0.0090332, -0.022583, ..., -0.00350952, 0.0118408,\n",
       "             0.015625],\n",
       "            [-0.00939941, 0.00350952, -0.00263977, ..., 0.0045166,\n",
       "             -0.00216675, -0.00811768],\n",
       "            [0.0124512, -0.00726318, -0.00292969, ..., 0.020752, -0.0133057,\n",
       "             -0.00280762]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00811768, -0.0158691, 0.0117188, ..., -0.0120239, 0.0187988,\n",
       "             0.00613403],\n",
       "            [-0.00213623, 0.00958252, -0.034668, ..., -0.00579834,\n",
       "             -0.0167236, 0.00567627],\n",
       "            [-0.0297852, 0.0114746, -0.00305176, ..., 0.0072937, 0.00970459,\n",
       "             -0.00317383],\n",
       "            ...,\n",
       "            [-0.00282288, -0.00491333, -0.00424194, ..., 0.00512695,\n",
       "             0.0118408, 0.00564575],\n",
       "            [0.000312805, 0.000450134, 0.00341797, ..., 0.0045166,\n",
       "             -0.00375366, -0.00592041],\n",
       "            [0.00289917, 0.00671387, 0.00159454, ..., 0.00872803,\n",
       "             0.00793457, 0.00540161]],\n",
       "    \n",
       "           [[0.0140991, -0.013855, -0.006073, ..., -0.026123, -0.00082016,\n",
       "             -0.00157928],\n",
       "            [0.000160217, 0.00915527, -0.00546265, ..., 0.0102539,\n",
       "             0.0015564, -0.0117798],\n",
       "            [-0.00726318, -0.0314941, -0.00228882, ..., -0.0197754,\n",
       "             -0.00352478, 0.0211182],\n",
       "            ...,\n",
       "            [0.00778198, -0.0045166, -0.00582886, ..., -0.000717163,\n",
       "             -0.00805664, -0.0123901],\n",
       "            [0.013916, 0.000169754, -0.00222778, ..., -0.00921631,\n",
       "             0.0113525, 0.00534058],\n",
       "            [-0.00775146, 0.00418091, 0.00970459, ..., 0.00445557,\n",
       "             -0.00463867, 0.00619507]],\n",
       "    \n",
       "           [[0.00088501, 0.00958252, 0.0150146, ..., 0.0014267, -0.0100708,\n",
       "             -0.0128784],\n",
       "            [-0.0090332, -0.00689697, -0.0128784, ..., 0.0235596,\n",
       "             -0.0302734, -0.00476074],\n",
       "            [0.00454712, -0.0140991, 0.0037384, ..., -0.00149536,\n",
       "             -0.0168457, -0.000778198],\n",
       "            ...,\n",
       "            [0.00149536, 0.012085, 0.00436401, ..., 0.0209961, -0.0344238,\n",
       "             -0.00540161],\n",
       "            [0.00958252, -0.013916, -0.0106201, ..., -0.0163574, 0.0125732,\n",
       "             0.0183105],\n",
       "            [-0.00463867, -0.00518799, 0.00701904, ..., 0.0148926,\n",
       "             0.00473022, 0.0151978]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.00317383, 0.0146484, -0.0119019, ..., 0.0163574,\n",
       "              0.00218201, -0.0238037],\n",
       "             [-0.0131836, -0.0285645, -0.0101318, ..., -0.0187988,\n",
       "              0.0247803, 0.00741577],\n",
       "             [-8.10623e-05, -0.0163574, -0.00125122, ..., 0.00546265,\n",
       "              0.0110474, 0.0151367],\n",
       "             ...,\n",
       "             [0.000873566, 4.60148e-05, -0.0217285, ..., -0.0183105,\n",
       "              0.0057373, 0.0209961],\n",
       "             [0.0114136, -0.00701904, -0.010437, ..., 0.0124512,\n",
       "              -0.0120239, 0.000789642],\n",
       "             [0.00741577, 0.00585938, 0.0045166, ..., -0.00424194,\n",
       "              -0.0035553, -0.00512695]],\n",
       "    \n",
       "            [[-0.000177383, -0.0206299, -0.00276184, ..., 0.00233459,\n",
       "              -2.75373e-05, 0.0181885],\n",
       "             [-0.00109863, 0.00592041, -0.00180054, ..., -0.0114136,\n",
       "              0.0125732, 0.0139771],\n",
       "             [-0.0189209, 0.00161743, 0.00823975, ..., 0.0109863,\n",
       "              0.0162354, 0.00524902],\n",
       "             ...,\n",
       "             [-0.00534058, 0.00367737, 0.00167847, ..., 0.0142212,\n",
       "              0.0127563, -0.026123],\n",
       "             [-0.0090332, 0.0167236, 0.00469971, ..., 0.0043335, 0.0157471,\n",
       "              0.00585938],\n",
       "             [0.00209045, -0.0098877, 0.00445557, ..., -0.0090332,\n",
       "              0.0163574, -0.0187988]],\n",
       "    \n",
       "            [[-0.00112152, 0.0072937, 0.0142212, ..., -0.0181885,\n",
       "              -0.00263977, 0.0129395],\n",
       "             [-0.00442505, -0.00686646, 0.00753784, ..., -0.00135803,\n",
       "              0.0444336, -0.03125],\n",
       "             [-0.000184059, -0.00662231, -0.0131226, ..., 0.0170898,\n",
       "              0.00424194, 0.0354004],\n",
       "             ...,\n",
       "             [-0.00326538, -0.0181885, -0.00668335, ..., 0.000862122,\n",
       "              -0.0148926, -0.0122681],\n",
       "             [0.0164795, -0.0071106, 0.0222168, ..., 0.0114746,\n",
       "              -0.00793457, -0.0153198],\n",
       "             [-0.00024128, 0.0114136, 0.0016861, ..., -0.0119019,\n",
       "              0.0219727, 0.0246582]],\n",
       "    \n",
       "            [[-0.0124512, 0.000232697, -0.0169678, ..., 0.0017395,\n",
       "              -0.0157471, 0.0108032],\n",
       "             [0.000946045, 0.00964355, 0.00741577, ..., -0.0164795,\n",
       "              0.0189209, -0.00811768],\n",
       "             [-0.00176239, -0.0113525, -0.0126343, ..., 0.00112915,\n",
       "              -0.00159454, 0.00421143],\n",
       "             ...,\n",
       "             [-0.00218201, 0.00897217, 0.019043, ..., 0.00494385,\n",
       "              -0.00671387, -0.00631714],\n",
       "             [0.0314941, 0.00308228, 0.0150757, ..., -0.00634766,\n",
       "              -0.00476074, 0.000198364],\n",
       "             [-0.000244141, -0.00769043, 0.0166016, ..., 0.0150757,\n",
       "              0.000117302, 0.0125732]]],\n",
       "    \n",
       "    \n",
       "           [[[0.00939941, -0.00668335, 0.00512695, ..., 0.026123,\n",
       "              0.000907898, -0.00689697],\n",
       "             [-0.00294495, -0.00588989, -0.00830078, ..., -0.00830078,\n",
       "              -0.00424194, 0.0011673],\n",
       "             [0.00393677, -0.00546265, -0.0140991, ..., 0.0030365,\n",
       "              0.0043335, 0.00424194],\n",
       "             ...,\n",
       "             [-0.0128174, 0.00543213, 0.0118408, ..., -0.0218506,\n",
       "              -0.0115967, -0.00680542],\n",
       "             [0.00247192, 0.00138092, 0.000991821, ..., 0.00285339,\n",
       "              0.00151062, 0.00128937],\n",
       "             [0.00149536, 0.00823975, -0.0127563, ..., 0.00714111,\n",
       "              -0.0018158, -0.00994873]],\n",
       "    \n",
       "            [[-0.0107422, 0.0197754, -0.00994873, ..., 0.0108643,\n",
       "              -0.0131226, 0.0154419],\n",
       "             [-0.00282288, 0.0194092, 0.000267029, ..., -0.0172119,\n",
       "              -0.00628662, -0.0132446],\n",
       "             [-0.00215149, 0.0130005, -0.00698853, ..., -0.0356445,\n",
       "              0.00222778, -0.000827789],\n",
       "             ...,\n",
       "             [0.00150299, 0.00482178, -0.00112915, ..., -0.00270081,\n",
       "              0.0072937, -0.0163574],\n",
       "             [0.00442505, -0.0145264, 0.000972748, ..., 0.00219727,\n",
       "              -0.000226974, 0.0155029],\n",
       "             [0.0115356, 0.0198975, 0.00897217, ..., 0.00854492,\n",
       "              0.000968933, 0.00952148]],\n",
       "    \n",
       "            [[0.00793457, 0.0072937, 0.0385742, ..., 0.000576019,\n",
       "              -0.00320435, -0.00297546],\n",
       "             [0.0134277, -0.0148926, -0.010498, ..., 0.0240479,\n",
       "              -0.00415039, 0.00674438],\n",
       "             [-0.0142822, 0.045166, 0.00131989, ..., 0.00375366,\n",
       "              -0.00270081, -0.00726318],\n",
       "             ...,\n",
       "             [0.00811768, 0.0101929, -0.0108032, ..., -0.0088501,\n",
       "              0.00227356, -0.0220947],\n",
       "             [-0.013855, -0.00115204, -0.00318909, ..., -0.00270081,\n",
       "              0.00259399, -0.00634766],\n",
       "             [-0.0055542, 0.00216675, -0.000564575, ..., -0.00726318,\n",
       "              0.00488281, -0.00448608]],\n",
       "    \n",
       "            [[0.0108643, 0.00631714, -0.0090332, ..., -0.000185966,\n",
       "              -0.00836182, -0.0128784],\n",
       "             [0.00305176, 0.00872803, -0.015625, ..., 0.00147247,\n",
       "              0.00320435, 0.00358582],\n",
       "             [-0.00558472, 0.0101929, -0.00744629, ..., 0.0117798,\n",
       "              0.00189972, -0.010437],\n",
       "             ...,\n",
       "             [-0.00382996, 0.00151825, -0.00136566, ..., -0.00119019,\n",
       "              0.0107422, -0.0247803],\n",
       "             [0.0111694, 0.00308228, 0.00823975, ..., -0.0115967,\n",
       "              0.0103149, 0.00683594],\n",
       "             [0.0119019, -0.00286865, 0.00137329, ..., 0.00146484,\n",
       "              -0.0108643, 0.00393677]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00762939, 0.00537109, 0.00680542, ..., -0.00151062,\n",
       "             -0.0045166, 0.00384521],\n",
       "            [-0.00163269, 0.0178223, 0.00485229, ..., -0.0140991,\n",
       "             -0.0124512, -0.015564],\n",
       "            [0.00933838, 0.00933838, 0.00830078, ..., 0.00994873,\n",
       "             0.00111389, -0.00723267],\n",
       "            ...,\n",
       "            [0.00393677, -0.00708008, -0.00216675, ..., -0.00069046,\n",
       "             0.0120239, -0.0126343],\n",
       "            [0.0194092, 0.0162354, -0.0198975, ..., 0.00964355, 0.00637817,\n",
       "             0.00952148],\n",
       "            [-0.00178528, 0.0101929, 0.00196838, ..., 0.0148926,\n",
       "             -0.00357056, -0.0168457]],\n",
       "    \n",
       "           [[-0.0115967, -0.0105591, -0.0062561, ..., 0.00162506,\n",
       "             -0.00147247, -0.0170898],\n",
       "            [0.00793457, 0.00741577, -0.0134888, ..., 0.0103149,\n",
       "             -0.00325012, -0.024292],\n",
       "            [-0.00221252, 0.0120239, -0.00276184, ..., -0.00994873,\n",
       "             -0.0014801, -0.0308838],\n",
       "            ...,\n",
       "            [0.0269775, -0.00262451, 0.00491333, ..., 0.0136108, -0.0018692,\n",
       "             0.0217285],\n",
       "            [4.55379e-05, 0.0183105, -0.0133667, ..., -0.0100098, -0.013916,\n",
       "             -0.00628662],\n",
       "            [-0.00811768, 0.0114746, -0.00119781, ..., 0.0055542,\n",
       "             -0.00695801, 0.0223389]],\n",
       "    \n",
       "           [[0.000957489, -0.00418091, -0.00668335, ..., 0.0317383,\n",
       "             -0.0043335, -0.0205078],\n",
       "            [0.00946045, 0.00205994, -0.0088501, ..., -0.0112915, -0.036377,\n",
       "             -0.0269775],\n",
       "            [0.00191498, 0.00141907, -0.00389099, ..., -0.00387573,\n",
       "             -0.0551758, -0.00579834],\n",
       "            ...,\n",
       "            [0.032959, -0.0344238, 0.000368118, ..., 0.00228882, 0.0170898,\n",
       "             0.0473633],\n",
       "            [-0.0118408, 0.00308228, 0.00402832, ..., 0.00149536,\n",
       "             0.00720215, -0.00378418],\n",
       "            [-0.015564, 0.000793457, -0.00927734, ..., 0.00823975,\n",
       "             -0.00976562, 0.0291748]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00262451, 0.00811768, 0.00616455, ..., 0.0125732,\n",
       "             -0.00811768, 0.00958252],\n",
       "            [-0.00927734, 0.0133057, -0.00964355, ..., -0.0118408,\n",
       "             0.0152588, -0.000153542],\n",
       "            [0.00613403, 0.0196533, -0.0155029, ..., -0.0119629, 0.0103149,\n",
       "             -0.00189209],\n",
       "            ...,\n",
       "            [-0.0253906, 0.0341797, -0.0245361, ..., -0.00201416,\n",
       "             -0.00546265, 0.00292969],\n",
       "            [0.00292969, -0.0137329, 0.000843048, ..., -0.0150146,\n",
       "             0.00442505, -0.0133057],\n",
       "            [0.0194092, 0.0336914, -0.0177002, ..., 0.0111694, 0.0201416,\n",
       "             -0.00376892]],\n",
       "    \n",
       "           [[-0.00613403, 0.0100098, 0.00494385, ..., -0.0246582,\n",
       "             0.00135803, -0.00994873],\n",
       "            [0.0118408, 0.00421143, -0.0289307, ..., 0.00334167, -0.0200195,\n",
       "             -0.0113525],\n",
       "            [-0.00866699, 0.0136108, -0.0145264, ..., 0.0213623, -0.0252686,\n",
       "             -0.00352478],\n",
       "            ...,\n",
       "            [0.00540161, 0.00131989, -0.00747681, ..., -0.00872803,\n",
       "             -0.000576019, 0.0038147],\n",
       "            [0.0202637, -0.0119019, -0.0235596, ..., 0.0157471, 0.00222778,\n",
       "             0.00823975],\n",
       "            [-0.00183868, -0.010498, -0.000139236, ..., 0.00161743,\n",
       "             0.0137329, -0.0134277]],\n",
       "    \n",
       "           [[0.0012207, -0.00120544, 0.00518799, ..., 1.70469e-05,\n",
       "             -0.000579834, -0.00314331],\n",
       "            [0.00136566, 0.0100098, -0.00463867, ..., -0.00512695,\n",
       "             0.00680542, 0.00280762],\n",
       "            [0.00335693, 0.00387573, -0.00169373, ..., 0.0196533, 0.0123901,\n",
       "             -0.00244141],\n",
       "            ...,\n",
       "            [-0.00131226, 0.00933838, -0.00216675, ..., 0.00300598,\n",
       "             0.00160217, -0.0125732],\n",
       "            [0.00265503, -0.00692749, 0.00372314, ..., -0.00282288,\n",
       "             0.00897217, 0.00933838],\n",
       "            [-0.00265503, 0.00708008, 0.00205994, ..., 0.00891113,\n",
       "             -0.0111694, 0.0155029]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.00469971, 0.0118408, 0.0032959, ..., -0.00427246, 0.0030365,\n",
       "            0.00741577],\n",
       "           [-0.00228882, -0.00170135, -0.00753784, ..., -0.0129395,\n",
       "            0.00726318, 0.00878906],\n",
       "           [-0.00695801, -0.0100708, -0.0103149, ..., 0.00460815,\n",
       "            -0.00244141, -0.00534058],\n",
       "           ...,\n",
       "           [-0.000804901, -2.63453e-05, -0.00242615, ..., -0.0120239,\n",
       "            -0.000541687, 0.00430298],\n",
       "           [0.0142212, -0.00415039, -0.00183868, ..., 0.012207,\n",
       "            -0.00463867, 0.0062561],\n",
       "           [0.00360107, -0.00897217, 0.0107422, ..., -0.0107422, 0.0098877,\n",
       "            -0.00570679]],\n",
       "   \n",
       "          [[-0.00445557, 0.00024128, 0.00317383, ..., -0.00291443,\n",
       "            0.00273132, 0.00473022],\n",
       "           [-0.0113525, -0.000762939, 0.00344849, ..., 0.00653076,\n",
       "            0.0158691, 0.00405884],\n",
       "           [0.0032196, -0.0159912, -0.00386047, ..., 0.0144043,\n",
       "            -0.00350952, -0.00294495],\n",
       "           ...,\n",
       "           [0.00334167, -0.00285339, -0.00041008, ..., 0.0149536,\n",
       "            0.00204468, -0.00170898],\n",
       "           [-0.00137329, -0.00534058, 0.00860596, ..., -0.00408936,\n",
       "            0.00509644, -0.00466919],\n",
       "           [-0.00201416, -0.00982666, 0.00180817, ..., 0.00191498,\n",
       "            0.000337601, -0.00576782]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00933838, 0.00193024, -0.0123291, ..., 0.00848389, 0.0016098,\n",
       "           -0.0016098],\n",
       "          [-0.00610352, 0.00439453, -0.00933838, ..., -0.0180664, -0.012085,\n",
       "           -0.00595093],\n",
       "          [0.000587463, 0.000507355, 0.00582886, ..., 0.00244141,\n",
       "           -0.00236511, 0.00350952],\n",
       "          ...,\n",
       "          [0.000671387, 0.00939941, 0.00823975, ..., -0.00537109, 0.0020752,\n",
       "           -0.0136719],\n",
       "          [-0.00512695, 0.0159912, -0.00854492, ..., -0.0137329,\n",
       "           -0.000907898, -0.0090332],\n",
       "          [-0.0123291, -0.00537109, 0.010437, ..., 0.00189209, -0.0038147,\n",
       "           0.00291443]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([-0.232422, -0.229492, -0.160156, ..., -0.414062, 0.0179443,\n",
       "          -0.265625], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.131836, 0.105469, 0.139648, ..., -0.141602, 0.326172, 0.135742],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.714844, 0.667969, 0.71875, ..., 1.07812, 0.300781, 0.515625],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.5, 0.511719, 0.53125, ..., 0.941406, 0.00320435, 0.40625],      dtype=bfloat16)}},\n",
       " 'layer_20': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.00756836, -0.00601196, -0.00952148, ..., 0.0114136,\n",
       "             -0.00830078, -0.00546265],\n",
       "            [-0.00179291, -0.006073, -0.000801086, ..., 0.00212097,\n",
       "             -0.00817871, -0.00640869],\n",
       "            [-0.000724792, 0.0166016, -0.00154877, ..., -0.00344849,\n",
       "             0.019043, -0.0019455],\n",
       "            ...,\n",
       "            [0.00778198, -0.0098877, -0.00139618, ..., 0.0174561,\n",
       "             -0.0107422, 0.00497437],\n",
       "            [-0.00378418, -0.00352478, 0.00100708, ..., 0.0101929,\n",
       "             0.00653076, -0.0043335],\n",
       "            [-0.00352478, 0.00154877, 0.00714111, ..., 0.00291443,\n",
       "             -0.00872803, 0.0057373]],\n",
       "    \n",
       "           [[-0.00158691, -0.00390625, 0.00430298, ..., 0.000968933,\n",
       "             -0.00189972, -0.00187683],\n",
       "            [0.00216675, 0.00302124, 0.0227051, ..., -0.0184326,\n",
       "             -0.00274658, -0.00227356],\n",
       "            [-0.0098877, -0.010498, 0.00138855, ..., -0.000701904,\n",
       "             0.0106201, 0.0136719],\n",
       "            ...,\n",
       "            [-0.00106049, -0.00154114, 0.00830078, ..., 0.000740051,\n",
       "             -0.00717163, -0.0022583],\n",
       "            [-0.00156403, -0.0141602, -0.00662231, ..., -0.00506592,\n",
       "             0.00717163, 0.00315857],\n",
       "            [0.00793457, 0.00494385, -0.00469971, ..., -0.0161133,\n",
       "             0.00656128, 0.0229492]],\n",
       "    \n",
       "           [[-0.0123901, 0.00105286, 0.0206299, ..., -0.0088501, -0.0241699,\n",
       "             0.00653076],\n",
       "            [-0.00921631, 0.00191498, 0.0162354, ..., -0.0126343,\n",
       "             0.00164032, -0.00454712],\n",
       "            [0.00811768, 0.0183105, -0.019043, ..., -0.0131836, 0.0135498,\n",
       "             -0.0128784],\n",
       "            ...,\n",
       "            [-0.0146484, 0.0251465, -0.0205078, ..., 0.00202942,\n",
       "             -0.00106812, -0.00350952],\n",
       "            [-0.0142212, 0.0219727, 0.00280762, ..., 0.00970459, 0.00247192,\n",
       "             0.000272751],\n",
       "            [-0.00267029, -0.00494385, 0.0020752, ..., 0.00308228,\n",
       "             0.0141602, 0.00698853]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00662231, -0.00270081, -0.00424194, ..., 0.00332642,\n",
       "             -0.00848389, -0.0211182],\n",
       "            [-0.00775146, -0.0108032, -0.0155029, ..., -0.0222168,\n",
       "             0.0131836, -0.000682831],\n",
       "            [-0.000541687, 0.00866699, 0.0227051, ..., 0.00031662,\n",
       "             -0.019165, 0.00878906],\n",
       "            ...,\n",
       "            [0.0012207, -0.00328064, 0.0125732, ..., 0.0088501, -0.0136108,\n",
       "             0.00878906],\n",
       "            [0.00183868, 0.00396729, 0.00762939, ..., -0.00315857,\n",
       "             0.00187683, -0.00337219],\n",
       "            [-0.00595093, -0.0045166, 0.0108032, ..., -0.00299072,\n",
       "             -0.00836182, 0.0125732]],\n",
       "    \n",
       "           [[-0.012146, -0.00759888, 0.00744629, ..., -0.0162354,\n",
       "             -0.00634766, -0.00187683],\n",
       "            [-0.00631714, -0.00524902, 0.0222168, ..., 0.00595093,\n",
       "             -0.0159912, 0.0098877],\n",
       "            [-0.00576782, -0.000743866, -0.0125122, ..., -0.000206947,\n",
       "             -0.00165558, -0.00564575],\n",
       "            ...,\n",
       "            [-0.00485229, 0.0150146, -0.00382996, ..., 0.0145264,\n",
       "             0.00946045, 0.0114136],\n",
       "            [0.0109863, -0.00601196, 0.0106201, ..., -0.0194092,\n",
       "             -0.00631714, 0.0134888],\n",
       "            [-0.000572205, -0.00125122, -0.0103149, ..., 0.00753784,\n",
       "             0.00363159, 0.0149536]],\n",
       "    \n",
       "           [[0.0109863, 0.00238037, -0.0090332, ..., 0.0166016, 0.0159912,\n",
       "             -0.00187683],\n",
       "            [0.00964355, 0.00854492, -0.0109253, ..., -0.0159912,\n",
       "             0.00747681, -0.0140381],\n",
       "            [0.00964355, -0.00479126, 0.00164795, ..., 0.0118408,\n",
       "             -0.0105591, 0.0148315],\n",
       "            ...,\n",
       "            [-0.0090332, -0.0133667, 0.00131226, ..., -0.00650024,\n",
       "             -0.00830078, -0.00259399],\n",
       "            [-0.00540161, 0.00537109, -0.0170898, ..., 0.00872803,\n",
       "             -0.00939941, -0.00506592],\n",
       "            [0.00263977, -0.00154877, 0.00939941, ..., -0.00346375,\n",
       "             -0.0281982, 0.00939941]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.0022583, -0.00382996, -0.00463867, ..., -0.0157471,\n",
       "              -0.0196533, -0.000295639],\n",
       "             [-0.00445557, -0.0114746, 0.00848389, ..., -0.0134888,\n",
       "              0.00158691, 0.000934601],\n",
       "             [0.00430298, -0.00389099, -0.0177002, ..., 0.00582886,\n",
       "              0.00357056, -0.0186768],\n",
       "             ...,\n",
       "             [-0.00601196, 0.0078125, 0.00141907, ..., 0.0195312,\n",
       "              0.00921631, -0.0231934],\n",
       "             [0.0103149, 0.0264893, -0.0057373, ..., -0.000440598,\n",
       "              -0.0098877, 0.00674438],\n",
       "             [0.0019989, 0.000709534, 0.00379944, ..., -0.000789642,\n",
       "              0.00616455, -0.00271606]],\n",
       "    \n",
       "            [[0.000831604, 0.0112915, -0.00111389, ..., -0.0131836,\n",
       "              0.000356674, 0.000659943],\n",
       "             [-0.00173187, 0.00276184, 0.00588989, ..., 0.00314331,\n",
       "              -0.0115356, -0.00291443],\n",
       "             [-0.00111389, -0.00994873, -0.00137329, ..., -0.0236816,\n",
       "              -0.00250244, -0.0159912],\n",
       "             ...,\n",
       "             [-0.00610352, 0.0103149, -0.000255585, ..., -0.022583,\n",
       "              0.00107574, 0.000614166],\n",
       "             [0.0170898, 0.0152588, 0.0055542, ..., 0.0178223, 0.0142212,\n",
       "              0.00570679],\n",
       "             [-0.00182343, -0.00482178, 2.90871e-05, ..., 0.0383301,\n",
       "              -0.00497437, -0.00836182]],\n",
       "    \n",
       "            [[-0.0167236, -0.0247803, 0.0178223, ..., 0.0217285,\n",
       "              -0.00512695, 0.00010252],\n",
       "             [-0.0107422, -0.0245361, -0.000125885, ..., -0.00346375,\n",
       "              -0.00442505, -0.0181885],\n",
       "             [0.000991821, 0.00970459, 0.000541687, ..., -0.024292,\n",
       "              -0.00393677, -0.00872803],\n",
       "             ...,\n",
       "             [-0.00634766, 0.00939941, 0.00704956, ..., 0.0119629,\n",
       "              -0.00245667, -0.013855],\n",
       "             [0.00300598, 0.00549316, 0.00854492, ..., 0.0111084,\n",
       "              -0.00439453, 0.012146],\n",
       "             [-0.00650024, -0.00279236, -0.00311279, ..., -0.00107574,\n",
       "              -0.00121307, -0.0108643]],\n",
       "    \n",
       "            [[-0.0027771, -0.017334, -0.00360107, ..., 0.0163574,\n",
       "              0.00704956, -0.0139771],\n",
       "             [-0.0117798, -0.00604248, 0.00186157, ..., 0.0212402,\n",
       "              0.00674438, 0.0137939],\n",
       "             [-0.00811768, 0.00537109, -0.00305176, ..., -0.0305176,\n",
       "              0.00518799, 0.0150757],\n",
       "             ...,\n",
       "             [-0.00619507, 0.00370789, 0.00970459, ..., 9.0003e-06,\n",
       "              -0.00558472, -0.0108032],\n",
       "             [0.00228882, 0.0179443, -0.0114746, ..., 0.000747681,\n",
       "              -0.0131836, 0.00704956],\n",
       "             [-0.0098877, 0.00811768, 0.00830078, ..., -0.00823975,\n",
       "              0.00537109, -0.00346375]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0129395, -0.0135498, -0.0120239, ..., -0.00179291,\n",
       "              0.00756836, -0.00915527],\n",
       "             [0.00717163, 0.00637817, 0.0123291, ..., 0.00326538,\n",
       "              0.0146484, 0.00915527],\n",
       "             [0.0196533, -0.00964355, 0.00668335, ..., 0.0115967,\n",
       "              -0.00134277, 0.00515747],\n",
       "             ...,\n",
       "             [-0.00817871, 0.0113525, -0.00982666, ..., 0.000930786,\n",
       "              0.0228271, 0.0103149],\n",
       "             [-0.00238037, -0.020874, 0.0100098, ..., -0.00634766,\n",
       "              0.00643921, -0.0126953],\n",
       "             [-0.0119629, -0.00592041, 0.00265503, ..., 1.15037e-05,\n",
       "              -0.0115967, -0.00349426]],\n",
       "    \n",
       "            [[0.0131836, -0.00415039, -0.0100708, ..., 0.00805664,\n",
       "              0.029541, -0.0168457],\n",
       "             [-0.00300598, -0.00878906, -0.012085, ..., -0.00811768,\n",
       "              -0.00787354, 0.0280762],\n",
       "             [-0.00680542, -0.0107422, 0.000667572, ..., 0.0109863,\n",
       "              -0.00228882, 0.0111084],\n",
       "             ...,\n",
       "             [-0.0177002, -0.00598145, 0.000142097, ..., -0.00811768,\n",
       "              -0.00286865, 0.0150146],\n",
       "             [0.0339355, 0.00323486, -0.0169678, ..., 0.019043,\n",
       "              -0.00695801, -0.00631714],\n",
       "             [-0.0168457, 0.00759888, 0.0218506, ..., -0.00173187,\n",
       "              -0.0115967, 0.0141602]],\n",
       "    \n",
       "            [[0.0285645, -0.0152588, -0.00915527, ..., 0.00836182,\n",
       "              -0.0153809, 0.0078125],\n",
       "             [-0.0219727, -0.00714111, 0.0178223, ..., -0.0105591,\n",
       "              -0.0103149, 0.0153198],\n",
       "             [-0.0115356, -0.00622559, -0.0212402, ..., -0.0167236,\n",
       "              -0.00601196, 0.0119019],\n",
       "             ...,\n",
       "             [-0.0119019, -0.00634766, -0.0185547, ..., 0.000675201,\n",
       "              0.00775146, -0.00421143],\n",
       "             [-0.0157471, 0.0088501, 0.0140381, ..., -0.0214844,\n",
       "              -0.00540161, 0.00367737],\n",
       "             [0.00592041, 0.00765991, 0.00209045, ..., 0.000295639,\n",
       "              0.00662231, 0.00312805]],\n",
       "    \n",
       "            [[-0.0100708, -0.0109863, -0.00698853, ..., -0.00915527,\n",
       "              0.00189209, 0.00396729],\n",
       "             [-0.000953674, -0.00418091, 0.00558472, ..., 0.00552368,\n",
       "              0.00189209, -0.0071106],\n",
       "             [0.00102997, 0.0148926, 0.00927734, ..., -0.00231934,\n",
       "              0.00866699, -0.00335693],\n",
       "             ...,\n",
       "             [-0.00248718, -0.00765991, -0.0140991, ..., 0.0120239,\n",
       "              -0.000549316, 0.00762939],\n",
       "             [0.0137939, -0.0178223, -0.0118408, ..., 0.0233154,\n",
       "              -0.00469971, -0.0065918],\n",
       "             [-3.3617e-05, 0.00279236, -0.0115356, ..., -0.000297546,\n",
       "              -0.000957489, 0.00497437]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00193024, -0.00836182, -0.00127411, ..., -0.00482178,\n",
       "             -0.0319824, 0.0105591],\n",
       "            [-0.00236511, 0.00860596, -0.00686646, ..., 0.0235596,\n",
       "             -0.0115356, -0.0177002],\n",
       "            [-0.0135498, 0.00204468, 0.000249863, ..., -0.00854492,\n",
       "             -0.0214844, -0.0050354],\n",
       "            ...,\n",
       "            [-0.0135498, -0.00723267, -0.00701904, ..., -0.00772095,\n",
       "             0.0107422, 0.00183105],\n",
       "            [-0.00698853, 0.0162354, 0.000495911, ..., 0.0067749,\n",
       "             -0.0158691, -0.00145721],\n",
       "            [0.00439453, -0.00469971, -0.000816345, ..., -0.00604248,\n",
       "             0.0172119, 0.00970459]],\n",
       "    \n",
       "           [[0.00521851, -0.00506592, -0.0144653, ..., -0.0149536,\n",
       "             0.0136719, 0.012146],\n",
       "            [0.00500488, 0.00195312, 0.00793457, ..., -0.00512695,\n",
       "             0.00683594, -0.0107422],\n",
       "            [0.00387573, 0.00778198, 0.0101318, ..., 0.0158691, -0.0152588,\n",
       "             -0.00561523],\n",
       "            ...,\n",
       "            [-0.0122681, 0.0103149, -0.0107422, ..., 0.00958252, 0.00610352,\n",
       "             -0.00494385],\n",
       "            [0.00150299, 0.00299072, 0.000976562, ..., 0.000377655,\n",
       "             0.000286102, -0.00701904],\n",
       "            [0.0107422, -0.00854492, 0.0183105, ..., -0.00494385,\n",
       "             0.00424194, -0.00674438]],\n",
       "    \n",
       "           [[-0.00263977, -0.0158691, -0.00958252, ..., 0.00421143,\n",
       "             -0.0209961, -0.00248718],\n",
       "            [0.00976562, 0.0220947, 0.0189209, ..., -0.0192871, -0.0168457,\n",
       "             0.015625],\n",
       "            [-0.00872803, -5.62668e-05, 0.0109863, ..., 0.00332642,\n",
       "             -0.0039978, -0.0065918],\n",
       "            ...,\n",
       "            [0.00860596, -0.0292969, -0.00094223, ..., 0.0239258, 0.0109253,\n",
       "             0.00570679],\n",
       "            [-0.00056076, 0.00680542, 0.0234375, ..., -0.0115356,\n",
       "             0.00308228, 0.0157471],\n",
       "            [0.000216484, 0.00411987, -0.0167236, ..., 0.00300598,\n",
       "             -0.0110474, -0.00982666]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0043335, -0.00154877, 0.0158691, ..., 0.0258789,\n",
       "             -0.00738525, 0.00799561],\n",
       "            [0.010498, 0.0088501, 0.0114746, ..., 0.00273132, -0.00158691,\n",
       "             -0.0266113],\n",
       "            [0.00994873, -0.0123901, -0.00683594, ..., -0.00897217,\n",
       "             -0.00222778, 0.0130615],\n",
       "            ...,\n",
       "            [-0.0128784, -0.00218201, 0.00741577, ..., 0.00379944,\n",
       "             0.00119019, -0.00405884],\n",
       "            [-0.0145264, -0.00119019, -0.0100708, ..., -0.0246582,\n",
       "             0.0144043, 0.0103149],\n",
       "            [-0.00305176, -0.00946045, 0.00750732, ..., 0.00191498,\n",
       "             -0.0136108, -0.0143433]],\n",
       "    \n",
       "           [[0.00296021, -0.0206299, 0.0163574, ..., -0.00285339,\n",
       "             -0.00872803, -0.0166016],\n",
       "            [0.0168457, 4.1008e-05, -0.00909424, ..., -0.00891113,\n",
       "             0.00340271, 0.0169678],\n",
       "            [-0.0179443, -0.00964355, 0.0057373, ..., 0.0113525,\n",
       "             -0.00408936, 0.003479],\n",
       "            ...,\n",
       "            [-0.0180664, 0.00111389, -3.48091e-05, ..., -0.0198975,\n",
       "             -0.00100708, -0.00159454],\n",
       "            [0.00891113, 0.00866699, 0.00747681, ..., -0.00601196,\n",
       "             -0.00063324, 0.00291443],\n",
       "            [-0.00521851, 0.00668335, -0.0127563, ..., 0.010437, 0.00216675,\n",
       "             0.000896454]],\n",
       "    \n",
       "           [[0.00518799, -0.00056839, 0.00460815, ..., -0.0129395,\n",
       "             -0.0045166, 0.00915527],\n",
       "            [-0.001297, 0.00415039, -0.00233459, ..., -0.0202637, 0.0198975,\n",
       "             0.00346375],\n",
       "            [-0.00524902, -0.00102997, 0.0126343, ..., 0.020874, 0.0119019,\n",
       "             0.00717163],\n",
       "            ...,\n",
       "            [-0.00250244, -0.010498, -0.012207, ..., -0.0109253, 0.0206299,\n",
       "             -0.0098877],\n",
       "            [0.00454712, -0.00212097, -0.00241089, ..., -0.0137329,\n",
       "             0.010376, -0.00247192],\n",
       "            [0.00279236, -0.00215149, -0.0012207, ..., -0.00927734,\n",
       "             -0.015625, -0.0150757]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.00689697, 0.0146484, 0.00717163, ..., 0.00154877, 0.00634766,\n",
       "            -0.00582886],\n",
       "           [-0.00279236, -0.00576782, -0.00228882, ..., 0.006073,\n",
       "            -0.00370789, -0.00312805],\n",
       "           [0.00430298, 0.00222778, -0.00585938, ..., -0.00860596,\n",
       "            0.00692749, 0.00128174],\n",
       "           ...,\n",
       "           [0.00662231, 0.00494385, -0.00982666, ..., -0.00145721,\n",
       "            0.00546265, -0.00970459],\n",
       "           [-0.00524902, 0.0027771, -0.00482178, ..., 0.00125122,\n",
       "            0.0147095, 0.0030365],\n",
       "           [-0.00123596, -0.00318909, 0.0146484, ..., 0.000352859,\n",
       "            -0.00564575, -0.00291443]],\n",
       "   \n",
       "          [[-0.00570679, 0.0039978, -0.00357056, ..., -0.00473022,\n",
       "            0.0117798, 0.0223389],\n",
       "           [-0.00192261, 0.0078125, 0.00230408, ..., -0.00185394,\n",
       "            0.000358582, 0.00302124],\n",
       "           [0.00164032, 0.00325012, -0.00714111, ..., 0.00878906,\n",
       "            -0.00500488, -0.00408936],\n",
       "           ...,\n",
       "           [-0.00112915, 0.0137329, -0.00637817, ..., 0.00145721,\n",
       "            -0.0133667, -0.00328064],\n",
       "           [-0.00325012, -0.0057373, 0.00509644, ..., 0.00878906,\n",
       "            0.0105591, 0.0133667],\n",
       "           [-0.00411987, 0.00126648, -0.00872803, ..., -0.00088501,\n",
       "            0.00140381, 0.0100708]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.00915527, 0.00689697, -0.00189972, ..., -0.00546265,\n",
       "           0.00509644, 0.000930786],\n",
       "          [-0.0124512, -0.0078125, 0.00325012, ..., 0.0147705, 0.000320435,\n",
       "           -0.00552368],\n",
       "          [0.0035553, 0.00112915, -0.00585938, ..., -0.0151367, 0.00549316,\n",
       "           0.00169373],\n",
       "          ...,\n",
       "          [0.00292969, -0.00210571, -0.00390625, ..., 0.00123596,\n",
       "           -9.25064e-05, -0.0071106],\n",
       "          [0.00726318, 0.0186768, 0.00289917, ..., -0.0159912, 0.0107422,\n",
       "           -0.0132446],\n",
       "          [0.0148315, 0.0125732, -0.0025177, ..., 0.00946045, -0.00424194,\n",
       "           0.0115967]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([1.39062, 1.32031, 1.55469, ..., 1.32031, 1.50781, 1.29688],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([2.84375, 2.875, 2.90625, ..., 2.64062, 2.78125, 2.5625], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.359375, 0.330078, 0.347656, ..., 0.306641, 0.318359, 0.5],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.0220947, 0.0688477, 0.0303955, ..., 0.0279541, 0.0133057,\n",
       "          0.108887], dtype=bfloat16)}},\n",
       " 'layer_21': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.00692749, 0.0206299, -0.00121307, ..., 0.00306702,\n",
       "             0.00421143, -0.00147247],\n",
       "            [0.00878906, 0.0067749, -0.000530243, ..., 0.0213623, 0.0128784,\n",
       "             0.00209045],\n",
       "            [0.0123291, -0.0161133, -0.0114136, ..., -0.00393677,\n",
       "             -0.0213623, 0.0153198],\n",
       "            ...,\n",
       "            [0.00558472, 0.00848389, -0.0152588, ..., 0.0109253,\n",
       "             -0.00640869, 0.00136566],\n",
       "            [-0.0124512, 0.00445557, -0.0162354, ..., -0.0288086,\n",
       "             -0.00354004, -0.00787354],\n",
       "            [-0.0117188, 0.00579834, 3.69549e-05, ..., 0.0147705,\n",
       "             -0.00143433, 0.0164795]],\n",
       "    \n",
       "           [[-0.00282288, 0.000257492, 0.00479126, ..., -0.0135498,\n",
       "             0.00125885, 0.00141907],\n",
       "            [0.0062561, -0.00122833, 0.00466919, ..., 0.00340271,\n",
       "             -0.000919342, 0.00738525],\n",
       "            [-0.00131226, 0.00037384, 0.0158691, ..., -0.00753784,\n",
       "             -0.00216675, 0.010437],\n",
       "            ...,\n",
       "            [0.00628662, 0.00634766, -0.00836182, ..., 0.00524902, 0.012207,\n",
       "             0.00241089],\n",
       "            [-0.0133057, -0.00101471, 0.0108643, ..., 0.00817871, 0.0117798,\n",
       "             -0.00308228],\n",
       "            [0.00296021, -0.0175781, 0.000478745, ..., -0.00411987,\n",
       "             -0.012085, 0.0098877]],\n",
       "    \n",
       "           [[-0.0027771, -0.00915527, -0.00878906, ..., -0.00210571,\n",
       "             0.00309753, 0.0174561],\n",
       "            [0.00531006, -0.0154419, -0.0123291, ..., 0.00643921,\n",
       "             -0.0283203, 0.00497437],\n",
       "            [-0.0123901, 0.0038147, -0.0246582, ..., 0.0107422, 0.00201416,\n",
       "             0.0167236],\n",
       "            ...,\n",
       "            [-0.0236816, -0.00415039, 0.0183105, ..., -0.0322266,\n",
       "             -0.00231934, 0.0405273],\n",
       "            [-0.00646973, -0.0167236, 0.0180664, ..., 0.00488281,\n",
       "             -0.00418091, -0.0113525],\n",
       "            [0.00537109, 0.0146484, -0.00112915, ..., 0.00613403,\n",
       "             -0.0123291, 0.0112305]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00306702, 0.00842285, -0.00202942, ..., -0.0139771,\n",
       "             0.019165, 0.0108032],\n",
       "            [0.0035553, -0.00364685, -0.00811768, ..., 0.0144653,\n",
       "             -0.000400543, 0.0126343],\n",
       "            [0.000564575, -0.00402832, -0.00141907, ..., -0.00558472,\n",
       "             -0.00366211, 0.000205994],\n",
       "            ...,\n",
       "            [-0.00340271, 0.00958252, -0.0152588, ..., -0.00494385,\n",
       "             0.00799561, -0.00312805],\n",
       "            [0.00372314, -0.00534058, 0.0105591, ..., -0.00534058,\n",
       "             0.0116577, -0.0145874],\n",
       "            [0.00543213, -0.0130005, -0.00448608, ..., 0.00735474,\n",
       "             0.000180244, -0.0035553]],\n",
       "    \n",
       "           [[-0.00386047, -0.000926971, 0.012146, ..., 0.0098877, 0.015625,\n",
       "             0.0150146],\n",
       "            [-0.0100708, -0.00964355, 0.00228882, ..., 0.00308228,\n",
       "             -0.00187683, -0.00643921],\n",
       "            [-0.00338745, -0.00234985, 0.0161133, ..., -0.012207,\n",
       "             -0.00775146, 0.00088501],\n",
       "            ...,\n",
       "            [0.00515747, 0.026123, 0.0203857, ..., -0.000804901, 0.00891113,\n",
       "             -0.00915527],\n",
       "            [-0.0163574, -0.0241699, 0.00891113, ..., 0.0067749, 0.00909424,\n",
       "             0.0150146],\n",
       "            [-0.00171661, -0.00787354, -0.0140381, ..., -0.00357056,\n",
       "             -0.00537109, -0.0201416]],\n",
       "    \n",
       "           [[0.0147705, 0.00933838, -0.006073, ..., -0.0116577, -0.0050354,\n",
       "             -0.0159912],\n",
       "            [0.0157471, 0.0140991, 0.00167084, ..., -0.00328064, 0.00759888,\n",
       "             0.0131836],\n",
       "            [0.00111389, 0.019043, -0.00769043, ..., 0.00836182, 0.00582886,\n",
       "             0.0177002],\n",
       "            ...,\n",
       "            [-0.000522614, -0.0134277, -0.0300293, ..., 0.0129395,\n",
       "             -0.0285645, 0.0144653],\n",
       "            [0.000984192, 0.0126343, 0.00415039, ..., -0.012085, 0.0004673,\n",
       "             -0.00909424],\n",
       "            [0.000265121, 0.00726318, 0.0129395, ..., 0.00389099,\n",
       "             -0.00314331, 0.00445557]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.0141602, 0.00115204, 0.00933838, ..., 0.0134277,\n",
       "              -0.00177765, 0.00280762],\n",
       "             [0.000257492, 0.0025177, -0.0012207, ..., -0.00543213,\n",
       "              -0.000656128, -0.0251465],\n",
       "             [-0.00488281, 0.00262451, 0.00604248, ..., 0.00521851,\n",
       "              0.00646973, -0.019165],\n",
       "             ...,\n",
       "             [-0.0197754, 0.0110474, -0.00218201, ..., -0.0224609,\n",
       "              0.0144043, 0.00315857],\n",
       "             [0.012207, 0.0151978, -0.00546265, ..., -0.00402832,\n",
       "              -0.0134888, -0.00247192],\n",
       "             [0.0115967, -0.0166016, -0.00805664, ..., 0.00842285,\n",
       "              0.00653076, -0.00152588]],\n",
       "    \n",
       "            [[-0.006073, -0.00976562, -0.00445557, ..., -0.00189209,\n",
       "              0.00585938, -0.00683594],\n",
       "             [6.81877e-05, -0.0134277, 0.0126343, ..., 0.0130005,\n",
       "              0.0175781, 0.020752],\n",
       "             [-0.00909424, -0.00427246, 0.0109863, ..., -0.00299072,\n",
       "              -0.00933838, 0.0115967],\n",
       "             ...,\n",
       "             [0.00427246, -0.00491333, 0.0045166, ..., -0.00101471,\n",
       "              0.00811768, 0.0354004],\n",
       "             [0.00328064, 0.00933838, -0.00860596, ..., -0.00921631,\n",
       "              -0.0174561, -0.0181885],\n",
       "             [0.0131836, -0.0101929, -0.00147247, ..., 0.00860596,\n",
       "              -0.00952148, -0.00469971]],\n",
       "    \n",
       "            [[0.00210571, -0.00357056, -0.00124359, ..., -0.00439453,\n",
       "              -0.0118408, -0.0178223],\n",
       "             [0.00386047, 0.00411987, 0.000282288, ..., -0.00909424,\n",
       "              0.000286102, 0.00836182],\n",
       "             [-0.00159454, -0.0123291, 0.00279236, ..., 0.0125122,\n",
       "              0.0132446, 0.00312805],\n",
       "             ...,\n",
       "             [0.00708008, 0.00793457, 0.00219727, ..., -0.0115356,\n",
       "              0.00218201, 0.00604248],\n",
       "             [-0.00830078, -0.00279236, 0.00222778, ..., -0.0019989,\n",
       "              -0.0110474, 0.00958252],\n",
       "             [-0.000873566, -0.00263977, -0.00427246, ..., -0.0168457,\n",
       "              -0.0175781, 0.00106049]],\n",
       "    \n",
       "            [[-0.00793457, -0.00653076, 0.00120544, ..., 0.00292969,\n",
       "              -0.00646973, -0.00323486],\n",
       "             [0.017334, 0.00619507, -0.0184326, ..., 8.4877e-05,\n",
       "              0.00386047, 0.00436401],\n",
       "             [-0.00622559, -0.0112305, 0.000518799, ..., -0.00191498,\n",
       "              0.00671387, -0.0124512],\n",
       "             ...,\n",
       "             [0.00034523, 0.0103149, -0.0100708, ..., -0.015564,\n",
       "              -0.00376892, 0.00494385],\n",
       "             [-0.00970459, -0.000297546, 0.00376892, ..., -0.00354004,\n",
       "              0.0110474, 0.0114136],\n",
       "             [-0.0078125, -0.00161743, -0.00775146, ..., -0.0110474,\n",
       "              0.00512695, -0.0019989]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0025177, 0.0257568, 0.00714111, ..., 0.00952148,\n",
       "              -0.020874, -0.000991821],\n",
       "             [0.0153809, 0.0126953, -0.012207, ..., 0.0071106, 0.00689697,\n",
       "              -0.0117798],\n",
       "             [0.0098877, -0.00418091, 0.00309753, ..., -0.022583,\n",
       "              -0.0169678, 0.00717163],\n",
       "             ...,\n",
       "             [0.0067749, 0.02771, 3.50475e-05, ..., 0.0112915, -0.0103149,\n",
       "              0.00735474],\n",
       "             [-0.00421143, 0.00189209, -0.0196533, ..., 0.0128174,\n",
       "              0.0090332, -0.000617981],\n",
       "             [-0.00384521, 0.0177002, 0.0126953, ..., -0.00634766,\n",
       "              0.00994873, 0.0174561]],\n",
       "    \n",
       "            [[0.00933838, -0.00193787, -0.00159454, ..., -0.00897217,\n",
       "              -0.00689697, 0.0107422],\n",
       "             [0.00915527, -0.0224609, 0.00230408, ..., -0.00169373,\n",
       "              -0.019043, 0.00469971],\n",
       "             [0.0101318, -0.00320435, -0.0230713, ..., 0.0146484, 0.020752,\n",
       "              0.0101929],\n",
       "             ...,\n",
       "             [-0.0098877, 0.00280762, 0.0157471, ..., -0.0172119,\n",
       "              -0.00320435, 0.00188446],\n",
       "             [0.0130615, -0.00262451, -0.00115967, ..., -0.0223389,\n",
       "              -0.0148926, -0.00259399],\n",
       "             [0.0187988, -0.0117188, 0.00582886, ..., 0.0108643,\n",
       "              -0.00497437, 0.015625]],\n",
       "    \n",
       "            [[-0.00485229, 0.0045166, 0.00543213, ..., 0.00878906,\n",
       "              0.0117188, 0.00656128],\n",
       "             [-0.0129395, 0.00738525, -0.00227356, ..., 0.0150757,\n",
       "              -0.00634766, 0.0166016],\n",
       "             [-0.00334167, -0.0151978, 0.00561523, ..., -0.00878906,\n",
       "              -0.0174561, -0.0114746],\n",
       "             ...,\n",
       "             [-0.00759888, -0.0045166, 0.00723267, ..., 0.000911713,\n",
       "              -0.00897217, -0.0200195],\n",
       "             [-0.00170898, -0.00860596, -0.00302124, ..., -0.00628662,\n",
       "              -0.00106049, 0.00236511],\n",
       "             [0.0220947, 0.012146, -0.00753784, ..., -0.00369263,\n",
       "              0.0106812, 0.00613403]],\n",
       "    \n",
       "            [[0.00454712, 0.000138283, -0.0115356, ..., 0.0117188,\n",
       "              0.00552368, 0.00915527],\n",
       "             [0.00561523, -0.0114136, 0.00460815, ..., 0.0124512,\n",
       "              -0.00588989, -0.0169678],\n",
       "             [-0.00952148, 0.0117188, 0.0162354, ..., 0.0131836, 0.0140991,\n",
       "              -0.00842285],\n",
       "             ...,\n",
       "             [0.00689697, -0.00265503, -0.0103149, ..., 0.0118408,\n",
       "              0.000207901, -0.0107422],\n",
       "             [0.0150757, 0.0136108, 0.010376, ..., 0.0149536, 0.00062561,\n",
       "              -0.00994873],\n",
       "             [0.010376, -0.0159912, -0.00125885, ..., -0.00717163,\n",
       "              0.0147095, -0.0133667]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00183105, 0.0106812, -0.00762939, ..., -0.00634766,\n",
       "             0.00509644, -0.0039978],\n",
       "            [0.0148926, 0.00183105, 0.000583649, ..., 0.00376892,\n",
       "             -0.0236816, -0.0139771],\n",
       "            [-0.0203857, -0.0275879, 0.000511169, ..., -0.00294495,\n",
       "             0.00195312, 0.0154419],\n",
       "            ...,\n",
       "            [0.0151367, 0.00378418, 0.00717163, ..., -0.00958252,\n",
       "             0.00830078, -0.00646973],\n",
       "            [-0.012085, -0.0124512, 0.00537109, ..., 0.000478745,\n",
       "             -0.00854492, -0.0185547],\n",
       "            [-0.00604248, -0.000991821, -0.000667572, ..., 0.0143433,\n",
       "             -0.00872803, 0.000141144]],\n",
       "    \n",
       "           [[-0.00183868, -0.0101929, -0.000610352, ..., -0.00463867,\n",
       "             0.0233154, 0.0209961],\n",
       "            [-7.67708e-05, -0.000762939, -0.00680542, ..., 0.0136108,\n",
       "             -0.0366211, -0.0344238],\n",
       "            [-0.00213623, -0.0192871, -0.0175781, ..., -0.0106201,\n",
       "             0.0283203, -0.00656128],\n",
       "            ...,\n",
       "            [-0.00668335, -0.0257568, -0.00430298, ..., -0.00582886,\n",
       "             0.0334473, 0.0155029],\n",
       "            [0.00671387, 0.000350952, 0.00271606, ..., -0.00939941,\n",
       "             -0.00485229, -0.0025177],\n",
       "            [-0.00110626, 0.00299072, 0.0203857, ..., -0.017334, -0.0119019,\n",
       "             0.00242615]],\n",
       "    \n",
       "           [[-0.0134277, 0.0130615, 0.00473022, ..., 0.00830078,\n",
       "             -0.00131226, 0.00872803],\n",
       "            [0.0130615, -0.0162354, -0.00656128, ..., 0.0119019, 0.00390625,\n",
       "             0.00970459],\n",
       "            [0.00445557, -0.00150299, -0.00665283, ..., 0.00224304,\n",
       "             0.0170898, -0.0189209],\n",
       "            ...,\n",
       "            [-0.012085, -0.00701904, -0.00515747, ..., -0.0177002,\n",
       "             -0.00537109, -0.0192871],\n",
       "            [-0.013855, 0.00921631, 0.00619507, ..., -0.00262451,\n",
       "             0.00482178, 0.0067749],\n",
       "            [0.0019989, -0.000839233, 0.00195312, ..., 0.00238037,\n",
       "             0.0133667, -0.00325012]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00637817, 0.00375366, -0.000957489, ..., -0.0124512,\n",
       "             -0.00946045, -0.0113525],\n",
       "            [0.00604248, 0.00082016, -0.0115356, ..., 0.0183105, 0.0119019,\n",
       "             0.0234375],\n",
       "            [0.0088501, -0.00561523, -0.000173569, ..., -0.0200195,\n",
       "             0.00726318, 0.00665283],\n",
       "            ...,\n",
       "            [0.00643921, -0.0037384, 0.000115395, ..., -0.000766754,\n",
       "             -0.00340271, -0.0012207],\n",
       "            [-0.00769043, 0.00854492, -0.0111084, ..., 0.0270996,\n",
       "             -0.0211182, -0.0017395],\n",
       "            [0.00476074, -0.0014267, 0.0072937, ..., 0.0186768, 0.017334,\n",
       "             -0.00305176]],\n",
       "    \n",
       "           [[-0.00215149, -0.00349426, 0.00976562, ..., 0.0106201,\n",
       "             0.00854492, -0.0117188],\n",
       "            [-0.00671387, 0.000553131, -0.00610352, ..., -0.00854492,\n",
       "             0.0142822, 0.00384521],\n",
       "            [-0.00811768, 0.00842285, 0.00927734, ..., -0.019165,\n",
       "             0.00656128, -0.00479126],\n",
       "            ...,\n",
       "            [0.00170898, -0.00106049, -0.00506592, ..., 0.00964355,\n",
       "             -0.0222168, 0.00585938],\n",
       "            [0.00236511, 0.00747681, 0.00915527, ..., 0.00604248,\n",
       "             -0.00643921, -0.0153198],\n",
       "            [-0.0057373, -0.00619507, 0.00331116, ..., 0.00132751,\n",
       "             0.00686646, -0.00701904]],\n",
       "    \n",
       "           [[-0.0157471, 0.0027771, 0.0136719, ..., 0.0043335, -0.00144958,\n",
       "             -0.00527954],\n",
       "            [-0.0020752, 0.00463867, -0.0037384, ..., -0.00946045,\n",
       "             -0.00131989, -0.0125732],\n",
       "            [-0.00183868, 0.0088501, -0.00970459, ..., -0.0163574,\n",
       "             -0.00424194, -0.0157471],\n",
       "            ...,\n",
       "            [0.0172119, -0.00939941, -0.00250244, ..., 0.00204468,\n",
       "             0.0107422, 0.000352859],\n",
       "            [-0.00196838, 0.010376, -0.000263214, ..., -0.00561523,\n",
       "             0.0111694, 0.0131226],\n",
       "            [0.00442505, -0.00872803, -0.00469971, ..., 0.00411987,\n",
       "             0.00224304, 0.00836182]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.00723267, 0.00106812, -0.0110474, ..., 0.0136719,\n",
       "            -0.00854492, -0.00500488],\n",
       "           [-0.0027771, -0.0148926, 0.00454712, ..., 0.00701904,\n",
       "            -0.0101929, -0.000617981],\n",
       "           [-0.000182152, -0.0107422, 0.0032959, ..., 0.0116577,\n",
       "            -0.0101929, -0.0119629],\n",
       "           ...,\n",
       "           [-0.00151062, -0.0037384, -0.00585938, ..., -0.000541687,\n",
       "            0.00189209, 0.00424194],\n",
       "           [0.0020752, 0.00158691, 0.000522614, ..., 0.00280762,\n",
       "            -0.0174561, 0.0103149],\n",
       "           [0.00527954, 0.00244141, 0.00102997, ..., 0.00171661,\n",
       "            -0.00132751, 0.000736237]],\n",
       "   \n",
       "          [[-0.000545502, 0.00354004, -0.00552368, ..., 0.00402832,\n",
       "            0.00787354, 0.00592041],\n",
       "           [0.0100098, 0.00204468, 0.00442505, ..., 0.0136719, -0.0111694,\n",
       "            -0.0118408],\n",
       "           [0.00454712, 0.0016098, -0.012085, ..., -0.00500488, -0.0144043,\n",
       "            0.00213623],\n",
       "           ...,\n",
       "           [0.00056839, 0.000366211, 0.000511169, ..., 0.00238037,\n",
       "            0.000923157, -0.0125732],\n",
       "           [-0.00469971, -0.00069809, -0.00793457, ..., 0.0018692,\n",
       "            0.00769043, -0.0175781],\n",
       "           [0.00759888, -0.00137329, 0.0055542, ..., -0.00212097,\n",
       "            0.00588989, 0.00891113]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.00314331, 0.0147705, -0.00466919, ..., 0.00262451, -0.00154114,\n",
       "           0.00112152],\n",
       "          [-0.00227356, -0.0139771, 0.000432968, ..., 0.00161743, 0.0137939,\n",
       "           0.0107422],\n",
       "          [-0.00878906, 0.00561523, -0.00198364, ..., -0.00326538,\n",
       "           0.00354004, -0.00424194],\n",
       "          ...,\n",
       "          [0.00415039, -0.00100708, 0.0177002, ..., 0.0088501, -0.010376,\n",
       "           0.000713348],\n",
       "          [0.0144043, -0.000417709, -0.00613403, ..., 0.003479, 0.00114441,\n",
       "           -0.00628662],\n",
       "          [0.00248718, -0.0116577, 0.00793457, ..., 0.00177765, -0.0147095,\n",
       "           0.0202637]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([1.34375, 1.36719, 1.53906, ..., 1.33594, 1.35156, 1.24219],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([3.1875, 3.34375, 3.375, ..., 3.04688, 3.32812, 3.03125], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.421875, 0.402344, 0.400391, ..., 0.457031, 0.480469, 0.53125],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.0605469, -0.0107422, -0.0512695, ..., -0.0512695, -0.0771484,\n",
       "          0.0262451], dtype=bfloat16)}},\n",
       " 'layer_22': {'attn': {'attn_vec_einsum': {'w': Array([[[0.0078125, -0.00454712, -0.00616455, ..., 0.00674438,\n",
       "             -0.0180664, 0.00726318],\n",
       "            [-0.0151978, 0.00622559, -0.00735474, ..., -0.000341415,\n",
       "             -0.0103149, -0.0038147],\n",
       "            [0.0227051, 0.0100098, 0.00187683, ..., 0.0175781, 0.00117493,\n",
       "             0.000652313],\n",
       "            ...,\n",
       "            [0.00317383, 0.00262451, 0.00970459, ..., -0.0146484,\n",
       "             -0.0163574, -0.012146],\n",
       "            [-0.00491333, 8.82149e-05, -0.000953674, ..., -0.0197754,\n",
       "             -0.000747681, -0.00473022],\n",
       "            [-0.00836182, -0.00239563, 0.00361633, ..., 0.0118408,\n",
       "             -0.0164795, 0.00769043]],\n",
       "    \n",
       "           [[-0.00759888, -0.00302124, -0.00153351, ..., 0.00601196,\n",
       "             0.00384521, 0.013916],\n",
       "            [0.00234985, 0.00031662, -0.0159912, ..., 0.00274658, -0.017334,\n",
       "             -0.00643921],\n",
       "            [-0.000341415, 0.00579834, 0.0118408, ..., -0.0145874,\n",
       "             0.0071106, -0.0126953],\n",
       "            ...,\n",
       "            [-0.000904083, 0.00302124, -0.00196838, ..., 0.00108337,\n",
       "             -0.00515747, -0.00952148],\n",
       "            [-0.00891113, -0.00662231, 0.000206947, ..., -0.00150299,\n",
       "             0.00823975, -0.00120544],\n",
       "            [0.012207, -0.00582886, -0.00744629, ..., 0.0122681, -0.0100708,\n",
       "             0.0162354]],\n",
       "    \n",
       "           [[0.0162354, 0.00279236, 0.0108032, ..., -0.0236816, 0.00138855,\n",
       "             -0.000440598],\n",
       "            [0.0197754, -0.00312805, -0.00964355, ..., -0.00267029,\n",
       "             0.0114746, 0.0148926],\n",
       "            [0.00153351, -0.00732422, -0.00466919, ..., 0.00286865,\n",
       "             0.00756836, 0.00811768],\n",
       "            ...,\n",
       "            [0.0137329, 0.00273132, 0.00424194, ..., 0.032959, 0.020874,\n",
       "             0.00408936],\n",
       "            [-0.0135498, -0.0161133, 0.00286865, ..., -0.00595093,\n",
       "             0.0131226, 0.00717163],\n",
       "            [0.0111694, 0.0139771, -0.0098877, ..., -0.012085, 0.00598145,\n",
       "             -0.00204468]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00454712, -0.0219727, -0.00558472, ..., -0.00958252,\n",
       "             0.0223389, 0.0032959],\n",
       "            [0.0162354, 0.00393677, 0.001091, ..., -0.00115204, -0.00842285,\n",
       "             -0.00964355],\n",
       "            [-0.0159912, -0.00692749, -0.00772095, ..., 0.0057373,\n",
       "             -0.00653076, -0.00482178],\n",
       "            ...,\n",
       "            [0.00288391, 0.00247192, 0.0119629, ..., 0.00314331, 0.012085,\n",
       "             -0.0120239],\n",
       "            [0.00805664, -0.00335693, 0.0126953, ..., -0.00512695,\n",
       "             0.0106812, -0.00146484],\n",
       "            [-0.0147095, -0.0157471, 0.0198975, ..., -0.00107574,\n",
       "             -0.000656128, -0.0112305]],\n",
       "    \n",
       "           [[0.026001, -0.00854492, 0.00125122, ..., 0.0148926, 0.0019455,\n",
       "             0.00787354],\n",
       "            [0.0144043, 0.00164795, -0.00976562, ..., -0.00720215,\n",
       "             0.0108643, -0.00482178],\n",
       "            [-0.0105591, -0.0112305, 0.00891113, ..., -0.00622559,\n",
       "             0.00695801, -0.00921631],\n",
       "            ...,\n",
       "            [-0.0019455, -0.0111084, -0.019165, ..., -0.019165, -0.0211182,\n",
       "             -0.0108643],\n",
       "            [0.00860596, 0.00222778, 0.020752, ..., 0.00476074, -0.00848389,\n",
       "             0.00695801],\n",
       "            [0.00259399, 0.00213623, 0.00109863, ..., 0.00753784,\n",
       "             -0.00140381, -0.00772095]],\n",
       "    \n",
       "           [[-0.0275879, -0.00193024, 0.0137329, ..., -0.00946045,\n",
       "             -0.0039978, -0.00527954],\n",
       "            [-0.0246582, -0.0153809, 0.00132751, ..., 0.0164795, -0.0187988,\n",
       "             0.00282288],\n",
       "            [0.0072937, 0.020874, 0.00592041, ..., 0.00592041, -0.00320435,\n",
       "             0.0124512],\n",
       "            ...,\n",
       "            [-0.0128784, 0.00270081, 0.00598145, ..., 0.00836182, 0.0184326,\n",
       "             -0.0038147],\n",
       "            [-0.013855, -0.00662231, -0.0143433, ..., 0.00107574,\n",
       "             -0.00695801, -0.0255127],\n",
       "            [0.00263977, -0.00411987, -0.00244141, ..., -0.00335693,\n",
       "             -0.00172424, -0.000972748]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.00689697, -0.00328064, -0.00402832, ..., -0.00262451,\n",
       "              -0.000362396, -0.00653076],\n",
       "             [0.00662231, 0.000375748, -0.00552368, ..., 0.00379944,\n",
       "              -0.0308838, -0.00546265],\n",
       "             [0.0102539, -0.0140381, -0.0238037, ..., -0.00756836,\n",
       "              0.00442505, -0.00872803],\n",
       "             ...,\n",
       "             [-0.0129395, -0.0137939, 0.00125885, ..., -0.0162354,\n",
       "              0.0122681, 0.0162354],\n",
       "             [0.00390625, 0.000873566, -0.0106812, ..., 0.0166016,\n",
       "              -0.000522614, 0.0233154],\n",
       "             [-0.00653076, 0.00765991, -0.000946045, ..., 0.00765991,\n",
       "              -0.0163574, 0.00312805]],\n",
       "    \n",
       "            [[-0.00101471, -0.00376892, -0.00878906, ..., -0.000354767,\n",
       "              -0.00105286, 0.0035553],\n",
       "             [0.00650024, -0.00769043, 0.00466919, ..., 0.00805664,\n",
       "              -0.00331116, 0.0194092],\n",
       "             [5.55515e-05, 0.0043335, 0.00457764, ..., 0.00665283,\n",
       "              0.00159454, -0.00582886],\n",
       "             ...,\n",
       "             [0.00294495, 0.00479126, -0.00387573, ..., 0.00171661,\n",
       "              -0.000297546, -0.00952148],\n",
       "             [0.00326538, 0.0043335, 0.0057373, ..., -0.00595093,\n",
       "              0.00604248, -0.0115967],\n",
       "             [0.00552368, -0.00631714, -0.0039978, ..., 0.00799561,\n",
       "              -0.0106812, -0.00750732]],\n",
       "    \n",
       "            [[0.00543213, -0.00521851, -0.00161743, ..., -0.0106812,\n",
       "              0.00946045, 0.00653076],\n",
       "             [-0.00213623, -0.00515747, 0.0071106, ..., -0.00460815,\n",
       "              -0.00153351, -0.00239563],\n",
       "             [0.0032959, 0.00643921, -0.00014782, ..., 0.0170898,\n",
       "              -0.00701904, 0.00915527],\n",
       "             ...,\n",
       "             [0.00273132, -0.00154114, 0.00439453, ..., -0.0170898,\n",
       "              -0.00823975, -0.000854492],\n",
       "             [-0.000488281, -0.00143433, -0.00476074, ..., 0.0123291,\n",
       "              -0.0219727, -0.00430298],\n",
       "             [-0.00161743, -0.0055542, -0.00747681, ..., -0.0205078,\n",
       "              -0.0133667, -0.00933838]],\n",
       "    \n",
       "            [[-0.00166321, 0.0027771, -0.00254822, ..., 0.00595093,\n",
       "              -0.0112915, -0.024292],\n",
       "             [4.69685e-05, 0.00909424, -0.0106812, ..., 0.00144196,\n",
       "              -0.00836182, 0.0218506],\n",
       "             [0.00531006, -0.00354004, 0.00860596, ..., 0.0168457,\n",
       "              -0.00285339, 0.000740051],\n",
       "             ...,\n",
       "             [0.000444412, -0.00976562, -0.00285339, ..., -0.0107422,\n",
       "              0.0112305, 0.0125122],\n",
       "             [0.0103149, -0.00598145, -0.00334167, ..., -0.00473022,\n",
       "              -0.0195312, -0.00427246],\n",
       "             [-0.0045166, 0.00411987, -0.012146, ..., 0.00306702, 0.017334,\n",
       "              0.0027771]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0180664, -0.00692749, 0.00382996, ..., -0.000455856,\n",
       "              -0.0168457, -0.00191498],\n",
       "             [-0.00315857, -0.00726318, 0.00817871, ..., 0.0120239,\n",
       "              -0.00643921, -0.00772095],\n",
       "             [-0.0144043, -0.00473022, 0.010376, ..., -0.00283813,\n",
       "              -0.00637817, -0.00537109],\n",
       "             ...,\n",
       "             [0.00289917, 0.00598145, -0.00897217, ..., 0.00720215,\n",
       "              0.000751495, 0.0129395],\n",
       "             [-0.00891113, -0.0250244, 0.00424194, ..., -0.0126343,\n",
       "              0.0072937, -0.019043],\n",
       "             [0.00610352, -0.00291443, -0.0106201, ..., -0.0166016,\n",
       "              0.000591278, 0.0247803]],\n",
       "    \n",
       "            [[0.00191498, -0.012207, 0.00300598, ..., -0.00138855,\n",
       "              0.00408936, -0.00300598],\n",
       "             [0.015564, 0.00527954, -0.00506592, ..., -0.00927734,\n",
       "              0.000907898, 0.0050354],\n",
       "             [-0.00254822, -0.00765991, 0.00370789, ..., -0.013855,\n",
       "              0.0088501, -0.00515747],\n",
       "             ...,\n",
       "             [-0.0090332, 0.0317383, 0.000648499, ..., -0.0107422,\n",
       "              -0.000200272, 0.000495911],\n",
       "             [0.0102539, 0.00188446, -0.00683594, ..., 0.0167236,\n",
       "              -0.0106201, 0.0203857],\n",
       "             [0.0057373, -0.00689697, 0.00872803, ..., 0.00469971,\n",
       "              0.00588989, -0.000576019]],\n",
       "    \n",
       "            [[-0.00848389, -0.0050354, -0.00552368, ..., -0.00805664,\n",
       "              -0.00756836, 0.00500488],\n",
       "             [-0.0109253, -0.0229492, -0.00185394, ..., -0.0126953,\n",
       "              0.0116577, -0.0169678],\n",
       "             [-0.0183105, 0.00552368, -0.00762939, ..., -0.00872803,\n",
       "              -0.000915527, 0.00674438],\n",
       "             ...,\n",
       "             [-0.00473022, -0.0119629, -0.0154419, ..., 0.00476074,\n",
       "              -0.00964355, 0.000911713],\n",
       "             [-0.0090332, 0.0167236, 0.00488281, ..., 0.00273132,\n",
       "              -0.0151978, 0.00567627],\n",
       "             [-0.0128784, 0.00540161, 0.00765991, ..., -0.0185547,\n",
       "              -0.00527954, -0.00964355]],\n",
       "    \n",
       "            [[-0.00692749, -0.0162354, 0.00939941, ..., -0.0140991,\n",
       "              0.0148315, -0.0201416],\n",
       "             [0.0018158, 4.64916e-05, 0.00976562, ..., 0.0303955,\n",
       "              0.00643921, 0.0114136],\n",
       "             [0.0245361, 0.0144653, 0.0055542, ..., 0.0147705, -0.00915527,\n",
       "              0.000480652],\n",
       "             ...,\n",
       "             [-0.001091, -0.00976562, -0.0019989, ..., -0.00585938,\n",
       "              -0.00506592, -0.00689697],\n",
       "             [0.00372314, -0.0240479, -0.0100098, ..., 0.0065918,\n",
       "              -0.0120239, -0.0109253],\n",
       "             [0.0223389, -0.00765991, 0.00325012, ..., 0.00921631,\n",
       "              -0.00515747, 0.0111694]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.0062561, 0.0123291, 0.0133057, ..., 0.0137329, 2.80142e-05,\n",
       "             -0.00144196],\n",
       "            [-0.012146, 0.00387573, 0.0106201, ..., -0.0341797, 0.0163574,\n",
       "             0.0172119],\n",
       "            [-0.00842285, 0.00424194, 6.4373e-05, ..., -0.00389099,\n",
       "             -0.0317383, 0.0253906],\n",
       "            ...,\n",
       "            [0.0140381, -0.000843048, -0.020874, ..., 0.00393677,\n",
       "             -0.00793457, 0.0284424],\n",
       "            [-0.0126953, 0.0212402, -0.0127563, ..., -0.000904083,\n",
       "             0.0105591, -0.0314941],\n",
       "            [0.00175476, -0.00891113, -0.0388184, ..., -0.0136719,\n",
       "             0.0144043, 0.0181885]],\n",
       "    \n",
       "           [[-0.00349426, -0.00564575, 0.0177002, ..., 0.013916,\n",
       "             -0.00817871, -0.00218201],\n",
       "            [-0.00430298, 0.00970459, -0.00787354, ..., 0.00241089,\n",
       "             -0.000846863, 0.0211182],\n",
       "            [-0.00543213, 0.00787354, 0.0253906, ..., 0.0273438,\n",
       "             -0.00363159, 0.00222778],\n",
       "            ...,\n",
       "            [0.00509644, -0.00297546, 0.00460815, ..., 0.0299072,\n",
       "             -0.0144043, -0.0126343],\n",
       "            [-0.00344849, 0.00747681, 0.0088501, ..., -0.0164795, 0.0157471,\n",
       "             -0.0145264],\n",
       "            [-0.0098877, -0.00747681, 0.0211182, ..., -0.0147705, 0.0115967,\n",
       "             0.0161133]],\n",
       "    \n",
       "           [[2.49147e-05, 0.00156403, 0.00202942, ..., -0.00280762,\n",
       "             0.00160217, 0.0495605],\n",
       "            [-0.00311279, 0.012207, 0.00134277, ..., 0.00230408,\n",
       "             -0.00689697, -0.02771],\n",
       "            [0.00927734, 0.0072937, 0.00469971, ..., -0.00723267,\n",
       "             -0.0151367, 0.00897217],\n",
       "            ...,\n",
       "            [-0.00178528, -0.00793457, -0.00817871, ..., 0.0339355,\n",
       "             -0.00958252, -0.00598145],\n",
       "            [-0.00442505, -0.00952148, -0.0150757, ..., 0.0187988,\n",
       "             0.00747681, -0.0247803],\n",
       "            [0.00282288, -0.0032959, -0.0100098, ..., -0.0183105,\n",
       "             -0.0179443, -0.0169678]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00830078, 0.00595093, -0.0206299, ..., -0.00349426,\n",
       "             -0.0183105, -0.00775146],\n",
       "            [-0.00439453, 0.000976562, 0.00747681, ..., -0.0305176,\n",
       "             0.0131226, -0.00537109],\n",
       "            [0.000572205, 0.0123291, -0.0133667, ..., 0.00549316,\n",
       "             -0.000482559, 0.00424194],\n",
       "            ...,\n",
       "            [0.00390625, -0.00619507, -0.0212402, ..., -0.0179443,\n",
       "             -0.00976562, -0.000123024],\n",
       "            [-0.00708008, 0.00534058, -0.00411987, ..., 0.00735474,\n",
       "             -0.00133514, -0.00184631],\n",
       "            [-0.00515747, -0.0130615, 0.0158691, ..., -0.0098877,\n",
       "             -0.00534058, 0.020874]],\n",
       "    \n",
       "           [[-0.00370789, -0.000587463, -0.00457764, ..., -0.0143433,\n",
       "             0.0045166, 0.0181885],\n",
       "            [-0.00653076, 0.0270996, -0.00436401, ..., 0.00643921,\n",
       "             0.000425339, -0.0334473],\n",
       "            [0.00056839, -0.0158691, -0.00735474, ..., -0.0112305,\n",
       "             0.00396729, 0.0105591],\n",
       "            ...,\n",
       "            [-0.00683594, -0.00408936, -0.00215149, ..., -0.00415039,\n",
       "             -0.0262451, 0.00939941],\n",
       "            [0.0147705, -0.0136719, -3.93391e-05, ..., 0.019165, 0.0123901,\n",
       "             -0.0119629],\n",
       "            [-0.00230408, 0.0134888, 0.00179291, ..., 0.0158691, 0.0043335,\n",
       "             -0.00897217]],\n",
       "    \n",
       "           [[0.00257874, -0.00384521, -0.00231934, ..., -0.0279541,\n",
       "             0.00653076, 0.0219727],\n",
       "            [0.00274658, -0.00311279, -0.00180817, ..., -0.0189209,\n",
       "             0.00952148, -0.0358887],\n",
       "            [-0.00860596, 0.00408936, -0.00479126, ..., -0.0203857,\n",
       "             0.0322266, 0.0378418],\n",
       "            ...,\n",
       "            [-0.000991821, 0.00921631, 0.00561523, ..., 0.00878906,\n",
       "             -0.041748, -0.00653076],\n",
       "            [-0.00595093, 0.010437, 0.000118256, ..., 0.0111084, 0.0336914,\n",
       "             -0.00195312],\n",
       "            [-0.00860596, 0.00188446, -0.00161743, ..., 0.0216064,\n",
       "             0.0157471, -0.0268555]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.00372314, 0.00527954, -0.00463867, ..., 0.00141144,\n",
       "            0.00518799, -0.00280762],\n",
       "           [0.00244141, 0.00454712, -0.00302124, ..., 0.00637817,\n",
       "            0.00411987, 0.00332642],\n",
       "           [0.000312805, -0.00970459, 0.00497437, ..., 0.00817871,\n",
       "            -0.00668335, -0.0100708],\n",
       "           ...,\n",
       "           [0.00128174, -0.00793457, 0.0103149, ..., 0.00601196,\n",
       "            -0.00360107, 0.0141602],\n",
       "           [0.0131836, -0.0124512, -0.000495911, ..., 0.0062561, 0.0201416,\n",
       "            -0.00263977],\n",
       "           [-0.00823975, 0.00212097, 0.00811768, ..., -0.00939941,\n",
       "            -0.00457764, -0.00242615]],\n",
       "   \n",
       "          [[0.00110626, -0.00113678, -0.001091, ..., 0.00363159,\n",
       "            0.00610352, -0.00210571],\n",
       "           [0.0109863, -0.00479126, 0.00286865, ..., 0.00860596,\n",
       "            -0.00445557, -0.0050354],\n",
       "           [0.00328064, 0.00915527, 0.00753784, ..., 0.0125732,\n",
       "            -0.00970459, -0.00222778],\n",
       "           ...,\n",
       "           [-0.00202942, 0.00171661, 7.43866e-05, ..., -1.62125e-05,\n",
       "            -0.0198975, -0.0164795],\n",
       "           [0.00075531, 0.0045166, 0.00872803, ..., 0.0088501, -0.0090332,\n",
       "            0.0136108],\n",
       "           [-0.00506592, 0.00182343, 0.00778198, ..., -0.00149536,\n",
       "            -0.0071106, 0.00524902]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00393677, 0.00209045, -0.0140991, ..., -0.00386047,\n",
       "           -0.0123901, 0.00726318],\n",
       "          [-0.000331879, 0.00204468, -0.0101318, ..., -0.00121307,\n",
       "           0.0088501, -0.0050354],\n",
       "          [0.00126648, 0.000553131, 0.00234985, ..., -0.00521851,\n",
       "           -0.00653076, -0.0112305],\n",
       "          ...,\n",
       "          [-0.00242615, -0.00778198, -0.000192642, ..., -0.00717163,\n",
       "           0.00897217, 0.00274658],\n",
       "          [-0.00402832, -0.00273132, 0.00485229, ..., 0.00445557,\n",
       "           -0.0030365, -0.00927734],\n",
       "          [0.00236511, 0.00588989, 0.00753784, ..., 0.00762939, 0.00259399,\n",
       "           0.00494385]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([2.54688, 2.875, 2.70312, ..., 2.375, 2.73438, 2.35938], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([3.73438, 3.75, 3.84375, ..., 3.57812, 3.89062, 3.48438], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.232422, 0.261719, 0.180664, ..., 0.330078, 0.298828, 0.355469],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.090332, -0.0563965, -0.0976562, ..., -0.104004, -0.11084,\n",
       "          -0.0168457], dtype=bfloat16)}},\n",
       " 'layer_23': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.0125122, -0.0043335, -0.000934601, ..., -0.0128784,\n",
       "             0.003479, 0.00340271],\n",
       "            [0.00946045, -0.0143433, -0.0109253, ..., 0.00334167,\n",
       "             -0.00372314, 0.00442505],\n",
       "            [0.00139618, 0.00994873, 0.000694275, ..., 0.00265503,\n",
       "             0.0152588, -0.00473022],\n",
       "            ...,\n",
       "            [-0.0088501, 0.00952148, -0.012146, ..., 0.00165558, -0.0151367,\n",
       "             -0.00175476],\n",
       "            [-0.00476074, 0.00341797, -0.00167084, ..., 0.0133057,\n",
       "             -0.0145264, -0.0125732],\n",
       "            [-0.00209045, 0.0127563, -0.00561523, ..., 0.00191498,\n",
       "             -0.00427246, 0.000195503]],\n",
       "    \n",
       "           [[0.00628662, 0.00836182, -0.000455856, ..., 0.0166016,\n",
       "             0.00726318, -0.00427246],\n",
       "            [-0.0144043, 0.0177002, 0.0183105, ..., -0.0030365, 0.0136719,\n",
       "             -0.00604248],\n",
       "            [0.0014267, -0.010437, -0.0116577, ..., -0.00872803, -0.0168457,\n",
       "             0.00315857],\n",
       "            ...,\n",
       "            [0.0106812, -0.0105591, 0.0153809, ..., -0.0106201, 0.00759888,\n",
       "             0.000915527],\n",
       "            [-0.00897217, -0.00750732, -0.00457764, ..., -0.0133667,\n",
       "             0.0128784, 0.00332642],\n",
       "            [0.00680542, -0.0116577, 0.00854492, ..., -0.00285339,\n",
       "             0.00585938, 0.00294495]],\n",
       "    \n",
       "           [[-0.00256348, 0.00306702, -0.00415039, ..., 0.0166016,\n",
       "             -0.0133667, -0.00294495],\n",
       "            [-0.00506592, -0.0164795, 0.00479126, ..., -0.0241699,\n",
       "             0.000299454, 0.00515747],\n",
       "            [0.0140991, 0.010498, 0.00753784, ..., -0.00253296, -0.00686646,\n",
       "             -5.36442e-05],\n",
       "            ...,\n",
       "            [-0.00692749, -0.00927734, 0.0280762, ..., -0.00279236,\n",
       "             -0.00643921, -0.00601196],\n",
       "            [0.0170898, 0.00506592, 0.000450134, ..., 0.000846863, 0.019043,\n",
       "             0.00595093],\n",
       "            [0.0109863, 0.00105286, 0.0133057, ..., 0.0143433, -0.00162506,\n",
       "             -0.000816345]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0144043, 0.00396729, -0.0065918, ..., -0.00561523, 0.0180664,\n",
       "             0.0101929],\n",
       "            [-0.00402832, -0.0194092, 0.00218201, ..., 0.0123291, 0.0108643,\n",
       "             -0.00107574],\n",
       "            [0.0127563, -0.00878906, 0.00701904, ..., 0.019043, -0.00616455,\n",
       "             0.00022316],\n",
       "            ...,\n",
       "            [-0.0114746, -0.00193024, 0.0158691, ..., 0.00315857,\n",
       "             -0.00276184, 0.0130005],\n",
       "            [-0.00289917, 0.00518799, -0.00445557, ..., 0.00735474,\n",
       "             0.00370789, -0.00811768],\n",
       "            [0.00221252, -0.0065918, 0.00160217, ..., -0.00723267,\n",
       "             -0.00552368, 0.0137939]],\n",
       "    \n",
       "           [[5.76973e-05, -0.0018692, -0.00811768, ..., -0.00970459,\n",
       "             0.00102997, 0.010498],\n",
       "            [-0.0178223, 0.0115356, 0.00119019, ..., -0.0108643, -0.0161133,\n",
       "             -0.00189209],\n",
       "            [0.0136719, 0.0214844, 0.0162354, ..., 0.017334, -0.00069809,\n",
       "             -0.00778198],\n",
       "            ...,\n",
       "            [0.00344849, -0.0119629, -0.019165, ..., -0.000865936,\n",
       "             -0.00227356, 0.00933838],\n",
       "            [0.010376, -0.0129395, 0.00994873, ..., -0.000709534, 0.0136108,\n",
       "             0.0130005],\n",
       "            [-0.00273132, 0.00147247, 0.0132446, ..., 0.00723267,\n",
       "             0.00933838, -0.00717163]],\n",
       "    \n",
       "           [[0.00637817, 0.00735474, 0.000268936, ..., -0.00704956,\n",
       "             -0.00717163, -0.000843048],\n",
       "            [-0.00253296, -0.00558472, -0.0071106, ..., 0.015625,\n",
       "             -7.58171e-05, 0.00119781],\n",
       "            [0.00927734, -0.0117798, -0.00325012, ..., -0.0117798,\n",
       "             0.00854492, -0.0134888],\n",
       "            ...,\n",
       "            [-0.0239258, -0.00193024, 0.00921631, ..., -0.00628662,\n",
       "             -0.0142822, -0.00778198],\n",
       "            [-0.00215149, -0.0103149, -0.0247803, ..., -0.0035553,\n",
       "             0.0112915, 0.0126343],\n",
       "            [-0.00297546, -0.0217285, -0.00689697, ..., -0.00263977,\n",
       "             0.0098877, 0.0198975]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.015564, 0.00558472, 0.00100708, ..., 0.0016098,\n",
       "              -0.0285645, -0.0078125],\n",
       "             [0.0179443, -0.0249023, 0.0014267, ..., 0.00695801,\n",
       "              0.00860596, 0.0139771],\n",
       "             [-0.00805664, -0.00680542, -0.00151062, ..., -0.00570679,\n",
       "              0.00448608, 0.00927734],\n",
       "             ...,\n",
       "             [0.00741577, -0.00482178, 0.00448608, ..., 0.0186768,\n",
       "              0.00805664, -0.00238037],\n",
       "             [0.0014801, 0.0158691, -0.00753784, ..., -0.00674438,\n",
       "              -0.0045166, -0.00369263],\n",
       "             [-0.0057373, 0.0132446, 0.0103149, ..., 0.00558472,\n",
       "              0.00799561, -0.00222778]],\n",
       "    \n",
       "            [[0.0062561, 0.00288391, 0.00334167, ..., -0.0102539,\n",
       "              0.00294495, -0.0184326],\n",
       "             [0.00289917, 0.000282288, 0.0072937, ..., 0.00221252,\n",
       "              0.00552368, 0.00231934],\n",
       "             [0.00283813, 0.020752, 0.0125122, ..., 0.0110474, 0.0117188,\n",
       "              0.00878906],\n",
       "             ...,\n",
       "             [-0.0112915, -0.00817871, -0.00424194, ..., 0.00570679,\n",
       "              -0.0132446, 0.00970459],\n",
       "             [0.00952148, 0.0131836, -0.00180054, ..., -0.00909424,\n",
       "              -0.00376892, 0.0130615],\n",
       "             [0.00527954, -0.0186768, -0.00488281, ..., -0.00720215,\n",
       "              -0.0128784, 0.0310059]],\n",
       "    \n",
       "            [[-0.00231934, 0.000329971, 0.00897217, ..., 0.00964355,\n",
       "              -0.00939941, -0.00595093],\n",
       "             [-0.00473022, 0.0057373, 0.0115356, ..., -0.00106812,\n",
       "              0.0219727, -0.00172424],\n",
       "             [0.00123596, 0.00418091, 0.0137329, ..., -0.00326538,\n",
       "              -0.00332642, -0.0150757],\n",
       "             ...,\n",
       "             [-0.00601196, 0.00121307, 0.00396729, ..., -0.0109863,\n",
       "              -0.00299072, 0.0126953],\n",
       "             [0.00759888, 0.00860596, -0.00328064, ..., -0.00756836,\n",
       "              -0.00830078, -0.0283203],\n",
       "             [-0.0100098, -0.00817871, -0.000370026, ..., -0.0268555,\n",
       "              0.00334167, -0.0256348]],\n",
       "    \n",
       "            [[0.00717163, 0.00415039, 0.00494385, ..., 0.0148315,\n",
       "              0.00122833, -0.00262451],\n",
       "             [-0.0132446, -0.00430298, 0.00494385, ..., 0.00485229,\n",
       "              0.0140991, 0.0072937],\n",
       "             [-0.00921631, -0.00515747, 0.0072937, ..., -0.00830078,\n",
       "              0.0131836, 0.00680542],\n",
       "             ...,\n",
       "             [0.0119019, -2.45571e-05, -0.00561523, ..., 0.0118408,\n",
       "              0.0308838, -0.00105286],\n",
       "             [0.0116577, -0.0032959, -0.00236511, ..., -0.000865936,\n",
       "              0.00488281, 0.00497437],\n",
       "             [0.00726318, 0.00823975, 0.00292969, ..., 0.00289917,\n",
       "              0.00331116, -0.0122681]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0115356, 0.0196533, -0.00463867, ..., -0.00769043,\n",
       "              -0.00628662, -0.00537109],\n",
       "             [-0.00921631, -0.00457764, 0.026123, ..., 0.0209961,\n",
       "              0.0187988, 0.00436401],\n",
       "             [-0.00372314, -0.0112915, 0.0131226, ..., -0.0137329,\n",
       "              -0.00259399, -0.00817871],\n",
       "             ...,\n",
       "             [-0.0157471, 0.00750732, 0.00939941, ..., 0.00274658,\n",
       "              0.0101929, 0.00201416],\n",
       "             [0.00177765, -0.00318909, 0.0127563, ..., -0.0108643,\n",
       "              -0.0194092, -0.00136566],\n",
       "             [0.00717163, -0.00854492, -0.00656128, ..., 0.000682831,\n",
       "              -0.00698853, 0.0019989]],\n",
       "    \n",
       "            [[0.00823975, -0.00549316, 0.00257874, ..., -0.0159912,\n",
       "              0.00933838, 0.00482178],\n",
       "             [0.0100708, -0.0101318, -0.0185547, ..., 0.00778198,\n",
       "              -0.00836182, 0.00271606],\n",
       "             [-0.00708008, -0.00325012, -0.0157471, ..., -0.0161133,\n",
       "              -0.00714111, -0.00628662],\n",
       "             ...,\n",
       "             [-0.0136719, 0.00646973, 0.00239563, ..., -0.0264893,\n",
       "              0.0123291, 0.00674438],\n",
       "             [-0.00300598, -0.00909424, -0.00787354, ..., 0.0262451,\n",
       "              3.01003e-06, 0.0272217],\n",
       "             [-0.00970459, 0.0143433, 0.00787354, ..., -0.0216064,\n",
       "              0.00369263, -0.0222168]],\n",
       "    \n",
       "            [[0.0128174, 0.0072937, 0.0128174, ..., -0.0120239, -0.0155029,\n",
       "              -0.000843048],\n",
       "             [-0.000637054, -0.0106812, -0.00257874, ..., -0.0123291,\n",
       "              -0.00588989, 0.0019989],\n",
       "             [-0.00564575, 0.00744629, -0.00747681, ..., 0.00491333,\n",
       "              0.00753784, -0.00842285],\n",
       "             ...,\n",
       "             [0.0123901, 0.00750732, -0.00619507, ..., -0.00244141,\n",
       "              -0.00909424, -0.00157166],\n",
       "             [0.019043, 0.019165, -0.00250244, ..., 0.00848389,\n",
       "              -0.000328064, 0.012207],\n",
       "             [0.0200195, -0.0110474, 0.00141144, ..., 0.0200195, 0.0162354,\n",
       "              -0.0236816]],\n",
       "    \n",
       "            [[-0.00366211, -0.0146484, -0.00144958, ..., -0.000197411,\n",
       "              -0.0187988, -0.0106812],\n",
       "             [0.0161133, 0.00994873, 0.000205994, ..., 0.0114746,\n",
       "              -0.00141907, -0.00320435],\n",
       "             [-0.00582886, 0.00842285, -0.0067749, ..., -0.00613403,\n",
       "              -0.0134888, -0.00854492],\n",
       "             ...,\n",
       "             [0.0115356, -0.0253906, 0.0098877, ..., -0.0125732,\n",
       "              -0.00202942, 0.0200195],\n",
       "             [-0.0214844, -0.00598145, -0.00306702, ..., 0.00350952,\n",
       "              0.0100098, -0.00650024],\n",
       "             [0.019165, 0.0128784, -0.00418091, ..., -0.0319824,\n",
       "              0.00576782, 0.0112305]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00866699, 7.27177e-06, -0.00256348, ..., 0.0162354,\n",
       "             -0.0301514, 0.00227356],\n",
       "            [0.00166321, 0.00708008, -0.00482178, ..., 0.000196457,\n",
       "             0.0223389, 0.0214844],\n",
       "            [-0.00671387, -0.0062561, -0.0144653, ..., -0.00720215,\n",
       "             -0.022583, -0.00534058],\n",
       "            ...,\n",
       "            [-0.00344849, -0.00212097, -0.00778198, ..., 0.00283813,\n",
       "             -0.0153809, -0.0039978],\n",
       "            [0.00488281, 0.0014801, 0.00188446, ..., -0.00178528,\n",
       "             -0.0124512, 0.00811768],\n",
       "            [-0.00227356, 0.00445557, 0.00115204, ..., -0.00457764,\n",
       "             -0.00613403, -0.0195312]],\n",
       "    \n",
       "           [[-0.0108032, -0.00909424, 0.010376, ..., 0.0169678, -0.00772095,\n",
       "             -0.00775146],\n",
       "            [0.000816345, -0.00759888, -0.00891113, ..., -0.00346375,\n",
       "             0.003479, 0.00842285],\n",
       "            [-0.000675201, 0.00891113, -0.0166016, ..., -0.003479,\n",
       "             -0.000747681, 0.000644684],\n",
       "            ...,\n",
       "            [0.00457764, 0.0200195, 0.010498, ..., -0.017334, 0.00265503,\n",
       "             -0.00686646],\n",
       "            [-0.00343323, 0.00689697, -0.00842285, ..., -0.00686646,\n",
       "             -0.00665283, 0.00326538],\n",
       "            [-0.0129395, 0.00154114, 0.0098877, ..., -0.00476074,\n",
       "             -0.0101929, 0.00334167]],\n",
       "    \n",
       "           [[0.000272751, -0.00518799, 0.00375366, ..., -0.0305176,\n",
       "             -0.0189209, 0.00726318],\n",
       "            [-0.000299454, 0.000923157, 0.00257874, ..., -0.0223389,\n",
       "             -0.00872803, -0.00326538],\n",
       "            [-0.000339508, -0.00062561, 0.0030365, ..., -0.0324707,\n",
       "             -0.0126343, 0.00372314],\n",
       "            ...,\n",
       "            [1.18613e-05, 0.0016861, 0.00267029, ..., 0.000850677,\n",
       "             0.00424194, -0.0136719],\n",
       "            [0.000858307, 0.000701904, -0.0106201, ..., -0.0167236,\n",
       "             0.00753784, -0.0336914],\n",
       "            [-0.00445557, 0.000127792, 0.00177002, ..., 0.00488281,\n",
       "             -0.00463867, -0.0186768]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.000797272, -0.00375366, 0.0163574, ..., -0.00332642,\n",
       "             0.000152588, -0.0105591],\n",
       "            [-0.00343323, 0.00297546, -0.00405884, ..., 0.012146,\n",
       "             -0.0032959, 0.00141907],\n",
       "            [0.0098877, 0.00637817, -0.00491333, ..., 0.00582886,\n",
       "             -0.0072937, 0.00656128],\n",
       "            ...,\n",
       "            [0.000322342, 0.00244141, 0.00415039, ..., -0.0018692, 0.010498,\n",
       "             0.0192871],\n",
       "            [-0.00616455, 0.000249863, 0.00970459, ..., -0.00637817,\n",
       "             0.00357056, 0.00094986],\n",
       "            [0.00579834, -0.00260925, 0.000679016, ..., 0.00540161,\n",
       "             0.00601196, 0.0279541]],\n",
       "    \n",
       "           [[-0.000595093, -0.0088501, -0.0144043, ..., -0.0159912,\n",
       "             -0.0299072, 0.0262451],\n",
       "            [0.00268555, -0.00817871, 0.00579834, ..., 4.36306e-05,\n",
       "             0.00637817, 0.00221252],\n",
       "            [-0.000206947, 0.00497437, 0.010498, ..., -5.126e-05,\n",
       "             -0.00588989, 0.0412598],\n",
       "            ...,\n",
       "            [0.0045166, 0.0019989, -0.00140381, ..., -0.0062561,\n",
       "             -0.00878906, -0.0170898],\n",
       "            [-0.00139618, 0.0139771, -0.00176239, ..., -0.0244141,\n",
       "             0.00361633, 0.0071106],\n",
       "            [-0.00436401, -0.00842285, -0.00187683, ..., -0.00106049,\n",
       "             -0.00491333, 0.0106201]],\n",
       "    \n",
       "           [[-0.00285339, 0.00970459, -0.00842285, ..., -0.0108032,\n",
       "             -0.0292969, 0.0375977],\n",
       "            [-0.0179443, 0.0169678, 0.0161133, ..., 0.00166321, 0.00296021,\n",
       "             0.012207],\n",
       "            [0.00367737, 0.00439453, -0.00738525, ..., 0.00643921,\n",
       "             -0.0257568, 0.0109253],\n",
       "            ...,\n",
       "            [0.0157471, 0.00723267, 0.00133514, ..., -0.0105591, -0.019165,\n",
       "             0.0125122],\n",
       "            [0.000717163, 0.0151978, 0.00708008, ..., -0.0285645,\n",
       "             0.00866699, 0.00427246],\n",
       "            [-0.0159912, -0.0197754, 0.0128784, ..., -0.00448608,\n",
       "             -0.00354004, 0.00735474]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.001297, 0.00415039, 0.000614166, ..., -0.00891113,\n",
       "            -0.0113525, -0.013855],\n",
       "           [0.00167084, -0.00411987, 0.00518799, ..., -0.00466919,\n",
       "            0.00497437, 0.00169373],\n",
       "           [0.00546265, 0.00170135, 0.00372314, ..., 0.00744629,\n",
       "            0.00933838, 0.00236511],\n",
       "           ...,\n",
       "           [0.0122681, 0.00576782, -0.00579834, ..., 0.0050354, 0.00233459,\n",
       "            -0.00174713],\n",
       "           [0.00482178, -0.00195312, 0.00104523, ..., -0.00424194,\n",
       "            -0.0102539, 0.0120239],\n",
       "           [-0.0149536, 0.00439453, 0.00230408, ..., 0.00860596,\n",
       "            -0.00695801, 0.0147095]],\n",
       "   \n",
       "          [[-0.0131226, 0.000778198, 0.0140381, ..., -0.00778198,\n",
       "            -0.00248718, -0.000667572],\n",
       "           [0.00613403, -0.00204468, 0.00332642, ..., 0.00171661,\n",
       "            -0.00524902, -0.000797272],\n",
       "           [0.00415039, 0.000109196, -0.0205078, ..., 0.010498, 0.00546265,\n",
       "            0.00170135],\n",
       "           ...,\n",
       "           [-0.00717163, 0.00326538, 0.010376, ..., -0.00424194,\n",
       "            -0.00174713, 0.00202942],\n",
       "           [0.0189209, -0.00939941, -0.00531006, ..., -0.00386047,\n",
       "            -0.00527954, -0.00558472],\n",
       "           [-0.00204468, -0.00222778, 0.00549316, ..., 0.00463867,\n",
       "            -0.00187683, -0.00387573]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00427246, -0.0030365, -0.00289917, ..., 0.00360107,\n",
       "           -0.00704956, -0.00637817],\n",
       "          [-0.00165558, -0.0067749, -0.0055542, ..., -0.00305176,\n",
       "           -0.0101929, -0.00793457],\n",
       "          [0.000318527, 0.0168457, -0.0045166, ..., 0.0150757, -0.00173187,\n",
       "           -0.00817871],\n",
       "          ...,\n",
       "          [0.00762939, -0.00921631, 2.75373e-05, ..., -0.00393677,\n",
       "           0.00860596, -0.0032196],\n",
       "          [-0.0022583, 0.00933838, 0.003479, ..., 0.00717163, 0.00778198,\n",
       "           0.013916],\n",
       "          [-0.00534058, -0.00933838, -0.00469971, ..., -0.00762939,\n",
       "           0.00482178, -0.0150757]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([2.21875, 2.28125, 2.20312, ..., 2.07812, 2.29688, 2.03125],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([4.15625, 4.28125, 4.34375, ..., 4.25, 4.53125, 4], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.306641, 0.337891, 0.300781, ..., 0.367188, 0.396484, 0.429688],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.158203, -0.146484, -0.166016, ..., -0.147461, -0.173828,\n",
       "          -0.10791], dtype=bfloat16)}},\n",
       " 'layer_24': {'attn': {'attn_vec_einsum': {'w': Array([[[0.00497437, 0.020874, 0.00302124, ..., 0.0132446, 0.0116577,\n",
       "             0.00646973],\n",
       "            [0.00631714, -0.00579834, -0.00897217, ..., 0.00726318,\n",
       "             0.0117188, 0.00854492],\n",
       "            [-0.00946045, 0.0185547, 0.00367737, ..., 0.00233459,\n",
       "             0.00558472, -0.00610352],\n",
       "            ...,\n",
       "            [0.0169678, 0.0125732, 0.0244141, ..., 0.0131226, 0.0279541,\n",
       "             -0.0105591],\n",
       "            [0.00176239, -0.0257568, 0.0108643, ..., -0.00860596,\n",
       "             -0.0130005, -0.00799561],\n",
       "            [0.00326538, -0.0111084, 0.00473022, ..., -3.09944e-05,\n",
       "             0.0184326, 0.00662231]],\n",
       "    \n",
       "           [[0.00958252, 0.0240479, -0.0124512, ..., -0.0098877, -0.010376,\n",
       "             0.00289917],\n",
       "            [0.0157471, -0.00799561, -0.00378418, ..., 0.0206299, 0.0136719,\n",
       "             -0.00872803],\n",
       "            [0.0145264, -0.00805664, 0.015625, ..., 0.00283813, -0.0145874,\n",
       "             0.00650024],\n",
       "            ...,\n",
       "            [-0.00799561, -0.00799561, -5.126e-05, ..., -0.0144043,\n",
       "             -0.00466919, 0.00598145],\n",
       "            [-0.0038147, -0.00234985, -0.00982666, ..., 0.0172119,\n",
       "             0.0130005, 0.0111694],\n",
       "            [-0.0222168, -0.00234985, -0.00476074, ..., -0.00497437,\n",
       "             -0.0223389, -0.00254822]],\n",
       "    \n",
       "           [[0.0203857, -0.022583, 0.0131226, ..., 0.0273438, -0.00878906,\n",
       "             -0.00830078],\n",
       "            [-0.00186157, -0.00747681, -0.010376, ..., 0.0158691, 0.0167236,\n",
       "             -0.000671387],\n",
       "            [0.00157928, 0.0147705, -0.0155029, ..., -0.00031662,\n",
       "             0.00939941, 0.0220947],\n",
       "            ...,\n",
       "            [0.00823975, 0.00741577, 0.00309753, ..., 0.0133057, 0.00848389,\n",
       "             -0.00340271],\n",
       "            [-0.00674438, -0.0128784, 0.00805664, ..., -0.000154495,\n",
       "             0.00469971, 0.0172119],\n",
       "            [-0.0212402, -0.0147705, -0.00860596, ..., 0.0297852, 0.0090332,\n",
       "             0.00582886]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00976562, 0.0168457, 0.010498, ..., 0.0107422, 0.0234375,\n",
       "             -0.00665283],\n",
       "            [-0.0244141, -0.0132446, 0.0223389, ..., 0.00823975, -0.0144043,\n",
       "             0.0167236],\n",
       "            [0.00337219, 0.0132446, -0.0194092, ..., -0.0134277, 0.00219727,\n",
       "             -0.012085],\n",
       "            ...,\n",
       "            [-0.00370789, 0.0022583, -0.0019455, ..., 0.0202637, 0.0114746,\n",
       "             -0.00227356],\n",
       "            [0.0125732, -0.00125885, -0.00744629, ..., 0.0101929,\n",
       "             -0.0203857, 0.0114746],\n",
       "            [-0.0290527, 0.00842285, 0.000793457, ..., -0.00302124,\n",
       "             0.0071106, -0.0177002]],\n",
       "    \n",
       "           [[-0.000322342, -0.00592041, 0.00145721, ..., 0.00402832,\n",
       "             0.00619507, -0.0045166],\n",
       "            [0.00144196, -0.00482178, 0.0015564, ..., -0.00531006,\n",
       "             -0.00872803, -0.0198975],\n",
       "            [0.0129395, -0.00515747, -0.00405884, ..., 0.0115967,\n",
       "             -0.00326538, 0.00872803],\n",
       "            ...,\n",
       "            [-0.00970459, 0.0134277, -0.00402832, ..., -0.00338745,\n",
       "             -0.0019989, -0.012085],\n",
       "            [-0.0105591, -0.00692749, 0.00262451, ..., 0.0109253,\n",
       "             -0.0112915, -0.00491333],\n",
       "            [0.0128784, -0.00601196, -0.00198364, ..., -0.00159454,\n",
       "             -0.0166016, -0.00320435]],\n",
       "    \n",
       "           [[0.00552368, 0.00366211, 0.00245667, ..., -0.0146484,\n",
       "             -0.00561523, 0.00221252],\n",
       "            [0.00299072, -0.0101929, -0.00439453, ..., 0.000961304,\n",
       "             -0.00191498, 0.0234375],\n",
       "            [0.0146484, -0.0125732, -0.0272217, ..., 0.00202942, 0.0170898,\n",
       "             -0.000583649],\n",
       "            ...,\n",
       "            [0.00570679, -0.0174561, 0.022583, ..., 0.0236816, 0.000946045,\n",
       "             0.0116577],\n",
       "            [-0.00708008, -0.0169678, -0.00106049, ..., 0.00982666,\n",
       "             0.00170135, -0.00927734],\n",
       "            [0.00445557, 0.0137329, 0.000823975, ..., -0.00567627, 0.010376,\n",
       "             0.00714111]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.00221252, 0.00494385, -0.00315857, ..., -0.00166321,\n",
       "              -0.00515747, 0.00872803],\n",
       "             [-0.00174713, -0.00152588, 0.00558472, ..., -0.00415039,\n",
       "              0.00460815, -0.00787354],\n",
       "             [2.53916e-05, -0.00202942, -0.00384521, ..., -0.00512695,\n",
       "              0.0146484, -0.015625],\n",
       "             ...,\n",
       "             [0.0112915, 0.00296021, -0.0183105, ..., -0.0109863,\n",
       "              -0.0101929, 0.000862122],\n",
       "             [-0.00680542, -0.00765991, 0.000364304, ..., -0.0102539,\n",
       "              0.00631714, 0.0050354],\n",
       "             [-0.0140991, 0.00958252, 0.00190735, ..., -0.00454712,\n",
       "              -0.015625, 0.00994873]],\n",
       "    \n",
       "            [[-0.0245361, -0.0100098, 0.0117188, ..., 0.0180664, 0.0327148,\n",
       "              -0.0291748],\n",
       "             [-0.00326538, -0.00744629, 0.00769043, ..., 0.00952148,\n",
       "              -0.000968933, 0.00778198],\n",
       "             [0.00509644, -0.0174561, 0.0114136, ..., 0.00156403,\n",
       "              0.0216064, 0.000237465],\n",
       "             ...,\n",
       "             [0.0109863, -0.00393677, -0.00271606, ..., -0.0317383,\n",
       "              -0.0129395, 0.010498],\n",
       "             [-0.0241699, 0.00595093, 0.0112915, ..., -0.000621796,\n",
       "              0.0125122, -0.00430298],\n",
       "             [0.00668335, -0.00270081, -0.0113525, ..., -0.0136108,\n",
       "              -0.0157471, 0.0251465]],\n",
       "    \n",
       "            [[-0.00469971, 0.00296021, 0.0206299, ..., 0.010498, 0.0142212,\n",
       "              -0.00454712],\n",
       "             [-0.0351562, 0.0174561, 0.0126343, ..., -0.00442505,\n",
       "              0.00494385, 0.00561523],\n",
       "             [-0.00296021, -0.0148926, 0.0124512, ..., -0.00561523,\n",
       "              -0.0122681, -0.00273132],\n",
       "             ...,\n",
       "             [0.012146, -0.0140991, 0.0196533, ..., 0.0103149, -0.00601196,\n",
       "              -0.0101318],\n",
       "             [0.00366211, -0.000991821, 0.00260925, ..., 0.0142212,\n",
       "              -0.000406265, -0.00897217],\n",
       "             [0.020752, -0.00358582, 0.0132446, ..., 0.000112534, 0.026001,\n",
       "              0.0185547]],\n",
       "    \n",
       "            [[-0.00817871, 0.00043869, -0.00579834, ..., -0.0145874,\n",
       "              0.0020752, 0.00842285],\n",
       "             [0.00376892, -0.0238037, -0.0071106, ..., -0.00210571,\n",
       "              -0.0157471, 0.00436401],\n",
       "             [-0.00136566, 4.3869e-05, -0.00848389, ..., -0.00109863,\n",
       "              -0.00317383, 0.0147095],\n",
       "             ...,\n",
       "             [-0.00482178, -0.00610352, 0.000461578, ..., 0.00695801,\n",
       "              0.0181885, -0.00120544],\n",
       "             [0.00328064, -0.00427246, -0.00405884, ..., 0.00805664,\n",
       "              0.0289307, 0.000774384],\n",
       "             [-0.0161133, 0.0179443, -0.0152588, ..., -0.0153809,\n",
       "              -0.0159912, -0.00564575]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0159912, 0.0115967, 0.0071106, ..., -0.0122681, 0.00357056,\n",
       "              -0.022583],\n",
       "             [0.0157471, -0.0131836, -0.00958252, ..., -0.00267029,\n",
       "              -0.00646973, -0.00665283],\n",
       "             [-0.00424194, -0.00958252, 0.0187988, ..., 0.0109253,\n",
       "              -0.00634766, 0.00172424],\n",
       "             ...,\n",
       "             [0.00164795, 0.0102539, 0.00860596, ..., 0.00367737,\n",
       "              0.0106201, -0.00830078],\n",
       "             [-0.00753784, 0.0178223, -0.00179291, ..., 0.00506592,\n",
       "              -0.0148315, -0.0130615],\n",
       "             [0.0117188, -0.000341415, -0.0013504, ..., 0.00408936,\n",
       "              -0.00233459, 0.00488281]],\n",
       "    \n",
       "            [[-0.0196533, 0.0159912, 0.000858307, ..., -0.00759888,\n",
       "              0.00540161, 0.0286865],\n",
       "             [0.0285645, 0.0175781, -0.00756836, ..., -0.00631714,\n",
       "              4.73857e-06, 0.0256348],\n",
       "             [-0.00994873, 0.00427246, 0.0120239, ..., -0.017334,\n",
       "              0.00270081, 0.0180664],\n",
       "             ...,\n",
       "             [-0.0234375, -0.017334, -0.0123291, ..., -0.0142212,\n",
       "              -0.0123291, -0.0336914],\n",
       "             [0.0143433, -0.00909424, -0.0139771, ..., -0.0107422,\n",
       "              -0.00970459, -0.00358582],\n",
       "             [0.00964355, -0.000171661, -0.0136719, ..., 0.00656128,\n",
       "              -0.0180664, -0.0186768]],\n",
       "    \n",
       "            [[0.0010376, -0.0019989, 0.00497437, ..., -0.00337219,\n",
       "              0.00375366, -0.0222168],\n",
       "             [0.00405884, 0.00376892, 0.0144043, ..., -0.00601196,\n",
       "              -0.00326538, 0.0131226],\n",
       "             [0.000488281, 0.015564, 0.00382996, ..., 0.00915527,\n",
       "              0.0107422, -0.00958252],\n",
       "             ...,\n",
       "             [0.0106812, 0.0090332, 0.0205078, ..., -0.00115204,\n",
       "              -0.00909424, 0.00787354],\n",
       "             [0.00628662, -0.00762939, 0.00866699, ..., 0.00860596,\n",
       "              0.00108337, -0.000115871],\n",
       "             [-0.0161133, 0.0147095, -0.0143433, ..., 0.0105591,\n",
       "              -0.00793457, 0.00531006]],\n",
       "    \n",
       "            [[0.00958252, 0.00439453, 0.0112305, ..., 0.00653076,\n",
       "              0.00180054, 0.0128174],\n",
       "             [-3.95775e-05, 0.0126953, -0.00180817, ..., 0.00640869,\n",
       "              -0.0150146, -0.0211182],\n",
       "             [-0.00570679, -0.00585938, -0.0111694, ..., 0.00588989,\n",
       "              -0.0189209, 0.00127411],\n",
       "             ...,\n",
       "             [0.00723267, -0.000389099, 0.0185547, ..., 0.0140381,\n",
       "              0.000843048, 0.0112305],\n",
       "             [0.00302124, -0.00170898, -0.0102539, ..., 0.00628662,\n",
       "              -0.00848389, -0.00167084],\n",
       "             [0.0201416, -0.00891113, -0.0132446, ..., -0.00848389,\n",
       "              0.00634766, 0.0090332]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00372314, -0.000329971, 0.000394821, ..., 0.00280762,\n",
       "             0.0111084, 0.0108643],\n",
       "            [0.00222778, -0.00069046, 0.00268555, ..., -0.00367737,\n",
       "             0.00570679, -0.0375977],\n",
       "            [0.00150299, 0.00238037, 0.00448608, ..., 0.0397949, 0.00218201,\n",
       "             -0.00723267],\n",
       "            ...,\n",
       "            [-0.00020504, -0.0018158, -0.00213623, ..., 0.0136108,\n",
       "             0.0202637, -0.0197754],\n",
       "            [0.00415039, 0.00735474, 0.00805664, ..., 0.0150757,\n",
       "             0.000976562, -0.00891113],\n",
       "            [0.0019989, -0.00270081, 0.00546265, ..., -0.0177002,\n",
       "             -0.0272217, 0.0137329]],\n",
       "    \n",
       "           [[0.0109863, -0.0155029, -0.00148773, ..., 0.00382996, 0.0194092,\n",
       "             0.0125122],\n",
       "            [0.0101318, -0.0126343, 0.00133514, ..., 0.0144653, -0.00430298,\n",
       "             0.00218201],\n",
       "            [-0.0126953, 0.00454712, 0.0136108, ..., 0.00738525, 0.0108643,\n",
       "             -0.015625],\n",
       "            ...,\n",
       "            [0.000926971, -0.0235596, 0.0125122, ..., 0.00531006, 0.0114136,\n",
       "             0.00561523],\n",
       "            [-0.00338745, 0.0162354, -0.00157928, ..., 0.0100098,\n",
       "             -0.0170898, -0.0164795],\n",
       "            [0.00811768, 0.0123291, 0.0101929, ..., -0.00497437, -0.0112915,\n",
       "             -0.0145874]],\n",
       "    \n",
       "           [[-0.0147705, -0.00540161, -0.00387573, ..., -0.000196457,\n",
       "             0.00205994, -0.00521851],\n",
       "            [-0.00224304, -0.00159454, 0.00952148, ..., -0.0187988,\n",
       "             0.00683594, 0.0111694],\n",
       "            [-0.00552368, -0.0118408, 0.0213623, ..., 0.00457764,\n",
       "             0.00860596, -0.00254822],\n",
       "            ...,\n",
       "            [-0.00186157, -0.00512695, 0.00378418, ..., -0.0305176,\n",
       "             0.0022583, 0.0178223],\n",
       "            [0.00552368, 0.0037384, -0.0106812, ..., 0.0194092, 0.00376892,\n",
       "             -0.0196533],\n",
       "            [-0.0019989, -0.00231934, 0.00157928, ..., -0.0131226,\n",
       "             -0.0110474, -0.00436401]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00279236, -0.00811768, -0.00320435, ..., 0.00524902,\n",
       "             0.0115356, 0.00482178],\n",
       "            [-0.00153351, -0.00367737, -0.0100708, ..., -0.00933838,\n",
       "             0.0164795, 0.0164795],\n",
       "            [0.000263214, -0.00137329, -0.00221252, ..., -0.000137329,\n",
       "             0.0148926, -0.0184326],\n",
       "            ...,\n",
       "            [0.00163269, 0.0125122, 0.0144653, ..., -0.00640869,\n",
       "             -0.00939941, 0.00552368],\n",
       "            [0.00125885, -0.00772095, 0.00025177, ..., 0.0220947,\n",
       "             0.00878906, 0.00166321],\n",
       "            [-0.00294495, 0.00177002, 0.0065918, ..., -0.0027771,\n",
       "             0.00747681, 0.0339355]],\n",
       "    \n",
       "           [[-0.00592041, 0.0043335, 0.0078125, ..., -0.0123901, -0.0194092,\n",
       "             0.0163574],\n",
       "            [-0.0133667, -0.00189972, 0.015564, ..., -0.00860596,\n",
       "             0.00805664, 0.00332642],\n",
       "            [0.00382996, -0.00588989, -0.00265503, ..., -0.015564,\n",
       "             0.0229492, -1.3113e-05],\n",
       "            ...,\n",
       "            [9.9659e-05, -0.0123901, 0.0146484, ..., -0.00747681,\n",
       "             0.00364685, -0.00360107],\n",
       "            [0.0117798, 0.00023365, -0.000295639, ..., 0.00363159,\n",
       "             -0.00193024, -0.00189972],\n",
       "            [0.0116577, 0.0012207, -0.00747681, ..., 0.00842285, 0.00317383,\n",
       "             0.0114746]],\n",
       "    \n",
       "           [[0.00198364, 0.00698853, -0.0174561, ..., -0.00485229,\n",
       "             -0.00415039, -0.00897217],\n",
       "            [0.00457764, -0.00506592, 0.00131226, ..., -0.0213623,\n",
       "             -0.0500488, 0.0127563],\n",
       "            [0.00184631, -0.00130463, 0.000679016, ..., 0.00317383,\n",
       "             -0.013916, -0.032959],\n",
       "            ...,\n",
       "            [0.00212097, 0.00793457, -0.00750732, ..., 0.00689697,\n",
       "             0.0322266, 0.0200195],\n",
       "            [-0.000211716, -0.00552368, -0.000448227, ..., -0.00491333,\n",
       "             -0.00343323, -0.00473022],\n",
       "            [0.000694275, -0.00628662, 0.00469971, ..., -0.00457764,\n",
       "             0.00564575, -0.00128937]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00430298, 0.0016861, -0.0071106, ..., 0.0150757, 0.0130005,\n",
       "            0.00210571],\n",
       "           [-0.00549316, -0.00268555, 0.00460815, ..., -0.00448608,\n",
       "            0.00500488, -0.00549316],\n",
       "           [0.00823975, 0.00326538, -0.00153351, ..., 0.0101929, 0.0111694,\n",
       "            -0.00185394],\n",
       "           ...,\n",
       "           [-0.00671387, -0.0129395, 0.0249023, ..., 0.0108643, 0.00741577,\n",
       "            -0.00836182],\n",
       "           [-0.00631714, 0.0140991, 0.00915527, ..., -0.0112305,\n",
       "            0.000347137, -0.0043335],\n",
       "           [0.00265503, -0.0043335, -0.00958252, ..., -0.00579834,\n",
       "            0.00643921, 0.0045166]],\n",
       "   \n",
       "          [[-0.00292969, 0.00933838, 0.0136719, ..., -0.00671387,\n",
       "            0.00082016, -0.00521851],\n",
       "           [-0.0043335, -0.000457764, -0.0115356, ..., -0.00043869,\n",
       "            -0.0030365, 0.00543213],\n",
       "           [-0.0111084, -0.017334, -0.00357056, ..., 0.00460815,\n",
       "            -0.00454712, 0.00799561],\n",
       "           ...,\n",
       "           [0.00585938, 0.00817871, -0.00308228, ..., -0.00866699,\n",
       "            -0.00723267, -0.000858307],\n",
       "           [0.00418091, -0.0120239, 0.00242615, ..., 0.0032959,\n",
       "            -7.34329e-05, 0.000499725],\n",
       "           [0.0067749, -0.00531006, -0.00872803, ..., 0.0071106,\n",
       "            0.00613403, 0.00799561]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.000617981, 0.00732422, 0.012085, ..., -0.00393677,\n",
       "           -0.00442505, -0.0090332],\n",
       "          [0.0147705, 0.010498, -0.00524902, ..., 0.00778198, -0.00952148,\n",
       "           0.00671387],\n",
       "          [-0.00787354, -0.010498, -0.000862122, ..., -0.0162354,\n",
       "           -0.00921631, -0.00415039],\n",
       "          ...,\n",
       "          [0.0113525, -0.00836182, 0.00159454, ..., 0.00460815,\n",
       "           -0.000349045, -0.0137329],\n",
       "          [0.00185394, 0.00137329, -0.00756836, ..., 0.00860596, 0.00543213,\n",
       "           0.00915527],\n",
       "          [-0.0150757, -0.00402832, 0.00286865, ..., -0.000164032,\n",
       "           0.00543213, -0.0152588]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([2.5625, 2.40625, 2.51562, ..., 2.625, 2.76562, 2.46875], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([4.75, 4.78125, 4.90625, ..., 5.59375, 5.34375, 4.6875], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.248047, 0.223633, 0.21582, ..., 0.345703, 0.259766, 0.339844],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.188477, -0.169922, -0.19043, ..., -0.158203, -0.195312,\n",
       "          -0.142578], dtype=bfloat16)}},\n",
       " 'layer_25': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.00209045, -0.00415039, -0.000907898, ..., -0.0712891,\n",
       "             -0.012085, -0.000808716],\n",
       "            [0.000637054, 0.0110474, -0.00257874, ..., 0.00187683,\n",
       "             -0.00485229, 0.0177002],\n",
       "            [0.000518799, -0.0141602, 0.00421143, ..., -0.0125122,\n",
       "             -0.0264893, -0.00254822],\n",
       "            ...,\n",
       "            [-0.00250244, -0.0202637, 0.00671387, ..., -0.0234375,\n",
       "             0.0113525, 0.00488281],\n",
       "            [-0.00219727, 0.00726318, 0.00138855, ..., 0.0118408,\n",
       "             -0.0161133, -0.0120239],\n",
       "            [0.0135498, 0.00123596, -0.00418091, ..., -0.00518799,\n",
       "             0.00549316, 0.00140381]],\n",
       "    \n",
       "           [[-0.00344849, 0.0055542, 0.0201416, ..., -0.024292, 0.012207,\n",
       "             0.00260925],\n",
       "            [0.00915527, -0.00396729, -0.00772095, ..., -0.00372314,\n",
       "             0.000119209, 0.0197754],\n",
       "            [0.00305176, 0.0100098, -0.00701904, ..., 0.0115967, 0.00674438,\n",
       "             0.0149536],\n",
       "            ...,\n",
       "            [0.00640869, 0.0241699, -0.0107422, ..., 0.00222778,\n",
       "             -0.00157928, 0.00332642],\n",
       "            [0.00601196, 0.00270081, 0.00314331, ..., -0.00939941,\n",
       "             -0.00708008, 0.00360107],\n",
       "            [0.0174561, 0.00762939, 0.0078125, ..., -0.0162354, 0.00634766,\n",
       "             0.00515747]],\n",
       "    \n",
       "           [[0.0164795, 0.0155029, -0.00268555, ..., -0.00457764, 0.0155029,\n",
       "             0.00964355],\n",
       "            [-0.000679016, -0.0111694, 0.0178223, ..., -0.017334,\n",
       "             -0.00741577, -0.0339355],\n",
       "            [-0.00723267, -0.0228271, -0.0162354, ..., 0.0201416,\n",
       "             -0.00939941, 0.00294495],\n",
       "            ...,\n",
       "            [0.0233154, 0.000736237, -0.03125, ..., -0.013855, 0.00159454,\n",
       "             0.0115356],\n",
       "            [0.00735474, 0.0167236, -0.00665283, ..., -0.000343323,\n",
       "             0.00135803, -0.0175781],\n",
       "            [-0.00650024, -0.0108032, -0.00518799, ..., -0.00595093,\n",
       "             -0.0020752, -0.0122681]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.022583, -0.00340271, -0.0022583, ..., 0.00872803,\n",
       "             0.00958252, -0.0101318],\n",
       "            [-0.0136108, 0.00231934, 0.0131226, ..., 0.0125122, 0.00297546,\n",
       "             -0.000452042],\n",
       "            [-0.0202637, 0.0200195, -0.0132446, ..., 0.0107422, 0.0181885,\n",
       "             0.00439453],\n",
       "            ...,\n",
       "            [0.0137939, -0.00271606, -0.0102539, ..., -0.00244141,\n",
       "             0.000230789, 0.00463867],\n",
       "            [-0.00146484, -0.00695801, 0.019165, ..., -0.00132751,\n",
       "             0.00366211, -0.00836182],\n",
       "            [-0.0314941, 0.0140381, 0.0137939, ..., -0.00604248,\n",
       "             0.000411987, -0.00349426]],\n",
       "    \n",
       "           [[-0.00570679, 0.0164795, -0.0136108, ..., 0.00915527, 0.0098877,\n",
       "             0.00488281],\n",
       "            [-0.00491333, -0.00106812, 0.00189972, ..., 0.00245667,\n",
       "             -4.52995e-05, 0.00285339],\n",
       "            [0.00101471, -0.0119019, -0.00564575, ..., 0.00695801,\n",
       "             -0.00448608, -0.0169678],\n",
       "            ...,\n",
       "            [0.00527954, 0.0251465, 0.0133057, ..., -0.00842285, 0.00396729,\n",
       "             0.00616455],\n",
       "            [-0.00166321, 0.0148926, 0.00753784, ..., 0.00689697,\n",
       "             0.00970459, 0.00613403],\n",
       "            [0.00836182, 0.0161133, -0.0120239, ..., 0.000896454,\n",
       "             -0.0067749, -0.00119019]],\n",
       "    \n",
       "           [[0.00405884, 0.00212097, 0.0154419, ..., -0.00927734,\n",
       "             0.000349045, -0.0185547],\n",
       "            [0.0170898, -0.00738525, -0.000200272, ..., -0.00747681,\n",
       "             0.00909424, -0.00552368],\n",
       "            [0.00162506, 0.00191498, 0.00172424, ..., -0.0016861, 0.017334,\n",
       "             -0.00732422],\n",
       "            ...,\n",
       "            [0.00270081, -0.0018692, 0.00610352, ..., 0.00273132,\n",
       "             -0.00247192, -0.0126343],\n",
       "            [-0.000915527, -0.010437, 0.00720215, ..., 0.0027771,\n",
       "             0.00509644, -0.00476074],\n",
       "            [0.00512695, -0.0137329, 0.00306702, ..., 0.00402832,\n",
       "             -0.00860596, 0.00448608]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.0196533, -0.00787354, 0.00144196, ..., -0.0155029,\n",
       "              -0.0220947, -0.00457764],\n",
       "             [0.0145264, 0.00842285, -0.0135498, ..., -0.0148315,\n",
       "              0.0117798, -0.0122681],\n",
       "             [0.0032196, 0.013855, -0.00239563, ..., 0.0126953, 0.0129395,\n",
       "              0.0157471],\n",
       "             ...,\n",
       "             [-0.000180244, 0.0134888, 0.00138855, ..., 0.00915527,\n",
       "              0.00280762, 0.00338745],\n",
       "             [0.00285339, -0.00405884, -0.00878906, ..., 0.00891113,\n",
       "              -0.0128784, -0.00184631],\n",
       "             [-0.00283813, -0.00619507, -0.00445557, ..., 0.00561523,\n",
       "              -0.0238037, 0.0112305]],\n",
       "    \n",
       "            [[-0.00588989, 0.0124512, -0.000211716, ..., -0.00442505,\n",
       "              -0.00601196, 0.00238037],\n",
       "             [-0.0057373, -0.0174561, -0.00265503, ..., 0.00616455,\n",
       "              -1.84774e-05, 0.00279236],\n",
       "             [0.00125885, 0.013855, -0.00297546, ..., 0.0134888,\n",
       "              -0.00872803, 0.0027771],\n",
       "             ...,\n",
       "             [-0.0255127, -0.00023365, -0.0230713, ..., 0.00860596,\n",
       "              0.00430298, -0.0065918],\n",
       "             [0.000862122, 0.00540161, -0.000356674, ..., 0.00372314,\n",
       "              0.0149536, 0.0123291],\n",
       "             [0.00145721, -0.0153198, -0.00285339, ..., 0.0130615,\n",
       "              0.00442505, -0.00952148]],\n",
       "    \n",
       "            [[-0.000128746, 0.0228271, -0.000640869, ..., -0.00830078,\n",
       "              0.0045166, 0.00741577],\n",
       "             [0.00946045, -0.00112152, -0.00256348, ..., -0.0189209,\n",
       "              -0.010498, -0.00775146],\n",
       "             [-0.00701904, -0.0117798, -0.0112915, ..., -0.0134277,\n",
       "              -0.00537109, -0.00576782],\n",
       "             ...,\n",
       "             [0.0220947, -0.0192871, 0.00372314, ..., 0.00219727,\n",
       "              0.000274658, 0.00457764],\n",
       "             [-0.0090332, 0.00634766, -0.0108032, ..., -0.00131989,\n",
       "              0.0168457, 0.00787354],\n",
       "             [0.00326538, -0.00616455, 0.00759888, ..., -0.00131226,\n",
       "              -0.0115967, -0.0162354]],\n",
       "    \n",
       "            [[0.00567627, -0.0108032, -0.00646973, ..., -0.000965118,\n",
       "              -0.00256348, 0.00188446],\n",
       "             [0.00772095, 0.0177002, 0.00836182, ..., 0.0128784,\n",
       "              -0.00778198, -0.0116577],\n",
       "             [-0.0128784, 0.0134277, 0.00415039, ..., -0.00247192,\n",
       "              -0.0194092, -0.00357056],\n",
       "             ...,\n",
       "             [-0.0166016, -0.0119629, -0.0168457, ..., -0.00188446,\n",
       "              -0.0244141, 0.00153351],\n",
       "             [0.00415039, -0.00270081, 0.00854492, ..., -0.0119629,\n",
       "              0.0134277, 0.0163574],\n",
       "             [0.0112915, -0.0219727, -0.00102997, ..., 0.00878906,\n",
       "              -0.00604248, 0.0067749]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0219727, 0.000953674, -0.00442505, ..., -0.00616455,\n",
       "              0.0141602, 0.00946045],\n",
       "             [0.00509644, 0.00476074, 0.0153198, ..., 0.00750732,\n",
       "              0.0116577, 0.00582886],\n",
       "             [0.0294189, 0.00104523, -0.017334, ..., -0.00153351,\n",
       "              0.00759888, 0.0151367],\n",
       "             ...,\n",
       "             [-0.0175781, -0.0015564, 0.00830078, ..., -0.00723267,\n",
       "              0.00445557, 0.00363159],\n",
       "             [0.0100708, -0.0127563, -0.00379944, ..., -0.000595093,\n",
       "              -0.00738525, 0.0118408],\n",
       "             [-0.00872803, 0.00656128, 0.0107422, ..., -0.000919342,\n",
       "              -0.00350952, 0.00799561]],\n",
       "    \n",
       "            [[0.0231934, 0.00183868, 0.00476074, ..., 0.0107422,\n",
       "              -0.00247192, -0.0106201],\n",
       "             [0.00933838, -0.00512695, -0.03125, ..., 0.00128937,\n",
       "              0.0131226, 0.00454712],\n",
       "             [-0.00062561, 0.0219727, -0.00241089, ..., -0.0174561,\n",
       "              -0.0133667, -0.00482178],\n",
       "             ...,\n",
       "             [-0.0088501, -0.00970459, 0.0197754, ..., 0.000303268,\n",
       "              0.0233154, -0.00772095],\n",
       "             [0.0144043, -0.00793457, -0.0110474, ..., 0.00976562,\n",
       "              0.00604248, -0.00860596],\n",
       "             [0.00695801, -0.0178223, -0.0035553, ..., 0.0117188,\n",
       "              -0.0129395, 0.00257874]],\n",
       "    \n",
       "            [[0.0241699, 0.0057373, 0.0167236, ..., -0.0117188, 0.00112152,\n",
       "              0.027832],\n",
       "             [0.0088501, 0.000411987, -0.0284424, ..., -0.00463867,\n",
       "              0.0148926, -0.0252686],\n",
       "             [0.00485229, -0.00540161, 0.0108643, ..., 0.0236816,\n",
       "              -0.0214844, -0.0155029],\n",
       "             ...,\n",
       "             [-0.0146484, -0.0268555, -0.00909424, ..., 0.0162354,\n",
       "              0.00811768, 0.00982666],\n",
       "             [-0.0134888, 0.00418091, -0.0150757, ..., 0.00640869,\n",
       "              -0.0109253, 0.00216675],\n",
       "             [0.0109863, -4.48227e-05, -0.00177765, ..., -0.0197754,\n",
       "              0.012146, 0.00497437]],\n",
       "    \n",
       "            [[-0.0129395, -0.0135498, 0.0148926, ..., -0.00714111,\n",
       "              0.0164795, 0.0140991],\n",
       "             [0.00476074, -0.000452042, 0.000478745, ..., 0.0065918,\n",
       "              0.0137329, 0.0154419],\n",
       "             [-0.00723267, 0.000930786, -0.0112915, ..., 0.006073,\n",
       "              0.0123291, -0.00479126],\n",
       "             ...,\n",
       "             [0.0140381, -0.0045166, -0.0035553, ..., 0.00230408, 0.012146,\n",
       "              -0.0039978],\n",
       "             [0.00308228, -0.00939941, -0.0140991, ..., 0.000329971,\n",
       "              -0.00317383, -0.00585938],\n",
       "             [0.0032196, 0.019043, 0.00260925, ..., 0.00787354, 0.0164795,\n",
       "              -0.00665283]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00360107, -0.0090332, -0.0025177, ..., 0.00239563,\n",
       "             -0.00735474, 0.00689697],\n",
       "            [0.00543213, -0.00297546, -0.00231934, ..., -0.0122681,\n",
       "             0.00241089, -0.012207],\n",
       "            [-0.00723267, 9.67979e-05, 0.0114746, ..., -0.00247192,\n",
       "             0.00524902, -0.0130005],\n",
       "            ...,\n",
       "            [-0.000492096, -0.000682831, -0.000747681, ..., -0.0168457,\n",
       "             -0.0303955, -0.00759888],\n",
       "            [-0.00154114, 0.0078125, 0.00454712, ..., -0.00537109,\n",
       "             -0.0134277, 0.0220947],\n",
       "            [0.00540161, -0.000324249, -0.00402832, ..., 0.010437,\n",
       "             0.0170898, 0.00219727]],\n",
       "    \n",
       "           [[0.0229492, 0.0130615, -0.0170898, ..., 0.00494385, 0.0184326,\n",
       "             -0.0180664],\n",
       "            [-0.0119019, 0.00640869, 0.0222168, ..., -0.00738525,\n",
       "             0.00799561, -0.00384521],\n",
       "            [0.0109253, 0.00367737, -0.0078125, ..., -0.00683594,\n",
       "             0.00897217, -0.000926971],\n",
       "            ...,\n",
       "            [-0.0150757, -0.0324707, 0.0175781, ..., -0.0167236, -0.0159912,\n",
       "             0.00227356],\n",
       "            [0.0071106, 0.015625, -0.00537109, ..., 0.0217285, 0.00976562,\n",
       "             -0.00100708],\n",
       "            [0.00897217, -0.0122681, -0.0128174, ..., -0.000153542,\n",
       "             -0.00601196, 0.00405884]],\n",
       "    \n",
       "           [[-0.000408173, 0.00717163, -0.0179443, ..., 0.000150681,\n",
       "             0.0264893, -0.0147095],\n",
       "            [-0.000469208, -0.00349426, 0.00350952, ..., 0.0270996,\n",
       "             0.00836182, 0.012146],\n",
       "            [-0.00151062, 0.00128174, 0.00970459, ..., 0.0184326,\n",
       "             0.00582886, -0.0106812],\n",
       "            ...,\n",
       "            [0.0114136, 0.00302124, 0.00952148, ..., -0.0222168,\n",
       "             -0.00778198, 0.0135498],\n",
       "            [0.0166016, 0.000740051, -0.00152588, ..., -0.00726318,\n",
       "             -0.00233459, 0.0130615],\n",
       "            [0.0111694, 0.00157928, 0.00273132, ..., 0.00921631, 0.0103149,\n",
       "             -0.0218506]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00860596, 0.0155029, -0.0322266, ..., -0.0161133,\n",
       "             0.00531006, 0.00112152],\n",
       "            [0.00308228, 0.00445557, 0.00695801, ..., 6.58035e-05,\n",
       "             -0.00164032, -0.00378418],\n",
       "            [-0.0072937, 0.00340271, -0.0251465, ..., 0.00750732,\n",
       "             -1.71661e-05, 0.0120239],\n",
       "            ...,\n",
       "            [0.00360107, 0.00558472, -0.00723267, ..., -3.79086e-05,\n",
       "             -0.00546265, 0.000201225],\n",
       "            [0.00245667, 0.00131226, -0.0151367, ..., -0.00192261,\n",
       "             0.00842285, 0.0112915],\n",
       "            [0.00595093, 0.00482178, 0.0228271, ..., 0.00500488, -0.0112915,\n",
       "             -0.0166016]],\n",
       "    \n",
       "           [[-0.0038147, 0.00524902, -0.00234985, ..., 0.0103149,\n",
       "             0.000938416, 0.00750732],\n",
       "            [-0.00616455, 0.00485229, 0.00279236, ..., 0.0172119,\n",
       "             -0.00994873, -0.00674438],\n",
       "            [-0.001297, 0.00162506, 0.0065918, ..., -0.00183105, -0.0134888,\n",
       "             -0.0196533],\n",
       "            ...,\n",
       "            [-0.00245667, -0.00485229, -0.00335693, ..., -0.0098877,\n",
       "             -0.000705719, -0.00218201],\n",
       "            [-0.00540161, 0.000793457, 0.000892639, ..., 0.00186157,\n",
       "             -0.000448227, -0.00430298],\n",
       "            [-0.0030365, -0.0119019, -0.00811768, ..., -0.0112915,\n",
       "             0.0209961, 0.00817871]],\n",
       "    \n",
       "           [[0.00364685, -0.00375366, 0.00726318, ..., 0.00836182,\n",
       "             -0.00592041, -0.00189972],\n",
       "            [-0.00379944, 0.00173187, -0.00460815, ..., -0.0078125,\n",
       "             -0.00811768, -0.0110474],\n",
       "            [0.00424194, 0.00674438, -0.00296021, ..., 0.0100708, -0.026001,\n",
       "             0.00772095],\n",
       "            ...,\n",
       "            [0.00227356, 0.00946045, -0.00494385, ..., 0.00479126,\n",
       "             -0.0202637, -0.000843048],\n",
       "            [0.000801086, -0.00427246, -0.00117493, ..., 0.000976562,\n",
       "             -0.000873566, -0.0100098],\n",
       "            [0.00643921, -0.0045166, 0.0100098, ..., 0.00576782, 0.00567627,\n",
       "             -0.0142822]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00134277, -0.0019989, -0.00135803, ..., 0.00349426,\n",
       "            0.006073, -0.00616455],\n",
       "           [-0.00325012, -0.0118408, 0.00141907, ..., 0.00158691,\n",
       "            -0.0088501, 0.00375366],\n",
       "           [-0.00500488, 0.00619507, 0.000537872, ..., 0.00613403,\n",
       "            -0.0141602, 9.67979e-05],\n",
       "           ...,\n",
       "           [-0.00210571, 0.00927734, -0.00171661, ..., -0.0108032,\n",
       "            0.00457764, -0.00524902],\n",
       "           [0.00187683, -0.0043335, 0.00047493, ..., 0.00805664,\n",
       "            -0.00582886, 0.00121307],\n",
       "           [-0.00512695, 0.0189209, 0.00549316, ..., 0.0090332, 0.0112305,\n",
       "            -0.00180054]],\n",
       "   \n",
       "          [[-0.000442505, 0.00631714, -0.0145264, ..., 0.0116577,\n",
       "            -0.0285645, 0.0109863],\n",
       "           [-0.00811768, 0.00735474, 0.000740051, ..., 0.00543213,\n",
       "            0.0159912, -0.00104523],\n",
       "           [0.000354767, 0.00460815, 0.00811768, ..., -0.00714111,\n",
       "            0.000473022, -0.00463867],\n",
       "           ...,\n",
       "           [0.00567627, 0.00294495, 0.000293732, ..., -0.00643921,\n",
       "            -0.0001688, 0.00521851],\n",
       "           [-0.00044632, -0.0162354, -0.0045166, ..., -0.0133667,\n",
       "            0.00102997, 0.00460815],\n",
       "           [0.000747681, 0.00662231, -0.00585938, ..., 0.0136108,\n",
       "            -0.0057373, 0.00769043]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00257874, 0.00442505, -0.00585938, ..., -0.000991821,\n",
       "           -0.00772095, -0.010437],\n",
       "          [0.00349426, -0.00023365, 0.0017395, ..., -0.00118256,\n",
       "           0.000984192, 0.00157928],\n",
       "          [-0.00170898, 0.00787354, -0.00218201, ..., 0.00439453,\n",
       "           -0.00270081, 0.00552368],\n",
       "          ...,\n",
       "          [0.0108032, 0.00576782, 0.00878906, ..., 0.00213623, 0.000214577,\n",
       "           0.00247192],\n",
       "          [-0.00750732, 0.00897217, 0.0100098, ..., -0.0163574, 0.0020752,\n",
       "           0.00190735],\n",
       "          [-0.00193787, 0.00216675, 0.00515747, ..., 0.0039978, -0.00384521,\n",
       "           -0.0078125]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([2.39062, 2.375, 2.32812, ..., 3.42188, 2.84375, 2.29688], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([4.6875, 4.84375, 4.9375, ..., 5.9375, 4.5625, 4.6875], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.296875, 0.261719, 0.265625, ..., 0.380859, 0.296875, 0.373047],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.136719, -0.134766, -0.133789, ..., -0.0761719, -0.129883,\n",
       "          -0.105957], dtype=bfloat16)}},\n",
       " 'layer_3': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.015625, -0.0299072, 0.0206299, ..., -0.0202637, 0.0197754,\n",
       "             -0.012207],\n",
       "            [-0.0192871, 0.0227051, 0.0184326, ..., 0.0123291, 0.00288391,\n",
       "             0.0112305],\n",
       "            [0.000459671, 0.00396729, -0.0102539, ..., -0.0130615,\n",
       "             0.00952148, -0.0108032],\n",
       "            ...,\n",
       "            [0.019043, -0.00643921, -0.0116577, ..., -0.00726318,\n",
       "             0.00836182, -0.00267029],\n",
       "            [-0.0019989, 0.0212402, -0.00149536, ..., -0.00289917,\n",
       "             0.0106812, 0.00469971],\n",
       "            [0.00921631, -0.00738525, -0.00189209, ..., 0.00689697,\n",
       "             -5.36442e-05, 0.000396729]],\n",
       "    \n",
       "           [[0.000303268, -0.0166016, -0.00671387, ..., 0.0151367,\n",
       "             0.0283203, 0.00352478],\n",
       "            [-0.00448608, 0.0101318, 0.0255127, ..., -0.0157471, 0.00933838,\n",
       "             0.0114746],\n",
       "            [0.0178223, 0.00769043, -0.0124512, ..., -0.00701904,\n",
       "             0.00369263, 0.00765991],\n",
       "            ...,\n",
       "            [-0.00765991, 0.00127411, 0.0045166, ..., 0.00567627, 0.0152588,\n",
       "             0.0078125],\n",
       "            [-0.00262451, 0.00268555, -0.00546265, ..., 0.0234375,\n",
       "             0.00167084, -0.0037384],\n",
       "            [-0.0136108, -0.0147705, 0.00442505, ..., 0.00778198,\n",
       "             -0.00196838, 0.0117188]],\n",
       "    \n",
       "           [[0.0196533, 0.00656128, -0.0249023, ..., -0.0224609, 0.00595093,\n",
       "             0.00218201],\n",
       "            [0.012085, 0.00817871, -0.00970459, ..., -0.00288391,\n",
       "             0.00878906, -0.0071106],\n",
       "            [0.0180664, -0.0157471, 0.00909424, ..., 0.00019455,\n",
       "             -0.00714111, -0.00159454],\n",
       "            ...,\n",
       "            [-0.00897217, 0.0113525, 0.0065918, ..., -0.000667572,\n",
       "             -0.0148926, -0.00170898],\n",
       "            [-0.00817871, -0.00382996, -0.00653076, ..., -0.00267029,\n",
       "             -0.00714111, 0.0131836],\n",
       "            [0.006073, 0.00588989, -0.00927734, ..., 0.00872803,\n",
       "             -0.00552368, 0.00308228]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00656128, -0.000621796, -0.00131989, ..., 0.0110474,\n",
       "             0.00418091, -0.00683594],\n",
       "            [0.00747681, 0.0103149, 0.00285339, ..., 0.00650024,\n",
       "             -0.00318909, 0.00897217],\n",
       "            [0.00823975, 0.00567627, -0.0119629, ..., -0.000549316,\n",
       "             -0.000310898, -0.0043335],\n",
       "            ...,\n",
       "            [0.00500488, 0.00698853, -0.00050354, ..., 0.00386047,\n",
       "             0.00830078, -0.00112915],\n",
       "            [-0.00244141, -0.00263977, -0.00915527, ..., -0.00872803,\n",
       "             0.00189209, 0.0195312],\n",
       "            [0.0197754, -0.00939941, 0.00701904, ..., -0.0270996,\n",
       "             -0.0119629, -0.00369263]],\n",
       "    \n",
       "           [[0.00216675, 0.00140381, -0.00817871, ..., 0.00256348,\n",
       "             0.0105591, 0.0100708],\n",
       "            [0.0115967, -0.00701904, -0.00531006, ..., 0.0222168,\n",
       "             -0.00101471, 0.0219727],\n",
       "            [0.00430298, 0.0114746, -0.000157356, ..., 0.0114136,\n",
       "             -0.00276184, -0.0336914],\n",
       "            ...,\n",
       "            [-0.00527954, -0.00546265, -6.62804e-05, ..., -0.00131226,\n",
       "             -0.00326538, -0.00167084],\n",
       "            [0.020874, -0.00933838, 0.0129395, ..., -0.0189209, 0.00668335,\n",
       "             -0.0167236],\n",
       "            [0.00172424, 0.0139771, 0.0115356, ..., 0.00473022, 0.0186768,\n",
       "             0.00897217]],\n",
       "    \n",
       "           [[-0.0109253, 0.000478745, -0.00268555, ..., 0.00378418,\n",
       "             0.0123901, 0.00787354],\n",
       "            [0.00976562, 0.00482178, 0.0078125, ..., -0.000762939,\n",
       "             0.00805664, -0.001297],\n",
       "            [-0.00418091, -0.00546265, -0.00238037, ..., 0.00588989,\n",
       "             0.0158691, 0.00292969],\n",
       "            ...,\n",
       "            [-0.00260925, -0.00537109, -0.00239563, ..., 0.00393677,\n",
       "             -0.0136108, 0.0102539],\n",
       "            [0.00515747, 0.0222168, 0.0203857, ..., 0.00292969, -0.001091,\n",
       "             -0.0126953],\n",
       "            [-0.0140991, 0.0140991, -0.0122681, ..., -0.00309753,\n",
       "             -0.0112305, -0.00823975]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.00799561, 0.00439453, 0.0146484, ..., 0.00332642,\n",
       "              -0.00872803, 0.00245667],\n",
       "             [0.00144196, 0.000379562, 0.0100708, ..., 0.00619507,\n",
       "              0.0202637, -0.0181885],\n",
       "             [-0.0039978, -0.00389099, 0.00952148, ..., -0.0145264,\n",
       "              -0.00448608, -0.00946045],\n",
       "             ...,\n",
       "             [-0.00671387, -0.00314331, -0.00933838, ..., 0.00708008,\n",
       "              -0.000869751, -0.00619507],\n",
       "             [-0.0039978, 0.00305176, 0.00212097, ..., 0.000107288,\n",
       "              0.00308228, 0.00463867],\n",
       "             [-0.00720215, -0.00915527, -0.00386047, ..., 0.00759888,\n",
       "              0.010376, 0.00497437]],\n",
       "    \n",
       "            [[-0.00897217, 0.0106201, 0.0142212, ..., -0.0098877,\n",
       "              0.0187988, 0.00328064],\n",
       "             [0.00543213, -0.0126953, 0.000207901, ..., 0.0140991,\n",
       "              -0.000507355, 0.00750732],\n",
       "             [-0.00482178, -0.000507355, 0.00265503, ..., -0.0211182,\n",
       "              -0.00196838, 0.0098877],\n",
       "             ...,\n",
       "             [-0.0123291, 0.0194092, -0.0166016, ..., -0.017334, 0.0296631,\n",
       "              0.00244141],\n",
       "             [0.00543213, 0.00132751, 0.00524902, ..., 0.00127411,\n",
       "              -0.00166321, -0.0163574],\n",
       "             [-0.000159264, -0.0131226, 0.000957489, ..., 0.0155029,\n",
       "              0.0169678, -0.0109253]],\n",
       "    \n",
       "            [[-0.00494385, 0.020752, -0.00315857, ..., -0.0137939,\n",
       "              -0.00698853, 0.0125732],\n",
       "             [0.00178528, 0.00836182, -0.00297546, ..., -0.0145874,\n",
       "              -0.0163574, 0.00102997],\n",
       "             [-0.00939941, 0.0120239, -0.00469971, ..., -0.0169678,\n",
       "              -0.00205994, -0.00271606],\n",
       "             ...,\n",
       "             [-0.0134277, 0.0150146, 0.0115967, ..., -0.000663757,\n",
       "              -0.00230408, 0.0109863],\n",
       "             [0.0212402, -0.00799561, -0.00402832, ..., -0.00927734,\n",
       "              0.00161743, -0.00323486],\n",
       "             [-0.0098877, 0.00370789, -0.0158691, ..., 0.0145264,\n",
       "              0.0211182, 0.00653076]],\n",
       "    \n",
       "            [[0.00543213, 0.00634766, 0.0136719, ..., 0.00124359,\n",
       "              -0.0019989, -0.00836182],\n",
       "             [0.000747681, 0.0111084, 0.00717163, ..., -0.0067749,\n",
       "              0.0045166, 0.0105591],\n",
       "             [0.00389099, 0.0107422, -0.0137329, ..., -0.0159912,\n",
       "              -0.0107422, 0.00613403],\n",
       "             ...,\n",
       "             [0.00408936, 0.00527954, 0.00378418, ..., -0.00463867,\n",
       "              0.0314941, -0.00524902],\n",
       "             [-0.0235596, -0.0186768, 0.00671387, ..., 0.00650024,\n",
       "              0.013855, -0.00221252],\n",
       "             [0.0131226, -0.00570679, 0.00376892, ..., 0.00765991,\n",
       "              -0.0140381, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[6.10352e-05, -0.0125122, -0.0101318, ..., 0.0174561,\n",
       "              -0.00221252, -0.0045166],\n",
       "             [0.00180817, 0.00753784, -0.0037384, ..., -0.0101318,\n",
       "              0.00260925, -0.00622559],\n",
       "             [0.0153809, 0.000652313, -0.00750732, ..., -0.00390625,\n",
       "              0.00668335, -0.000930786],\n",
       "             ...,\n",
       "             [-0.0253906, -0.0145264, 0.0108032, ..., -0.00842285,\n",
       "              -0.00970459, 0.0222168],\n",
       "             [-0.0163574, 0.00564575, 0.000514984, ..., -0.00476074,\n",
       "              0.0177002, 0.00361633],\n",
       "             [-0.0129395, -0.0133667, -0.00805664, ..., 0.00424194,\n",
       "              0.00439453, -0.0196533]],\n",
       "    \n",
       "            [[-0.0136719, -0.0129395, -0.0105591, ..., 0.0134888,\n",
       "              0.00775146, -0.00772095],\n",
       "             [-0.010498, 0.000766754, 0.0175781, ..., -0.00270081,\n",
       "              -0.00253296, 0.000911713],\n",
       "             [0.0247803, 0.0186768, -0.00402832, ..., 0.0011673, 0.0131836,\n",
       "              0.0143433],\n",
       "             ...,\n",
       "             [0.0154419, 0.000701904, 0.00387573, ..., -0.00247192,\n",
       "              0.0090332, -0.0149536],\n",
       "             [-0.00765991, -0.0134277, 0.00396729, ..., 0.00787354,\n",
       "              0.0038147, -0.00793457],\n",
       "             [-0.00436401, 0.00994873, 0.000455856, ..., -0.000923157,\n",
       "              -0.00878906, 0.00421143]],\n",
       "    \n",
       "            [[-0.00159454, -0.0257568, 0.00592041, ..., -0.0032196,\n",
       "              0.00302124, 0.00204468],\n",
       "             [0.00964355, -0.0222168, 0.0112915, ..., -0.00357056,\n",
       "              -0.00927734, -0.00140381],\n",
       "             [0.0111084, -0.00402832, -0.0109863, ..., -0.00524902,\n",
       "              0.0150146, 0.000471115],\n",
       "             ...,\n",
       "             [0.00518799, -0.0159912, -0.0123291, ..., -0.0180664,\n",
       "              -0.00213623, -0.0192871],\n",
       "             [-0.00769043, 0.00769043, 0.00872803, ..., 0.000686646,\n",
       "              0.00982666, 0.00415039],\n",
       "             [0.00254822, -0.00337219, -0.0112915, ..., 0.00202942,\n",
       "              -0.00305176, -0.00479126]],\n",
       "    \n",
       "            [[-0.00921631, 0.00309753, -0.00172424, ..., -0.0137329,\n",
       "              0.000972748, 0.00183105],\n",
       "             [-0.00570679, -0.00765991, -0.00056076, ..., 0.00656128,\n",
       "              0.00111389, 0.0307617],\n",
       "             [-0.0123901, 0.00805664, 0.00546265, ..., 0.000911713,\n",
       "              -0.00897217, 0.000644684],\n",
       "             ...,\n",
       "             [0.0163574, 0.0103149, -0.0157471, ..., -0.00389099,\n",
       "              -0.00643921, 0.012146],\n",
       "             [0.0055542, 0.0114746, 0.0133667, ..., 0.00439453,\n",
       "              -0.000429153, 0.0106201],\n",
       "             [0.0050354, 0.0088501, -0.00704956, ..., -0.00485229,\n",
       "              -0.0255127, 0.00921631]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.0116577, 0.00300598, 0.0112305, ..., 0.000368118,\n",
       "             -0.00994873, -0.00274658],\n",
       "            [0.0219727, 0.019043, -0.006073, ..., -0.00280762, -0.00668335,\n",
       "             0.0152588],\n",
       "            [-0.00592041, 0.00576782, 0.0205078, ..., 0.00512695,\n",
       "             0.00546265, -0.000368118],\n",
       "            ...,\n",
       "            [0.00186157, 0.000762939, 0.00479126, ..., -0.00897217,\n",
       "             0.00823975, 0.00524902],\n",
       "            [0.0062561, 0.00357056, -0.00866699, ..., 0.0153198, 0.00134277,\n",
       "             -0.012146],\n",
       "            [-0.0112915, -0.00485229, -0.0055542, ..., 0.00970459,\n",
       "             0.00198364, 0.00151825]],\n",
       "    \n",
       "           [[0.0016098, -0.00738525, -0.0153809, ..., 0.0133667, -0.010437,\n",
       "             0.00457764],\n",
       "            [0.00723267, 0.00952148, -0.00640869, ..., -0.00567627,\n",
       "             0.0272217, -0.00674438],\n",
       "            [-0.00193787, 0.00338745, 0.00154114, ..., -0.0123901,\n",
       "             -0.0229492, -0.00775146],\n",
       "            ...,\n",
       "            [-0.00595093, -0.0153198, 0.0102539, ..., 0.0174561, 0.00588989,\n",
       "             -0.00367737],\n",
       "            [0.00695801, -0.00106049, -0.00927734, ..., -0.00650024,\n",
       "             0.00680542, -0.00579834],\n",
       "            [-0.00034523, -0.00227356, -0.00147247, ..., 0.00311279,\n",
       "             -0.0113525, -0.012085]],\n",
       "    \n",
       "           [[-0.00732422, 0.00527954, 0.000640869, ..., -0.00537109,\n",
       "             0.0149536, -0.00671387],\n",
       "            [0.000991821, -0.00421143, -0.00335693, ..., -0.00174713,\n",
       "             0.0109863, -0.00457764],\n",
       "            [0.00118256, 0.00167084, 0.00793457, ..., -0.00793457,\n",
       "             0.00686646, 0.0103149],\n",
       "            ...,\n",
       "            [0.000511169, -0.00466919, -0.00570679, ..., -0.0236816,\n",
       "             0.00769043, 0.0131836],\n",
       "            [0.000930786, -0.00111389, 0.00331116, ..., 0.0167236,\n",
       "             0.00982666, -0.00509644],\n",
       "            [7.29561e-05, -0.0013504, 0.00279236, ..., 0.00300598,\n",
       "             0.0197754, 0.0109253]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00601196, -0.0158691, -0.0122681, ..., -0.00897217,\n",
       "             -0.00309753, 0.00387573],\n",
       "            [0.0178223, -0.00994873, 0.0229492, ..., -0.00311279, -0.024292,\n",
       "             0.0172119],\n",
       "            [-0.0186768, -0.00224304, -0.0133667, ..., -0.0241699,\n",
       "             0.00265503, -0.00628662],\n",
       "            ...,\n",
       "            [-0.00120544, -0.0019989, -0.0174561, ..., -0.012207,\n",
       "             -0.0148315, -0.00656128],\n",
       "            [0.0251465, -0.00506592, 0.00062561, ..., 0.00665283,\n",
       "             -0.00215149, 0.00167847],\n",
       "            [-0.0137329, 0.0150757, -0.0223389, ..., -0.00198364,\n",
       "             -0.00939941, 0.00515747]],\n",
       "    \n",
       "           [[-0.00263977, -0.0107422, -0.00349426, ..., 0.015564, -0.010376,\n",
       "             0.0218506],\n",
       "            [0.00482178, -0.0150146, -0.0151978, ..., 0.00747681, 0.0116577,\n",
       "             -0.00221252],\n",
       "            [-0.000556946, 0.00192261, 0.000352859, ..., -0.00056839,\n",
       "             0.0214844, -0.00775146],\n",
       "            ...,\n",
       "            [0.024292, 0.00946045, -0.0134888, ..., 0.0179443, 0.00106812,\n",
       "             0.0137939],\n",
       "            [-0.00358582, 0.000610352, -0.00509644, ..., -0.00411987,\n",
       "             -0.000896454, -0.0113525],\n",
       "            [-0.00222778, 0.00418091, -0.00634766, ..., -0.00119781,\n",
       "             0.0145874, -0.0105591]],\n",
       "    \n",
       "           [[0.00830078, 0.0169678, 0.00180054, ..., 0.0111084, -0.00151825,\n",
       "             0.0145874],\n",
       "            [-0.032959, 0.00222778, -0.0115356, ..., -0.0145874, 0.0111084,\n",
       "             -0.0123291],\n",
       "            [0.00735474, 0.0118408, 0.000335693, ..., 0.000514984,\n",
       "             -0.00311279, -0.0179443],\n",
       "            ...,\n",
       "            [-0.00162506, -0.0179443, -0.012085, ..., -0.0252686,\n",
       "             -0.00958252, 0.00268555],\n",
       "            [-0.00805664, -0.000915527, 0.0055542, ..., 0.00418091,\n",
       "             0.00909424, -0.0213623],\n",
       "            [0.0211182, 0.0119629, 0.00262451, ..., -0.00546265,\n",
       "             0.000679016, 0.0116577]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.0014801, -0.0143433, 0.00695801, ..., 0.012146, 0.00023365,\n",
       "            0.0136719],\n",
       "           [0.00289917, 0.0139771, 0.00445557, ..., -0.0205078,\n",
       "            -0.000701904, 0.0143433],\n",
       "           [-0.00491333, 0.00331116, -0.00842285, ..., -0.00366211,\n",
       "            -0.00939941, 0.000350952],\n",
       "           ...,\n",
       "           [0.0181885, -0.00546265, -0.0146484, ..., 0.00830078,\n",
       "            -0.00576782, -0.000362396],\n",
       "           [0.00364685, 0.00326538, 0.0132446, ..., -0.00183868,\n",
       "            0.00262451, 0.00878906],\n",
       "           [0.00830078, 0.00946045, -0.000115395, ..., 0.00213623,\n",
       "            -0.0119019, 0.0100098]],\n",
       "   \n",
       "          [[0.00500488, -0.00418091, 0.00485229, ..., 0.0114136,\n",
       "            2.67029e-05, 0.00567627],\n",
       "           [0.00346375, -0.00171661, -0.0170898, ..., -0.00897217,\n",
       "            0.0159912, 0.00927734],\n",
       "           [0.000652313, -0.00653076, -0.00534058, ..., -0.00982666,\n",
       "            0.0112305, 0.00402832],\n",
       "           ...,\n",
       "           [-0.00552368, -0.00457764, 0.0168457, ..., 0.0150146,\n",
       "            -0.00671387, -0.0106812],\n",
       "           [0.00436401, 0.0136108, 0.00341797, ..., 0.0038147, 0.00561523,\n",
       "            -0.00891113],\n",
       "           [-0.000225067, -0.000610352, -0.0218506, ..., 0.00540161,\n",
       "            -0.020874, 0.006073]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.0088501, -0.000556946, -0.000946045, ..., -0.0131226,\n",
       "           0.0123901, -0.0098877],\n",
       "          [-0.00291443, -0.00637817, 0.000459671, ..., -0.0131226,\n",
       "           0.0115967, -0.000145912],\n",
       "          [0.00283813, -0.0108643, -0.00254822, ..., 0.0130005, 0.0150146,\n",
       "           -0.0141602],\n",
       "          ...,\n",
       "          [0.0125732, -0.0057373, -0.00263977, ..., 0.0128784, -0.0127563,\n",
       "           0.00408936],\n",
       "          [0.00213623, 0.0135498, 0.00668335, ..., 0.00769043, 0.00402832,\n",
       "           -0.0148315],\n",
       "          [0.00242615, 0.0039978, -0.0019989, ..., -0.0148926, -0.000553131,\n",
       "           0.00582886]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([-0.166992, -0.209961, -0.139648, ..., -0.363281, -0.0634766,\n",
       "          -0.261719], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.361328, 0.380859, 0.306641, ..., 0.0698242, 0.480469, 0.386719],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.617188, 0.453125, 0.699219, ..., 0.785156, 0.363281, 0.527344],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.859375, 0.824219, 0.894531, ..., 1.19531, 0.0356445, 0.714844],      dtype=bfloat16)}},\n",
       " 'layer_4': {'attn': {'attn_vec_einsum': {'w': Array([[[0.00259399, 0.0158691, -0.00891113, ..., -0.00567627,\n",
       "             -0.00279236, 0.0189209],\n",
       "            [-0.0251465, 0.00376892, 0.00233459, ..., 0.0015564,\n",
       "             -0.00531006, 0.0140991],\n",
       "            [-0.00817871, -0.00141907, -0.00140381, ..., -0.00107574,\n",
       "             0.000276566, 0.00308228],\n",
       "            ...,\n",
       "            [-0.00946045, 0.0183105, 0.0145874, ..., -0.00793457,\n",
       "             -0.0045166, -0.0289307],\n",
       "            [0.00836182, 0.00315857, 0.00286865, ..., -0.00561523,\n",
       "             -0.000976562, 0.00254822],\n",
       "            [0.00964355, 0.00242615, 0.00306702, ..., 0.000713348,\n",
       "             -0.00386047, -0.0183105]],\n",
       "    \n",
       "           [[-0.0107422, -0.00476074, -0.00515747, ..., -0.000923157,\n",
       "             0.00650024, -0.00674438],\n",
       "            [0.00689697, 0.00640869, 0.0037384, ..., 0.0120239, 0.00665283,\n",
       "             -0.00534058],\n",
       "            [-0.00921631, 0.0032959, 0.0114746, ..., 0.0233154, -0.006073,\n",
       "             0.00537109],\n",
       "            ...,\n",
       "            [0.00970459, 0.0273438, 0.006073, ..., 0.00692749, 0.0213623,\n",
       "             0.00656128],\n",
       "            [0.0166016, -0.0107422, 2.22921e-05, ..., -0.000862122,\n",
       "             -0.00686646, 0.00297546],\n",
       "            [-0.00558472, 0.0234375, 0.000579834, ..., 0.00171661,\n",
       "             -0.0178223, 0.00527954]],\n",
       "    \n",
       "           [[-0.00524902, -0.00897217, 0.00915527, ..., -0.0203857,\n",
       "             0.000713348, -0.00167084],\n",
       "            [-0.00726318, -0.0115356, -0.00205994, ..., 0.00561523,\n",
       "             -0.00338745, -0.00274658],\n",
       "            [-0.0151978, -0.00263977, -0.00271606, ..., 0.00994873,\n",
       "             -0.00479126, 0.000193596],\n",
       "            ...,\n",
       "            [-0.0219727, 0.00765991, 0.0185547, ..., -0.00454712,\n",
       "             -0.00891113, 0.0050354],\n",
       "            [-0.00515747, 0.0117188, 0.0112305, ..., -0.00469971,\n",
       "             -0.00473022, 0.00476074],\n",
       "            [-0.00738525, -0.0126343, 0.0140381, ..., 0.00527954,\n",
       "             0.00415039, 0.010437]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00848389, 0.00230408, -0.00427246, ..., -0.0187988,\n",
       "             0.00479126, 0.00512695],\n",
       "            [0.000869751, -0.000356674, -0.0022583, ..., -0.00390625,\n",
       "             0.0217285, -0.00314331],\n",
       "            [0.0180664, 0.012085, -0.00994873, ..., -0.00198364,\n",
       "             -0.00473022, -0.0236816],\n",
       "            ...,\n",
       "            [-0.0109253, 0.0017395, 0.00257874, ..., -0.000326157,\n",
       "             0.00787354, -0.00485229],\n",
       "            [-0.00817871, -0.0114136, 0.0128174, ..., -0.00300598,\n",
       "             -0.0127563, -0.00247192],\n",
       "            [-0.00622559, 0.00296021, 0.00830078, ..., -0.00259399,\n",
       "             -0.0195312, -0.00257874]],\n",
       "    \n",
       "           [[-0.0088501, 0.00439453, 0.00109863, ..., -0.00389099,\n",
       "             0.00415039, 0.0015564],\n",
       "            [-0.00469971, -0.00787354, 0.000728607, ..., -0.00506592,\n",
       "             -0.0235596, -0.0172119],\n",
       "            [-0.0071106, -0.000896454, -0.00195312, ..., 0.00393677,\n",
       "             -0.00299072, -0.00306702],\n",
       "            ...,\n",
       "            [-0.00576782, 0.00157928, -0.0136719, ..., 0.0174561,\n",
       "             0.00188446, -0.00421143],\n",
       "            [0.000606537, 0.0179443, -0.0280762, ..., 0.0114746, -0.0163574,\n",
       "             0.00946045],\n",
       "            [-0.0030365, 0.0170898, -0.00104523, ..., 0.00564575,\n",
       "             -0.00933838, 0.0166016]],\n",
       "    \n",
       "           [[-0.00375366, 0.00228882, 0.0088501, ..., -0.0011673,\n",
       "             -0.000455856, -0.0112305],\n",
       "            [0.00704956, 0.0108032, -0.00799561, ..., -0.00300598,\n",
       "             -0.00087738, -0.00296021],\n",
       "            [-0.00259399, -0.0106812, 0.00335693, ..., -0.000976562,\n",
       "             -0.00357056, -0.00735474],\n",
       "            ...,\n",
       "            [0.00338745, 0.0151978, 0.00823975, ..., -0.00708008,\n",
       "             0.00762939, -0.00122833],\n",
       "            [-0.00732422, -0.00836182, 0.00149536, ..., -0.0163574,\n",
       "             -0.0137329, -0.00518799],\n",
       "            [0.00300598, -0.0148315, 0.022583, ..., -0.0148315, 0.0250244,\n",
       "             -0.00753784]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.00939941, 0.00136566, 0.0114746, ..., -0.00131989,\n",
       "              -0.00726318, 0.00236511],\n",
       "             [-0.000113964, -0.00466919, -0.00756836, ..., -0.0162354,\n",
       "              0.00113678, 0.00248718],\n",
       "             [-0.00157928, 0.00799561, -0.0139771, ..., -0.00202942,\n",
       "              -0.0205078, -0.0102539],\n",
       "             ...,\n",
       "             [-0.00772095, -0.0209961, -0.00387573, ..., 0.00436401,\n",
       "              0.00610352, -0.0155029],\n",
       "             [0.0269775, -0.0123901, -0.0132446, ..., -0.00939941,\n",
       "              -0.00387573, -0.0130005],\n",
       "             [-0.0102539, -0.0245361, 0.010376, ..., 0.0106812,\n",
       "              -0.00222778, -0.0220947]],\n",
       "    \n",
       "            [[0.00427246, -0.00297546, 0.000284195, ..., -0.0164795,\n",
       "              0.0147095, -0.0169678],\n",
       "             [0.00708008, 0.000326157, -0.00296021, ..., -0.0078125,\n",
       "              0.0285645, -0.00567627],\n",
       "             [0.00714111, -0.00285339, -0.0131226, ..., -0.00878906,\n",
       "              -0.0181885, -0.0358887],\n",
       "             ...,\n",
       "             [0.00701904, 0.0132446, -0.00848389, ..., -0.0172119,\n",
       "              -0.00656128, -0.02771],\n",
       "             [-0.0235596, -0.00169373, -0.029541, ..., -0.00421143,\n",
       "              0.0285645, 0.0106812],\n",
       "             [0.0241699, 0.0118408, 0.00540161, ..., -0.00848389,\n",
       "              -0.000816345, -0.0114746]],\n",
       "    \n",
       "            [[0.00921631, 0.00735474, 0.00297546, ..., -0.00454712,\n",
       "              0.013855, -0.0119629],\n",
       "             [0.00634766, 0.00854492, -0.0223389, ..., 0.00328064,\n",
       "              -0.0444336, -0.00576782],\n",
       "             [0.015564, 0.0126953, -0.00102997, ..., -0.0106201,\n",
       "              -0.00891113, 0.00964355],\n",
       "             ...,\n",
       "             [0.000644684, 0.00500488, 0.0090332, ..., 0.00204468,\n",
       "              -0.000149727, 0.015564],\n",
       "             [0.012146, -0.00964355, -0.0141602, ..., 0.0361328,\n",
       "              -0.00285339, 0.0216064],\n",
       "             [0.0126953, 0.0065918, -0.00704956, ..., -0.00598145,\n",
       "              -0.00836182, 0.0301514]],\n",
       "    \n",
       "            [[0.00500488, -0.00683594, -0.00662231, ..., -0.0178223,\n",
       "              -0.0124512, 0.00695801],\n",
       "             [0.00212097, -0.00646973, 0.00927734, ..., -0.00473022,\n",
       "              0.0125732, -0.0144043],\n",
       "             [0.00236511, -0.00379944, 0.00463867, ..., -0.000213623,\n",
       "              0.00933838, 0.0186768],\n",
       "             ...,\n",
       "             [0.0139771, -0.0111694, -0.00415039, ..., 0.0167236,\n",
       "              -0.00921631, -0.0220947],\n",
       "             [-0.0115967, 0.0123901, 5.05447e-05, ..., 0.00860596,\n",
       "              0.00415039, 0.00122833],\n",
       "             [0.00201416, -0.00209045, -0.00476074, ..., -0.0149536,\n",
       "              -0.012146, 0.0184326]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00970459, 0.0101318, 0.000556946, ..., -0.00817871,\n",
       "              0.0111694, 0.00524902],\n",
       "             [-0.0072937, -0.00494385, 0.0170898, ..., -0.00692749,\n",
       "              -0.00521851, 0.0223389],\n",
       "             [-0.000778198, 0.00830078, 0.00860596, ..., 0.0139771,\n",
       "              -0.0027771, -0.00408936],\n",
       "             ...,\n",
       "             [-0.00370789, -0.0100098, 0.00476074, ..., -0.0098877,\n",
       "              0.0151367, -0.00387573],\n",
       "             [0.0123901, 0.00588989, 0.00369263, ..., -0.00360107,\n",
       "              0.015625, -0.00848389],\n",
       "             [-0.00698853, -0.0175781, 0.0100708, ..., -0.0202637,\n",
       "              -0.00308228, 0.000930786]],\n",
       "    \n",
       "            [[0.0163574, 0.0027771, -0.00248718, ..., -0.0266113,\n",
       "              -0.00701904, 0.00130463],\n",
       "             [-0.0137329, -0.00830078, -0.0050354, ..., 0.0140381,\n",
       "              0.00588989, -0.00476074],\n",
       "             [0.0174561, 0.00613403, -0.0106812, ..., 0.0101318,\n",
       "              0.000637054, 0.00146484],\n",
       "             ...,\n",
       "             [-0.00686646, -0.0131226, 0.0206299, ..., 0.00854492,\n",
       "              0.00872803, 0.00114441],\n",
       "             [0.00171661, 0.00680542, 0.00201416, ..., 0.00579834,\n",
       "              0.00245667, 0.0124512],\n",
       "             [0.0172119, -0.0132446, -0.0018158, ..., 0.00662231,\n",
       "              0.00866699, 0.010498]],\n",
       "    \n",
       "            [[0.0113525, 0.00558472, -0.0164795, ..., 0.00239563,\n",
       "              0.00156403, 0.0133057],\n",
       "             [0.00123596, -0.00769043, -0.00939941, ..., 0.00671387,\n",
       "              0.0228271, 0.000862122],\n",
       "             [0.00376892, -0.00424194, 0.0123291, ..., -0.00732422,\n",
       "              -0.00964355, -0.0126953],\n",
       "             ...,\n",
       "             [0.0147705, 0.0200195, 0.0161133, ..., -0.00512695,\n",
       "              -0.00592041, 0.00668335],\n",
       "             [-0.000839233, -0.0235596, 0.00448608, ..., -0.000785828,\n",
       "              0.0132446, 0.0214844],\n",
       "             [-0.00674438, 0.000946045, 0.0134888, ..., 0.00643921,\n",
       "              -0.00341797, -0.000368118]],\n",
       "    \n",
       "            [[-0.0108032, 0.0145874, -0.00601196, ..., 0.00201416,\n",
       "              0.00698853, -0.00209045],\n",
       "             [-0.000904083, -0.0123901, 0.0114136, ..., 0.00156403,\n",
       "              -0.00543213, 0.0235596],\n",
       "             [-0.00193787, 0.00219727, 0.000652313, ..., 0.00878906,\n",
       "              -0.0302734, 0.00701904],\n",
       "             ...,\n",
       "             [0.0266113, 0.00964355, 0.0196533, ..., 0.0189209, 0.00836182,\n",
       "              -0.0032196],\n",
       "             [0.0135498, -0.0109863, -0.0170898, ..., -0.00714111,\n",
       "              -0.0102539, 0.00115967],\n",
       "             [-0.00613403, -0.00332642, 0.00341797, ..., 0.00946045,\n",
       "              0.0308838, 0.0206299]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.0043335, 0.0185547, -0.00393677, ..., -0.0256348,\n",
       "             -0.00582886, 0.0195312],\n",
       "            [-0.00364685, -0.0148315, 0.0123291, ..., -0.0136108,\n",
       "             -0.0288086, -0.0100708],\n",
       "            [0.00494385, -0.010437, 0.0137939, ..., 0.00765991, -0.0218506,\n",
       "             -0.020752],\n",
       "            ...,\n",
       "            [0.00156403, 0.0327148, -0.0163574, ..., -0.00198364, 0.0299072,\n",
       "             -0.00256348],\n",
       "            [0.0130005, -0.00213623, 0.00726318, ..., -0.00848389,\n",
       "             -0.0144653, 0.0162354],\n",
       "            [0.0037384, 0.0117798, -0.022583, ..., -0.0112305, -0.0169678,\n",
       "             -0.0161133]],\n",
       "    \n",
       "           [[0.0107422, -0.0129395, 0.00279236, ..., 0.00439453, 0.00292969,\n",
       "             -0.00132751],\n",
       "            [-0.000182152, -0.00315857, -0.00387573, ..., 0.0180664,\n",
       "             0.00765991, 0.0236816],\n",
       "            [-0.0122681, -0.00878906, -0.00262451, ..., -0.00285339,\n",
       "             -0.00436401, -0.0142822],\n",
       "            ...,\n",
       "            [0.0120239, 0.020752, 0.00601196, ..., -0.012146, 0.0167236,\n",
       "             -0.00358582],\n",
       "            [-0.00233459, -0.00964355, 0.000118732, ..., -0.00122833,\n",
       "             -0.00212097, 0.012207],\n",
       "            [0.0045166, -0.0022583, -0.0142212, ..., -0.00546265,\n",
       "             0.00646973, 0.0115967]],\n",
       "    \n",
       "           [[-0.0200195, -0.0130615, 0.00765991, ..., -0.00430298,\n",
       "             0.00405884, 0.003479],\n",
       "            [0.00543213, 0.00408936, -0.00787354, ..., -0.00126648,\n",
       "             -0.0169678, 0.000545502],\n",
       "            [0.010437, 0.00738525, -0.00179291, ..., 0.00872803, 0.017334,\n",
       "             0.00245667],\n",
       "            ...,\n",
       "            [0.00588989, -0.00909424, 0.00082016, ..., 0.00543213,\n",
       "             -0.0039978, 0.0119629],\n",
       "            [-0.00692749, 0.000991821, -0.0174561, ..., -0.00558472,\n",
       "             -0.00418091, -0.0111084],\n",
       "            [0.00187683, -0.00897217, 0.00866699, ..., 0.00878906,\n",
       "             -0.0108643, 0.0150146]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0045166, -0.00686646, -0.00793457, ..., -0.012207,\n",
       "             -0.012085, -0.00424194],\n",
       "            [-0.0144653, -0.0111084, -0.0123291, ..., 0.00799561,\n",
       "             -0.00811768, 0.0145874],\n",
       "            [0.0134277, -0.0249023, -0.00765991, ..., 0.000235558,\n",
       "             -0.00396729, -0.0125122],\n",
       "            ...,\n",
       "            [0.00209045, -0.0123291, -0.0098877, ..., 0.00823975, 0.0032196,\n",
       "             -0.000782013],\n",
       "            [-0.00695801, -0.0407715, -0.00469971, ..., -0.00811768,\n",
       "             -0.00195312, -0.000499725],\n",
       "            [0.00265503, 0.0014801, 0.00878906, ..., -0.00300598,\n",
       "             0.00418091, 0.0114746]],\n",
       "    \n",
       "           [[-0.00332642, -6.38962e-05, -0.0088501, ..., -0.0170898,\n",
       "             0.0112915, 0.0114746],\n",
       "            [-0.000312805, -0.00189209, 0.00439453, ..., -0.00515747,\n",
       "             -0.0018158, -0.0166016],\n",
       "            [-0.00848389, -0.0013504, 0.00717163, ..., 0.00276184,\n",
       "             -0.00337219, 0.00521851],\n",
       "            ...,\n",
       "            [-0.0111084, -0.0101929, 0.00671387, ..., 0.024292, 0.0230713,\n",
       "             -0.0166016],\n",
       "            [0.00497437, 0.00744629, 0.0045166, ..., -0.00564575, 0.010376,\n",
       "             -0.00650024],\n",
       "            [0.00744629, -0.00241089, 0.00848389, ..., 0.0151978,\n",
       "             -0.00622559, -0.00747681]],\n",
       "    \n",
       "           [[-0.00454712, 0.00248718, -0.0071106, ..., -0.0291748,\n",
       "             -0.00442505, 0.00436401],\n",
       "            [-0.00775146, 0.00442505, -0.00628662, ..., 9.58443e-05,\n",
       "             -0.00512695, -0.00512695],\n",
       "            [-0.00546265, -0.00830078, -0.000976562, ..., -0.00132751,\n",
       "             0.0251465, -0.00976562],\n",
       "            ...,\n",
       "            [0.00156403, -0.0123901, -0.00579834, ..., 0.010498, 0.0177002,\n",
       "             -0.00415039],\n",
       "            [-0.00668335, -0.00897217, -0.00811768, ..., -0.0115356,\n",
       "             -0.00331116, -0.017334],\n",
       "            [-0.00279236, 0.000486374, -0.0155029, ..., 0.0157471,\n",
       "             0.00500488, 0.00619507]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00686646, -0.00628662, 0.00628662, ..., 0.00848389,\n",
       "            -0.00756836, 0.010437],\n",
       "           [-0.00315857, -0.00463867, 0.000448227, ..., 0.00482178,\n",
       "            0.00245667, 0.00927734],\n",
       "           [-0.00408936, -0.0167236, -0.00994873, ..., 0.00382996,\n",
       "            -0.000411987, 0.00799561],\n",
       "           ...,\n",
       "           [0.00136566, 0.000133514, 0.00891113, ..., -0.00331116,\n",
       "            0.0016098, 0.00376892],\n",
       "           [0.00485229, 0.0161133, 0.00567627, ..., 0.000400543,\n",
       "            -0.00130463, 0.0108643],\n",
       "           [-2.32458e-05, 0.00163269, -0.00280762, ..., 0.0102539,\n",
       "            -0.00695801, -0.0032959]],\n",
       "   \n",
       "          [[0.00744629, 0.00872803, 0.0055542, ..., 0.00276184, -0.0142212,\n",
       "            -0.00976562],\n",
       "           [-0.00102997, 0.00312805, 0.000511169, ..., 0.00805664,\n",
       "            0.00634766, -0.00811768],\n",
       "           [-0.00787354, -0.000740051, -0.00221252, ..., 0.024292,\n",
       "            0.00418091, -0.0035553],\n",
       "           ...,\n",
       "           [-0.010498, 0.000972748, -0.00540161, ..., -0.000459671,\n",
       "            -0.00294495, -0.0112305],\n",
       "           [-0.00305176, 0.000495911, 0.00708008, ..., -0.0113525,\n",
       "            -0.00866699, 0.00848389],\n",
       "           [0.0144653, -0.00479126, -0.0032196, ..., 0.0043335, 0.00506592,\n",
       "            0.00811768]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.00891113, 0.00970459, -0.00151062, ..., -0.0108032,\n",
       "           -0.00360107, 0.00717163],\n",
       "          [-0.000900269, 0.00148773, -0.00619507, ..., -0.00320435,\n",
       "           -0.00695801, -0.00671387],\n",
       "          [0.00463867, -0.0111084, 0.00196838, ..., 0.0101318, 0.0045166,\n",
       "           -0.000709534],\n",
       "          ...,\n",
       "          [0.000488281, 0.00909424, 0.0111694, ..., 0.015625, -0.00994873,\n",
       "           0.0118408],\n",
       "          [6.19888e-05, 0.00524902, -0.00720215, ..., -0.00184631,\n",
       "           -0.00628662, 0.0113525],\n",
       "          [-0.0112915, -0.00358582, 0.00182343, ..., -0.0201416,\n",
       "           -0.00463867, 0.00230408]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([-0.193359, -0.28125, -0.21582, ..., -0.378906, -0.0407715,\n",
       "          -0.332031], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.285156, 0.245117, 0.246094, ..., 0.0476074, 0.613281, 0.271484],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.652344, 0.507812, 0.613281, ..., 0.824219, -0.0534668, 0.363281],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.554688, 0.570312, 0.554688, ..., 0.851562, 0.124512, 0.453125],      dtype=bfloat16)}},\n",
       " 'layer_5': {'attn': {'attn_vec_einsum': {'w': Array([[[0.00173187, 0.00221252, -0.00119781, ..., -0.00017643,\n",
       "             -0.00933838, 0.00221252],\n",
       "            [-0.00540161, -0.00692749, -0.0183105, ..., -0.00308228,\n",
       "             -0.0032959, -0.00570679],\n",
       "            [-0.00933838, 0.00866699, -0.000465393, ..., -0.00982666,\n",
       "             -0.00107574, 0.00363159],\n",
       "            ...,\n",
       "            [0.00193787, -0.00178528, 0.0117188, ..., 0.00375366,\n",
       "             -0.00518799, -0.00415039],\n",
       "            [-0.00576782, -0.00338745, -0.0158691, ..., -0.0135498,\n",
       "             0.00976562, -0.00182343],\n",
       "            [0.000747681, -0.00860596, 0.000545502, ..., -0.00326538,\n",
       "             -0.0212402, -0.00579834]],\n",
       "    \n",
       "           [[-0.00534058, -0.00289917, -0.0189209, ..., 0.0020752,\n",
       "             0.0131836, 0.00976562],\n",
       "            [-0.00469971, -0.0137939, -0.0229492, ..., 0.00193787,\n",
       "             0.00415039, 0.00671387],\n",
       "            [0.0344238, -0.000243187, 0.0314941, ..., -0.0183105, 0.0134888,\n",
       "             0.0180664],\n",
       "            ...,\n",
       "            [0.0354004, -0.00952148, 0.00732422, ..., -0.0162354,\n",
       "             0.00183105, -0.00830078],\n",
       "            [-0.00174713, -0.000307083, -0.0013504, ..., 0.0179443,\n",
       "             0.000797272, 0.000595093],\n",
       "            [-0.000766754, 0.0057373, -0.0108643, ..., -0.000553131,\n",
       "             -0.0149536, 0.00376892]],\n",
       "    \n",
       "           [[0.00842285, -0.0273438, 0.00836182, ..., -0.00683594,\n",
       "             -0.00805664, 0.0151978],\n",
       "            [-0.0118408, 0.0202637, -0.0159912, ..., -0.00872803,\n",
       "             -0.0179443, -0.00364685],\n",
       "            [-0.0184326, 0.0144043, -0.00927734, ..., -0.00448608,\n",
       "             0.00346375, -0.0117188],\n",
       "            ...,\n",
       "            [0.0155029, 0.00393677, 0.0115967, ..., -0.0118408, -0.00692749,\n",
       "             0.00178528],\n",
       "            [-0.00439453, 0.00367737, 0.0088501, ..., 0.0140381,\n",
       "             -0.00148773, -0.000299454],\n",
       "            [0.0133667, 0.00762939, -0.00396729, ..., -0.0166016,\n",
       "             0.00270081, -0.00576782]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00759888, 0.0351562, -0.0119019, ..., -0.0136108,\n",
       "             -0.0115967, 0.0172119],\n",
       "            [-0.0022583, -0.00366211, -0.00610352, ..., 0.0100708,\n",
       "             0.0134888, -0.0179443],\n",
       "            [0.0129395, -0.00616455, -0.0150146, ..., 0.012207,\n",
       "             -0.000759125, 0.019165],\n",
       "            ...,\n",
       "            [-0.00104523, 0.0145264, 0.0146484, ..., 0.00897217,\n",
       "             -0.00576782, -0.000854492],\n",
       "            [0.0246582, -0.00204468, -0.00952148, ..., -0.00546265,\n",
       "             0.00274658, 0.0162354],\n",
       "            [-0.00476074, -0.0153198, -0.0137329, ..., 0.00160217,\n",
       "             0.00506592, -0.015564]],\n",
       "    \n",
       "           [[0.0114746, 0.00726318, 0.0198975, ..., -0.0184326, -0.0179443,\n",
       "             -0.00289917],\n",
       "            [-0.017334, -0.00231934, -0.0245361, ..., -0.0219727,\n",
       "             0.00616455, 0.0105591],\n",
       "            [0.00280762, -0.00765991, -0.00469971, ..., 0.00756836,\n",
       "             -0.0167236, -0.0198975],\n",
       "            ...,\n",
       "            [0.00130463, 0.0314941, -0.000253677, ..., -0.00160217,\n",
       "             -0.00866699, 0.0194092],\n",
       "            [0.0158691, 0.00723267, -0.00616455, ..., 0.0130005, -0.0115356,\n",
       "             -0.00167847],\n",
       "            [0.00112915, 0.0167236, -0.0144653, ..., 0.0212402, 0.0101929,\n",
       "             0.0108643]],\n",
       "    \n",
       "           [[-0.0135498, -0.0130615, -0.0126953, ..., 0.013855, 0.00866699,\n",
       "             -0.00372314],\n",
       "            [0.0172119, 1.29342e-05, 0.0118408, ..., -0.0122681, -0.0240479,\n",
       "             0.00686646],\n",
       "            [0.0140991, 0.0159912, 0.00491333, ..., 0.00604248, -0.00994873,\n",
       "             0.00236511],\n",
       "            ...,\n",
       "            [-0.00335693, 0.0145874, -0.0151367, ..., 0.0286865, -0.0229492,\n",
       "             -0.0251465],\n",
       "            [-0.00512695, 0.0109253, 0.0216064, ..., -0.00128174,\n",
       "             0.00283813, -0.00165558],\n",
       "            [0.0284424, -0.0157471, 0.00872803, ..., 0.0169678, 0.00369263,\n",
       "             0.00970459]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.00860596, -0.0126343, 0.00297546, ..., 0.00340271,\n",
       "              -0.00137329, 0.00334167],\n",
       "             [-0.00430298, -0.00567627, -0.00491333, ..., -0.0122681,\n",
       "              0.00337219, 0.000347137],\n",
       "             [-0.0140991, -0.00665283, -0.00198364, ..., 0.0109253,\n",
       "              -0.00714111, 0.006073],\n",
       "             ...,\n",
       "             [-0.0101318, -0.00671387, -0.00842285, ..., 0.000900269,\n",
       "              0.00418091, -0.00418091],\n",
       "             [0.022583, 0.0211182, -0.0140991, ..., 0.00358582, 0.0268555,\n",
       "              0.00138855],\n",
       "             [-0.0133667, -0.0012207, 0.00952148, ..., -0.0161133,\n",
       "              -0.00601196, 0.00357056]],\n",
       "    \n",
       "            [[0.0012207, 0.00227356, 0.00137329, ..., -0.0351562,\n",
       "              0.0255127, -0.0220947],\n",
       "             [-0.000549316, -0.000705719, 0.00117493, ..., -0.0100098,\n",
       "              -0.0155029, 0.0195312],\n",
       "             [0.00415039, 0.00106049, 0.00126648, ..., -0.00640869,\n",
       "              0.0039978, -0.00793457],\n",
       "             ...,\n",
       "             [0.00294495, 0.00805664, -0.0062561, ..., -0.0118408,\n",
       "              0.00241089, -0.0131226],\n",
       "             [0.0167236, 0.00270081, 0.0108032, ..., 0.0128174, -0.0252686,\n",
       "              0.0184326],\n",
       "             [-0.00753784, 0.00411987, 0.000591278, ..., -0.0170898,\n",
       "              0.00872803, 0.0187988]],\n",
       "    \n",
       "            [[0.012085, 0.00817871, -0.00866699, ..., 0.00170135,\n",
       "              0.0213623, -0.0035553],\n",
       "             [-0.00878906, -0.0043335, 0.00552368, ..., -0.00405884,\n",
       "              -8.29697e-05, 0.00695801],\n",
       "             [-0.00811768, -0.0101318, 0.00128174, ..., -0.0178223,\n",
       "              -0.00112915, 0.00294495],\n",
       "             ...,\n",
       "             [0.0244141, -0.00762939, -0.0011673, ..., 0.00759888,\n",
       "              -0.0016098, 0.00430298],\n",
       "             [-0.0162354, 0.00500488, -0.0218506, ..., 0.0201416,\n",
       "              0.0267334, 0.0219727],\n",
       "             [-0.00427246, -0.00296021, -0.0103149, ..., -0.019043,\n",
       "              0.00570679, -0.00375366]],\n",
       "    \n",
       "            [[0.00288391, -0.00592041, -0.000976562, ..., -0.0136108,\n",
       "              0.000167847, 0.00439453],\n",
       "             [-0.000230789, -0.000923157, -0.0151978, ..., 0.00294495,\n",
       "              0.0174561, 0.00656128],\n",
       "             [0.0146484, -0.00610352, 0.00289917, ..., -0.000808716,\n",
       "              0.00411987, 0.02771],\n",
       "             ...,\n",
       "             [0.0115356, 0.00735474, 0.00369263, ..., 0.0088501, 0.0107422,\n",
       "              -0.0264893],\n",
       "             [0.00202942, 0.00195312, 0.00970459, ..., 0.0236816,\n",
       "              0.0164795, -0.00193024],\n",
       "             [0.017334, 0.00323486, 0.00567627, ..., -0.0324707, 0.0336914,\n",
       "              -0.0115356]]],\n",
       "    \n",
       "    \n",
       "           [[[0.00292969, 0.000740051, -0.0045166, ..., -0.0185547,\n",
       "              0.010437, -0.0174561],\n",
       "             [-0.00598145, 0.00741577, 0.00927734, ..., -0.00396729,\n",
       "              0.00491333, -0.00479126],\n",
       "             [0.0098877, -0.00224304, 0.00445557, ..., 0.00259399,\n",
       "              -0.0125732, 0.00830078],\n",
       "             ...,\n",
       "             [-0.00650024, -0.012085, -0.00346375, ..., 0.0240479,\n",
       "              -0.00349426, 0.0234375],\n",
       "             [-0.0187988, -0.00323486, -0.00285339, ..., -0.00457764,\n",
       "              0.00799561, 0.00228882],\n",
       "             [-0.00872803, 0.00909424, -0.0050354, ..., -9.25064e-05,\n",
       "              0.0194092, 0.0128784]],\n",
       "    \n",
       "            [[0.0167236, -0.0213623, -0.00457764, ..., 0.013916,\n",
       "              -0.00582886, -0.00069046],\n",
       "             [-0.00405884, -0.00823975, -0.00268555, ..., 0.0290527,\n",
       "              0.00854492, -0.00393677],\n",
       "             [-0.0136108, 0.000314713, 0.0187988, ..., -0.00323486,\n",
       "              -0.0119629, -0.027832],\n",
       "             ...,\n",
       "             [0.0179443, -0.0113525, 0.00358582, ..., -0.010437,\n",
       "              -0.00836182, -0.010437],\n",
       "             [-0.0130005, 0.003479, 0.0109863, ..., 0.0111084, 0.000774384,\n",
       "              -0.00424194],\n",
       "             [0.00140381, 0.00811768, -0.00088501, ..., 0.00723267,\n",
       "              -0.0134277, 0.00144958]],\n",
       "    \n",
       "            [[-0.0235596, -0.0134888, 0.020874, ..., 0.0102539, 0.0120239,\n",
       "              -0.0088501],\n",
       "             [0.0290527, 0.0025177, -0.00473022, ..., -0.00842285,\n",
       "              -0.00817871, -0.00637817],\n",
       "             [-0.00328064, -0.00946045, -0.0269775, ..., 0.00204468,\n",
       "              0.0057373, -0.00421143],\n",
       "             ...,\n",
       "             [-0.0308838, 0.00473022, -0.012146, ..., 0.013916, 0.00201416,\n",
       "              0.00842285],\n",
       "             [-0.00043869, 0.00289917, 0.000801086, ..., -0.00311279,\n",
       "              -0.00540161, -0.010437],\n",
       "             [0.00063324, -0.010498, -0.000637054, ..., 0.00488281,\n",
       "              -0.00823975, 0.0158691]],\n",
       "    \n",
       "            [[0.0120239, -0.00735474, 0.0050354, ..., -0.00439453,\n",
       "              0.0111084, -0.000492096],\n",
       "             [0.0117798, 0.010498, 0.00192261, ..., -0.0230713, -0.019165,\n",
       "              -0.0107422],\n",
       "             [-0.00994873, 0.0102539, 0.0114746, ..., 0.0283203, 0.0162354,\n",
       "              -0.00262451],\n",
       "             ...,\n",
       "             [-0.000835419, 0.0152588, 0.0167236, ..., 0.00222778,\n",
       "              0.0101318, -0.00183105],\n",
       "             [0.00762939, 0.00259399, -0.00683594, ..., -0.0123901,\n",
       "              0.00756836, -0.00622559],\n",
       "             [0.0195312, 0.0118408, 0.0289307, ..., -0.0236816, -0.010376,\n",
       "              -0.0157471]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.0055542, -0.00805664, 0.000514984, ..., 0.00656128,\n",
       "             0.00552368, 0.00491333],\n",
       "            [0.0116577, 0.000495911, 0.0125122, ..., -0.00646973,\n",
       "             0.00325012, -0.00114441],\n",
       "            [-0.0297852, -0.0129395, 0.00775146, ..., 0.0032196, 0.0133057,\n",
       "             0.00811768],\n",
       "            ...,\n",
       "            [-0.0107422, -0.00308228, 0.0147095, ..., 0.000801086,\n",
       "             0.000576019, -0.00631714],\n",
       "            [0.00799561, 0.0065918, -0.00473022, ..., 0.00570679,\n",
       "             -0.0192871, 0.00202942],\n",
       "            [-0.0062561, 0.00427246, 0.00332642, ..., -0.0118408,\n",
       "             0.00765991, 0.00872803]],\n",
       "    \n",
       "           [[-0.00357056, 0.00469971, -0.00646973, ..., 0.012085,\n",
       "             0.00153351, 0.0211182],\n",
       "            [-0.00518799, 0.00328064, 0.0220947, ..., 0.00732422,\n",
       "             0.000648499, -0.0126343],\n",
       "            [-0.00137329, -0.00276184, 0.00735474, ..., -0.0112305,\n",
       "             0.00178528, -0.00915527],\n",
       "            ...,\n",
       "            [-0.0233154, 0.00933838, 0.0290527, ..., -0.0140991, 0.00222778,\n",
       "             -0.0236816],\n",
       "            [-0.00177765, 0.00328064, -0.0062561, ..., 0.00427246,\n",
       "             -0.0168457, 0.00653076],\n",
       "            [-0.00212097, -0.0100708, -0.0134277, ..., -0.00500488,\n",
       "             0.00741577, -0.000255585]],\n",
       "    \n",
       "           [[0.00177765, 0.00735474, 0.00424194, ..., -0.012207, 0.022583,\n",
       "             -0.0253906],\n",
       "            [-0.00720215, -0.0100098, -0.0150757, ..., -0.0375977,\n",
       "             -0.0050354, 0.0361328],\n",
       "            [-0.00714111, -0.0100708, 0.000379562, ..., -0.013916,\n",
       "             -0.00753784, -0.0101929],\n",
       "            ...,\n",
       "            [0.00927734, 0.0134888, 0.0196533, ..., 0.00512695, -0.00296021,\n",
       "             -0.0109863],\n",
       "            [-0.00405884, -0.00479126, -0.00147247, ..., -0.00363159,\n",
       "             0.00122833, 0.0177002],\n",
       "            [-0.00430298, 0.000303268, -0.00799561, ..., -0.0166016,\n",
       "             0.0250244, 0.0133667]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00171661, 0.00564575, 0.00317383, ..., -0.0098877,\n",
       "             -0.0019989, -0.00119019],\n",
       "            [-0.012146, -0.00265503, -0.0108643, ..., -0.003479,\n",
       "             -0.00534058, -0.00561523],\n",
       "            [0.0170898, -0.0218506, 0.0147095, ..., -0.00390625,\n",
       "             -0.00216675, 0.00521851],\n",
       "            ...,\n",
       "            [-0.00567627, 0.00378418, -0.00408936, ..., -0.00982666,\n",
       "             -0.0147705, -0.000123024],\n",
       "            [-0.00126648, -0.00174713, 0.00787354, ..., 0.00285339,\n",
       "             0.00145721, -0.00379944],\n",
       "            [0.00720215, 0.00585938, -0.000553131, ..., 0.00549316,\n",
       "             0.00799561, 0.00753784]],\n",
       "    \n",
       "           [[-0.00219727, 0.00297546, 0.000383377, ..., -0.00288391,\n",
       "             -0.00552368, -0.00463867],\n",
       "            [0.00909424, -0.0147095, 0.00230408, ..., -0.00222778,\n",
       "             0.00384521, -0.00613403],\n",
       "            [0.00328064, -0.00509644, 0.00169373, ..., -0.00756836,\n",
       "             0.0108643, -0.0163574],\n",
       "            ...,\n",
       "            [-0.00186157, 0.000797272, 0.0109253, ..., -0.00946045,\n",
       "             -0.0292969, 0.0361328],\n",
       "            [-0.0198975, 0.00466919, -0.00646973, ..., 0.0102539,\n",
       "             -0.00878906, -0.000865936],\n",
       "            [0.00254822, 9.9659e-05, 0.000142097, ..., -0.00396729,\n",
       "             -0.02771, 0.0216064]],\n",
       "    \n",
       "           [[-0.00662231, 0.00915527, 0.00976562, ..., -0.00753784,\n",
       "             -0.00247192, -0.00189972],\n",
       "            [0.00457764, 0.0137939, 0.0172119, ..., -0.00114441,\n",
       "             -0.000972748, 0.000953674],\n",
       "            [-0.00309753, -0.0206299, -0.00161743, ..., -0.0111084,\n",
       "             0.00375366, 0.00372314],\n",
       "            ...,\n",
       "            [0.00430298, -0.00370789, 0.00183868, ..., 0.000461578,\n",
       "             0.00300598, -0.00708008],\n",
       "            [0.00195312, 0.00753784, -0.0101318, ..., 0.00787354,\n",
       "             0.00823975, 0.00479126],\n",
       "            [-0.00878906, 0.00364685, 0.00169373, ..., 0.000904083,\n",
       "             7.00951e-05, -0.00482178]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.00107574, 0.00662231, -0.00872803, ..., 0.00561523,\n",
       "            0.00909424, 0.00312805],\n",
       "           [0.00601196, 0.00418091, 0.0105591, ..., 0.00534058, 0.013855,\n",
       "            0.00239563],\n",
       "           [0.00866699, -0.00952148, 0.000545502, ..., -0.00732422,\n",
       "            0.0146484, 0.00436401],\n",
       "           ...,\n",
       "           [-0.00112152, -0.00421143, 0.00994873, ..., -0.00723267,\n",
       "            -0.0111694, -0.00160217],\n",
       "           [0.0150146, 0.00436401, -0.0100098, ..., -0.00787354,\n",
       "            -0.00469971, 0.0131836],\n",
       "           [-0.000587463, 0.00497437, 0.0137329, ..., 0.00494385,\n",
       "            -0.000392914, -0.0118408]],\n",
       "   \n",
       "          [[0.000370026, -0.0118408, 0.0289307, ..., -0.0141602,\n",
       "            -0.00805664, 0.00604248],\n",
       "           [-0.001297, 0.000196457, -0.0127563, ..., 0.00222778, -0.013916,\n",
       "            -0.000614166],\n",
       "           [-0.00506592, 0.0108032, 0.00958252, ..., -0.00375366,\n",
       "            -0.00933838, -0.00294495],\n",
       "           ...,\n",
       "           [-0.0038147, -0.010376, -0.0035553, ..., 0.0106812, 0.00361633,\n",
       "            0.00717163],\n",
       "           [0.0043335, -0.000686646, 0.0147095, ..., -0.000180244,\n",
       "            0.0072937, 0.00282288],\n",
       "           [0.0012207, 0.0111694, -0.00491333, ..., -0.00860596,\n",
       "            -0.00909424, 0.00283813]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.00415039, -0.00134277, -0.00189972, ..., -0.00366211,\n",
       "           -0.00107574, 0.0043335],\n",
       "          [-0.00744629, 0.00726318, 0.00897217, ..., -0.00308228,\n",
       "           0.000663757, 0.00537109],\n",
       "          [0.0150757, -0.0078125, -0.00244141, ..., -0.00817871,\n",
       "           -0.00775146, -0.00631714],\n",
       "          ...,\n",
       "          [-0.00402832, -0.0148926, -0.0030365, ..., 0.00756836, -0.0161133,\n",
       "           -0.00457764],\n",
       "          [-0.00692749, -0.00289917, -0.0108032, ..., 0.00891113,\n",
       "           -0.00732422, -0.00613403],\n",
       "          [0.0161133, -0.00332642, 0.00631714, ..., 0.00497437, 0.00384521,\n",
       "           -0.00491333]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.0136108, -0.150391, -0.020874, ..., -0.355469, -0.0186768,\n",
       "          -0.425781], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.0888672, 0.0622559, 0.12793, ..., -0.00866699, 0.337891,\n",
       "          0.0756836], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.490234, 0.255859, 0.330078, ..., 0.367188, -0.0544434, 0.046875],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.388672, 0.382812, 0.402344, ..., 0.597656, -0.0415039, 0.236328],      dtype=bfloat16)}},\n",
       " 'layer_6': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.0103149, 0.000452042, -0.0153809, ..., -0.00915527,\n",
       "             0.0106201, 0.00836182],\n",
       "            [-0.00848389, 0.0072937, 0.000648499, ..., -0.00823975,\n",
       "             0.010437, 0.0090332],\n",
       "            [0.00927734, -0.00402832, -0.00141907, ..., -0.00317383,\n",
       "             0.0161133, 0.00418091],\n",
       "            ...,\n",
       "            [0.0145874, 0.0222168, 0.00640869, ..., 0.00817871, -0.0137329,\n",
       "             -0.0114746],\n",
       "            [-0.00668335, 0.00195312, 0.00424194, ..., -0.00133514,\n",
       "             0.000226974, 0.0030365],\n",
       "            [-0.00195312, 0.00558472, -0.020752, ..., 0.00830078,\n",
       "             -0.0014801, 0.00341797]],\n",
       "    \n",
       "           [[-0.00139618, 0.000881195, -0.0119019, ..., 0.0112305,\n",
       "             -0.00799561, -0.0140381],\n",
       "            [0.0164795, -0.0131226, 0.00582886, ..., 0.000228882,\n",
       "             -0.00772095, -0.00708008],\n",
       "            [0.00170135, 0.00753784, -0.00842285, ..., 0.00558472,\n",
       "             0.00601196, -0.00221252],\n",
       "            ...,\n",
       "            [-0.00509644, 0.00665283, 0.0127563, ..., -0.00933838,\n",
       "             0.0127563, -0.000141144],\n",
       "            [-0.0123901, -0.0179443, 0.0045166, ..., -0.00765991,\n",
       "             0.00133514, 0.00390625],\n",
       "            [0.00202942, -0.00221252, 0.00424194, ..., 0.00567627,\n",
       "             -0.00515747, 0.0050354]],\n",
       "    \n",
       "           [[0.000213623, 0.000831604, -0.00720215, ..., -0.00933838,\n",
       "             0.00186157, -0.00527954],\n",
       "            [0.0113525, 0.00405884, -0.00585938, ..., -0.00253296,\n",
       "             0.00497437, 0.0174561],\n",
       "            [0.00136566, 0.00189972, 0.00570679, ..., -0.00704956,\n",
       "             0.00174713, -0.00358582],\n",
       "            ...,\n",
       "            [0.0130005, 3.40939e-05, 0.0153198, ..., 0.00112915,\n",
       "             -0.00247192, -0.0131226],\n",
       "            [-0.00646973, -0.0108643, 0.00628662, ..., 0.00312805,\n",
       "             0.00244141, -0.00848389],\n",
       "            [-0.00915527, 0.00836182, 0.000206947, ..., -0.013916,\n",
       "             -0.0111694, -0.00512695]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.000766754, 0.00285339, -0.0065918, ..., -0.0184326,\n",
       "             -0.00286865, 0.00170898],\n",
       "            [-0.000185966, -0.0106201, 0.0113525, ..., 0.00747681,\n",
       "             -0.0127563, 0.0106812],\n",
       "            [0.0137329, -0.00848389, -0.00120544, ..., 0.00320435,\n",
       "             0.00723267, 0.00897217],\n",
       "            ...,\n",
       "            [0.00897217, -0.00102997, -0.0257568, ..., -0.00686646,\n",
       "             -0.00753784, 0.0133057],\n",
       "            [0.00848389, -0.00141907, 0.0270996, ..., 0.00219727, 0.0145874,\n",
       "             0.000261307],\n",
       "            [0.000204086, -0.00363159, -0.0090332, ..., -0.00198364,\n",
       "             0.00509644, -0.0154419]],\n",
       "    \n",
       "           [[0.00147247, -0.00531006, -0.00402832, ..., -0.00970459,\n",
       "             -0.00613403, 0.0113525],\n",
       "            [-0.000453949, 0.026001, -0.00872803, ..., -0.00136566,\n",
       "             -0.000320435, -0.000239372],\n",
       "            [-0.0256348, 0.00075531, -0.017334, ..., 0.00897217, -0.0238037,\n",
       "             0.0200195],\n",
       "            ...,\n",
       "            [-0.00592041, -0.00314331, -0.00317383, ..., -0.0189209,\n",
       "             -0.00540161, -0.0119629],\n",
       "            [-0.0131226, 0.0118408, -0.0125122, ..., 0.00273132, 0.00506592,\n",
       "             -0.00811768],\n",
       "            [0.0192871, 0.00479126, -0.0145874, ..., 0.0119629, 0.00408936,\n",
       "             0.0240479]],\n",
       "    \n",
       "           [[0.0143433, 0.0111084, 0.0145874, ..., 0.0169678, 0.00964355,\n",
       "             -0.0144653],\n",
       "            [-0.00552368, -0.020752, -0.00296021, ..., 0.000173569,\n",
       "             0.00692749, -0.00939941],\n",
       "            [0.00643921, 0.00335693, 0.0230713, ..., 0.00567627, 0.00473022,\n",
       "             -0.0140381],\n",
       "            ...,\n",
       "            [0.0194092, -0.0213623, -0.00799561, ..., -0.00506592,\n",
       "             -0.0227051, 0.0147705],\n",
       "            [0.00509644, 0.000545502, 0.00180054, ..., -0.000682831,\n",
       "             -0.0162354, 0.00823975],\n",
       "            [-0.0132446, -0.0142212, 0.00799561, ..., -0.0128784,\n",
       "             -0.00352478, 0.00427246]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.000455856, 0.0103149, 0.00732422, ..., -0.000148773,\n",
       "              0.00927734, -0.00491333],\n",
       "             [0.00102997, 0.0098877, -0.00289917, ..., -0.0123901,\n",
       "              0.0214844, -0.0014801],\n",
       "             [-0.00241089, -0.00753784, 0.00866699, ..., -0.0126953,\n",
       "              -0.00445557, -0.00531006],\n",
       "             ...,\n",
       "             [-0.0113525, -0.00476074, 0.00805664, ..., -0.00701904,\n",
       "              0.00149536, -0.0150757],\n",
       "             [0.00291443, -0.00144196, -0.00248718, ..., -0.0127563,\n",
       "              0.00787354, 0.00860596],\n",
       "             [-0.00491333, -0.0284424, -0.00473022, ..., -0.0027771,\n",
       "              0.0148926, -0.036377]],\n",
       "    \n",
       "            [[-0.000293732, 0.0032959, -0.00772095, ..., 0.00653076,\n",
       "              0.0252686, -0.0090332],\n",
       "             [0.00537109, -0.00390625, -0.0071106, ..., -0.0101318,\n",
       "              0.0175781, 0.0109253],\n",
       "             [0.00364685, -0.00331116, -0.00143433, ..., 0.00521851,\n",
       "              -0.0212402, 0.0103149],\n",
       "             ...,\n",
       "             [-0.00209045, -0.000530243, -0.00294495, ..., -2.36034e-05,\n",
       "              0.0162354, -0.019043],\n",
       "             [-0.00506592, -0.00823975, 0.00640869, ..., -0.0103149,\n",
       "              -0.00860596, 0.0249023],\n",
       "             [-0.00546265, 0.00424194, 0.0067749, ..., -0.00125885,\n",
       "              0.00708008, -0.0262451]],\n",
       "    \n",
       "            [[0.0105591, 0.00686646, -0.00466919, ..., 0.00305176,\n",
       "              0.00189972, -0.0249023],\n",
       "             [-0.0205078, 0.00360107, -0.00245667, ..., -0.00592041,\n",
       "              -0.00291443, -0.0115356],\n",
       "             [0.00370789, 0.00735474, -0.001297, ..., -0.0100098,\n",
       "              -0.0131226, 0.0205078],\n",
       "             ...,\n",
       "             [-0.00982666, -0.0019455, -0.010437, ..., 0.0102539,\n",
       "              -0.00343323, 0.00436401],\n",
       "             [0.00732422, 0.00485229, -0.00686646, ..., -0.0137939,\n",
       "              -0.0257568, 0.0151978],\n",
       "             [0.0071106, -1.80006e-05, 0.00952148, ..., -0.012085,\n",
       "              -0.0131836, 0.0078125]],\n",
       "    \n",
       "            [[-0.0126343, 0.00325012, 0.0142212, ..., 0.00141144,\n",
       "              0.00305176, -0.00305176],\n",
       "             [0.00169373, 0.00543213, -0.00280762, ..., -0.00227356,\n",
       "              0.0112915, -0.0206299],\n",
       "             [0.000404358, 0.00021553, -0.0057373, ..., -0.0122681,\n",
       "              -0.00689697, 0.00460815],\n",
       "             ...,\n",
       "             [0.0126953, -0.00762939, -0.00289917, ..., 0.0013504,\n",
       "              0.00952148, 0.00028801],\n",
       "             [-0.00933838, 0.000434875, 0.00897217, ..., -0.0016861,\n",
       "              -0.00872803, -0.00689697],\n",
       "             [-0.00769043, 0.00216675, 0.0039978, ..., -0.00732422,\n",
       "              0.0101929, -0.00488281]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0169678, 0.0133057, -0.00382996, ..., -0.0045166,\n",
       "              0.00396729, -0.00375366],\n",
       "             [0.00306702, -0.0106201, 0.00506592, ..., -0.0151978,\n",
       "              -0.0195312, -0.0144043],\n",
       "             [0.00933838, -0.00732422, 0.00561523, ..., -0.00769043,\n",
       "              0.00219727, 0.0233154],\n",
       "             ...,\n",
       "             [0.00150299, 0.00390625, 0.00485229, ..., -0.0098877,\n",
       "              -0.0010376, -0.00692749],\n",
       "             [-0.00137329, -0.00047493, -0.00680542, ..., 0.0151367,\n",
       "              -0.0136719, -0.00270081],\n",
       "             [-7.43866e-05, -0.0111084, -0.00136566, ..., 0.0130005,\n",
       "              -0.0016861, -0.00521851]],\n",
       "    \n",
       "            [[0.000530243, -0.00982666, -0.00209045, ..., 0.0055542,\n",
       "              0.00958252, -0.0108643],\n",
       "             [0.00952148, -4.86374e-05, 0.0100098, ..., 0.0111084,\n",
       "              -0.012085, 0.0124512],\n",
       "             [0.00178528, 0.00854492, -0.00309753, ..., 0.00680542,\n",
       "              -0.00193787, 0.000576019],\n",
       "             ...,\n",
       "             [-0.0231934, 0.0222168, -0.0140991, ..., -0.0112915,\n",
       "              0.0137329, -0.0142212],\n",
       "             [0.00014782, 0.00350952, 0.0011673, ..., 0.000656128,\n",
       "              -0.00540161, -0.00939941],\n",
       "             [0.0119019, -0.00411987, -0.0139771, ..., 0.00338745,\n",
       "              0.00595093, 0.00124359]],\n",
       "    \n",
       "            [[-0.00436401, 0.00735474, -0.00476074, ..., 0.0153198,\n",
       "              0.00787354, -0.00982666],\n",
       "             [-0.000188828, -0.0385742, 0.00534058, ..., -0.010498,\n",
       "              -0.00671387, 0.00643921],\n",
       "             [-0.00759888, 0.0118408, 0.0224609, ..., 0.0130005,\n",
       "              -0.0131226, -0.00038147],\n",
       "             ...,\n",
       "             [0.0158691, 0.0115967, 0.0100098, ..., 0.0170898, -0.00476074,\n",
       "              -0.00415039],\n",
       "             [0.0122681, 0.00233459, -0.0057373, ..., 0.00326538,\n",
       "              -0.0027771, -0.0107422],\n",
       "             [-0.0118408, 0.00346375, 0.000219345, ..., 0.0126953,\n",
       "              -0.00338745, 0.0299072]],\n",
       "    \n",
       "            [[0.00305176, 0.00279236, 0.0185547, ..., 0.0025177,\n",
       "              0.00601196, -0.020752],\n",
       "             [0.00424194, -0.0354004, 0.0198975, ..., 0.00689697,\n",
       "              -0.00350952, 0.00238037],\n",
       "             [0.0114746, -0.0184326, 0.034668, ..., 0.00744629, 0.0227051,\n",
       "              0.0137329],\n",
       "             ...,\n",
       "             [0.00567627, 0.010437, 0.00114441, ..., 0.0100098, 0.0133057,\n",
       "              -0.0177002],\n",
       "             [0.00537109, -0.000709534, 0.0102539, ..., 0.00421143,\n",
       "              -0.00830078, -0.0122681],\n",
       "             [-0.0134888, 0.0140381, -0.0150146, ..., 0.00601196,\n",
       "              0.0192871, -0.0090332]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.0222168, -0.0038147, -0.00323486, ..., 0.00360107,\n",
       "             0.0177002, 0.00436401],\n",
       "            [-0.0290527, -0.00921631, 0.0100708, ..., -0.0203857,\n",
       "             0.00300598, -0.00132751],\n",
       "            [0.00343323, 0.00311279, 0.000858307, ..., -0.0071106,\n",
       "             -0.00448608, 0.00787354],\n",
       "            ...,\n",
       "            [0.00173187, -0.0106201, -0.00485229, ..., 0.00546265,\n",
       "             0.0050354, -0.000135422],\n",
       "            [0.00382996, 0.0151978, 0.00439453, ..., -0.00369263,\n",
       "             -0.00946045, -0.0043335],\n",
       "            [-0.0130615, -0.00692749, -0.00402832, ..., -0.00271606,\n",
       "             0.0134888, -0.013855]],\n",
       "    \n",
       "           [[-0.00326538, -0.00286865, -0.0071106, ..., 0.00704956,\n",
       "             0.0125732, 0.00878906],\n",
       "            [-0.00976562, -0.00282288, -0.00113678, ..., 0.00485229,\n",
       "             0.000238419, 0.00750732],\n",
       "            [0.00150299, -0.00927734, -0.0057373, ..., -0.022583,\n",
       "             -0.000999451, -0.0102539],\n",
       "            ...,\n",
       "            [0.00182343, -0.00138855, -0.00921631, ..., -0.00469971,\n",
       "             0.00531006, 0.0137939],\n",
       "            [-0.00933838, 0.00244141, 0.00227356, ..., 0.000919342,\n",
       "             -0.0133057, -0.0200195],\n",
       "            [-0.0038147, 0.0150757, -0.00109863, ..., -0.03125, -0.022583,\n",
       "             -0.029541]],\n",
       "    \n",
       "           [[0.00747681, -0.00485229, -0.00646973, ..., 0.00224304,\n",
       "             0.010376, -0.00799561],\n",
       "            [0.000141144, 0.00921631, -0.000892639, ..., 0.000322342,\n",
       "             -0.00308228, 0.00210571],\n",
       "            [-0.00686646, 0.00305176, 0.00552368, ..., 0.000675201,\n",
       "             0.00379944, -0.00427246],\n",
       "            ...,\n",
       "            [-0.00643921, 0.00442505, 0.00175476, ..., 0.000134468,\n",
       "             0.0045166, -0.00793457],\n",
       "            [0.00300598, -0.00616455, 0.00460815, ..., 0.000312805,\n",
       "             0.00302124, -0.0101318],\n",
       "            [0.00976562, 0.00756836, -0.00260925, ..., -0.00376892,\n",
       "             -0.00364685, 0.00260925]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00341797, -0.0178223, -0.00263977, ..., -0.0050354,\n",
       "             -0.00256348, -0.00253296],\n",
       "            [0.00524902, 0.0103149, 0.0269775, ..., 0.00267029, -0.00753784,\n",
       "             -0.00415039],\n",
       "            [-0.0119019, -0.00469971, -0.00793457, ..., 0.00915527,\n",
       "             0.00854492, 0.00762939],\n",
       "            ...,\n",
       "            [-0.00439453, 0.0129395, -0.00427246, ..., -0.00674438,\n",
       "             0.00775146, 0.00909424],\n",
       "            [0.00515747, 0.0032196, 0.0117798, ..., 0.0170898, -0.00352478,\n",
       "             -0.0050354],\n",
       "            [-0.00500488, -0.00717163, -0.00297546, ..., -0.0203857,\n",
       "             -0.0115967, 0.0153198]],\n",
       "    \n",
       "           [[0.0142212, -0.00180817, 0.0267334, ..., 0.00585938,\n",
       "             3.86238e-05, -0.00527954],\n",
       "            [0.0144043, 0.00242615, -0.0022583, ..., -0.0164795, 0.00509644,\n",
       "             -0.000171661],\n",
       "            [0.0071106, -0.00224304, 0.00415039, ..., -0.019165, -0.0152588,\n",
       "             0.0122681],\n",
       "            ...,\n",
       "            [0.0212402, 0.0167236, -0.0139771, ..., 0.00204468, 0.00564575,\n",
       "             -0.012207],\n",
       "            [-0.00286865, 0.00202942, 0.00476074, ..., -0.0131836,\n",
       "             8.53539e-05, -0.00136566],\n",
       "            [-0.0130005, 0.00653076, -0.00497437, ..., -0.0153809,\n",
       "             -0.0105591, -0.000511169]],\n",
       "    \n",
       "           [[0.00946045, 0.0224609, 0.00149536, ..., 0.00680542,\n",
       "             -0.00233459, -0.000579834],\n",
       "            [0.00564575, -0.00680542, 0.0214844, ..., -0.00314331,\n",
       "             0.0267334, 0.00921631],\n",
       "            [-0.00897217, 0.00701904, 0.00325012, ..., 0.0114746, 0.0117188,\n",
       "             0.0281982],\n",
       "            ...,\n",
       "            [-0.0103149, 0.00854492, -0.0134277, ..., 0.00439453,\n",
       "             -0.0151978, -0.000740051],\n",
       "            [0.0101929, 0.000904083, 0.00921631, ..., 0.00299072,\n",
       "             -0.0177002, -0.0187988],\n",
       "            [0.000965118, -8.39233e-05, -0.00202942, ..., 5.50747e-05,\n",
       "             0.0045166, -0.00463867]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00227356, -0.00634766, 0.00634766, ..., 0.00701904,\n",
       "            -0.00534058, -0.010437],\n",
       "           [-0.00436401, 0.00524902, 0.010498, ..., -0.0154419, 0.00756836,\n",
       "            8.34465e-05],\n",
       "           [0.0131836, 0.00268555, -0.00683594, ..., -0.0106201, 0.0062561,\n",
       "            0.0111694],\n",
       "           ...,\n",
       "           [0.00276184, -0.00314331, 0.00430298, ..., 0.00805664,\n",
       "            0.00512695, -0.00231934],\n",
       "           [-0.00445557, -0.00280762, 0.00332642, ..., -0.000785828,\n",
       "            0.0057373, -0.00325012],\n",
       "           [0.00164795, -0.00454712, 0.00165558, ..., 0.00631714,\n",
       "            -0.015564, 0.00375366]],\n",
       "   \n",
       "          [[-0.012207, -0.00622559, 0.00708008, ..., -0.00509644,\n",
       "            -0.00747681, 0.00708008],\n",
       "           [0.000263214, 0.00325012, 0.0228271, ..., -0.00393677,\n",
       "            0.00662231, -0.00650024],\n",
       "           [-0.0136108, 0.0100098, 0.00157928, ..., -0.00756836,\n",
       "            0.00402832, 0.00125122],\n",
       "           ...,\n",
       "           [0.0112915, 0.00143433, 0.00512695, ..., 0.00671387, 0.00279236,\n",
       "            0.0142212],\n",
       "           [-0.00765991, -0.00976562, -0.00114441, ..., -0.00665283,\n",
       "            -0.003479, -0.0107422],\n",
       "           [0.00534058, -0.013916, 0.00494385, ..., -0.00126648,\n",
       "            0.00259399, 0.00302124]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.0153198, -0.00793457, -0.0203857, ..., 0.0152588, -0.00891113,\n",
       "           0.00259399],\n",
       "          [-0.0142212, 0.0132446, 0.00976562, ..., 0.0123291, 0.00534058,\n",
       "           -0.00445557],\n",
       "          [0.00244141, 0.00318909, -0.0145264, ..., -0.000740051,\n",
       "           -0.00265503, -0.00405884],\n",
       "          ...,\n",
       "          [-0.0153198, 0.00187683, -0.00402832, ..., 0.00842285, -0.0174561,\n",
       "           0.00157928],\n",
       "          [0.0014801, 0.0045166, -0.00524902, ..., -0.0020752, -0.0114136,\n",
       "           -0.00146484],\n",
       "          [0.00230408, -0.0117188, -0.00201416, ..., 0.00970459, -0.019043,\n",
       "           -0.00352478]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.0039978, -0.124512, -0.0678711, ..., -0.241211, 0.00665283,\n",
       "          -0.359375], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.106934, 0.0874023, 0.219727, ..., 0.0168457, 0.365234, 0.10498],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([1.10156, 0.796875, 0.84375, ..., 0.988281, 0.0463867, 0.369141],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.435547, 0.447266, 0.443359, ..., 0.636719, -0.0673828, 0.363281],      dtype=bfloat16)}},\n",
       " 'layer_7': {'attn': {'attn_vec_einsum': {'w': Array([[[0.0178223, 0.00132751, -0.00531006, ..., 0.00689697,\n",
       "             -0.00561523, -0.00982666],\n",
       "            [-0.00958252, 0.0183105, -0.00515747, ..., 0.00263977,\n",
       "             -0.0137329, 0.00741577],\n",
       "            [0.000368118, -0.0192871, -0.0109253, ..., -0.0161133,\n",
       "             -0.0101318, -0.00698853],\n",
       "            ...,\n",
       "            [-0.013916, 0.00430298, -0.0222168, ..., 0.012207, -0.0014267,\n",
       "             -0.0120239],\n",
       "            [0.0148926, 0.0256348, 0.00123596, ..., 0.00317383, 0.00466919,\n",
       "             -0.00753784],\n",
       "            [0.0072937, -0.00842285, 0.0294189, ..., -0.0128784,\n",
       "             -0.00473022, -0.0011673]],\n",
       "    \n",
       "           [[-0.003479, 0.0122681, 0.00640869, ..., 0.00193787, -0.0123291,\n",
       "             0.00357056],\n",
       "            [0.00473022, 0.00558472, -0.00219727, ..., -0.00323486,\n",
       "             0.006073, 0.0209961],\n",
       "            [0.00512695, 0.0111694, 0.0202637, ..., 0.0144653, 0.00309753,\n",
       "             -0.012146],\n",
       "            ...,\n",
       "            [0.00119781, 0.00276184, -0.0175781, ..., 0.00291443,\n",
       "             0.00485229, 0.00222778],\n",
       "            [0.00202942, -0.00506592, 0.000371933, ..., 0.00122833,\n",
       "             0.00982666, 0.000289917],\n",
       "            [0.00482178, -0.00283813, 0.0124512, ..., -0.000366211,\n",
       "             -0.000431061, 0.000459671]],\n",
       "    \n",
       "           [[0.00561523, 0.00195312, 0.00946045, ..., -0.017334, -0.0109253,\n",
       "             0.00720215],\n",
       "            [-0.00279236, 0.0131836, 0.0019989, ..., -0.0088501,\n",
       "             -0.00515747, -0.000488281],\n",
       "            [-0.0145874, 0.0166016, -0.00340271, ..., 0.0134277, 0.00668335,\n",
       "             0.0136108],\n",
       "            ...,\n",
       "            [0.00939941, 0.0111084, -0.0119019, ..., 0.0152588, 0.00708008,\n",
       "             0.00460815],\n",
       "            [-0.0251465, 0.00286865, -0.0132446, ..., -0.0241699,\n",
       "             -0.00201416, 0.0144043],\n",
       "            [-0.00271606, 0.0169678, -0.0164795, ..., -0.00570679,\n",
       "             0.00230408, 0.00202942]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0133667, -0.00288391, 0.00558472, ..., -0.0107422,\n",
       "             -0.0145264, -0.017334],\n",
       "            [-0.00236511, 0.00396729, 0.00756836, ..., 0.00177765,\n",
       "             -0.00209045, -0.00915527],\n",
       "            [-0.0120239, 0.0245361, 0.0170898, ..., -0.00430298,\n",
       "             -0.00759888, -0.00427246],\n",
       "            ...,\n",
       "            [-0.0170898, -0.0217285, -0.00692749, ..., -0.0114746,\n",
       "             -0.0246582, 0.00576782],\n",
       "            [0.0158691, 0.0055542, -0.00793457, ..., 0.0162354, -0.0145874,\n",
       "             -0.00698853],\n",
       "            [0.0062561, -0.00585938, -0.00787354, ..., 0.00933838,\n",
       "             -0.026123, 0.0288086]],\n",
       "    \n",
       "           [[-0.00793457, -0.00921631, -0.00382996, ..., -2.03848e-05,\n",
       "             0.00524902, -0.00964355],\n",
       "            [-0.0197754, 0.00185394, -0.00558472, ..., 0.0071106,\n",
       "             -0.0187988, 0.00512695],\n",
       "            [0.00952148, -0.0161133, 0.00842285, ..., -0.0150146,\n",
       "             -0.00309753, -0.00830078],\n",
       "            ...,\n",
       "            [-0.0014801, 0.0142822, 0.0101929, ..., -0.0032196, 0.0327148,\n",
       "             0.00595093],\n",
       "            [-0.00427246, 0.00915527, -0.0161133, ..., -0.00692749,\n",
       "             0.0125732, 0.0112305],\n",
       "            [0.0132446, -0.00823975, 0.012146, ..., -0.0247803, -0.00909424,\n",
       "             -0.00604248]],\n",
       "    \n",
       "           [[-0.00842285, 0.00579834, -0.00121307, ..., 0.00442505,\n",
       "             -0.0157471, 0.00104523],\n",
       "            [-0.0142822, -0.00132751, -0.0123901, ..., -0.010437,\n",
       "             0.00576782, -0.0144043],\n",
       "            [-0.0144653, -0.00260925, 0.00946045, ..., -0.00643921,\n",
       "             -0.00224304, 0.00402832],\n",
       "            ...,\n",
       "            [0.00567627, -0.00145721, 0.00469971, ..., -0.0062561, 0.001297,\n",
       "             -0.00291443],\n",
       "            [-0.00188446, -0.00259399, 0.00184631, ..., -0.0174561,\n",
       "             -0.0153198, -0.00958252],\n",
       "            [-0.00582886, -0.00753784, -0.0124512, ..., 0.00793457,\n",
       "             0.0148926, -0.0220947]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.0001688, -0.00723267, 0.00915527, ..., 0.0118408,\n",
       "              0.00854492, -0.00842285],\n",
       "             [0.00793457, 0.00396729, 0.0098877, ..., 0.00653076,\n",
       "              -0.00101471, -0.0290527],\n",
       "             [0.00491333, 0.00127411, 0.00561523, ..., 0.0136108,\n",
       "              -0.00494385, 0.00482178],\n",
       "             ...,\n",
       "             [6.38962e-05, 0.0155029, 0.00897217, ..., 0.00698853,\n",
       "              -0.00363159, 0.0078125],\n",
       "             [-0.0123291, 0.00317383, 0.00384521, ..., -0.0145874,\n",
       "              -0.00386047, 0.000656128],\n",
       "             [0.00180054, 0.0011673, 0.00720215, ..., 3.86238e-05,\n",
       "              0.00248718, -0.00424194]],\n",
       "    \n",
       "            [[0.00546265, -0.00854492, -0.000201225, ..., -0.00534058,\n",
       "              -0.0192871, 0.0155029],\n",
       "             [-0.00491333, 0.00897217, -0.00315857, ..., -0.0067749,\n",
       "              -0.0163574, -0.00817871],\n",
       "             [-0.0130005, 0.00167084, 0.000907898, ..., 0.000413895,\n",
       "              -0.00323486, 0.0116577],\n",
       "             ...,\n",
       "             [-0.0195312, 0.0022583, 0.000411987, ..., 0.0147095,\n",
       "              -0.0126953, -0.0368652],\n",
       "             [-0.00601196, -0.00367737, 0.0067749, ..., 0.00488281,\n",
       "              0.0118408, 0.0203857],\n",
       "             [0.00292969, -0.0130005, -0.00488281, ..., -0.027832,\n",
       "              -0.010376, -0.0134888]],\n",
       "    \n",
       "            [[-0.00811768, -0.00448608, 0.0113525, ..., 0.00427246,\n",
       "              -0.022583, 0.0140381],\n",
       "             [-0.00191498, -0.00256348, -0.00267029, ..., -0.0136108,\n",
       "              0.00332642, -0.00439453],\n",
       "             [-0.00582886, 0.00601196, 0.00448608, ..., -0.000675201,\n",
       "              -0.00311279, 0.00260925],\n",
       "             ...,\n",
       "             [0.00616455, 0.00836182, -0.0127563, ..., -0.00306702,\n",
       "              0.0101929, -0.00421143],\n",
       "             [0.000278473, -0.00201416, -0.0216064, ..., 0.0090332,\n",
       "              -0.0306396, 0.00714111],\n",
       "             [-0.00473022, -0.0027771, 0.0106812, ..., -0.00552368,\n",
       "              -0.00297546, -0.0123291]],\n",
       "    \n",
       "            [[0.0050354, -0.00952148, -0.0114136, ..., 0.0119629,\n",
       "              -0.0288086, 0.012146],\n",
       "             [-0.0123291, -0.0145874, 0.000686646, ..., 0.00921631,\n",
       "              -0.00842285, 0.012085],\n",
       "             [0.00234985, 0.00375366, -0.00476074, ..., -0.0288086,\n",
       "              0.010498, -0.00350952],\n",
       "             ...,\n",
       "             [-0.00146484, -0.00390625, -0.0115967, ..., 0.0349121,\n",
       "              -0.0336914, -0.00582886],\n",
       "             [-0.00897217, 0.00177002, -0.00537109, ..., 0.00500488,\n",
       "              0.0098877, 0.0378418],\n",
       "             [0.00793457, -0.0043335, -0.00720215, ..., 0.0371094,\n",
       "              0.0180664, -0.0177002]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0020752, -0.00927734, -0.00436401, ..., -0.00244141,\n",
       "              0.00537109, 0.0120239],\n",
       "             [0.00765991, 0.0172119, 0.00952148, ..., 0.00408936,\n",
       "              0.0158691, 0.00360107],\n",
       "             [0.00178528, -0.00454712, -0.00445557, ..., -0.0126953,\n",
       "              -0.00411987, 0.0106812],\n",
       "             ...,\n",
       "             [0.00314331, 0.00588989, -0.00238037, ..., 0.00331116,\n",
       "              -0.0128174, -0.0114746],\n",
       "             [-0.00173187, -0.00939941, -0.00854492, ..., -0.00369263,\n",
       "              0.0145874, 0.00393677],\n",
       "             [-0.0126343, 0.00424194, 0.000432968, ..., -0.00842285,\n",
       "              -0.0103149, -0.00106049]],\n",
       "    \n",
       "            [[0.0163574, 0.00860596, 0.0072937, ..., -0.0289307,\n",
       "              -0.0279541, 0.0181885],\n",
       "             [-0.0151367, 0.0234375, -0.0128784, ..., 0.0186768,\n",
       "              -0.00576782, -0.0196533],\n",
       "             [0.00811768, 0.00567627, 0.00224304, ..., -6.00815e-05,\n",
       "              -0.0194092, -0.0139771],\n",
       "             ...,\n",
       "             [-0.00946045, -0.00717163, 0.00753784, ..., 0.0230713,\n",
       "              0.00196838, -0.00136566],\n",
       "             [0.0122681, -0.00872803, -0.00653076, ..., 0.00613403,\n",
       "              0.00836182, -0.00442505],\n",
       "             [-0.0157471, -0.00387573, 0.00354004, ..., 0.0088501,\n",
       "              0.0236816, 0.0134888]],\n",
       "    \n",
       "            [[0.00396729, -0.000349045, -0.00476074, ..., -0.00393677,\n",
       "              0.00811768, 0.00695801],\n",
       "             [-0.0114136, -0.0170898, 0.00518799, ..., -0.0115967,\n",
       "              0.0140991, 0.0105591],\n",
       "             [-0.00482178, 0.0183105, -0.0105591, ..., -0.00588989,\n",
       "              -0.00619507, 0.00488281],\n",
       "             ...,\n",
       "             [-0.0192871, -0.0130005, 0.00369263, ..., -0.00311279,\n",
       "              0.00723267, 0.00354004],\n",
       "             [0.00524902, 0.0110474, -0.00793457, ..., -0.0134277,\n",
       "              -0.00236511, -0.00292969],\n",
       "             [-0.0119629, 0.00069809, 0.00537109, ..., 0.0212402,\n",
       "              0.0185547, 0.0065918]],\n",
       "    \n",
       "            [[-0.0178223, 0.0233154, -0.00238037, ..., -0.00198364,\n",
       "              -0.0149536, -0.00576782],\n",
       "             [0.0174561, -0.0127563, 0.000299454, ..., -0.0169678,\n",
       "              -0.0110474, 0.00114441],\n",
       "             [0.0178223, -0.00552368, -0.00069809, ..., 0.0231934,\n",
       "              0.0013504, 0.0145874],\n",
       "             ...,\n",
       "             [-0.00305176, -0.0172119, -0.0043335, ..., -0.00546265,\n",
       "              -0.00704956, 0.0155029],\n",
       "             [-0.00674438, -0.00576782, 0.00120544, ..., -0.010376,\n",
       "              0.00193024, -0.00854492],\n",
       "             [0.00598145, 0.0127563, 0.000957489, ..., 0.00494385,\n",
       "              -0.0045166, -0.00506592]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[-0.00174713, 0.00315857, 0.00646973, ..., -0.00830078,\n",
       "             -0.0164795, -0.0107422],\n",
       "            [0.0146484, -0.00439453, 0.00212097, ..., -0.00793457,\n",
       "             -0.00891113, -0.0119629],\n",
       "            [-0.00915527, 0.00119781, 0.0194092, ..., 0.0167236, 0.0203857,\n",
       "             0.00135803],\n",
       "            ...,\n",
       "            [-0.0217285, -0.0108032, 0.0167236, ..., 0.010498, -0.00069046,\n",
       "             -0.0217285],\n",
       "            [0.0213623, 0.00952148, -0.0233154, ..., -0.00598145, 0.0192871,\n",
       "             0.00436401],\n",
       "            [0.00187683, -0.00317383, -0.0197754, ..., 0.0112305,\n",
       "             0.00212097, 0.0142212]],\n",
       "    \n",
       "           [[0.000545502, 0.00564575, 0.0067749, ..., 0.0100708,\n",
       "             -0.00154114, -0.00958252],\n",
       "            [0.0158691, 0.00221252, -0.00805664, ..., 0.0137329, 0.0072937,\n",
       "             0.0336914],\n",
       "            [0.00047493, 0.00346375, 0.00115204, ..., 0.00105286, 0.0245361,\n",
       "             0.00285339],\n",
       "            ...,\n",
       "            [-0.00195312, 0.00248718, 0.00488281, ..., 0.00866699,\n",
       "             0.0241699, 0.015625],\n",
       "            [0.0111694, 0.000534058, -0.013916, ..., 0.0050354, 0.00463867,\n",
       "             -0.0150757],\n",
       "            [-0.00439453, -0.0134888, 0.0211182, ..., -0.0169678,\n",
       "             -0.0105591, 0.00343323]],\n",
       "    \n",
       "           [[0.0050354, 0.0065918, -0.00352478, ..., 0.0112305, -0.013916,\n",
       "             0.0272217],\n",
       "            [0.00296021, 0.00805664, -0.00842285, ..., -0.0118408,\n",
       "             0.00491333, -0.0422363],\n",
       "            [0.00291443, -0.000136375, 0.00793457, ..., 0.0269775,\n",
       "             0.00939941, -0.00124359],\n",
       "            ...,\n",
       "            [0.00106812, -0.000511169, -0.00245667, ..., -0.00300598,\n",
       "             0.024292, -0.0159912],\n",
       "            [0.00387573, -0.0111084, 0.00549316, ..., 0.00242615, 0.0148315,\n",
       "             -0.0016098],\n",
       "            [-0.00570679, -0.00634766, 0.00836182, ..., -0.00640869,\n",
       "             0.00582886, 0.000598907]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00158691, -0.000705719, -0.0133057, ..., -0.00518799,\n",
       "             -0.0145874, -0.0263672],\n",
       "            [-0.000762939, 0.00439453, -0.00686646, ..., -0.0213623,\n",
       "             -0.0270996, -0.0227051],\n",
       "            [0.000392914, -0.000177383, 0.00216675, ..., -0.0124512,\n",
       "             -0.00254822, -0.0137939],\n",
       "            ...,\n",
       "            [-0.00139618, -0.000862122, 0.00604248, ..., -0.0290527,\n",
       "             -0.0134277, -0.0127563],\n",
       "            [-0.00405884, 0.00141144, 0.0148315, ..., -0.00263977,\n",
       "             -0.00628662, 0.0319824],\n",
       "            [-0.00320435, 0.000419617, -0.00357056, ..., -0.00227356,\n",
       "             -0.0109863, -0.0200195]],\n",
       "    \n",
       "           [[0.000257492, -0.0015564, 0.00631714, ..., 0.0147095, -0.003479,\n",
       "             -0.00418091],\n",
       "            [-0.0108643, 0.00343323, -0.00616455, ..., 0.00466919,\n",
       "             -0.0219727, 0.00236511],\n",
       "            [-0.000459671, 0.00113678, 0.0111084, ..., -0.0289307,\n",
       "             0.00714111, -0.000705719],\n",
       "            ...,\n",
       "            [0.00213623, 0.00415039, 0.00488281, ..., 0.0145264, 0.0186768,\n",
       "             -0.0133057],\n",
       "            [-0.000167847, -0.00274658, -0.00288391, ..., -0.0189209,\n",
       "             0.00485229, -0.0247803],\n",
       "            [-0.00113678, 0.000400543, -0.00366211, ..., 0.0371094,\n",
       "             -0.00878906, 0.00610352]],\n",
       "    \n",
       "           [[-7.62939e-05, -0.00531006, -0.0117798, ..., -0.00151825,\n",
       "             0.000682831, 0.00793457],\n",
       "            [-0.0147705, -0.00390625, 0.000541687, ..., 0.00346375,\n",
       "             0.000907898, 0.00665283],\n",
       "            [-0.0134277, 0.00386047, -0.00909424, ..., -0.00126648,\n",
       "             0.000114918, 0.00186157],\n",
       "            ...,\n",
       "            [0.000930786, 0.00354004, 0.00370789, ..., -0.000839233,\n",
       "             0.00378418, -0.00411987],\n",
       "            [-0.00143433, 0.00212097, 0.0139771, ..., 0.00151062,\n",
       "             -0.00352478, -0.00842285],\n",
       "            [-0.0100098, -0.00332642, -0.010498, ..., 0.00121307,\n",
       "             0.00488281, 0.00579834]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[0.00805664, 0.00595093, -0.00527954, ..., -0.00494385,\n",
       "            0.00338745, -0.00314331],\n",
       "           [0.00177002, 0.00775146, 0.00445557, ..., 0.00582886,\n",
       "            -0.0100098, 0.00274658],\n",
       "           [-0.00442505, -0.001297, 0.00769043, ..., -0.0072937,\n",
       "            -0.0119629, -0.000591278],\n",
       "           ...,\n",
       "           [0.000999451, 0.00866699, 0.00552368, ..., 0.00622559,\n",
       "            0.000141144, -0.00296021],\n",
       "           [0.00265503, 0.000149727, 0.00063324, ..., -0.00588989,\n",
       "            0.0106812, -0.00585938],\n",
       "           [-0.00172424, 0.00872803, -0.0126953, ..., -0.0145874,\n",
       "            -0.00393677, -0.000652313]],\n",
       "   \n",
       "          [[-0.00756836, -0.00750732, -0.00772095, ..., -0.00387573,\n",
       "            -0.00213623, 0.013916],\n",
       "           [-0.000450134, 0.00109863, 0.00282288, ..., 0.00189972,\n",
       "            -0.00436401, -0.00375366],\n",
       "           [0.0110474, -0.00592041, 0.00268555, ..., 0.00318909,\n",
       "            0.00285339, -0.012146],\n",
       "           ...,\n",
       "           [-0.0153198, -0.00494385, 0.00482178, ..., 0.00288391,\n",
       "            -0.00509644, -0.000701904],\n",
       "           [-0.000358582, 0.00527954, -0.00610352, ..., 0.0111084,\n",
       "            -0.0110474, -0.00509644],\n",
       "           [0.000164986, -0.00830078, -0.000337601, ..., -0.00151062,\n",
       "            -0.00337219, -0.015625]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.00817871, 0.00157166, -0.00389099, ..., 0.00769043,\n",
       "           -0.00836182, -0.00286865],\n",
       "          [-0.0159912, -0.00500488, 0.0167236, ..., -0.00582886, -0.0011673,\n",
       "           0.0090332],\n",
       "          [-0.00311279, 0.00689697, -0.00259399, ..., 0.00604248,\n",
       "           -0.000442505, -0.0050354],\n",
       "          ...,\n",
       "          [-0.00227356, -0.00193787, 0.00653076, ..., 0.00244141,\n",
       "           -0.00352478, -0.00579834],\n",
       "          [0.00427246, 0.00866699, -0.0050354, ..., 0.00952148,\n",
       "           -0.000450134, -0.00107574],\n",
       "          [0.015564, 0.000236511, -0.00159454, ..., 0.00164795, 0.00415039,\n",
       "           -0.00570679]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.0143433, -0.0620117, 0.0375977, ..., -0.0898438, 0.110352,\n",
       "          -0.135742], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.191406, 0.195312, 0.308594, ..., 0.118164, 0.625, 0.196289],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.726562, 0.589844, 0.59375, ..., 0.789062, -0.155273, 0.455078],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.542969, 0.582031, 0.550781, ..., 0.742188, -0.00248718, 0.455078],      dtype=bfloat16)}},\n",
       " 'layer_8': {'attn': {'attn_vec_einsum': {'w': Array([[[-0.0039978, 0.0115967, 0.000343323, ..., 0.032959, 0.00454712,\n",
       "             0.00701904],\n",
       "            [-0.00799561, 0.0169678, 0.0223389, ..., -0.0151367, 0.00018692,\n",
       "             1.24574e-05],\n",
       "            [0.00411987, 0.00619507, 0.000823975, ..., -0.000961304,\n",
       "             -0.00460815, 0.0205078],\n",
       "            ...,\n",
       "            [0.00159454, 0.0268555, -0.0100098, ..., 0.00210571, 0.0189209,\n",
       "             -0.0238037],\n",
       "            [-0.00306702, -0.0134277, -0.0220947, ..., -0.0272217,\n",
       "             0.00585938, -0.00421143],\n",
       "            [-0.027832, -0.0111694, 0.0055542, ..., -0.012146, 0.0239258,\n",
       "             0.00747681]],\n",
       "    \n",
       "           [[0.00227356, -0.00762939, -0.00976562, ..., -0.0174561,\n",
       "             -0.0130005, -0.00497437],\n",
       "            [-0.00212097, -0.0150146, -0.00482178, ..., 0.00964355,\n",
       "             0.0027771, 0.000915527],\n",
       "            [-0.000471115, -0.0122681, -0.0101318, ..., -0.00976562,\n",
       "             0.00234985, -0.0035553],\n",
       "            ...,\n",
       "            [-0.00276184, -0.0177002, 0.000115395, ..., -0.00191498,\n",
       "             -0.013916, 0.0118408],\n",
       "            [0.0016861, 0.00946045, 0.015625, ..., 0.0178223, -0.00921631,\n",
       "             0.00778198],\n",
       "            [0.0134888, 0.00915527, -0.00427246, ..., 0.0078125, -0.0249023,\n",
       "             -0.0109253]],\n",
       "    \n",
       "           [[-0.0118408, 0.0203857, -0.00166321, ..., 0.0174561, 0.00144196,\n",
       "             0.00201416],\n",
       "            [-0.000522614, 0.0187988, 0.0147095, ..., -0.00497437,\n",
       "             0.00469971, 0.00106049],\n",
       "            [0.0192871, 0.0177002, 0.00543213, ..., -0.00878906,\n",
       "             0.000545502, 0.00245667],\n",
       "            ...,\n",
       "            [0.00613403, -0.0112305, 0.000965118, ..., -0.0203857,\n",
       "             -0.00186157, 0.0011673],\n",
       "            [0.00805664, -0.00479126, 0.00860596, ..., -0.00263977,\n",
       "             0.0184326, 0.000270844],\n",
       "            [-0.00631714, -0.00747681, -3.21865e-05, ..., 0.00421143,\n",
       "             -0.00323486, -0.00665283]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0168457, 0.0106201, -0.00738525, ..., -0.0168457, 0.00921631,\n",
       "             -0.0118408],\n",
       "            [0.00927734, -0.0168457, -0.00753784, ..., -0.000354767,\n",
       "             -0.0227051, -0.0039978],\n",
       "            [0.0111694, 0.00021553, 0.00337219, ..., 0.00946045, 0.0236816,\n",
       "             0.0179443],\n",
       "            ...,\n",
       "            [-0.0229492, -0.00436401, 0.0131836, ..., -0.0101929,\n",
       "             0.00842285, 0.0371094],\n",
       "            [-0.00842285, 0.0107422, 0.00994873, ..., -0.00148773,\n",
       "             -0.0290527, -0.00157928],\n",
       "            [-0.00343323, 0.0148315, 0.0015564, ..., -0.0118408,\n",
       "             -0.00112915, -0.0336914]],\n",
       "    \n",
       "           [[0.00340271, 0.00576782, 0.00671387, ..., -0.00457764,\n",
       "             -0.00242615, -0.00259399],\n",
       "            [0.0172119, -0.00115204, 0.0020752, ..., -0.0016098, 0.00430298,\n",
       "             -0.00619507],\n",
       "            [0.00332642, 0.00537109, 0.00174713, ..., -0.00521851,\n",
       "             -0.00121307, -0.00159454],\n",
       "            ...,\n",
       "            [-0.00136566, 0.00527954, 0.000740051, ..., 0.00720215,\n",
       "             -0.0118408, 0.000572205],\n",
       "            [-0.00364685, 0.000272751, 0.00279236, ..., -0.000202179,\n",
       "             -0.00133514, 0.00239563],\n",
       "            [0.00149536, -0.0119019, 0.00582886, ..., 0.00674438,\n",
       "             -0.00848389, 0.0103149]],\n",
       "    \n",
       "           [[-0.0153198, -0.0013504, -0.0130005, ..., -0.00622559,\n",
       "             0.0130615, -0.0212402],\n",
       "            [-0.00408936, 0.0112915, 0.00650024, ..., -0.00352478,\n",
       "             0.0192871, -0.0142212],\n",
       "            [0.00248718, 0.0168457, -0.0234375, ..., 0.00276184, 0.00744629,\n",
       "             0.00854492],\n",
       "            ...,\n",
       "            [0.00946045, -0.006073, -6.67572e-05, ..., 0.0043335,\n",
       "             -0.00110626, -0.0205078],\n",
       "            [-0.0178223, -0.0134277, -0.012085, ..., 0.00830078, 0.0108032,\n",
       "             -0.010437],\n",
       "            [-0.00393677, -0.017334, 0.000652313, ..., 0.00585938,\n",
       "             -0.00531006, 0.0153809]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[0.00772095, -0.00479126, 0.000606537, ..., -0.00552368,\n",
       "              0.0109863, -0.0022583],\n",
       "             [0.00195312, -0.000682831, 0.00379944, ..., 0.00402832,\n",
       "              -0.0111084, 0.0125732],\n",
       "             [0.00717163, -0.00939941, -0.0151978, ..., -0.00143433,\n",
       "              -0.00665283, -0.0167236],\n",
       "             ...,\n",
       "             [5.81741e-05, -0.00564575, -0.00312805, ..., 0.00579834,\n",
       "              0.0123291, 0.00112915],\n",
       "             [-0.00101471, 0.00698853, -0.00115967, ..., -0.0216064,\n",
       "              -0.00531006, 0.0292969],\n",
       "             [-0.0050354, 0.0088501, -0.000732422, ..., -0.00396729,\n",
       "              -0.0078125, -0.00463867]],\n",
       "    \n",
       "            [[-0.00500488, 0.00384521, -0.00088501, ..., 0.00294495,\n",
       "              -0.0263672, -0.0167236],\n",
       "             [-0.00778198, 0.00393677, -0.0137939, ..., 0.00805664,\n",
       "              -0.00138855, 0.0197754],\n",
       "             [-0.00357056, -0.00695801, 0.00460815, ..., -0.00479126,\n",
       "              0.00860596, -0.00488281],\n",
       "             ...,\n",
       "             [0.0161133, -0.00126648, -0.00047493, ..., 0.00151062,\n",
       "              0.00646973, 0.00265503],\n",
       "             [-0.0100098, 0.00595093, -0.0035553, ..., 0.0332031,\n",
       "              -0.00126648, -0.0236816],\n",
       "             [0.00224304, 0.0126953, 0.000984192, ..., 0.0166016,\n",
       "              -0.000965118, -0.00364685]],\n",
       "    \n",
       "            [[0.0119019, -0.00125885, -0.00201416, ..., 0.0159912,\n",
       "              -0.00897217, -0.0113525],\n",
       "             [-0.00162506, -0.00141144, 0.00534058, ..., 0.000530243,\n",
       "              -0.000436783, -0.00247192],\n",
       "             [-0.00344849, 0.0018692, 0.00158691, ..., 0.00537109,\n",
       "              -0.00427246, 0.00891113],\n",
       "             ...,\n",
       "             [-0.00408936, -0.00296021, -0.000188828, ..., 0.0013504,\n",
       "              0.00958252, -0.0149536],\n",
       "             [0.00250244, 0.00271606, -0.00265503, ..., -0.00772095,\n",
       "              -0.0147705, 0.0098877],\n",
       "             [-0.0100098, 0.00442505, 0.0045166, ..., -0.00436401,\n",
       "              -0.00653076, -0.0137329]],\n",
       "    \n",
       "            [[0.00872803, 0.00427246, 0.000448227, ..., -0.0167236,\n",
       "              -0.0133057, -0.00656128],\n",
       "             [-0.010437, 0.000720978, -0.00421143, ..., 0.00485229,\n",
       "              -0.019043, -0.00561523],\n",
       "             [0.00619507, 0.00135803, 0.00346375, ..., 0.000453949,\n",
       "              0.00260925, 0.0108032],\n",
       "             ...,\n",
       "             [-0.00113678, 3.12328e-05, -0.012085, ..., -0.000165939,\n",
       "              0.00415039, 0.00842285],\n",
       "             [0.00326538, -0.000976562, 0.00689697, ..., -0.0324707,\n",
       "              -0.00964355, -0.00221252],\n",
       "             [0.00430298, -0.00119019, -0.00317383, ..., 0.00427246,\n",
       "              -0.0145874, 0.0212402]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00650024, 0.000227928, -0.00245667, ..., -0.00939941,\n",
       "              0.00540161, 0.0280762],\n",
       "             [-0.000564575, 0.0131836, -0.0197754, ..., 0.00854492,\n",
       "              0.0153809, 0.0108032],\n",
       "             [-0.00107574, -0.000900269, -0.0216064, ..., 0.00753784,\n",
       "              -0.00326538, 0.000482559],\n",
       "             ...,\n",
       "             [-0.0125732, -0.0114746, -0.00160217, ..., 0.000221252,\n",
       "              0.00297546, 0.0131226],\n",
       "             [-0.00485229, -0.0145874, 9.53674e-05, ..., -0.00241089,\n",
       "              0.00320435, 0.001091],\n",
       "             [-0.000888824, -0.0062561, 0.00244141, ..., 0.00216675,\n",
       "              0.00415039, -0.00140381]],\n",
       "    \n",
       "            [[0.0125732, -0.0157471, 0.00494385, ..., 0.0147095,\n",
       "              0.00982666, 0.00300598],\n",
       "             [-0.00159454, -0.00479126, 0.00210571, ..., -0.0117798,\n",
       "              0.00491333, -0.00909424],\n",
       "             [-0.0106201, 0.00231934, 0.0229492, ..., -0.0115967,\n",
       "              0.000709534, 0.0301514],\n",
       "             ...,\n",
       "             [-0.00386047, -0.00579834, -0.00408936, ..., -0.0175781,\n",
       "              -0.013916, 0.019165],\n",
       "             [0.00193787, -0.00236511, -0.000328064, ..., -0.006073,\n",
       "              0.012085, -0.00170135],\n",
       "             [-0.0131226, -0.0133667, 0.0175781, ..., 0.0155029,\n",
       "              -0.0113525, -0.00576782]],\n",
       "    \n",
       "            [[-0.0179443, -0.0240479, 0.0108643, ..., 0.0267334, 0.0205078,\n",
       "              -0.00686646],\n",
       "             [-0.003479, 0.0145264, -0.0109863, ..., 0.0238037, -0.0158691,\n",
       "              -0.0174561],\n",
       "             [0.0151978, 0.00726318, 0.00860596, ..., -0.00263977,\n",
       "              0.00360107, 0.00442505],\n",
       "             ...,\n",
       "             [0.00704956, -0.00970459, -0.000255585, ..., 0.0175781,\n",
       "              -0.00738525, 0.00537109],\n",
       "             [-0.00872803, 0.0253906, -0.0117188, ..., -0.00744629,\n",
       "              0.0283203, -0.00233459],\n",
       "             [0.0167236, -0.00842285, -0.0105591, ..., -0.0427246,\n",
       "              -0.00205994, 0.0385742]],\n",
       "    \n",
       "            [[0.0100098, 0.00891113, 0.00610352, ..., -0.0170898,\n",
       "              -0.000328064, 0.00897217],\n",
       "             [-0.00582886, 0.00747681, 0.0194092, ..., 0.00263977,\n",
       "              -0.000919342, -0.0157471],\n",
       "             [-0.0050354, 0.00518799, -0.0324707, ..., 0.00215149,\n",
       "              0.00314331, -0.00463867],\n",
       "             ...,\n",
       "             [-0.0201416, -0.00939941, -0.0119629, ..., 0.0234375,\n",
       "              -0.00897217, 0.0109253],\n",
       "             [0.000170708, 0.000854492, 0.00216675, ..., -0.0217285,\n",
       "              0.0108032, -0.000938416],\n",
       "             [-0.019165, -0.00476074, -0.00259399, ..., -0.00518799,\n",
       "              0.0126343, 0.010376]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00328064, -0.00860596, -0.00848389, ..., -0.00259399,\n",
       "             0.00836182, 0.00817871],\n",
       "            [0.00982666, -0.00631714, -0.00151062, ..., 0.00141144,\n",
       "             -0.012085, -0.00430298],\n",
       "            [0.00411987, 0.00248718, -0.00257874, ..., -0.00378418,\n",
       "             0.00793457, -0.0067749],\n",
       "            ...,\n",
       "            [0.00543213, 0.00382996, 0.00506592, ..., -0.00292969,\n",
       "             0.00698853, -0.00379944],\n",
       "            [0.0136108, 0.00276184, -0.0161133, ..., 0.00180054,\n",
       "             0.000492096, 0.00247192],\n",
       "            [0.00582886, -0.0014801, -0.0114136, ..., -0.00204468,\n",
       "             0.00445557, -0.00650024]],\n",
       "    \n",
       "           [[0.0131226, -0.0124512, -0.0112915, ..., 0.00180817, 0.010376,\n",
       "             0.00473022],\n",
       "            [0.00817871, -0.00549316, -0.00622559, ..., -0.00622559,\n",
       "             -0.0209961, -0.0211182],\n",
       "            [-0.00166321, 0.00946045, 0.0112915, ..., 0.00143433,\n",
       "             -0.00564575, -0.00131226],\n",
       "            ...,\n",
       "            [-0.000720978, 0.00604248, 0.00326538, ..., 0.0240479,\n",
       "             0.0088501, 0.000188828],\n",
       "            [0.00186157, 0.00454712, -0.00262451, ..., 0.010376,\n",
       "             0.000172615, -0.00222778],\n",
       "            [-0.0035553, -0.00233459, -0.00183105, ..., -0.00854492,\n",
       "             -0.0197754, -0.0186768]],\n",
       "    \n",
       "           [[-0.00228882, 0.00122833, 0.00186157, ..., -0.00448608,\n",
       "             -0.0238037, -0.0117798],\n",
       "            [-0.00695801, 0.00582886, 0.00138092, ..., 0.0184326,\n",
       "             -0.00405884, 0.00848389],\n",
       "            [-0.00270081, -0.00396729, 0.000946045, ..., -0.00263977,\n",
       "             0.00946045, 0.0162354],\n",
       "            ...,\n",
       "            [-0.00958252, -0.0144653, -0.015625, ..., 0.0166016, -0.0175781,\n",
       "             0.00159454],\n",
       "            [0.00360107, -0.00105286, 0.0098877, ..., 0.0202637, 0.0205078,\n",
       "             -0.00271606],\n",
       "            [0.00518799, -0.0111694, 0.0039978, ..., -0.0183105, -0.0167236,\n",
       "             0.00369263]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00366211, 0.00939941, 0.0135498, ..., -0.00196838,\n",
       "             -0.000793457, -0.00646973],\n",
       "            [-0.0105591, 0.006073, 0.00866699, ..., -0.00671387, 0.00970459,\n",
       "             0.00891113],\n",
       "            [-0.00811768, 0.0170898, -0.00750732, ..., -0.000808716,\n",
       "             -0.0220947, 0.00836182],\n",
       "            ...,\n",
       "            [-0.0109253, 0.00576782, -0.00111389, ..., -0.00775146,\n",
       "             -0.0179443, 0.00497437],\n",
       "            [0.000591278, -0.00460815, -0.0039978, ..., 0.00619507,\n",
       "             -0.0022583, -0.00019455],\n",
       "            [-0.0127563, 0.00139618, 0.00187683, ..., 0.00245667, 0.013855,\n",
       "             -0.00205994]],\n",
       "    \n",
       "           [[-0.003479, 0.00379944, -0.0145874, ..., 0.0244141, -0.036377,\n",
       "             -0.00408936],\n",
       "            [0.00872803, 0.0189209, -0.00141144, ..., -0.00692749,\n",
       "             0.0368652, -0.00970459],\n",
       "            [-0.0105591, -0.0150757, -0.00643921, ..., -0.0324707,\n",
       "             -0.0123901, -0.0272217],\n",
       "            ...,\n",
       "            [-0.00970459, 0.00469971, -0.00695801, ..., -0.00878906,\n",
       "             -0.0135498, 0.0354004],\n",
       "            [-0.00506592, 0.0150757, 0.00982666, ..., -0.00946045,\n",
       "             0.0186768, 0.000396729],\n",
       "            [0.00939941, 0.00521851, 0.0090332, ..., -0.00921631,\n",
       "             0.00717163, -0.0227051]],\n",
       "    \n",
       "           [[0.015564, 0.00759888, 0.00056076, ..., 0.0317383, 0.0109253,\n",
       "             0.00927734],\n",
       "            [0.00344849, -0.00799561, 0.00897217, ..., 0.00289917,\n",
       "             0.0272217, -0.0439453],\n",
       "            [0.0137329, 0.0167236, 0.0167236, ..., -0.015625, 0.00063324,\n",
       "             0.00799561],\n",
       "            ...,\n",
       "            [-0.00231934, -0.00139618, 0.00411987, ..., -0.0153198,\n",
       "             -6.24657e-05, 0.0228271],\n",
       "            [0.00149536, 0.00753784, -0.00262451, ..., -0.000463486,\n",
       "             0.0214844, -0.00126648],\n",
       "            [0.0016861, 0.00708008, 0.0144043, ..., -0.00521851, 0.0132446,\n",
       "             -0.000434875]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.0115967, 0.00300598, -0.000114441, ..., 0.0032196,\n",
       "            0.0067749, -0.00665283],\n",
       "           [0.00396729, 0.00364685, -0.00799561, ..., 0.000915527,\n",
       "            0.00762939, 0.00891113],\n",
       "           [-0.00136566, 0.0105591, 0.0177002, ..., 0.00242615,\n",
       "            -0.000865936, -0.00848389],\n",
       "           ...,\n",
       "           [0.0101318, -0.00512695, -0.00218201, ..., -0.0123901,\n",
       "            -0.00106049, 0.000450134],\n",
       "           [-0.00466919, 0.00762939, 0.0110474, ..., 0.0100098,\n",
       "            -0.000679016, -0.0228271],\n",
       "           [0.00357056, 0.00445557, -0.00291443, ..., -0.00239563,\n",
       "            -0.00408936, -0.00921631]],\n",
       "   \n",
       "          [[0.0065918, 0.00747681, 0.0105591, ..., -0.0106201, 0.000743866,\n",
       "            0.00512695],\n",
       "           [0.0100708, -0.00637817, -0.00141907, ..., -0.00424194,\n",
       "            0.00427246, -0.00408936],\n",
       "           [-0.00982666, 0.00549316, -0.00830078, ..., -0.00619507,\n",
       "            0.00637817, 0.00415039],\n",
       "           ...,\n",
       "           [0.00909424, -0.00952148, -0.0107422, ..., -0.00631714,\n",
       "            0.00280762, 0.00063324],\n",
       "           [-0.00836182, 0.00854492, 0.00604248, ..., -0.0105591,\n",
       "            -0.0153809, -0.00280762],\n",
       "           [-0.0120239, 0.00305176, -0.00811768, ..., 0.0147095,\n",
       "            0.00921631, 0.00668335]]], dtype=bfloat16),\n",
       "   'linear': Array([[-0.010376, -0.00247192, 0.00189972, ..., 0.0128174, -0.00787354,\n",
       "           -0.00527954],\n",
       "          [0.00102997, -0.010498, 0.00263977, ..., 0.000743866, -0.00367737,\n",
       "           -0.000455856],\n",
       "          [0.0102539, -0.0137329, -0.0224609, ..., -0.00289917, 0.00334167,\n",
       "           -0.0108643],\n",
       "          ...,\n",
       "          [-0.0017395, -0.00028038, -0.00494385, ..., 0.000900269,\n",
       "           -0.0107422, -0.00817871],\n",
       "          [-0.00396729, -0.00650024, 0.00276184, ..., -0.00747681,\n",
       "           0.0062561, 0.00360107],\n",
       "          [0.00616455, 0.00631714, 0.0216064, ..., -0.00488281, 0.0030365,\n",
       "           0.00160217]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.120117, 0.132812, 0.211914, ..., 0.0247803, 0.125977, 0.0432129],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.277344, 0.273438, 0.369141, ..., 0.199219, 0.644531, 0.271484],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([1.14062, 1.02344, 1.03906, ..., 1.14062, 0.0703125, 0.894531],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.601562, 0.675781, 0.648438, ..., 0.785156, 0.0917969, 0.589844],      dtype=bfloat16)}},\n",
       " 'layer_9': {'attn': {'attn_vec_einsum': {'w': Array([[[0.00379944, 0.000249863, -0.0267334, ..., -0.0148315,\n",
       "             0.000656128, -0.00650024],\n",
       "            [-0.0100708, 0.00460815, 0.0133057, ..., 0.0071106, 0.00482178,\n",
       "             -0.00735474],\n",
       "            [-0.00534058, -0.00628662, -0.00349426, ..., -0.00195312,\n",
       "             0.0115356, 0.015625],\n",
       "            ...,\n",
       "            [0.000203133, 0.00854492, -0.00823975, ..., -0.00686646,\n",
       "             -0.0103149, 0.00723267],\n",
       "            [0.0241699, 0.00389099, 0.00860596, ..., 0.000999451,\n",
       "             -0.00227356, -0.00500488],\n",
       "            [0.0216064, 0.015564, -0.00817871, ..., -0.00125122, 0.00671387,\n",
       "             -0.0212402]],\n",
       "    \n",
       "           [[0.00805664, 0.0144653, -0.0108032, ..., 0.00384521,\n",
       "             0.000621796, -0.012146],\n",
       "            [-0.0140991, -0.0016098, -0.0175781, ..., -0.015564,\n",
       "             -0.00720215, -0.00210571],\n",
       "            [4.36306e-05, -0.0111084, -0.0101929, ..., 0.000413895,\n",
       "             0.0130615, -0.0154419],\n",
       "            ...,\n",
       "            [-0.0161133, -0.00215149, -0.00848389, ..., 0.00817871,\n",
       "             -0.00494385, -0.00405884],\n",
       "            [0.0166016, -0.00112152, 0.00546265, ..., 0.00872803,\n",
       "             0.00193787, 0.00817871],\n",
       "            [-0.0122681, -0.034668, -0.00473022, ..., 0.0169678, 0.00738525,\n",
       "             -0.0187988]],\n",
       "    \n",
       "           [[0.00823975, -0.0101929, 0.0102539, ..., -0.00222778,\n",
       "             -0.00335693, -0.0169678],\n",
       "            [0.0146484, -0.00933838, -0.00570679, ..., 0.00291443,\n",
       "             -0.00144958, 0.00177002],\n",
       "            [0.00309753, 0.0238037, -0.0341797, ..., 0.00473022, 0.0109863,\n",
       "             -0.00138092],\n",
       "            ...,\n",
       "            [-0.00178528, 0.00396729, -0.00228882, ..., 0.00144196,\n",
       "             -0.012207, -0.00738525],\n",
       "            [0.0327148, 0.00921631, -0.0015564, ..., 0.00179291,\n",
       "             -0.00540161, 0.0132446],\n",
       "            [-0.00891113, 0.00866699, 0.00387573, ..., 0.000190735,\n",
       "             -0.0144653, 0.0102539]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00497437, 0.00274658, -0.00170135, ..., 0.00485229,\n",
       "             -0.00726318, 0.0164795],\n",
       "            [0.019043, -0.00778198, 0.00921631, ..., -0.00335693, 0.0133057,\n",
       "             -0.00970459],\n",
       "            [-0.0267334, -0.0194092, -0.0022583, ..., 0.0157471, -0.0108643,\n",
       "             0.0109253],\n",
       "            ...,\n",
       "            [-0.00653076, 0.0144653, 0.0100708, ..., -0.0349121, 0.00209045,\n",
       "             -0.000991821],\n",
       "            [-0.0140381, 0.00239563, -0.00113678, ..., -0.00172424,\n",
       "             -0.0174561, 0.0112305],\n",
       "            [-0.0145874, 0.0192871, 0.00982666, ..., 0.00466919,\n",
       "             -0.00592041, -0.00689697]],\n",
       "    \n",
       "           [[0.0185547, 0.00283813, 0.00619507, ..., -0.00308228, 0.0142212,\n",
       "             0.00427246],\n",
       "            [-0.00341797, -0.0163574, 0.00723267, ..., -0.00500488,\n",
       "             -0.00177765, -0.00552368],\n",
       "            [-0.012207, 0.00280762, 0.0198975, ..., -0.0178223, -0.00479126,\n",
       "             -0.0088501],\n",
       "            ...,\n",
       "            [0.00387573, -0.0209961, -0.0120239, ..., 0.00402832,\n",
       "             0.00306702, 0.0139771],\n",
       "            [-3.48091e-05, -0.00224304, 0.00915527, ..., 0.0144043, 0.03125,\n",
       "             -0.0161133],\n",
       "            [-0.0105591, -0.00286865, 0.001091, ..., -0.0187988, 0.00860596,\n",
       "             -0.0212402]],\n",
       "    \n",
       "           [[-0.0177002, -0.00231934, 0.0050354, ..., 0.0108643,\n",
       "             -0.00698853, -0.000463486],\n",
       "            [0.0115967, 0.0019989, -0.000238419, ..., -0.00317383,\n",
       "             3.60608e-06, 0.00750732],\n",
       "            [-0.0131226, 0.00411987, 0.0119019, ..., -0.00848389,\n",
       "             0.00720215, -0.0118408],\n",
       "            ...,\n",
       "            [-0.0128174, 0.0185547, 0.0213623, ..., 0.0168457, -0.015625,\n",
       "             -0.0103149],\n",
       "            [-0.0238037, 0.00274658, 0.00598145, ..., 0.00866699,\n",
       "             -0.00878906, 0.00349426],\n",
       "            [0.00473022, -0.0055542, -0.00610352, ..., 0.00500488,\n",
       "             -0.00805664, 0.00732422]]], dtype=bfloat16)},\n",
       "   'kv_einsum': {'w': Array([[[[-0.00346375, -0.00686646, -0.00793457, ..., 0.00878906,\n",
       "              -0.00860596, 0.0113525],\n",
       "             [0.0146484, 0.00338745, -0.00762939, ..., -0.000379562,\n",
       "              0.0167236, -0.0162354],\n",
       "             [-0.0102539, 0.00476074, 0.0116577, ..., -0.0111694,\n",
       "              0.0134277, 0.00113678],\n",
       "             ...,\n",
       "             [-0.00167847, 0.00823975, 0.00778198, ..., -0.00939941,\n",
       "              0.0004673, 0.0246582],\n",
       "             [-0.00994873, 0.00650024, -0.00570679, ..., 0.00378418,\n",
       "              -0.00897217, 0.00671387],\n",
       "             [-0.00164795, 0.00976562, 0.0045166, ..., -0.010498,\n",
       "              0.0180664, 0.00411987]],\n",
       "    \n",
       "            [[0.00167847, -0.00337219, -0.00744629, ..., 0.00637817,\n",
       "              -0.00982666, 0.00180817],\n",
       "             [0.00479126, 0.00427246, 0.00175476, ..., 0.00634766,\n",
       "              -0.000831604, -0.0201416],\n",
       "             [0.000705719, 0.00408936, 0.00515747, ..., -0.00184631,\n",
       "              -0.00933838, -0.0123901],\n",
       "             ...,\n",
       "             [-0.00144196, 0.00927734, -0.00102997, ..., 0.0149536,\n",
       "              0.0268555, 0.00878906],\n",
       "             [-0.00253296, 0.00219727, 0.0111694, ..., 0.0233154,\n",
       "              -0.0144653, 0.00257874],\n",
       "             [-0.00579834, 0.0016861, 0.00163269, ..., -0.0148926,\n",
       "              0.00230408, 0.0158691]],\n",
       "    \n",
       "            [[0.015625, -0.000459671, 0.00101471, ..., 0.0131836,\n",
       "              -0.060791, -0.0124512],\n",
       "             [-0.00866699, 0.0184326, 0.00570679, ..., 0.0158691,\n",
       "              -0.0158691, 0.00769043],\n",
       "             [0.00331116, 0.00628662, -0.00534058, ..., 0.00250244,\n",
       "              -0.019043, 0.000896454],\n",
       "             ...,\n",
       "             [-0.000339508, -0.000663757, -0.0115356, ..., 0.00306702,\n",
       "              -0.00311279, 0.0148926],\n",
       "             [-0.00714111, -0.00179291, -0.00958252, ..., -0.00567627,\n",
       "              0.00860596, 0.0402832],\n",
       "             [-0.00982666, 0.00439453, -0.00216675, ..., -0.0117188,\n",
       "              0.0220947, -0.000514984]],\n",
       "    \n",
       "            [[0.00561523, 0.000648499, -0.00866699, ..., 0.00927734,\n",
       "              -0.00897217, -0.0117188],\n",
       "             [0.00585938, 0.00411987, 0.00147247, ..., 0.00610352,\n",
       "              0.00488281, 0.00402832],\n",
       "             [0.00107574, -0.00370789, -0.00515747, ..., 0.0139771,\n",
       "              0.0106201, -0.000747681],\n",
       "             ...,\n",
       "             [0.0043335, 0.00686646, 0.0088501, ..., -0.0043335, 0.0166016,\n",
       "              -0.0126343],\n",
       "             [-0.00479126, -0.00436401, -0.00069809, ..., 0.0301514,\n",
       "              -0.0154419, 0.00540161],\n",
       "             [0.00156403, 3.33786e-05, -0.00187683, ..., 0.00619507,\n",
       "              -0.00427246, 0.0664062]]],\n",
       "    \n",
       "    \n",
       "           [[[0.00915527, -0.0126343, 0.0205078, ..., -0.00701904,\n",
       "              0.0142212, -0.000843048],\n",
       "             [0.0256348, -0.0114136, -0.0196533, ..., 0.0196533,\n",
       "              0.00231934, -0.0131836],\n",
       "             [-0.00094223, -0.012085, -0.00390625, ..., -0.00317383,\n",
       "              -0.00463867, -0.00352478],\n",
       "             ...,\n",
       "             [0.0043335, -0.0112915, 0.00476074, ..., -0.0012207,\n",
       "              -0.00497437, 0.0236816],\n",
       "             [0.00366211, -0.00212097, -0.00476074, ..., 0.00628662,\n",
       "              -0.00958252, -0.00561523],\n",
       "             [-0.00543213, -0.0032959, -0.00134277, ..., -0.00915527,\n",
       "              -0.0238037, 0.00509644]],\n",
       "    \n",
       "            [[0.00680542, -0.00415039, 0.0222168, ..., 0.0106812,\n",
       "              0.0150757, -0.0067749],\n",
       "             [-0.0187988, -0.0115356, 0.0307617, ..., 0.0183105,\n",
       "              0.00567627, 0.00891113],\n",
       "             [0.00982666, -0.000425339, -0.0150146, ..., 0.00750732,\n",
       "              -0.00726318, -0.0130615],\n",
       "             ...,\n",
       "             [0.0110474, 0.0145874, 0.0262451, ..., -0.00102234, 0.001297,\n",
       "              -0.0140991],\n",
       "             [0.0142212, -0.00135803, 0.00228882, ..., -0.00154114,\n",
       "              0.00665283, -0.00778198],\n",
       "             [0.0090332, 0.00848389, -0.0390625, ..., -0.0154419,\n",
       "              0.000375748, 0.0164795]],\n",
       "    \n",
       "            [[0.00653076, 0.0147095, -0.00524902, ..., 0.00866699,\n",
       "              -0.00552368, 0.0022583],\n",
       "             [0.0062561, -0.00128937, -0.00637817, ..., 0.019043,\n",
       "              -0.0116577, 0.0157471],\n",
       "             [0.000137329, 0.0125732, -0.00708008, ..., 0.0286865,\n",
       "              0.00213623, -0.00866699],\n",
       "             ...,\n",
       "             [0.0163574, 0.0148315, -0.0143433, ..., -0.0217285, 0.0110474,\n",
       "              -0.00933838],\n",
       "             [0.0111084, -0.00701904, -0.00176239, ..., -0.00238037,\n",
       "              0.00769043, 0.00616455],\n",
       "             [0.00714111, -0.000247955, 0.00166321, ..., -0.00216675,\n",
       "              0.00933838, -0.00209045]],\n",
       "    \n",
       "            [[4.95911e-05, -0.00897217, -0.00141144, ..., 0.00296021,\n",
       "              -0.00328064, -0.0322266],\n",
       "             [0.0115356, 0.00466919, 0.00769043, ..., -0.00537109,\n",
       "              -0.00970459, -0.0119629],\n",
       "             [0.0111694, 0.000385284, -0.00494385, ..., 0.00830078,\n",
       "              0.0124512, 0.000198364],\n",
       "             ...,\n",
       "             [0.00518799, -0.0222168, -0.000595093, ..., 0.0250244,\n",
       "              -0.00430298, 0.0114136],\n",
       "             [-0.00195312, -0.00306702, -0.00747681, ..., -0.00291443,\n",
       "              -0.019165, 0.0108643],\n",
       "             [-0.00970459, 0.0263672, -0.000204086, ..., -0.0078125,\n",
       "              -0.0103149, 0.010437]]]], dtype=bfloat16)},\n",
       "   'q_einsum': {'w': Array([[[0.00595093, 0.00854492, 0.00390625, ..., 0.00741577, 0.0112305,\n",
       "             -0.0043335],\n",
       "            [-0.00534058, 0.00878906, -0.0113525, ..., 0.00202942,\n",
       "             -0.00604248, -0.00248718],\n",
       "            [-0.00897217, 0.00241089, -0.0128174, ..., -0.00860596,\n",
       "             -0.00683594, 0.010498],\n",
       "            ...,\n",
       "            [0.0162354, 0.00823975, 0.00872803, ..., -0.00610352, 0.0126953,\n",
       "             -0.0057373],\n",
       "            [0.0183105, 0.00030899, 0.0125122, ..., 0.00860596, -0.0123291,\n",
       "             0.000785828],\n",
       "            [0.000976562, 0.00390625, -0.00994873, ..., 0.0205078,\n",
       "             0.00418091, -0.0131836]],\n",
       "    \n",
       "           [[-0.00153351, 0.0202637, 0.0187988, ..., -0.000274658,\n",
       "             0.0125732, -0.000457764],\n",
       "            [-0.00521851, -0.00872803, -0.00138092, ..., -0.0140991,\n",
       "             0.012146, -0.00331116],\n",
       "            [-0.00738525, -0.00127411, -0.0126953, ..., -0.0349121,\n",
       "             -0.0050354, -0.0065918],\n",
       "            ...,\n",
       "            [0.00317383, -0.00714111, -0.0149536, ..., 0.0130615,\n",
       "             0.00793457, -0.0246582],\n",
       "            [0.010437, -0.0167236, 0.00335693, ..., 0.00854492, -0.0366211,\n",
       "             -0.0220947],\n",
       "            [0.0118408, -0.00708008, 0.00241089, ..., -0.00375366,\n",
       "             -0.0184326, 0.00787354]],\n",
       "    \n",
       "           [[0.00842285, -0.00119781, 0.00170135, ..., -0.0133667,\n",
       "             -0.00640869, -0.0143433],\n",
       "            [-0.0164795, -0.00637817, -0.0172119, ..., -0.00340271,\n",
       "             0.00309753, 0.000778198],\n",
       "            [0.000411987, -3.40939e-05, -0.00186157, ..., -0.0147705,\n",
       "             0.0155029, -0.0235596],\n",
       "            ...,\n",
       "            [-0.00524902, 0.00662231, 0.00393677, ..., -0.00256348,\n",
       "             0.000732422, -0.00799561],\n",
       "            [-0.00112152, -0.0200195, -0.0057373, ..., -0.00521851,\n",
       "             0.0214844, -0.0148926],\n",
       "            [0.00994873, -0.0135498, -0.00177002, ..., -0.0217285,\n",
       "             -0.015625, 0.00616455]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00765991, 0.00340271, -0.00738525, ..., -0.00360107,\n",
       "             -0.0130615, -0.0103149],\n",
       "            [0.00515747, -0.0134888, 0.00479126, ..., -0.00106049,\n",
       "             -0.00320435, -0.00598145],\n",
       "            [-0.00982666, 0.0217285, -0.00778198, ..., 0.00689697,\n",
       "             -0.0213623, 0.00527954],\n",
       "            ...,\n",
       "            [-0.00518799, 0.00315857, 0.00683594, ..., -0.0142212,\n",
       "             0.00300598, -0.00872803],\n",
       "            [-0.0141602, 0.00549316, 0.0101929, ..., 0.0109863, 0.0170898,\n",
       "             0.00233459],\n",
       "            [0.00964355, 0.00671387, -0.000545502, ..., 0.000333786,\n",
       "             0.00389099, -0.00457764]],\n",
       "    \n",
       "           [[-0.00772095, 0.00564575, -0.0105591, ..., -0.00970459,\n",
       "             -4.8399e-05, -0.0098877],\n",
       "            [-0.0108032, 0.000499725, 0.000667572, ..., 0.00640869,\n",
       "             0.0109253, 0.00430298],\n",
       "            [-0.00218201, -0.0114746, 0.0126953, ..., 0.0168457,\n",
       "             -0.00866699, 0.0185547],\n",
       "            ...,\n",
       "            [-0.00274658, -0.00285339, -0.00427246, ..., 0.006073,\n",
       "             0.0098877, 0.0120239],\n",
       "            [0.0098877, 0.0196533, -0.0186768, ..., 0.0109253, 0.00509644,\n",
       "             0.0187988],\n",
       "            [0.0118408, 0.00634766, -0.00854492, ..., -0.00408936,\n",
       "             0.000398636, 0.0195312]],\n",
       "    \n",
       "           [[-0.00549316, 0.00436401, 0.00848389, ..., 0.00312805,\n",
       "             0.0113525, 0.00445557],\n",
       "            [-0.00512695, -0.00732422, 0.00772095, ..., 0.0194092,\n",
       "             0.0108032, -0.00341797],\n",
       "            [0.00546265, -0.00241089, 0.000572205, ..., -0.00256348,\n",
       "             0.000213623, 0.012085],\n",
       "            ...,\n",
       "            [-0.00479126, -0.00382996, -0.00262451, ..., -0.00662231,\n",
       "             0.0201416, -0.00418091],\n",
       "            [0.00613403, 0.0125122, -0.00558472, ..., -0.00637817,\n",
       "             -0.0192871, -0.00769043],\n",
       "            [0.000234604, 0.00280762, -0.00567627, ..., -0.0136719,\n",
       "             -0.00457764, 0.026123]]], dtype=bfloat16)}},\n",
       "  'mlp': {'gating_einsum': Array([[[-0.00107574, -0.0137939, 0.013916, ..., 0.0205078, 0.000705719,\n",
       "            -0.000926971],\n",
       "           [0.000843048, 0.0109863, -0.00476074, ..., -0.00411987,\n",
       "            -0.00427246, 0.00138855],\n",
       "           [-0.00469971, 0.0162354, 0.00312805, ..., 0.000133514,\n",
       "            0.00408936, -0.00280762],\n",
       "           ...,\n",
       "           [-0.00196838, 0.000606537, 0.00445557, ..., -0.0109253,\n",
       "            -0.0115356, 0.00113678],\n",
       "           [0.00799561, 0.00598145, -0.00436401, ..., 0.00543213,\n",
       "            0.00390625, -0.0150146],\n",
       "           [-0.0100098, 0.012207, -0.00418091, ..., -3.71933e-05,\n",
       "            0.00317383, -0.00762939]],\n",
       "   \n",
       "          [[0.0131226, 0.00756836, 0.00860596, ..., 0.00970459, -0.0107422,\n",
       "            -0.000591278],\n",
       "           [-0.00762939, -0.00680542, 0.00692749, ..., -0.00337219,\n",
       "            0.00616455, 0.00830078],\n",
       "           [6.07967e-05, -0.00848389, 0.00683594, ..., 0.0144043,\n",
       "            0.00964355, 0.00494385],\n",
       "           ...,\n",
       "           [0.00427246, -0.012146, 0.0186768, ..., 0.00158691, -0.00759888,\n",
       "            0.000240326],\n",
       "           [0.00218201, 0.0078125, 0.0145874, ..., -0.00799561, 0.00384521,\n",
       "            0.00933838],\n",
       "           [0.00811768, -0.00424194, -0.00317383, ..., 0.003479,\n",
       "            -0.00289917, 0.00296021]]], dtype=bfloat16),\n",
       "   'linear': Array([[0.00128937, -0.0125732, -0.0032196, ..., 0.00576782, 0.00156403,\n",
       "           0.00473022],\n",
       "          [0.0037384, 0.000239372, 0.00402832, ..., 0.000394821,\n",
       "           -0.000530243, 0.010376],\n",
       "          [0.00817871, 0.00106812, 0.00132751, ..., 0.00848389, -0.00289917,\n",
       "           -0.00491333],\n",
       "          ...,\n",
       "          [-0.00891113, -0.00646973, 0.0057373, ..., -0.00320435,\n",
       "           -0.0106812, 0.00619507],\n",
       "          [-0.00558472, -0.00738525, -0.0100708, ..., 0.0043335, 0.00579834,\n",
       "           0.00738525],\n",
       "          [0.00341797, -0.0169678, -0.0038147, ..., 0.00439453, 0.00817871,\n",
       "           0.0125732]], dtype=bfloat16)},\n",
       "  'post_attention_norm': {'scale': Array([0.107422, 0.113281, 0.164062, ..., 0.0292969, 0.0986328,\n",
       "          -0.0441895], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.484375, 0.488281, 0.539062, ..., 0.390625, 0.65625, 0.408203],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.953125, 0.917969, 0.871094, ..., 1.10156, 0.15918, 0.871094],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.267578, 0.339844, 0.296875, ..., 0.400391, -0.120117, 0.251953],      dtype=bfloat16)}}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['transformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedder': {'input_embedding': LoraWeight(shape=(256128, 2304), dtype=dtype(bfloat16), w=Array([[0.0351562, -0.0229492, 0.081543, ..., 0.0211182, 0.0527344,\n",
       "          -0.0351562],\n",
       "         [-0.0200195, 0.0522461, -0.0302734, ..., 0.0027771, -0.0240479,\n",
       "          -0.017334],\n",
       "         [-0.000164032, -0.00592041, 0.0222168, ..., 0.0151978,\n",
       "          -0.00735474, -0.0119019],\n",
       "         ...,\n",
       "         [0.0227051, -0.0375977, 0.0356445, ..., 0.0402832, 0.0117798,\n",
       "          -0.0308838],\n",
       "         [0.0319824, -0.0368652, 0.0410156, ..., 0.0385742, 0.0196533,\n",
       "          -0.0270996],\n",
       "         [0.0203857, -0.0405273, 0.0368652, ..., 0.0400391, 0.0180664,\n",
       "          -0.0306396]], dtype=bfloat16), a=Array([[ 0.02199156,  0.0049439 , -0.01322838, ..., -0.01093095,\n",
       "           0.01156266,  0.01847863],\n",
       "         [ 0.01022545, -0.01507886, -0.0023296 , ...,  0.00661303,\n",
       "           0.02698121,  0.00401224]], dtype=float32), b=Array([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         ...,\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=float32), alpha=1.0)},\n",
       " 'final_norm': {'scale': Array([2.32812, 2.34375, 2.28125, ..., 4.65625, 2.53125, 2.4375],      dtype=bfloat16)},\n",
       " 'layer_0': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0090332, 0.0100708, 0.0155029, ..., 0.00256348, -0.00537109,\n",
       "             0.00848389],\n",
       "            [0.0114136, 0.0202637, 0.00952148, ..., -0.000166893, 0.0108032,\n",
       "             0.0124512],\n",
       "            [0.00543213, -0.000261307, 0.000991821, ..., 0.0150146,\n",
       "             0.0119019, 0.00424194],\n",
       "            ...,\n",
       "            [0.00188446, 0.00346375, -0.00598145, ..., 0.0195312,\n",
       "             -0.00405884, -0.00738525],\n",
       "            [-0.0111694, 0.00515747, 0.00306702, ..., -0.00750732,\n",
       "             0.00389099, -0.0107422],\n",
       "            [-0.00230408, 0.0202637, 0.00167084, ..., -0.0123901,\n",
       "             0.00787354, 0.00236511]],\n",
       "    \n",
       "           [[0.012207, -0.00169373, -0.0222168, ..., -0.0055542,\n",
       "             -0.00891113, -0.0150146],\n",
       "            [0.00546265, -0.00872803, -0.00112915, ..., 0.00854492,\n",
       "             -0.0110474, 0.0131836],\n",
       "            [0.00294495, 0.00230408, 0.00650024, ..., 0.0011673,\n",
       "             -0.00598145, 0.0131226],\n",
       "            ...,\n",
       "            [-0.00714111, -0.00848389, -0.00340271, ..., -0.000105381,\n",
       "             0.0118408, 0.00469971],\n",
       "            [0.00231934, -0.00115967, 0.0078125, ..., -0.00512695,\n",
       "             -0.00579834, 0.000249863],\n",
       "            [0.0045166, 0.00982666, 0.0105591, ..., 0.00479126, -0.00915527,\n",
       "             -0.00872803]],\n",
       "    \n",
       "           [[-0.0114136, -0.0194092, 0.00334167, ..., 0.0055542,\n",
       "             -0.00952148, 0.0133057],\n",
       "            [-0.00958252, 0.00224304, 0.000499725, ..., 0.0216064,\n",
       "             0.00268555, -0.000448227],\n",
       "            [0.00195312, -0.0214844, -0.00341797, ..., 0.00265503,\n",
       "             -0.00430298, 0.0169678],\n",
       "            ...,\n",
       "            [0.00320435, -0.00222778, 0.0111694, ..., -0.0151367,\n",
       "             -0.00994873, -0.0116577],\n",
       "            [-0.00187683, 0.00616455, 0.000991821, ..., 0.0168457,\n",
       "             0.00299072, -0.00149536],\n",
       "            [-0.00836182, 0.00772095, -0.00671387, ..., 0.00860596,\n",
       "             -0.000370026, -0.0116577]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00738525, -0.00878906, -0.0100708, ..., 0.00848389,\n",
       "             0.0108032, -0.0223389],\n",
       "            [0.0126343, -0.0055542, 0.0020752, ..., 0.0151367, 0.00741577,\n",
       "             0.00564575],\n",
       "            [0.0179443, -0.006073, 0.0152588, ..., -0.00552368, -0.0151978,\n",
       "             -0.0184326],\n",
       "            ...,\n",
       "            [-0.00364685, -0.0162354, 0.00897217, ..., -0.0114136,\n",
       "             -0.0234375, -0.0178223],\n",
       "            [0.0129395, -0.0134888, -0.0109253, ..., -0.0233154, 0.00335693,\n",
       "             -0.0144043],\n",
       "            [0.00482178, -0.0142822, 0.00370789, ..., 0.00473022,\n",
       "             0.00946045, 0.0132446]],\n",
       "    \n",
       "           [[0.0140381, 0.00576782, -0.0126953, ..., 0.00215149, -0.0015564,\n",
       "             -0.0118408],\n",
       "            [0.00335693, -0.0055542, 0.00872803, ..., 0.0145874, 0.0238037,\n",
       "             -0.0159912],\n",
       "            [-0.00601196, 0.0214844, -0.0140991, ..., 0.00460815, 0.0155029,\n",
       "             -0.00231934],\n",
       "            ...,\n",
       "            [-0.0127563, 0.0090332, -0.0126953, ..., -0.00842285,\n",
       "             -0.000185013, -0.00897217],\n",
       "            [-0.000663757, 4.91738e-06, -0.000220299, ..., -0.006073,\n",
       "             -0.00402832, 0.00114441],\n",
       "            [0.00634766, -0.0201416, -0.000180244, ..., -0.00494385,\n",
       "             -0.0183105, -0.00375366]],\n",
       "    \n",
       "           [[0.0167236, -0.00463867, 0.00646973, ..., 0.00082016,\n",
       "             0.00811768, -0.00338745],\n",
       "            [-0.0125732, -0.00860596, -0.00811768, ..., -0.00769043,\n",
       "             0.00473022, -0.00335693],\n",
       "            [-0.00105286, 0.0231934, 0.00216675, ..., 0.00646973,\n",
       "             -0.00331116, -0.0201416],\n",
       "            ...,\n",
       "            [0.00442505, 0.00927734, -0.0037384, ..., 0.00588989,\n",
       "             -0.0039978, -0.00131989],\n",
       "            [-0.00268555, -0.0032196, 0.00640869, ..., -0.00756836,\n",
       "             0.000105858, -0.00227356],\n",
       "            [-0.00102234, 0.00927734, 0.0174561, ..., 0.013855, -0.0142822,\n",
       "             0.0163574]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0055542, -0.00469971, 0.00686646, ..., -0.00312805,\n",
       "              -0.0183105, 0.0264893],\n",
       "             [0.00479126, -0.0022583, 0.00549316, ..., -0.00119781,\n",
       "              0.00958252, -0.00558472],\n",
       "             [-0.0192871, 0.00210571, 0.00720215, ..., 0.00128174,\n",
       "              0.00799561, 0.0136108],\n",
       "             ...,\n",
       "             [0.0120239, -0.00173187, -0.0088501, ..., 0.00296021,\n",
       "              0.0136719, -0.0144653],\n",
       "             [-0.00518799, 0.00744629, 0.00014019, ..., -0.000934601,\n",
       "              0.0106812, 0.010437],\n",
       "             [0.0126953, -0.00698853, -0.0113525, ..., 0.027832,\n",
       "              0.00921631, 0.00994873]],\n",
       "    \n",
       "            [[-0.00110626, -0.00497437, 0.0147095, ..., 0.0172119,\n",
       "              0.00714111, -0.00354004],\n",
       "             [0.0163574, -0.00386047, 0.0189209, ..., 0.0136108, 0.0192871,\n",
       "              -0.0257568],\n",
       "             [-0.0105591, -0.0100708, 0.0134277, ..., 0.0112915, 0.0152588,\n",
       "              -0.00302124],\n",
       "             ...,\n",
       "             [-0.0152588, -0.00537109, -0.00148773, ..., -0.0306396,\n",
       "              -0.0019455, 0.0206299],\n",
       "             [0.00714111, 0.00549316, 0.00396729, ..., -0.00122833,\n",
       "              0.00500488, 0.0157471],\n",
       "             [0.0101318, 0.00173187, -0.0100708, ..., -0.00604248,\n",
       "              0.00506592, 0.00830078]],\n",
       "    \n",
       "            [[0.00509644, 0.0194092, 0.00094223, ..., 0.0159912, 0.0120239,\n",
       "              0.00244141],\n",
       "             [0.0035553, -0.00753784, -0.0128174, ..., -0.0038147,\n",
       "              -0.00958252, -0.0162354],\n",
       "             [0.00352478, -0.00842285, -0.00564575, ..., 0.046875,\n",
       "              0.00286865, 0.0126343],\n",
       "             ...,\n",
       "             [-0.00927734, -0.0088501, -0.0114136, ..., 0.00933838,\n",
       "              0.0220947, -0.0124512],\n",
       "             [0.000629425, -0.0067749, 0.000930786, ..., 0.00720215,\n",
       "              -0.0228271, -0.0025177],\n",
       "             [0.00534058, 0.0152588, 0.00427246, ..., -0.0275879,\n",
       "              -0.0123901, 0.00145721]],\n",
       "    \n",
       "            [[0.000911713, 0.0195312, -0.00546265, ..., 0.0136108,\n",
       "              0.0017395, 0.0038147],\n",
       "             [0.00509644, 0.000364304, 0.000488281, ..., 0.00552368,\n",
       "              -0.00872803, 0.013855],\n",
       "             [0.00337219, -0.00216675, -0.00150299, ..., -0.020752,\n",
       "              0.0153198, -0.00183868],\n",
       "             ...,\n",
       "             [0.00494385, -0.00686646, -0.0014801, ..., -0.00830078,\n",
       "              0.00817871, 0.015625],\n",
       "             [-0.0211182, -0.00860596, 0.0180664, ..., -0.0133667,\n",
       "              0.00537109, -0.00257874],\n",
       "             [0.00500488, 0.00811768, -0.00765991, ..., -0.0120239,\n",
       "              -0.00778198, -0.00346375]]],\n",
       "    \n",
       "    \n",
       "           [[[0.00735474, 0.00170135, -0.00234985, ..., -0.0192871,\n",
       "              -0.0101929, -0.00209045],\n",
       "             [0.0105591, 0.0145874, 0.0067749, ..., -0.0050354, 0.00613403,\n",
       "              0.00531006],\n",
       "             [0.0213623, -0.00442505, -0.00418091, ..., 0.00396729,\n",
       "              0.00479126, -0.00543213],\n",
       "             ...,\n",
       "             [-0.00268555, -0.0088501, -0.0108032, ..., -0.0108643,\n",
       "              -0.0184326, -0.0157471],\n",
       "             [-0.00376892, 0.000387192, 0.00732422, ..., 0.00172424,\n",
       "              -0.00619507, 0.000286102],\n",
       "             [0.00260925, 0.00927734, -0.0218506, ..., -0.0102539,\n",
       "              -0.00183105, -0.00424194]],\n",
       "    \n",
       "            [[-0.00115204, 0.024292, 0.0072937, ..., -0.0122681,\n",
       "              -0.0241699, 0.00653076],\n",
       "             [-0.00689697, -0.0240479, -0.00196838, ..., -0.0032196,\n",
       "              -0.00570679, -0.00315857],\n",
       "             [0.00866699, -0.000195503, 0.00408936, ..., -0.000595093,\n",
       "              -0.00111389, 0.00349426],\n",
       "             ...,\n",
       "             [-0.0162354, 0.00325012, 0.000671387, ..., -0.0105591,\n",
       "              0.0106201, -0.0189209],\n",
       "             [0.0140381, -0.0145874, 0.0019455, ..., 0.0062561,\n",
       "              7.24792e-05, -0.0124512],\n",
       "             [0.00692749, 0.0108032, -0.00308228, ..., -0.00628662,\n",
       "              -0.00166321, 0.00358582]],\n",
       "    \n",
       "            [[0.00154114, 0.0030365, -0.00567627, ..., -0.00430298,\n",
       "              0.0120239, -0.00106049],\n",
       "             [0.0266113, -0.00588989, -0.00124359, ..., -0.00128937,\n",
       "              -0.00491333, -0.00104523],\n",
       "             [0.0141602, -0.00463867, 0.00402832, ..., -0.00744629,\n",
       "              0.00585938, 0.00680542],\n",
       "             ...,\n",
       "             [-0.00732422, 0.0172119, 0.0112915, ..., -0.0088501,\n",
       "              -0.010376, 0.0022583],\n",
       "             [0.00445557, 0.0032196, 0.00970459, ..., 0.0116577,\n",
       "              -0.0112915, 0.0106812],\n",
       "             [-0.00344849, -0.00640869, -0.00241089, ..., 0.0184326,\n",
       "              -0.00314331, 0.0129395]],\n",
       "    \n",
       "            [[0.0126953, 0.0267334, 0.00668335, ..., -0.00268555,\n",
       "              -0.00897217, -0.00176239],\n",
       "             [-0.0116577, -0.0045166, -0.0181885, ..., 0.0189209,\n",
       "              -0.00811768, 0.00439453],\n",
       "             [-0.00772095, -0.0078125, 0.0146484, ..., -0.0105591,\n",
       "              -0.00263977, -0.0118408],\n",
       "             ...,\n",
       "             [0.0153198, -0.0114746, -0.0217285, ..., 0.00357056,\n",
       "              0.0117798, 0.000226974],\n",
       "             [-0.00274658, -0.00306702, 0.010376, ..., -0.00305176,\n",
       "              0.0128784, -0.0088501],\n",
       "             [0.00613403, -0.00866699, 0.00491333, ..., -0.00848389,\n",
       "              -0.00512695, -0.00350952]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00701904, -0.00222778, 0.00172424, ..., 0.00131989,\n",
       "             0.00759888, 0.00173187],\n",
       "            [0.0148926, 0.015564, 0.00344849, ..., -0.00527954, 0.00524902,\n",
       "             -0.000448227],\n",
       "            [-0.0192871, -0.0253906, 0.00622559, ..., -0.00582886,\n",
       "             0.000656128, -0.013855],\n",
       "            ...,\n",
       "            [0.0147705, 0.0205078, -0.000892639, ..., 0.00747681,\n",
       "             0.00512695, -0.000797272],\n",
       "            [-0.027832, -0.0100098, 0.0136108, ..., -0.000249863,\n",
       "             -0.0112915, -0.0116577],\n",
       "            [0.00866699, 0.00494385, -0.00124359, ..., -0.0127563,\n",
       "             -0.000556946, 0.00515747]],\n",
       "    \n",
       "           [[-0.00497437, 0.00296021, 0.00723267, ..., -0.0065918,\n",
       "             -0.0189209, 0.0212402],\n",
       "            [-0.0038147, 0.00357056, 0.00236511, ..., 0.0100708, 0.00360107,\n",
       "             0.0153198],\n",
       "            [-0.00137329, -2.94447e-05, -0.00198364, ..., 0.0055542,\n",
       "             0.000164986, 0.00799561],\n",
       "            ...,\n",
       "            [0.0065918, -0.00180817, -0.00494385, ..., 0.00561523,\n",
       "             0.0314941, -0.0133057],\n",
       "            [0.00909424, 0.000522614, -0.00247192, ..., 9.58443e-05,\n",
       "             0.0228271, 0.0136108],\n",
       "            [0.00704956, -0.00379944, -0.00320435, ..., 0.0283203,\n",
       "             0.0143433, 0.0267334]],\n",
       "    \n",
       "           [[-0.00817871, 0.00317383, 0.010376, ..., -0.0124512, -0.0161133,\n",
       "             0.00695801],\n",
       "            [0.0177002, 0.00689697, -0.00662231, ..., -0.00830078,\n",
       "             0.0153198, -4.55379e-05],\n",
       "            [0.00500488, 0.00282288, -0.00592041, ..., 0.00379944,\n",
       "             0.0170898, -0.0043335],\n",
       "            ...,\n",
       "            [-0.00552368, -0.0050354, 0.012146, ..., 0.00708008,\n",
       "             -0.00219727, 0.020874],\n",
       "            [-0.000272751, -0.00393677, 0.000801086, ..., 0.010437,\n",
       "             -0.00817871, 0.0267334],\n",
       "            [-0.0197754, 6.4373e-05, -0.00927734, ..., 0.0039978,\n",
       "             -0.0169678, -0.00762939]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00176239, 0.0280762, 0.00958252, ..., 0.0253906, 0.00405884,\n",
       "             -0.0103149],\n",
       "            [-0.00830078, 0.0157471, 0.00405884, ..., -0.00753784,\n",
       "             0.0157471, 0.00364685],\n",
       "            [0.000482559, -0.0168457, -0.0189209, ..., 0.00564575,\n",
       "             0.00273132, -0.0219727],\n",
       "            ...,\n",
       "            [-0.0147095, 0.0137939, 0.000431061, ..., 0.0134888, 0.00195312,\n",
       "             0.0134888],\n",
       "            [-0.0035553, -0.0163574, 0.015564, ..., -0.00177002, -0.020752,\n",
       "             -0.00830078],\n",
       "            [-0.00221252, -0.00111389, 0.00866699, ..., -0.00123596,\n",
       "             -0.0220947, 0.0164795]],\n",
       "    \n",
       "           [[-0.000701904, 0.000305176, -0.00564575, ..., 0.0170898,\n",
       "             -0.00769043, 0.00793457],\n",
       "            [-0.00604248, -0.0133057, -0.00014782, ..., -0.013855,\n",
       "             0.0216064, 0.013916],\n",
       "            [0.00141907, -0.00622559, -0.00521851, ..., -0.00811768,\n",
       "             -0.00317383, 0.0133667],\n",
       "            ...,\n",
       "            [0.00466919, -0.0133667, 0.0220947, ..., -0.0198975,\n",
       "             -0.00909424, -0.00628662],\n",
       "            [-0.00263977, -0.00227356, -0.00592041, ..., -0.00518799,\n",
       "             -0.00720215, -0.00964355],\n",
       "            [-0.00704956, -0.010498, -0.0105591, ..., 0.00318909,\n",
       "             0.00306702, -0.00108337]],\n",
       "    \n",
       "           [[-0.000785828, -0.00302124, -0.00518799, ..., 0.0030365,\n",
       "             0.00415039, -0.0100098],\n",
       "            [0.00115967, 0.0045166, 0.0268555, ..., 0.0275879, -0.00248718,\n",
       "             -0.0110474],\n",
       "            [-0.000383377, 0.00564575, -0.00389099, ..., 0.00872803,\n",
       "             0.00549316, 0.0213623],\n",
       "            ...,\n",
       "            [0.00379944, 0.012085, -0.0219727, ..., 0.0174561, 0.00698853,\n",
       "             -0.0152588],\n",
       "            [0.0144653, -0.00476074, -0.0035553, ..., -0.0113525,\n",
       "             0.000263214, 0.0339355],\n",
       "            [0.0141602, 0.0151367, -0.0126953, ..., -0.00133514, 0.00598145,\n",
       "             -0.0184326]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.0027771, -0.00335693, -0.00897217, ..., 0.0078125,\n",
       "            -0.00592041, 0.0115356],\n",
       "           [-0.0178223, -0.00717163, 0.0169678, ..., -0.000892639,\n",
       "            -0.00102234, 0.00619507],\n",
       "           [-0.00344849, -0.0055542, 0.00110626, ..., 0.00692749,\n",
       "            -0.00527954, -0.010376],\n",
       "           ...,\n",
       "           [0.00698853, -0.000255585, -0.006073, ..., -0.00726318,\n",
       "            -0.00897217, -0.0106812],\n",
       "           [0.00543213, -0.00732422, 0.00288391, ..., -0.0098877,\n",
       "            0.0101929, -0.00909424],\n",
       "           [0.00698853, -0.0126953, 0.0032196, ..., -0.00772095,\n",
       "            -0.00714111, 0.0125122]],\n",
       "   \n",
       "          [[0.00817871, 0.0162354, 0.00274658, ..., -0.0105591,\n",
       "            -0.00811768, 0.00230408],\n",
       "           [-0.013855, -0.00346375, -0.00506592, ..., -0.00732422,\n",
       "            -0.00167847, 0.00552368],\n",
       "           [-0.00662231, 0.0125732, -0.0037384, ..., 0.00241089,\n",
       "            -0.00927734, -0.00946045],\n",
       "           ...,\n",
       "           [0.00674438, -0.0100098, -0.000713348, ..., -0.0116577,\n",
       "            -0.00037384, 0.00720215],\n",
       "           [-0.00622559, -0.00299072, -0.000191689, ..., 0.00576782,\n",
       "            -0.00424194, 0.00393677],\n",
       "           [0.000265121, -0.0195312, 0.00735474, ..., 0.00653076,\n",
       "            0.000455856, 0.0102539]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.000249863, 0.00778198, 0.0151978, ..., -0.00805664,\n",
       "           -0.00162506, -0.0137329],\n",
       "          [0.0143433, 0.00692749, 0.0136108, ..., -0.0235596, 0.00010252,\n",
       "           -0.00921631],\n",
       "          [0.00221252, 0.00842285, -0.00308228, ..., 0.000200272,\n",
       "           -0.00546265, -0.00994873],\n",
       "          ...,\n",
       "          [-0.000102043, -0.00230408, 0.00367737, ..., 0.0244141, 0.0109863,\n",
       "           -0.00683594],\n",
       "          [-0.00860596, 0.00357056, -0.006073, ..., -0.00616455,\n",
       "           -0.00698853, 0.00454712],\n",
       "          [-0.00708008, 0.00341797, 0.00242615, ..., 0.00189209,\n",
       "           -0.00402832, 0.00933838]], dtype=bfloat16), a=Array([[ 1.3663782e-02, -6.0665291e-03,  1.4391938e-02, ...,\n",
       "           -7.4021826e-03, -2.7578839e-03, -8.8478941e-03],\n",
       "          [ 1.8342493e-02,  3.5765569e-03,  2.9392069e-05, ...,\n",
       "           -1.2318562e-02,  2.7163564e-03,  2.3088796e-02]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([-0.53125, -0.515625, -0.490234, ..., -0.53125, 1.42188, -0.519531],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([-0.229492, -0.189453, -0.194336, ..., -0.361328, 0.441406,\n",
       "          -0.162109], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.116699, 0.134766, 0.192383, ..., 0.636719, 0.0402832, 0.243164],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.227539, 0.208008, 0.208008, ..., 0.992188, 2.15625, 0.197266],      dtype=bfloat16)}},\n",
       " 'layer_1': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00360107, 0.00775146, 0.0117798, ..., 0.00494385, -0.0147705,\n",
       "             -0.020752],\n",
       "            [0.00273132, -0.00309753, -0.00151825, ..., 0.00239563,\n",
       "             -0.00279236, -0.00411987],\n",
       "            [-0.0223389, -0.00183868, -0.0153198, ..., 0.00276184,\n",
       "             0.0239258, -0.0167236],\n",
       "            ...,\n",
       "            [0.0015564, 0.000617981, 0.00854492, ..., -0.00494385,\n",
       "             0.00331116, 0.00113678],\n",
       "            [-0.00389099, -0.00576782, -0.0159912, ..., 0.0119019,\n",
       "             -0.0410156, -0.0134277],\n",
       "            [-0.00018692, -0.0219727, 0.000747681, ..., -0.00274658,\n",
       "             -0.0114136, 0.00145721]],\n",
       "    \n",
       "           [[-0.00946045, -0.0118408, -0.00891113, ..., 0.00927734,\n",
       "             0.019165, -0.0142212],\n",
       "            [-0.00169373, -0.00482178, 0.00134277, ..., 0.00476074,\n",
       "             -0.00153351, -0.000442505],\n",
       "            [0.00204468, -0.0224609, 0.00595093, ..., -0.00866699,\n",
       "             -0.0163574, -0.00964355],\n",
       "            ...,\n",
       "            [0.003479, -0.00109863, -0.00860596, ..., 0.0037384, 0.0163574,\n",
       "             0.034668],\n",
       "            [0.0181885, -0.00104523, -0.00454712, ..., 0.0168457,\n",
       "             -0.0200195, 0.00787354],\n",
       "            [-0.00262451, 0.0161133, -0.00662231, ..., -0.00970459,\n",
       "             0.00695801, -0.00106812]],\n",
       "    \n",
       "           [[-0.0119019, -0.00598145, 0.00897217, ..., 0.00909424,\n",
       "             -0.0134277, 0.0162354],\n",
       "            [-0.00518799, 0.0168457, -0.00312805, ..., -0.00126648,\n",
       "             -0.00366211, -0.0149536],\n",
       "            [-0.00050354, 0.00125885, -0.0118408, ..., 0.00595093,\n",
       "             0.00637817, -0.00842285],\n",
       "            ...,\n",
       "            [-0.00714111, 0.0140991, -0.00479126, ..., -0.00165558,\n",
       "             -0.00273132, 0.019043],\n",
       "            [-0.00408936, -0.00144196, -0.0090332, ..., -0.0119019,\n",
       "             -0.00811768, 0.00524902],\n",
       "            [-0.00115204, -0.0230713, 0.00357056, ..., 0.0123901,\n",
       "             -0.00695801, 0.00860596]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00775146, 0.00799561, 0.0120239, ..., 0.0107422, -0.00811768,\n",
       "             -0.00952148],\n",
       "            [0.00744629, 0.0088501, 0.00567627, ..., 0.0126343, 0.0078125,\n",
       "             -0.0205078],\n",
       "            [0.0195312, -0.0112305, -0.0112915, ..., 0.0159912, -0.00799561,\n",
       "             0.0307617],\n",
       "            ...,\n",
       "            [0.0174561, 0.00405884, -0.00698853, ..., 0.000484467,\n",
       "             -0.0140381, 0.00830078],\n",
       "            [-0.00346375, -0.0141602, -0.0113525, ..., 0.00689697,\n",
       "             0.0272217, 0.00418091],\n",
       "            [-0.00927734, 0.0118408, -0.013855, ..., -0.00125122,\n",
       "             0.00952148, 0.000349045]],\n",
       "    \n",
       "           [[-0.0157471, -0.00564575, 0.0019989, ..., 0.00296021,\n",
       "             -0.00230408, -0.00279236],\n",
       "            [-0.00576782, 0.013855, -0.0115967, ..., -0.00842285, 0.010376,\n",
       "             -0.00476074],\n",
       "            [-0.0137939, -0.0108032, 0.00717163, ..., 0.00958252,\n",
       "             -0.00897217, -0.00662231],\n",
       "            ...,\n",
       "            [0.0209961, 0.0177002, -0.00592041, ..., -0.0131226, 0.00732422,\n",
       "             -0.012085],\n",
       "            [-0.0109863, 0.00830078, -0.000545502, ..., -0.00759888,\n",
       "             -0.00811768, -0.00787354],\n",
       "            [0.0187988, -0.00921631, 0.0148926, ..., 0.0043335, 0.00854492,\n",
       "             0.0159912]],\n",
       "    \n",
       "           [[-0.0100098, 0.00213623, 0.00836182, ..., 0.0043335, -0.0129395,\n",
       "             -0.00393677],\n",
       "            [0.00793457, 0.00579834, 0.00665283, ..., -0.00148773,\n",
       "             0.0110474, -0.0133667],\n",
       "            [0.00488281, -0.00466919, -0.0100708, ..., 0.0013504,\n",
       "             -0.00163269, -0.0123291],\n",
       "            ...,\n",
       "            [-0.0032959, -0.00415039, -0.0169678, ..., 0.00328064,\n",
       "             -0.00421143, -0.00109863],\n",
       "            [-0.0143433, -0.00247192, -0.00527954, ..., -0.00582886,\n",
       "             0.00162506, -0.00744629],\n",
       "            [0.0110474, -0.0263672, -0.00964355, ..., 0.00466919,\n",
       "             -0.0111084, -0.00909424]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0013504, -0.00108337, -0.00610352, ..., -0.0088501,\n",
       "              0.0020752, 0.0113525],\n",
       "             [0.00227356, 0.00799561, 0.00518799, ..., -0.00836182,\n",
       "              -0.00282288, -0.00564575],\n",
       "             [-0.00631714, 0.000492096, 7.92742e-06, ..., 0.0202637,\n",
       "              -0.0100098, 0.0124512],\n",
       "             ...,\n",
       "             [0.00245667, 0.00239563, 0.00082016, ..., 0.00178528,\n",
       "              0.0198975, 0.0238037],\n",
       "             [-0.00247192, 0.0206299, 0.00112152, ..., 0.043457,\n",
       "              1.43051e-05, 0.0150757],\n",
       "             [0.00112915, -0.0016098, 0.0025177, ..., 0.00720215,\n",
       "              0.0196533, -0.00775146]],\n",
       "    \n",
       "            [[-0.00701904, 0.00878906, -0.00842285, ..., -0.00320435,\n",
       "              0.0175781, -0.0111694],\n",
       "             [-0.00145721, -0.00389099, -0.0128174, ..., 0.00704956,\n",
       "              -0.0158691, -0.0162354],\n",
       "             [-0.00695801, -0.00616455, -0.0109253, ..., -0.0341797,\n",
       "              0.000155449, 0.0110474],\n",
       "             ...,\n",
       "             [-0.019165, 0.0258789, 0.000396729, ..., 0.0159912, 0.0131226,\n",
       "              0.013855],\n",
       "             [0.00020504, 0.00756836, -0.00708008, ..., 0.00891113,\n",
       "              -0.00933838, 0.00384521],\n",
       "             [-0.00723267, -0.00297546, -0.00063324, ..., 0.00228882,\n",
       "              0.0212402, 0.0148926]],\n",
       "    \n",
       "            [[-0.0118408, 0.00110626, 0.00177765, ..., 0.0019455,\n",
       "              -0.00379944, -0.0135498],\n",
       "             [-0.00137329, 0.00180054, -0.0117188, ..., 0.00160217,\n",
       "              0.027832, 0.000109673],\n",
       "             [-0.0155029, -0.00299072, 0.0103149, ..., 0.000865936,\n",
       "              -0.0172119, -0.0102539],\n",
       "             ...,\n",
       "             [-0.0168457, 0.00312805, 0.0361328, ..., -0.00427246,\n",
       "              0.0189209, 0.00952148],\n",
       "             [0.0125122, -0.0017395, 0.00531006, ..., -0.00817871,\n",
       "              -0.00402832, 0.00704956],\n",
       "             [0.00106812, -0.00457764, -0.0258789, ..., -0.00165558,\n",
       "              -0.0200195, -0.0131226]],\n",
       "    \n",
       "            [[-0.00497437, 0.00726318, -0.012085, ..., -0.0112305,\n",
       "              -0.0184326, -0.00811768],\n",
       "             [0.00460815, 0.0123291, 0.0043335, ..., -0.0103149,\n",
       "              -0.0280762, -0.032959],\n",
       "             [0.00296021, 0.00366211, -0.0134888, ..., -0.0108032,\n",
       "              0.00154877, 0.00622559],\n",
       "             ...,\n",
       "             [-0.00158691, 0.0100708, -0.0118408, ..., -0.0124512,\n",
       "              -0.0101929, 0.0432129],\n",
       "             [-0.003479, -0.015625, -0.00473022, ..., -0.010437, -0.027832,\n",
       "              -0.0270996],\n",
       "             [-0.00119781, -0.00282288, 0.0090332, ..., 0.0174561,\n",
       "              -0.00473022, -0.00102234]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00271606, -0.0164795, -0.00101471, ..., 0.0108032,\n",
       "              0.0334473, 0.00101471],\n",
       "             [-0.0249023, -0.000164032, -0.00582886, ..., -0.0050354,\n",
       "              0.00939941, -0.00479126],\n",
       "             [-0.00427246, 0.0088501, 0.00866699, ..., -0.0106201,\n",
       "              0.0126343, -0.00994873],\n",
       "             ...,\n",
       "             [-0.017334, 0.00393677, -0.00161743, ..., 0.00537109,\n",
       "              0.0116577, 0.00952148],\n",
       "             [0.0152588, -0.000926971, -0.00747681, ..., 0.00363159,\n",
       "              0.00369263, 0.00354004],\n",
       "             [-0.00842285, 0.000244141, -0.0166016, ..., 0.0045166,\n",
       "              -0.00273132, -0.00848389]],\n",
       "    \n",
       "            [[-0.0213623, -0.00268555, -0.00157928, ..., -0.00337219,\n",
       "              -0.0132446, -0.00509644],\n",
       "             [-0.000679016, 0.0117188, 0.00842285, ..., -0.0102539,\n",
       "              0.00485229, -0.00552368],\n",
       "             [-0.00262451, 0.00842285, 0.00364685, ..., -0.00552368,\n",
       "              0.0139771, -0.000999451],\n",
       "             ...,\n",
       "             [0.0105591, -0.00927734, 0.0286865, ..., 0.00370789,\n",
       "              -0.0179443, 0.00466919],\n",
       "             [0.012085, -0.00386047, 0.00756836, ..., 0.00300598,\n",
       "              -0.0020752, 0.00133514],\n",
       "             [0.015564, -0.0108032, -0.0209961, ..., 0.0151367, 0.00793457,\n",
       "              0.00372314]],\n",
       "    \n",
       "            [[-0.00379944, -0.00933838, 0.00805664, ..., 0.00848389,\n",
       "              -0.00209045, 0.00891113],\n",
       "             [-0.0170898, -0.0102539, -0.0111084, ..., -0.00488281,\n",
       "              0.00787354, 0.0134888],\n",
       "             [-0.0106201, -0.000972748, -0.0137939, ..., -0.00759888,\n",
       "              -0.00512695, -0.0100098],\n",
       "             ...,\n",
       "             [-0.001297, 0.00188446, 0.00897217, ..., 0.0170898,\n",
       "              -0.00151825, -0.00994873],\n",
       "             [-0.00921631, 0.00582886, 0.00363159, ..., -0.00337219,\n",
       "              -0.010376, -0.00909424],\n",
       "             [0.00445557, 0.00192261, 0.00604248, ..., 0.00131226,\n",
       "              0.00442505, 0.00497437]],\n",
       "    \n",
       "            [[0.0050354, 0.0136108, 0.00230408, ..., -0.0202637,\n",
       "              0.00674438, 0.0108032],\n",
       "             [-0.00854492, 0.0172119, -0.00848389, ..., 0.00460815,\n",
       "              0.00753784, 0.00378418],\n",
       "             [-0.013916, -0.00540161, -0.0113525, ..., 0.00210571,\n",
       "              0.00537109, 0.00224304],\n",
       "             ...,\n",
       "             [0.00787354, -0.000789642, -0.00671387, ..., -0.00726318,\n",
       "              0.00402832, 0.00125122],\n",
       "             [0.0169678, -0.00531006, -0.00509644, ..., 0.0155029,\n",
       "              0.00631714, 0.0100098],\n",
       "             [0.0088501, 0.0098877, -0.015625, ..., -0.0334473, -0.0201416,\n",
       "              0.0137329]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.000261307, -0.000207901, 0.0110474, ..., -0.0218506,\n",
       "             -0.0184326, -0.00034523],\n",
       "            [0.00430298, -0.00628662, -0.00927734, ..., 0.0112305,\n",
       "             0.00518799, 0.0131836],\n",
       "            [0.0112305, -0.00312805, -0.0062561, ..., -0.00334167,\n",
       "             0.00405884, 0.00576782],\n",
       "            ...,\n",
       "            [-0.00111389, 0.000934601, -0.010498, ..., 0.0136719,\n",
       "             -0.00805664, 0.00714111],\n",
       "            [0.0050354, -0.0147095, -0.00219727, ..., 0.0273438, 0.024292,\n",
       "             -0.0187988],\n",
       "            [-0.00326538, 0.0119629, 0.00909424, ..., 0.00717163,\n",
       "             -0.0153198, -0.00216675]],\n",
       "    \n",
       "           [[-0.00340271, -0.00613403, 0.0067749, ..., -0.0206299,\n",
       "             -0.00463867, 0.00546265],\n",
       "            [0.00382996, -0.00231934, -0.00714111, ..., -0.010376,\n",
       "             -0.00094986, -0.00354004],\n",
       "            [-0.00104523, -4.43459e-05, -0.003479, ..., -0.00765991,\n",
       "             0.0175781, -0.00595093],\n",
       "            ...,\n",
       "            [-0.00604248, -0.00735474, -0.00723267, ..., 0.0310059,\n",
       "             -0.00854492, 0.026123],\n",
       "            [0.0196533, -0.00601196, -0.00872803, ..., 0.00250244,\n",
       "             -0.00509644, 0.0111694],\n",
       "            [0.00231934, -0.00762939, -0.00343323, ..., 0.0112305,\n",
       "             0.00616455, -0.0108643]],\n",
       "    \n",
       "           [[0.0088501, 0.0118408, 0.00823975, ..., 0.00386047, 0.006073,\n",
       "             -0.0119629],\n",
       "            [0.00805664, -0.0114746, -0.0127563, ..., 0.00765991, 0.0136108,\n",
       "             0.00558472],\n",
       "            [-0.00338745, -0.0132446, 0.00836182, ..., 0.0133667,\n",
       "             -0.00601196, 0.00872803],\n",
       "            ...,\n",
       "            [-0.00283813, -0.00297546, 0.0130005, ..., -0.0213623,\n",
       "             -0.0117798, 0.00325012],\n",
       "            [0.0180664, -0.00158691, -0.00201416, ..., -0.0101318,\n",
       "             -0.00463867, 0.0037384],\n",
       "            [-0.00337219, -0.00744629, -0.0187988, ..., -0.00872803,\n",
       "             0.00288391, -0.0012207]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0185547, -0.0125122, -0.012085, ..., 0.00185394, -0.00714111,\n",
       "             -0.0159912],\n",
       "            [-0.00613403, -0.00582886, 0.00601196, ..., 0.00331116,\n",
       "             -0.0112305, -0.0161133],\n",
       "            [0.00689697, 0.0098877, -0.0107422, ..., 0.00285339, -0.0090332,\n",
       "             0.00350952],\n",
       "            ...,\n",
       "            [0.00741577, -0.0178223, 0.00427246, ..., -0.00662231,\n",
       "             0.00753784, -0.012146],\n",
       "            [-0.0197754, -0.00982666, 0.0065918, ..., 0.0163574,\n",
       "             -0.00576782, 0.00723267],\n",
       "            [-0.00582886, 0.019165, -0.000728607, ..., 0.00227356,\n",
       "             0.0113525, 0.0272217]],\n",
       "    \n",
       "           [[0.000717163, -0.00512695, 0.000724792, ..., -0.0159912,\n",
       "             -0.0155029, -0.00958252],\n",
       "            [0.00445557, -0.00250244, -0.00159454, ..., 0.00311279,\n",
       "             -0.00543213, -0.0180664],\n",
       "            [0.000235558, 0.00363159, 0.000339508, ..., 0.0106201,\n",
       "             0.00952148, 0.001091],\n",
       "            ...,\n",
       "            [-0.00244141, -0.00704956, 0.00476074, ..., -0.0534668,\n",
       "             -0.00582886, -0.0228271],\n",
       "            [0.0020752, 0.0124512, -0.00921631, ..., -0.0351562, -0.0495605,\n",
       "             -0.0103149],\n",
       "            [0.00215149, 0.00215149, 0.000904083, ..., 0.0133667,\n",
       "             0.00335693, -0.00108337]],\n",
       "    \n",
       "           [[0.00271606, -0.0090332, 0.0240479, ..., 0.019043, -0.00230408,\n",
       "             -0.0123901],\n",
       "            [-0.00286865, 0.00680542, -0.00144958, ..., 0.0197754,\n",
       "             -0.00276184, -0.00717163],\n",
       "            [0.00769043, 0.00227356, -0.00915527, ..., 0.000222206,\n",
       "             0.000717163, -0.012085],\n",
       "            ...,\n",
       "            [-0.00164795, 0.000495911, 0.0119629, ..., -0.0281982,\n",
       "             -0.0137939, -0.0159912],\n",
       "            [-0.00357056, 0.0178223, -0.00442505, ..., -0.00056076,\n",
       "             -0.00878906, -0.0184326],\n",
       "            [-0.00411987, 0.00123596, -0.00259399, ..., -0.000724792,\n",
       "             0.00958252, 0.0164795]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.0139771, 0.0163574, 0.0174561, ..., -0.00169373, 0.00854492,\n",
       "            -0.0071106],\n",
       "           [-0.00231934, -0.0141602, 0.00576782, ..., -0.00494385,\n",
       "            -0.010437, 0.00291443],\n",
       "           [-0.00075531, 0.00628662, 0.0078125, ..., 0.000728607,\n",
       "            0.00117493, 0.0101318],\n",
       "           ...,\n",
       "           [0.0114746, -0.00521851, 0.000671387, ..., -0.00726318,\n",
       "            -0.00830078, -0.0019455],\n",
       "           [-0.00778198, 0.00527954, 0.0174561, ..., 0.00139618,\n",
       "            -0.0166016, -0.00897217],\n",
       "           [-0.00543213, -0.0240479, -0.00119781, ..., -0.00897217,\n",
       "            -0.0136719, -0.00482178]],\n",
       "   \n",
       "          [[1.57356e-05, -0.0124512, 0.010498, ..., 0.00263977, 0.00396729,\n",
       "            -0.0078125],\n",
       "           [-0.00610352, -0.00257874, -0.00267029, ..., 0.00823975,\n",
       "            0.00732422, 0.00619507],\n",
       "           [-0.00122833, -0.00509644, -0.00726318, ..., -0.0112305,\n",
       "            0.00332642, 0.013916],\n",
       "           ...,\n",
       "           [-0.0098877, -0.00463867, -0.000675201, ..., -0.0055542,\n",
       "            -0.015564, 0.00616455],\n",
       "           [0.000265121, -0.00506592, -0.00549316, ..., 0.00738525,\n",
       "            -0.00300598, 0.000930786],\n",
       "           [4.12464e-05, -0.000762939, -0.00276184, ..., -0.0153198,\n",
       "            0.00215149, 0.00515747]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00463867, 0.00128174, 0.00817871, ..., 0.00216675, 0.0055542,\n",
       "           0.00386047],\n",
       "          [-0.00854492, -0.00830078, -0.00212097, ..., -0.00860596,\n",
       "           -0.00668335, 0.00466919],\n",
       "          [0.0016861, -0.0114136, 0.00842285, ..., -0.00976562, -0.00537109,\n",
       "           0.00144958],\n",
       "          ...,\n",
       "          [-0.00927734, 0.0125732, -0.0014267, ..., -0.00454712, 0.00576782,\n",
       "           -0.00405884],\n",
       "          [-0.00521851, 0.0011673, -0.00460815, ..., 0.00318909, 0.00248718,\n",
       "           -0.00146484],\n",
       "          [-0.0196533, 0.00497437, 0.00393677, ..., -0.00262451,\n",
       "           -0.00927734, 0.00732422]], dtype=bfloat16), a=Array([[ 0.01047093,  0.01922145, -0.01181239, ...,  0.0187807 ,\n",
       "           -0.002852  ,  0.01409159],\n",
       "          [-0.01944142,  0.00886716, -0.00052842, ..., -0.02301286,\n",
       "            0.00416193, -0.00264629]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([-0.507812, -0.46875, -0.466797, ..., -0.503906, 0.102539,\n",
       "          -0.498047], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([-0.0354004, 0.0598145, 0.043457, ..., -0.202148, 0.308594,\n",
       "          0.113281], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.648438, 0.589844, 0.640625, ..., 1.27344, 0.229492, 0.5625],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.498047, 0.570312, 0.535156, ..., 1.22656, 0.361328, 0.462891],      dtype=bfloat16)}},\n",
       " 'layer_10': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00695801, -0.00424194, 0.000801086, ..., 0.015625,\n",
       "             0.00854492, 0.0179443],\n",
       "            [-0.0110474, -0.00460815, 0.00842285, ..., -0.00708008,\n",
       "             0.0187988, -0.0118408],\n",
       "            [0.0228271, 0.0130005, 0.0062561, ..., 0.000766754, 0.0027771,\n",
       "             -0.00372314],\n",
       "            ...,\n",
       "            [0.00772095, 0.0185547, -0.00872803, ..., 0.0100098, 0.00860596,\n",
       "             0.00500488],\n",
       "            [0.0100708, 0.00439453, 0.0123291, ..., 0.00958252, 0.00656128,\n",
       "             -0.0133057],\n",
       "            [0.00732422, 0.0090332, 0.0167236, ..., 0.00343323, 0.0111694,\n",
       "             -0.00653076]],\n",
       "    \n",
       "           [[-0.000923157, -0.00344849, -0.00476074, ..., 0.0111694,\n",
       "             -0.0140381, -0.0224609],\n",
       "            [0.0256348, 0.0132446, 0.00668335, ..., 0.00488281, 0.0103149,\n",
       "             -0.0144653],\n",
       "            [0.00337219, -0.0115967, -0.029541, ..., -0.00634766,\n",
       "             -0.00418091, 0.00292969],\n",
       "            ...,\n",
       "            [-0.0143433, -0.00698853, -0.00872803, ..., -0.0098877,\n",
       "             -0.0327148, 0.0142212],\n",
       "            [-0.00364685, 0.00585938, 0.00686646, ..., 0.00221252,\n",
       "             0.00842285, 0.00897217],\n",
       "            [-0.0262451, -0.0274658, 0.00500488, ..., -0.00872803,\n",
       "             -0.015625, 0.000396729]],\n",
       "    \n",
       "           [[-0.0245361, -0.00127411, -0.00680542, ..., -0.00424194,\n",
       "             0.000900269, -0.00370789],\n",
       "            [-0.0057373, -0.00273132, -0.00178528, ..., 0.0106812,\n",
       "             0.0137939, 0.00860596],\n",
       "            [0.0124512, 0.00610352, 0.0090332, ..., -0.00257874, 0.00390625,\n",
       "             -0.00393677],\n",
       "            ...,\n",
       "            [-0.00463867, -0.0180664, -0.0108643, ..., 0.0162354,\n",
       "             -0.0130615, 0.00952148],\n",
       "            [0.00482178, 0.0245361, -0.0180664, ..., 0.027832, -0.0217285,\n",
       "             -0.0202637],\n",
       "            [0.00118256, -0.000305176, 0.00315857, ..., -0.00442505,\n",
       "             0.0170898, 0.00164795]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00622559, 0.00775146, 0.0043335, ..., -0.0152588, 0.0032196,\n",
       "             0.00643921],\n",
       "            [-0.00224304, 0.0122681, 0.00650024, ..., -0.0212402,\n",
       "             -0.00488281, -0.0078125],\n",
       "            [0.0114746, -0.0148315, -0.00909424, ..., 0.00805664,\n",
       "             0.000831604, -0.00909424],\n",
       "            ...,\n",
       "            [-0.00582886, 0.00213623, 0.0090332, ..., -0.00143433,\n",
       "             0.00241089, 0.00288391],\n",
       "            [0.00448608, -0.000545502, -0.00312805, ..., 0.00424194,\n",
       "             -0.00460815, 0.0142212],\n",
       "            [-0.000389099, 0.0195312, -0.00518799, ..., 0.00390625,\n",
       "             -0.00823975, 0.0306396]],\n",
       "    \n",
       "           [[-0.00646973, -0.000934601, -0.000629425, ..., -0.00427246,\n",
       "             -0.00576782, -0.0170898],\n",
       "            [-0.00107574, -0.00518799, 0.00242615, ..., -0.0161133,\n",
       "             0.0126953, -0.000610352],\n",
       "            [-0.019165, -0.0169678, -7.82013e-05, ..., -0.00396729,\n",
       "             -0.00379944, 0.00485229],\n",
       "            ...,\n",
       "            [0.0174561, 0.00695801, 0.00500488, ..., 0.00276184, -0.0137939,\n",
       "             -0.00982666],\n",
       "            [-0.0030365, -0.000789642, 0.00180817, ..., 0.0177002,\n",
       "             0.00897217, -0.00958252],\n",
       "            [0.00701904, 0.00521851, 0.0136108, ..., 0.0106812, -0.00830078,\n",
       "             -0.00665283]],\n",
       "    \n",
       "           [[-0.00595093, -0.00294495, -0.00613403, ..., -0.00448608,\n",
       "             -0.00250244, -0.0112915],\n",
       "            [-0.00231934, -0.010376, -0.0111084, ..., -0.00430298,\n",
       "             0.0194092, 0.00309753],\n",
       "            [-0.00769043, 0.00540161, 0.00370789, ..., -0.0134277,\n",
       "             0.0132446, 0.0108032],\n",
       "            ...,\n",
       "            [0.0106812, -0.00124359, -0.00564575, ..., 0.0145874,\n",
       "             -0.0172119, -0.0229492],\n",
       "            [-0.0167236, -0.00326538, -0.0106812, ..., 0.00488281,\n",
       "             0.0078125, 0.0201416],\n",
       "            [-0.0142212, -0.00488281, -0.0128174, ..., -0.0122681,\n",
       "             0.0134888, 0.0109253]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.000888824, -0.00115204, -0.000119209, ..., -0.00598145,\n",
       "              -0.00704956, 0.0197754],\n",
       "             [-0.00139618, 0.0198975, -0.00424194, ..., -0.00946045,\n",
       "              -0.00634766, 0.00515747],\n",
       "             [0.00215149, -0.000652313, 0.00964355, ..., 0.0142822,\n",
       "              -0.000282288, 0.00376892],\n",
       "             ...,\n",
       "             [0.00561523, -0.00582886, 0.00585938, ..., -0.00387573,\n",
       "              0.00805664, 0.00720215],\n",
       "             [-3.3617e-05, -0.00149536, -0.0098877, ..., 0.00952148,\n",
       "              0.00982666, -0.0148315],\n",
       "             [0.00927734, 0.0018692, -0.00598145, ..., -0.00402832,\n",
       "              -0.00405884, 0.00306702]],\n",
       "    \n",
       "            [[-0.00250244, 0.00183868, 0.000999451, ..., 0.0185547,\n",
       "              -0.0132446, 0.00564575],\n",
       "             [-0.00579834, 0.0150146, -0.0102539, ..., 0.0148926,\n",
       "              0.0184326, 0.0109863],\n",
       "             [-0.00346375, -0.00491333, -0.0148315, ..., 0.00216675,\n",
       "              0.0159912, 0.0118408],\n",
       "             ...,\n",
       "             [0.0106812, -0.00173187, -0.0045166, ..., 0.0114746,\n",
       "              -0.0281982, 0.00622559],\n",
       "             [0.00215149, -0.0157471, 0.0111084, ..., 0.000747681,\n",
       "              -0.000208855, 0.0183105],\n",
       "             [0.012207, -0.000537872, -0.0122681, ..., -0.019043,\n",
       "              -0.0088501, 0.00274658]],\n",
       "    \n",
       "            [[-0.00680542, -0.000667572, 0.00147247, ..., 0.0233154,\n",
       "              -0.0105591, -0.0136108],\n",
       "             [0.00102997, -0.000371933, -0.000156403, ..., -0.00671387,\n",
       "              -0.012207, -0.00579834],\n",
       "             [-0.00174713, 0.00285339, -0.0109863, ..., 0.00173187,\n",
       "              -0.0030365, -0.00588989],\n",
       "             ...,\n",
       "             [0.00588989, 0.00421143, -0.00695801, ..., -0.0220947,\n",
       "              0.00692749, -0.00209045],\n",
       "             [-0.00148773, -0.00680542, 0.00331116, ..., -0.0174561,\n",
       "              -0.0128174, 0.00595093],\n",
       "             [-0.00497437, 0.00405884, -0.00349426, ..., 0.00958252,\n",
       "              0.000218391, -2.31266e-05]],\n",
       "    \n",
       "            [[-0.00592041, -0.00367737, -0.00209045, ..., 0.0373535,\n",
       "              -0.0126953, 0.0240479],\n",
       "             [-0.00389099, -0.0015564, 0.00177765, ..., -0.006073,\n",
       "              0.00102234, 0.0222168],\n",
       "             [0.00753784, 0.00314331, -0.00708008, ..., 0.0163574,\n",
       "              -0.0129395, -0.00823975],\n",
       "             ...,\n",
       "             [-0.0108643, 0.00601196, 0.00283813, ..., 0.0120239,\n",
       "              -0.0228271, 0.0361328],\n",
       "             [0.00291443, -0.00253296, 0.00561523, ..., 0.0279541,\n",
       "              0.0147095, -0.022583],\n",
       "             [-0.0102539, -0.00582886, -0.0172119, ..., 0.00393677,\n",
       "              0.00463867, 0.0118408]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00241089, -0.0262451, -0.00878906, ..., 0.00750732,\n",
       "              -0.00376892, 0.0220947],\n",
       "             [-0.00102997, 0.00338745, 0.00891113, ..., 0.000117302,\n",
       "              -0.00540161, 0.0185547],\n",
       "             [0.00708008, -0.00567627, 0.0354004, ..., -0.00588989,\n",
       "              -0.00830078, -0.0214844],\n",
       "             ...,\n",
       "             [-0.00848389, 0.000541687, 0.0332031, ..., 0.00982666,\n",
       "              -0.00376892, 0.0187988],\n",
       "             [0.0133057, 0.00769043, -0.0214844, ..., 0.0184326, 0.0019989,\n",
       "              0.00854492],\n",
       "             [0.0272217, 0.0114746, -0.00708008, ..., -0.0219727,\n",
       "              0.0090332, -0.00872803]],\n",
       "    \n",
       "            [[0.00775146, -0.00241089, -0.00799561, ..., 0.0116577,\n",
       "              0.00442505, -0.0209961],\n",
       "             [-0.0224609, 0.00732422, 1.50204e-05, ..., -0.0170898,\n",
       "              0.0184326, 0.0247803],\n",
       "             [0.00610352, 0.0100098, 0.0297852, ..., 0.0178223, 0.00811768,\n",
       "              0.00976562],\n",
       "             ...,\n",
       "             [0.0159912, -0.00683594, -0.00909424, ..., 0.00454712,\n",
       "              0.00817871, 0.0078125],\n",
       "             [-0.00361633, 0.00576782, -0.00159454, ..., -0.0222168,\n",
       "              -0.0212402, -0.0147705],\n",
       "             [-0.000720978, -0.00509644, -0.00283813, ..., -0.00500488,\n",
       "              -0.00263977, 0.00726318]],\n",
       "    \n",
       "            [[0.00732422, -0.00195312, 0.00349426, ..., 0.0140381,\n",
       "              0.000766754, -0.0158691],\n",
       "             [0.00854492, 0.00396729, 0.00689697, ..., 0.00228882,\n",
       "              -0.00309753, -0.00178528],\n",
       "             [0.0168457, 0.02771, -0.00346375, ..., -0.00171661,\n",
       "              -0.0211182, -0.00805664],\n",
       "             ...,\n",
       "             [0.0272217, -0.0118408, 0.010498, ..., 0.000434875,\n",
       "              0.00190735, 0.00564575],\n",
       "             [-0.0039978, 0.0106812, -0.00402832, ..., 0.00209045,\n",
       "              -0.0168457, -0.00178528],\n",
       "             [-0.0098877, -0.0246582, -0.0354004, ..., -0.0206299,\n",
       "              0.00897217, 0.0172119]],\n",
       "    \n",
       "            [[-0.0136108, 0.00723267, -0.0159912, ..., -4.43459e-05,\n",
       "              -1.2219e-05, 0.00527954],\n",
       "             [-0.0134277, 0.0050354, 0.0151367, ..., 0.0212402,\n",
       "              -0.00320435, -0.0170898],\n",
       "             [0.0114746, -0.00674438, 0.00457764, ..., -0.00137329,\n",
       "              -0.00848389, -0.00170135],\n",
       "             ...,\n",
       "             [-0.00038147, -0.00759888, -0.00570679, ..., 0.00288391,\n",
       "              -0.010498, 0.00247192],\n",
       "             [0.00836182, 0.0119019, 0.012207, ..., -0.00982666,\n",
       "              0.00107574, -0.00738525],\n",
       "             [0.00234985, 0.00878906, 0.000202179, ..., 0.00540161,\n",
       "              0.00753784, -0.0129395]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.0137329, 0.0100708, -0.00680542, ..., -0.0101929, 0.00154114,\n",
       "             -0.00592041],\n",
       "            [-0.000583649, 0.0131836, -0.00335693, ..., 0.0147705,\n",
       "             0.00411987, 0.00376892],\n",
       "            [0.00830078, -0.0103149, -0.00598145, ..., -0.0155029,\n",
       "             -0.00616455, -0.00817871],\n",
       "            ...,\n",
       "            [0.0109253, -0.000679016, -0.0152588, ..., -0.000354767,\n",
       "             -0.0145874, 0.00390625],\n",
       "            [-0.00387573, -0.00141907, 0.00161743, ..., -0.001091,\n",
       "             -0.015625, 0.0100098],\n",
       "            [-0.00259399, 0.00230408, 0.00427246, ..., -0.000469208,\n",
       "             -0.00866699, -0.00439453]],\n",
       "    \n",
       "           [[0.00933838, 0.00170898, 9.05991e-05, ..., 0.0100098,\n",
       "             0.00747681, 0.0116577],\n",
       "            [0.00848389, 0.00732422, -0.00720215, ..., 0.00262451,\n",
       "             -0.0186768, 0.0067749],\n",
       "            [-0.00254822, 0.00527954, 0.00218201, ..., 0.020874, 0.00265503,\n",
       "             0.0065918],\n",
       "            ...,\n",
       "            [-0.0043335, -0.000183105, 0.00759888, ..., -0.00405884,\n",
       "             -3.30806e-06, -0.00448608],\n",
       "            [0.013916, -0.00209045, -0.00448608, ..., 0.00927734,\n",
       "             0.00241089, 0.0113525],\n",
       "            [-0.00393677, -0.00376892, 0.00576782, ..., -0.000740051,\n",
       "             0.00817871, 0.00823975]],\n",
       "    \n",
       "           [[0.0057373, 0.0240479, 0.0174561, ..., -0.0125732, -0.00302124,\n",
       "             -0.0115356],\n",
       "            [-0.0100708, -0.000305176, 0.00518799, ..., 0.00585938,\n",
       "             -0.00662231, 0.00221252],\n",
       "            [-0.00248718, 0.0161133, 0.000222206, ..., 0.000610352,\n",
       "             0.000530243, -0.00131989],\n",
       "            ...,\n",
       "            [0.00138855, -0.00291443, -0.00546265, ..., 0.00250244,\n",
       "             0.017334, -0.0032196],\n",
       "            [0.032959, -0.00692749, -0.0022583, ..., 0.0218506, -0.00692749,\n",
       "             -0.00154114],\n",
       "            [-0.0163574, 0.00408936, -0.00811768, ..., -0.0136719,\n",
       "             0.000583649, -0.0114746]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00723267, 0.000976562, -0.00463867, ..., 0.00610352,\n",
       "             -0.00259399, -0.024292],\n",
       "            [0.0030365, 0.00405884, -0.0112305, ..., 0.00610352, -0.0336914,\n",
       "             -0.0354004],\n",
       "            [-0.00231934, 0.000267029, -0.00344849, ..., 0.00946045,\n",
       "             -0.0120239, -0.00300598],\n",
       "            ...,\n",
       "            [-0.00128174, -0.00604248, -0.00579834, ..., 0.0020752,\n",
       "             -0.00056839, -0.0344238],\n",
       "            [-0.0057373, 0.00221252, -0.00408936, ..., 0.0180664, -0.032959,\n",
       "             0.000202179],\n",
       "            [0.00915527, -0.00769043, -0.00149536, ..., -0.0111084,\n",
       "             -0.00196838, -0.0110474]],\n",
       "    \n",
       "           [[0.0106201, -0.000976562, 0.00958252, ..., 0.00732422,\n",
       "             -0.00848389, 0.0103149],\n",
       "            [-0.00744629, 0.000915527, -0.00775146, ..., 0.0154419,\n",
       "             0.00759888, 0.0395508],\n",
       "            [-0.000602722, -0.00506592, 0.00427246, ..., -0.000242233,\n",
       "             0.0162354, 0.0245361],\n",
       "            ...,\n",
       "            [-0.00421143, 0.00750732, 0.00616455, ..., 0.03125, -0.00515747,\n",
       "             0.00121307],\n",
       "            [-0.00128174, 0.00643921, 0.00157928, ..., 0.00811768,\n",
       "             0.0123291, -0.0332031],\n",
       "            [0.00138092, -0.00387573, -0.00262451, ..., 0.00341797,\n",
       "             0.034668, -0.0349121]],\n",
       "    \n",
       "           [[0.00314331, -0.00454712, 0.00147247, ..., 0.0120239, -0.020752,\n",
       "             -0.0111694],\n",
       "            [0.0258789, -0.0181885, -0.0090332, ..., 0.0123291, -0.017334,\n",
       "             0.0214844],\n",
       "            [0.00439453, -0.00408936, -0.00291443, ..., 0.0103149,\n",
       "             -0.0101929, -0.00178528],\n",
       "            ...,\n",
       "            [0.00469971, 0.00753784, 0.0175781, ..., 0.0202637, 0.00421143,\n",
       "             0.0230713],\n",
       "            [-0.0235596, 0.00141907, 0.0131226, ..., 0.0137939, -0.00153351,\n",
       "             -0.0167236],\n",
       "            [0.00616455, 0.0177002, 0.0111084, ..., -0.0219727, -0.00354004,\n",
       "             -0.0117798]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00218201, 0.00506592, -0.00318909, ..., 0.0202637,\n",
       "            0.00619507, 0.010376],\n",
       "           [-0.00244141, 0.00582886, 0.00346375, ..., -0.000448227,\n",
       "            0.00137329, -0.0037384],\n",
       "           [-0.0022583, -0.00604248, -0.00805664, ..., 0.0140991,\n",
       "            0.000572205, -0.0071106],\n",
       "           ...,\n",
       "           [-0.0155029, -0.0098877, -1.42306e-06, ..., -0.00787354,\n",
       "            -0.00848389, -0.00393677],\n",
       "           [0.00248718, -0.00512695, 0.0114136, ..., 0.00592041,\n",
       "            -0.00283813, -0.00646973],\n",
       "           [-0.00364685, 0.0101318, 0.0057373, ..., 0.00601196,\n",
       "            -0.00062561, -0.00466919]],\n",
       "   \n",
       "          [[0.0136108, -0.00836182, 0.00720215, ..., -0.00811768,\n",
       "            0.0100708, -0.00167084],\n",
       "           [-0.00643921, -0.00262451, -0.00138855, ..., -0.00260925,\n",
       "            -0.0019455, 0.0130615],\n",
       "           [0.00735474, 0.00454712, 0.00595093, ..., 0.00579834,\n",
       "            0.00527954, -0.00491333],\n",
       "           ...,\n",
       "           [-0.00454712, 0.0144043, 0.00221252, ..., -0.0020752, 0.0105591,\n",
       "            -0.00592041],\n",
       "           [-0.0100708, -0.00717163, 0.010376, ..., 0.00112152, 0.0032196,\n",
       "            0.00270081],\n",
       "           [0.00445557, 0.00842285, -0.0100098, ..., -0.0090332,\n",
       "            0.00744629, 0.0139771]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.0102539, 0.0057373, -0.00534058, ..., 0.0134277, 0.00075531,\n",
       "           0.00314331],\n",
       "          [1.01924e-05, 0.0125732, -0.00222778, ..., -0.00314331,\n",
       "           -0.00213623, 0.0057373],\n",
       "          [0.00482178, -0.0131836, 0.000274658, ..., 0.00952148, 0.00640869,\n",
       "           -0.00909424],\n",
       "          ...,\n",
       "          [-0.00463867, -0.0183105, 0.00750732, ..., 0.00221252, 0.0090332,\n",
       "           -0.0150146],\n",
       "          [0.00631714, -0.00842285, 0.00151825, ..., 0.0027771, 0.000957489,\n",
       "           -0.00196838],\n",
       "          [-0.0111694, 0.0111084, 0.00415039, ..., -0.00241089, -2.2769e-05,\n",
       "           0.00497437]], dtype=bfloat16), a=Array([[ 0.00627691, -0.01385751, -0.00372067, ..., -0.01245145,\n",
       "           -0.01636037,  0.00584008],\n",
       "          [-0.01115024, -0.00439675,  0.00728602, ..., -0.01480319,\n",
       "            0.01306054,  0.00127973]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.244141, 0.330078, 0.421875, ..., 0.183594, 0.165039, 0.129883],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.496094, 0.535156, 0.570312, ..., 0.429688, 0.511719, 0.371094],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.699219, 0.773438, 0.65625, ..., 0.820312, 0.0186768, 0.671875],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.12793, 0.229492, 0.152344, ..., 0.227539, -0.212891, 0.125977],      dtype=bfloat16)}},\n",
       " 'layer_11': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0011673, -0.0067749, -0.00610352, ..., 0.0169678, -0.0100098,\n",
       "             0.0117188],\n",
       "            [0.0145874, -0.00564575, -0.0162354, ..., -0.0152588,\n",
       "             0.00692749, 0.0102539],\n",
       "            [-0.0109863, -0.00247192, -0.0133057, ..., 0.00268555,\n",
       "             0.00598145, -0.00787354],\n",
       "            ...,\n",
       "            [0.0275879, -0.000671387, -0.0110474, ..., -0.0108643,\n",
       "             -0.0098877, 0.0137939],\n",
       "            [0.0100708, 0.0010376, -0.00230408, ..., 0.00267029, 0.00460815,\n",
       "             -0.00653076],\n",
       "            [0.00588989, 0.0012207, 0.010376, ..., 0.00439453, 0.00613403,\n",
       "             0.0114746]],\n",
       "    \n",
       "           [[-0.0151367, 0.00233459, -0.0105591, ..., 0.000762939,\n",
       "             -0.00720215, 0.0201416],\n",
       "            [-0.0126343, 0.0133667, -0.0169678, ..., 0.00436401, 0.00325012,\n",
       "             0.00848389],\n",
       "            [0.00509644, -0.0043335, 0.0269775, ..., 0.00509644, 0.00540161,\n",
       "             0.00164795],\n",
       "            ...,\n",
       "            [0.00756836, 0.012207, -0.0133057, ..., -0.000736237,\n",
       "             -0.00976562, -0.00750732],\n",
       "            [-0.0101318, 0.00363159, -0.0219727, ..., -0.0179443,\n",
       "             0.00946045, 0.0238037],\n",
       "            [-0.00872803, 0.0186768, 0.0114136, ..., -0.0354004,\n",
       "             -0.000720978, 0.00338745]],\n",
       "    \n",
       "           [[-0.00063324, -0.0170898, 0.00616455, ..., -0.0142822,\n",
       "             0.0004673, -0.00335693],\n",
       "            [0.0149536, 0.00564575, -0.00375366, ..., 0.0144653, 0.00546265,\n",
       "             -0.00772095],\n",
       "            [-0.00476074, -0.00933838, 0.0157471, ..., 0.0103149, 0.0107422,\n",
       "             0.0169678],\n",
       "            ...,\n",
       "            [-0.00357056, 0.00354004, -0.000579834, ..., 0.00631714,\n",
       "             0.00952148, 0.0098877],\n",
       "            [-0.00552368, -0.00212097, 0.00466919, ..., 0.00289917,\n",
       "             0.00138855, 0.000522614],\n",
       "            [0.0111084, 0.000406265, 0.00370789, ..., 0.00265503,\n",
       "             0.00173187, 0.00653076]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00708008, 0.0113525, -0.0205078, ..., 0.000201225,\n",
       "             0.0201416, -0.00540161],\n",
       "            [0.0037384, 0.00094986, 0.0131836, ..., -0.00424194, 0.015625,\n",
       "             -0.00848389],\n",
       "            [-0.00897217, -0.00297546, 0.00421143, ..., -0.00704956,\n",
       "             0.00254822, -0.00769043],\n",
       "            ...,\n",
       "            [0.0014801, -0.0170898, -0.00411987, ..., 0.00933838,\n",
       "             0.00726318, 0.00043869],\n",
       "            [0.0116577, 0.00224304, 0.0151978, ..., 0.00209045, 0.0161133,\n",
       "             -0.00970459],\n",
       "            [-0.00315857, 0.0124512, -0.00515747, ..., 0.00227356,\n",
       "             -0.0146484, 0.00201416]],\n",
       "    \n",
       "           [[-0.0128784, 0.000854492, 0.00188446, ..., -0.0045166,\n",
       "             -0.00288391, 0.0115356],\n",
       "            [-0.0101929, -0.00521851, -0.00167847, ..., 0.00714111,\n",
       "             0.0115356, -0.0164795],\n",
       "            [0.00866699, -0.00424194, -0.00314331, ..., -0.00117493,\n",
       "             0.00549316, -0.0107422],\n",
       "            ...,\n",
       "            [-0.015625, 0.00772095, 9.25064e-05, ..., -0.00854492,\n",
       "             0.000720978, -0.00668335],\n",
       "            [-0.0213623, -0.00352478, 0.0129395, ..., -0.00964355,\n",
       "             -0.00793457, -0.00787354],\n",
       "            [-0.0198975, 0.00830078, -0.00245667, ..., -0.00646973,\n",
       "             0.00015831, -0.0164795]],\n",
       "    \n",
       "           [[0.000434875, -0.000946045, -0.00209045, ..., -0.0114746,\n",
       "             -0.0113525, -0.00698853],\n",
       "            [0.0108032, -0.0169678, 0.006073, ..., 0.0129395, 0.00297546,\n",
       "             0.00897217],\n",
       "            [0.00202942, 0.0112305, -0.000598907, ..., -0.00601196,\n",
       "             -0.0195312, -0.00253296],\n",
       "            ...,\n",
       "            [0.0145874, 0.000534058, 0.0178223, ..., 0.0107422, 0.0100708,\n",
       "             0.0192871],\n",
       "            [-0.00762939, 0.00430298, 0.00756836, ..., -0.00241089,\n",
       "             -0.0268555, 0.0142212],\n",
       "            [0.0071106, 0.00140381, 0.000144958, ..., -0.00668335,\n",
       "             0.00643921, 0.000705719]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00527954, -0.0098877, -0.0153809, ..., 0.00271606,\n",
       "              0.00152588, -0.00772095],\n",
       "             [0.00215149, -0.00830078, 0.00683594, ..., -0.00527954,\n",
       "              0.0202637, 0.00567627],\n",
       "             [-0.00964355, 0.00689697, 0.00286865, ..., 0.012146,\n",
       "              -0.0157471, -0.00769043],\n",
       "             ...,\n",
       "             [0.00318909, 0.000247955, 0.00897217, ..., -0.0429688,\n",
       "              0.00564575, -7.53403e-05],\n",
       "             [-0.0071106, -0.00253296, 0.00515747, ..., -0.0134277,\n",
       "              0.0196533, 0.0109253],\n",
       "             [0.00521851, -0.0159912, 0.00112152, ..., -0.000356674,\n",
       "              -0.0142822, 0.000455856]],\n",
       "    \n",
       "            [[0.00296021, 0.000417709, 0.00402832, ..., -0.00427246,\n",
       "              -0.0088501, 0.00297546],\n",
       "             [0.00247192, -0.00302124, 0.000368118, ..., -0.00393677,\n",
       "              -0.00485229, 0.00811768],\n",
       "             [0.00157166, -0.00799561, 0.00408936, ..., -0.00141144,\n",
       "              -0.00442505, 0.0279541],\n",
       "             ...,\n",
       "             [0.00087738, -0.00370789, 0.00640869, ..., 0.00479126,\n",
       "              0.000518799, -0.019165],\n",
       "             [-0.00218201, -0.00405884, -0.0133057, ..., 0.00521851,\n",
       "              -0.00445557, -0.00634766],\n",
       "             [-0.00634766, 0.000486374, -0.00213623, ..., -0.0098877,\n",
       "              -0.0224609, -0.0130005]],\n",
       "    \n",
       "            [[-0.0014267, 0.00744629, 0.00389099, ..., -0.00976562,\n",
       "              0.0105591, -0.0132446],\n",
       "             [0.000169754, 0.00245667, 0.00312805, ..., 0.00331116,\n",
       "              0.000366211, -0.00854492],\n",
       "             [-0.0130005, -0.00769043, -0.00340271, ..., -0.000606537,\n",
       "              -0.0131226, 0.0133667],\n",
       "             ...,\n",
       "             [-0.013855, 0.00158691, -0.00376892, ..., 0.00970459,\n",
       "              -0.00326538, -0.00402832],\n",
       "             [-0.0166016, -0.00375366, -0.013855, ..., -0.00683594,\n",
       "              -0.00704956, -0.00640869],\n",
       "             [0.00958252, -0.00830078, 0.0230713, ..., -0.0108643,\n",
       "              -0.0147705, -0.0194092]],\n",
       "    \n",
       "            [[-0.00352478, -0.000984192, -0.000356674, ..., 0.0108643,\n",
       "              -0.0230713, 0.00756836],\n",
       "             [0.000827789, 0.00561523, 0.00393677, ..., -0.0549316,\n",
       "              -0.00315857, 0.00439453],\n",
       "             [-0.00131226, 0.00567627, -0.00653076, ..., -0.0170898,\n",
       "              0.015625, -0.0170898],\n",
       "             ...,\n",
       "             [0.00289917, -0.0115967, -0.00352478, ..., 0.0166016,\n",
       "              0.0137329, 0.00396729],\n",
       "             [-0.0137329, 0.00263977, 0.0043335, ..., -0.0349121,\n",
       "              -0.0373535, 0.0201416],\n",
       "             [-0.00170898, -0.000427246, -0.0013504, ..., -0.0236816,\n",
       "              0.00282288, 0.0055542]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00897217, -0.0170898, -0.000888824, ..., 0.00170898,\n",
       "              -0.0119019, 0.0174561],\n",
       "             [0.0101929, -0.00174713, 0.0114746, ..., 0.00674438,\n",
       "              0.00445557, 0.0128784],\n",
       "             [-0.0038147, 0.0189209, 0.019043, ..., 0.00588989,\n",
       "              -0.00485229, -0.000919342],\n",
       "             ...,\n",
       "             [-0.000175476, -0.00646973, 0.00726318, ..., -0.00248718,\n",
       "              0.00506592, -0.0249023],\n",
       "             [-0.00582886, -0.00860596, -0.00854492, ..., 0.00375366,\n",
       "              -0.0144653, 0.00382996],\n",
       "             [0.0203857, -0.0299072, 0.0322266, ..., -0.00382996,\n",
       "              -0.00473022, 0.0213623]],\n",
       "    \n",
       "            [[0.0115356, 0.0151978, 0.0035553, ..., -0.00628662, 0.0150146,\n",
       "              0.00613403],\n",
       "             [0.00909424, -0.00221252, 0.0101929, ..., -0.010376,\n",
       "              0.00230408, -0.00628662],\n",
       "             [0.0108032, 0.0227051, 0.00592041, ..., 0.00120544,\n",
       "              -0.0181885, -0.000579834],\n",
       "             ...,\n",
       "             [-0.00537109, -0.00540161, 0.0105591, ..., 0.00582886,\n",
       "              0.0118408, 0.00114441],\n",
       "             [-0.000705719, 0.00185394, 0.0222168, ..., -0.00592041,\n",
       "              -0.00421143, -0.0136108],\n",
       "             [-0.00497437, -0.0098877, 0.00946045, ..., -0.00271606,\n",
       "              0.0105591, 0.0108643]],\n",
       "    \n",
       "            [[0.00650024, 0.0139771, -0.0115967, ..., 0.012146, 0.0213623,\n",
       "              -0.0159912],\n",
       "             [0.0270996, -0.0106812, -0.00762939, ..., -0.0262451,\n",
       "              -0.00994873, 0.00735474],\n",
       "             [-0.0239258, 0.00686646, 0.0238037, ..., -0.015564, 0.0209961,\n",
       "              -0.0140991],\n",
       "             ...,\n",
       "             [-0.00285339, -0.0122681, -0.00604248, ..., -0.000541687,\n",
       "              -0.0098877, 0.00430298],\n",
       "             [0.00430298, 0.0220947, -0.000368118, ..., -0.0296631,\n",
       "              0.00683594, -0.0039978],\n",
       "             [0.0120239, -0.020874, -0.0129395, ..., -0.00878906,\n",
       "              -0.0217285, -0.0131836]],\n",
       "    \n",
       "            [[-0.000991821, -0.00872803, 0.0133057, ..., -0.00698853,\n",
       "              -0.0306396, -0.0124512],\n",
       "             [0.0090332, -0.00276184, 0.0110474, ..., 0.010376,\n",
       "              -0.00224304, 0.000134468],\n",
       "             [-0.000968933, -0.0071106, -0.000621796, ..., -0.00138855,\n",
       "              0.00671387, 0.00628662],\n",
       "             ...,\n",
       "             [-0.0157471, 0.0183105, 0.012207, ..., -0.0219727, 0.00241089,\n",
       "              -0.00448608],\n",
       "             [0.00270081, -0.0213623, 0.00297546, ..., -0.0168457,\n",
       "              -0.013916, 0.00854492],\n",
       "             [-0.00102234, 0.00164795, 0.000843048, ..., 0.0264893,\n",
       "              -0.0255127, 0.0130615]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00720215, 0.00402832, -0.00344849, ..., -0.0120239,\n",
       "             0.00436401, 0.0136108],\n",
       "            [-0.00476074, -0.00328064, -0.0050354, ..., -0.0107422,\n",
       "             0.0122681, -0.00233459],\n",
       "            [-0.00735474, -0.00799561, -0.00482178, ..., 0.00741577,\n",
       "             -0.00701904, 0.00236511],\n",
       "            ...,\n",
       "            [-0.0030365, -0.000530243, 0.0043335, ..., -0.0252686,\n",
       "             -0.019165, -0.017334],\n",
       "            [-0.00262451, 0.00909424, 0.00317383, ..., -0.00927734,\n",
       "             -0.0227051, 0.00738525],\n",
       "            [-0.010498, 0.00358582, -0.00227356, ..., -0.0240479, 0.0205078,\n",
       "             0.000444412]],\n",
       "    \n",
       "           [[0.00491333, -0.00405884, 0.00692749, ..., -0.0038147,\n",
       "             0.00138092, 0.00372314],\n",
       "            [0.00430298, -0.00909424, -0.0149536, ..., 0.00184631, 0.020874,\n",
       "             0.00585938],\n",
       "            [-0.0101318, 0.00107574, -0.00662231, ..., 0.0186768,\n",
       "             -0.00497437, -0.00509644],\n",
       "            ...,\n",
       "            [0.00482178, 0.0140991, -0.0113525, ..., -0.00279236,\n",
       "             -0.00270081, -0.0045166],\n",
       "            [-0.0113525, -0.00842285, -0.0216064, ..., 0.0155029,\n",
       "             -0.00927734, 0.0256348],\n",
       "            [-0.00415039, 0.00196838, -0.00210571, ..., 0.00469971,\n",
       "             0.019043, 0.0294189]],\n",
       "    \n",
       "           [[-0.000709534, 0.00524902, 0.00442505, ..., -0.0189209,\n",
       "             -0.00683594, 0.000387192],\n",
       "            [0.00933838, 0.0088501, 0.0072937, ..., -0.00619507, 0.00726318,\n",
       "             -0.00169373],\n",
       "            [0.00408936, -0.00518799, 0.00442505, ..., -0.0137329,\n",
       "             0.0146484, 0.00653076],\n",
       "            ...,\n",
       "            [0.00952148, 0.00167847, 0.0192871, ..., -0.00915527,\n",
       "             0.00909424, -0.00309753],\n",
       "            [-0.00601196, -0.0153198, -0.00221252, ..., 0.015564,\n",
       "             0.00418091, 0.00318909],\n",
       "            [0.00430298, 0.010498, 0.00198364, ..., -0.000534058,\n",
       "             0.00604248, 0.00227356]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00346375, -0.0105591, 0.00256348, ..., -0.00457764,\n",
       "             -0.00424194, -0.00683594],\n",
       "            [0.0142212, 0.00823975, -0.000892639, ..., -0.00747681,\n",
       "             -0.0112915, 0.0001688],\n",
       "            [0.00162506, -0.0119629, -0.00239563, ..., 0.0067749,\n",
       "             -0.0153809, -0.00384521],\n",
       "            ...,\n",
       "            [0.000417709, -0.00692749, 0.000587463, ..., -0.0129395,\n",
       "             -0.00570679, 0.0222168],\n",
       "            [-0.000117779, -0.0158691, 0.00408936, ..., 0.00488281,\n",
       "             0.00552368, -0.00799561],\n",
       "            [-0.00326538, 0.0125732, 0.0233154, ..., -0.0228271, 0.00714111,\n",
       "             0.0202637]],\n",
       "    \n",
       "           [[-0.0100708, 0.00125885, -0.00248718, ..., 0.0233154,\n",
       "             -0.0463867, 0.0162354],\n",
       "            [-0.0100708, -0.00349426, -0.00769043, ..., -0.0127563,\n",
       "             0.0196533, 0.00497437],\n",
       "            [-0.000843048, -5.29289e-05, -0.00631714, ..., -0.0177002,\n",
       "             -0.00312805, -0.00741577],\n",
       "            ...,\n",
       "            [0.00982666, 0.00346375, 0.00830078, ..., -0.0366211, 0.0112305,\n",
       "             -0.00817871],\n",
       "            [0.0144653, -0.00357056, 0.00106812, ..., -0.0134277,\n",
       "             -0.0297852, -0.00909424],\n",
       "            [0.006073, 0.00964355, 0.0108032, ..., 0.0228271, 0.00442505,\n",
       "             -0.0291748]],\n",
       "    \n",
       "           [[0.0123901, 0.00723267, -0.00393677, ..., -0.000968933,\n",
       "             -0.00964355, 0.0253906],\n",
       "            [0.00946045, -0.00646973, 0.00506592, ..., -0.0281982,\n",
       "             0.00701904, 0.0111694],\n",
       "            [0.00448608, -0.012085, 0.00518799, ..., -0.0532227, -0.0258789,\n",
       "             -0.00268555],\n",
       "            ...,\n",
       "            [0.00156403, 0.00732422, 0.000583649, ..., 0.00546265, 0.020752,\n",
       "             0.0169678],\n",
       "            [0.013916, -0.000276566, 0.000934601, ..., 0.0219727,\n",
       "             -0.0246582, 0.00762939],\n",
       "            [0.00343323, -0.00337219, -0.00695801, ..., -0.00262451,\n",
       "             0.0179443, -0.0286865]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.0114746, -0.0014267, -0.00331116, ..., -0.00162506,\n",
       "            -0.0117188, 0.00370789],\n",
       "           [0.00326538, 0.00159454, -0.000766754, ..., -0.00460815,\n",
       "            -0.00561523, -9.77516e-06],\n",
       "           [-0.0123291, 0.0072937, -0.00274658, ..., -0.000173569,\n",
       "            0.00113678, -0.00646973],\n",
       "           ...,\n",
       "           [-0.000463486, 0.00427246, -0.0148315, ..., -0.00793457,\n",
       "            0.0151367, -0.0132446],\n",
       "           [-0.00549316, 0.00357056, -0.00915527, ..., 0.00372314,\n",
       "            -0.0471191, -0.001091],\n",
       "           [-0.00357056, -0.00219727, -0.0103149, ..., 9.39369e-05,\n",
       "            -0.00439453, -0.00125885]],\n",
       "   \n",
       "          [[0.0163574, 0.0035553, 0.00442505, ..., -0.0231934, -0.00723267,\n",
       "            0.0136108],\n",
       "           [0.00131989, 0.00976562, -0.00257874, ..., 0.013916,\n",
       "            -0.00271606, -0.0203857],\n",
       "           [-0.00732422, -0.00279236, -0.00860596, ..., -0.00479126,\n",
       "            -0.00473022, 0.00352478],\n",
       "           ...,\n",
       "           [0.0142822, -0.0112305, 0.00653076, ..., -0.00300598,\n",
       "            -0.00613403, 0.00280762],\n",
       "           [-0.0090332, 0.00312805, -0.00524902, ..., 0.00328064,\n",
       "            0.0130615, 0.0111694],\n",
       "           [0.000770569, 0.00646973, 0.0128174, ..., 4.8399e-05,\n",
       "            0.00592041, 0.0154419]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.0050354, 0.000976562, -0.00619507, ..., 0.0118408, -0.00799561,\n",
       "           -0.00179291],\n",
       "          [-0.0106812, -0.0114136, -0.00436401, ..., 0.00364685,\n",
       "           -0.00361633, -0.00372314],\n",
       "          [-0.00674438, 0.00170135, 0.00136566, ..., 0.000915527,\n",
       "           -0.00927734, 0.00415039],\n",
       "          ...,\n",
       "          [0.00335693, -0.00331116, 0.00463867, ..., 0.0010376, 0.0016861,\n",
       "           -0.00564575],\n",
       "          [0.0025177, -0.000295639, 0.000284195, ..., 0.00075531,\n",
       "           -0.00854492, -0.00244141],\n",
       "          [0.000148773, -0.0090332, -0.00650024, ..., -0.00686646,\n",
       "           0.0159912, 0.0155029]], dtype=bfloat16), a=Array([[ 0.01029943, -0.01047805,  0.00627802, ...,  0.00658243,\n",
       "            0.00416735, -0.00188006],\n",
       "          [-0.00780879, -0.00588758,  0.00545886, ...,  0.00931677,\n",
       "           -0.00922768,  0.00010113]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.417969, 0.449219, 0.496094, ..., 0.236328, 0.0996094, 0.226562],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.570312, 0.636719, 0.699219, ..., 0.523438, 0.554688, 0.421875],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.648438, 0.875, 0.738281, ..., 0.773438, -0.0170898, 0.667969],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.074707, 0.15625, 0.0830078, ..., 0.185547, -0.205078, 0.0991211],      dtype=bfloat16)}},\n",
       " 'layer_12': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0123291, 0.00909424, -0.001091, ..., 0.0146484, -0.000839233,\n",
       "             0.0090332],\n",
       "            [-0.00273132, 0.000862122, -0.00531006, ..., 0.0108032,\n",
       "             0.00160217, -0.00114441],\n",
       "            [0.00561523, 0.00665283, 0.00364685, ..., -0.0120239, 0.013855,\n",
       "             -0.00842285],\n",
       "            ...,\n",
       "            [-0.0336914, -0.0148315, -0.0022583, ..., -0.00204468,\n",
       "             0.00497437, 0.00309753],\n",
       "            [-0.0137939, -0.00276184, 0.000127792, ..., 0.0212402,\n",
       "             0.00488281, -0.00469971],\n",
       "            [-0.00239563, 0.00128174, 0.00592041, ..., -0.0129395,\n",
       "             -0.00262451, -0.00311279]],\n",
       "    \n",
       "           [[0.00799561, -0.0144653, 0.00285339, ..., -0.00302124,\n",
       "             -0.000644684, 0.012146],\n",
       "            [0.00424194, -0.0019455, 0.00787354, ..., -0.00741577,\n",
       "             -0.00695801, -0.00335693],\n",
       "            [-0.0125732, -0.00976562, -0.00561523, ..., -0.00210571,\n",
       "             -0.00958252, 0.0134888],\n",
       "            ...,\n",
       "            [0.0245361, 0.00579834, 0.00344849, ..., 0.00726318,\n",
       "             -0.00775146, 0.00379944],\n",
       "            [0.00430298, 0.00866699, -0.00349426, ..., 0.00308228,\n",
       "             -0.00793457, 0.0018692],\n",
       "            [-0.00124359, -0.000320435, 0.00640869, ..., 0.00411987,\n",
       "             0.0117798, 0.00891113]],\n",
       "    \n",
       "           [[-0.0200195, 0.00230408, 0.0246582, ..., -0.0205078, 0.0128174,\n",
       "             0.00762939],\n",
       "            [0.0189209, 0.00933838, -0.00708008, ..., 0.00418091, 0.0175781,\n",
       "             0.0136719],\n",
       "            [-0.012146, -0.00915527, 0.0164795, ..., 0.00564575, 0.00756836,\n",
       "             0.0174561],\n",
       "            ...,\n",
       "            [0.0133057, -0.0240479, -0.00891113, ..., 0.019165, 0.00494385,\n",
       "             0.0220947],\n",
       "            [0.00497437, 0.00744629, 0.010437, ..., 0.000926971, -0.0247803,\n",
       "             0.0169678],\n",
       "            [0.0249023, -0.00708008, -0.00546265, ..., 0.0166016,\n",
       "             -0.0202637, 0.00866699]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00153351, 0.0118408, -0.0019989, ..., -0.0102539,\n",
       "             -0.00169373, 0.00897217],\n",
       "            [-0.00872803, -0.0119019, 0.00656128, ..., -0.00297546,\n",
       "             -0.0205078, -0.000659943],\n",
       "            [-0.0106201, 0.000210762, 0.0133057, ..., -0.00442505,\n",
       "             -0.00738525, 0.0125122],\n",
       "            ...,\n",
       "            [-0.0111084, 0.000452042, -0.00915527, ..., -0.00387573,\n",
       "             -0.0117798, 0.000762939],\n",
       "            [-0.00723267, -0.00126648, -0.00169373, ..., -0.00872803,\n",
       "             1.32918e-05, 0.0148315],\n",
       "            [-0.00273132, 0.00109863, -0.00720215, ..., 0.0231934,\n",
       "             0.00390625, -0.0115967]],\n",
       "    \n",
       "           [[0.0164795, -0.00162506, -0.00219727, ..., -0.00933838,\n",
       "             0.0011673, 0.00069809],\n",
       "            [0.0181885, -0.00576782, 0.00466919, ..., 0.000514984,\n",
       "             0.00260925, 0.00376892],\n",
       "            [0.0098877, 0.00337219, -0.0043335, ..., 0.00909424, 0.00469971,\n",
       "             -0.00964355],\n",
       "            ...,\n",
       "            [-0.00637817, 0.00759888, -0.000324249, ..., -0.000352859,\n",
       "             -0.000770569, 0.0145264],\n",
       "            [0.00411987, 0.0181885, 0.000854492, ..., -0.00558472,\n",
       "             -0.00102997, -0.0101318],\n",
       "            [0.0101929, -0.00662231, 0.0206299, ..., -0.010498, 0.0108643,\n",
       "             -0.0136108]],\n",
       "    \n",
       "           [[-0.0115356, -0.000915527, 0.00341797, ..., -0.00150299,\n",
       "             -0.00717163, 0.00598145],\n",
       "            [-0.0157471, -0.0109253, -0.0117188, ..., 0.0109253, 0.00408936,\n",
       "             -0.00271606],\n",
       "            [-0.00793457, -0.00337219, -0.0037384, ..., 0.00234985,\n",
       "             0.00769043, 0.0112305],\n",
       "            ...,\n",
       "            [0.000957489, 0.000873566, -0.0117798, ..., 0.00164032,\n",
       "             -0.00500488, -0.0032196],\n",
       "            [0.000694275, -0.0185547, 0.00723267, ..., -0.00170135,\n",
       "             -0.00741577, 0.0109253],\n",
       "            [-0.00402832, 0.000999451, -0.0231934, ..., 0.00848389,\n",
       "             -0.00177765, 0.0130615]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00343323, 0.00543213, 0.0010376, ..., 0.0194092,\n",
       "              -0.0289307, 0.00854492],\n",
       "             [0.00335693, -0.000406265, -0.000614166, ..., -0.0223389,\n",
       "              -0.0181885, -0.0213623],\n",
       "             [0.0110474, -0.00549316, 0.000406265, ..., -0.0035553,\n",
       "              -0.00457764, 0.0284424],\n",
       "             ...,\n",
       "             [-0.0126343, 0.00759888, -0.00273132, ..., -0.00799561,\n",
       "              -0.00756836, -0.00378418],\n",
       "             [0.00364685, 0.00156403, 0.00567627, ..., 0.00558472,\n",
       "              -0.00909424, 0.00915527],\n",
       "             [0.00970459, -0.00213623, -0.000476837, ..., -0.0334473,\n",
       "              -0.00958252, -0.0162354]],\n",
       "    \n",
       "            [[-0.000766754, -0.00704956, 0.00424194, ..., -0.010498,\n",
       "              -0.019165, -0.00775146],\n",
       "             [0.00595093, 0.0111084, -0.00457764, ..., -0.0145874,\n",
       "              -0.0019455, 0.000892639],\n",
       "             [0.000255585, -0.00408936, 0.00312805, ..., 0.0244141,\n",
       "              -0.0106201, -0.017334],\n",
       "             ...,\n",
       "             [-0.00585938, -0.00366211, -0.00265503, ..., -0.00897217,\n",
       "              -0.0114746, -0.00328064],\n",
       "             [1.2517e-05, 0.00592041, 0.000459671, ..., 0.00408936,\n",
       "              -0.0147705, 0.00244141],\n",
       "             [0.00094223, 0.0018158, -0.0010376, ..., 0.010437, 0.0280762,\n",
       "              0.0088501]],\n",
       "    \n",
       "            [[0.00897217, 0.0078125, -0.00196838, ..., 0.00179291,\n",
       "              0.00156403, 0.00357056],\n",
       "             [-0.00173187, -0.00153351, -0.00598145, ..., -0.00982666,\n",
       "              0.00263977, -0.0120239],\n",
       "             [-0.00201416, -0.00494385, 0.00224304, ..., -0.00823975,\n",
       "              -0.00442505, -0.0273438],\n",
       "             ...,\n",
       "             [-0.00218201, 0.00111389, -0.00216675, ..., -0.00939941,\n",
       "              -0.00466919, -0.00946045],\n",
       "             [0.0039978, -0.00427246, -0.00747681, ..., -0.0159912,\n",
       "              -0.0322266, 0.0419922],\n",
       "             [0.00231934, -0.000358582, 0.00567627, ..., 0.00476074,\n",
       "              0.00448608, 0.00595093]],\n",
       "    \n",
       "            [[-0.00274658, 0.0132446, -0.00205994, ..., -0.00848389,\n",
       "              -0.00430298, -0.00245667],\n",
       "             [0.00726318, 0.00111389, 0.00267029, ..., 0.000595093,\n",
       "              -0.0157471, -0.00408936],\n",
       "             [-0.00897217, -8.86917e-05, 0.0072937, ..., -0.00396729,\n",
       "              0.000717163, 0.00279236],\n",
       "             ...,\n",
       "             [-0.00364685, -0.00671387, 0.00024128, ..., -0.0050354,\n",
       "              0.00735474, -0.00640869],\n",
       "             [0.00408936, 8.58307e-05, 0.00897217, ..., 0.000915527,\n",
       "              0.0112915, -0.0122681],\n",
       "             [-0.00592041, -0.00241089, -0.00872803, ..., 0.0205078,\n",
       "              -0.00337219, -8.82149e-05]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00527954, 0.00213623, -0.00387573, ..., 0.000329971,\n",
       "              0.00113678, 0.00315857],\n",
       "             [-0.00689697, 0.00610352, -0.0174561, ..., -0.0117798,\n",
       "              0.00141907, -0.00634766],\n",
       "             [0.0169678, -0.019165, -0.0185547, ..., 0.00915527,\n",
       "              0.00909424, -0.00958252],\n",
       "             ...,\n",
       "             [-0.0150757, -0.00270081, 0.0181885, ..., 3.19481e-05,\n",
       "              -0.00842285, 0.0146484],\n",
       "             [-0.00750732, -0.0216064, -0.003479, ..., -0.00723267,\n",
       "              0.0114746, 0.000545502],\n",
       "             [0.00346375, -0.0334473, 0.00361633, ..., 0.000919342,\n",
       "              -0.0116577, -0.00570679]],\n",
       "    \n",
       "            [[0.0135498, -0.0057373, 0.0128784, ..., -0.00674438,\n",
       "              0.000232697, -0.015564],\n",
       "             [-0.0194092, -0.000595093, 0.0117798, ..., 0.0212402,\n",
       "              -0.0177002, 0.0164795],\n",
       "             [-0.0247803, 0.00408936, -0.0153809, ..., 0.00765991,\n",
       "              -0.00376892, 0.00653076],\n",
       "             ...,\n",
       "             [0.00765991, -0.00457764, 0.0168457, ..., -0.0234375,\n",
       "              -0.0179443, -0.012085],\n",
       "             [-0.000953674, 0.00595093, 0.0119019, ..., -0.00588989,\n",
       "              0.0167236, 0.000192642],\n",
       "             [0.00506592, -0.00402832, 0.00328064, ..., -0.0195312,\n",
       "              -0.00175476, -0.0167236]],\n",
       "    \n",
       "            [[0.0240479, 0.0250244, -0.00466919, ..., -0.00140381,\n",
       "              0.00387573, 0.00479126],\n",
       "             [-0.0216064, 0.00366211, -0.00744629, ..., 0.0145874,\n",
       "              -0.00364685, -0.0181885],\n",
       "             [0.0144043, -0.00561523, -0.00616455, ..., -0.00534058,\n",
       "              -0.00312805, -0.00167847],\n",
       "             ...,\n",
       "             [0.00158691, 0.00265503, -0.00231934, ..., 0.00552368,\n",
       "              -0.00506592, 0.000976562],\n",
       "             [-0.0125732, 0.0162354, -0.00119019, ..., -0.00315857,\n",
       "              0.0145874, -0.00147247],\n",
       "             [-0.0123901, -0.0218506, 0.00500488, ..., 0.00531006,\n",
       "              -0.0101929, -0.00540161]],\n",
       "    \n",
       "            [[-0.00909424, -0.0184326, 0.00262451, ..., -0.00352478,\n",
       "              -0.0166016, -0.00500488],\n",
       "             [0.0022583, 0.00558472, -0.00296021, ..., -0.0137329,\n",
       "              -0.0294189, -0.0020752],\n",
       "             [0.0113525, -0.00549316, 0.0157471, ..., -0.00378418,\n",
       "              -0.00512695, -0.0119629],\n",
       "             ...,\n",
       "             [0.00640869, -0.00158691, -0.0055542, ..., -0.00137329,\n",
       "              0.0128784, 0.0090332],\n",
       "             [9.44138e-05, -0.00787354, -0.000178337, ..., -0.00128937,\n",
       "              0.0164795, -0.00854492],\n",
       "             [-0.000364304, 0.00056839, 0.00326538, ..., -0.0167236,\n",
       "              0.00123596, 0.0122681]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00866699, -0.000282288, -0.00335693, ..., 0.00732422,\n",
       "             -0.0071106, -0.0164795],\n",
       "            [0.00315857, -0.00297546, -0.00753784, ..., -0.00527954,\n",
       "             -0.00927734, -0.00349426],\n",
       "            [-0.010498, -0.0107422, -0.0129395, ..., -0.0223389, 0.0057373,\n",
       "             -0.00747681],\n",
       "            ...,\n",
       "            [0.00588989, -0.00308228, -0.00318909, ..., 0.000679016,\n",
       "             -0.000337601, -0.00515747],\n",
       "            [-0.00585938, -0.00592041, 0.0222168, ..., -0.00273132,\n",
       "             0.00320435, -0.0110474],\n",
       "            [0.000331879, 0.00167847, -0.00515747, ..., 0.0098877,\n",
       "             0.0016861, 0.0200195]],\n",
       "    \n",
       "           [[0.000492096, -0.00396729, -0.000984192, ..., 0.0222168,\n",
       "             0.0202637, -0.00585938],\n",
       "            [-0.00564575, -0.0119629, -0.0131836, ..., -0.032959,\n",
       "             -0.0169678, 0.0153809],\n",
       "            [-0.0155029, -0.00921631, 0.000724792, ..., -0.0177002,\n",
       "             -0.00430298, 0.000751495],\n",
       "            ...,\n",
       "            [0.0016098, -0.00674438, 0.00488281, ..., 0.00367737,\n",
       "             0.00106049, -0.0157471],\n",
       "            [0.0116577, -0.000326157, -0.0211182, ..., 0.0115356, 0.0101318,\n",
       "             0.000812531],\n",
       "            [0.00323486, 0.0157471, -0.00418091, ..., 0.00231934, 0.0257568,\n",
       "             0.0339355]],\n",
       "    \n",
       "           [[0.00823975, -0.00424194, -0.00317383, ..., 0.00534058,\n",
       "             0.0105591, -0.00267029],\n",
       "            [-0.00531006, 0.000789642, -0.00515747, ..., 0.010437,\n",
       "             -0.00817871, -0.00389099],\n",
       "            [-0.00668335, -0.000461578, -0.00631714, ..., 0.0158691,\n",
       "             0.0012207, 0.00668335],\n",
       "            ...,\n",
       "            [0.00418091, -0.000274658, 0.000398636, ..., -0.0252686,\n",
       "             -0.00866699, 0.00958252],\n",
       "            [-0.00933838, -0.000934601, 0.026001, ..., -0.0067749,\n",
       "             -0.00219727, -0.00909424],\n",
       "            [0.00212097, -2.75671e-06, -0.00460815, ..., 0.00668335,\n",
       "             -0.00186157, 0.0136719]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00488281, -0.00262451, 0.00250244, ..., 0.00897217,\n",
       "             0.00778198, 0.0332031],\n",
       "            [0.000770569, -0.00088501, 0.00830078, ..., -0.0067749,\n",
       "             -0.0169678, -0.00982666],\n",
       "            [-0.00320435, 0.00518799, -0.00506592, ..., -0.0180664,\n",
       "             0.00897217, -0.0119019],\n",
       "            ...,\n",
       "            [0.00540161, 0.00485229, 0.00288391, ..., -0.00735474,\n",
       "             0.0119629, -0.013855],\n",
       "            [-0.00497437, 0.0035553, -0.000398636, ..., -0.019165,\n",
       "             -0.00823975, -0.0111694],\n",
       "            [-0.00402832, -0.00242615, -0.00108337, ..., -0.00933838,\n",
       "             -0.00119019, -0.0240479]],\n",
       "    \n",
       "           [[-0.000526428, -0.0107422, 0.000923157, ..., -0.0088501,\n",
       "             -0.00970459, -0.0088501],\n",
       "            [-0.00878906, -0.0109253, -0.00860596, ..., -0.0143433,\n",
       "             0.00466919, -4.62532e-05],\n",
       "            [0.0071106, -0.00346375, -0.00741577, ..., 0.00540161,\n",
       "             -0.00964355, -0.00152588],\n",
       "            ...,\n",
       "            [-0.0039978, -0.00976562, 0.00976562, ..., -0.0107422,\n",
       "             0.0174561, -0.00897217],\n",
       "            [0.00671387, -0.00830078, 0.00156403, ..., -0.0150146,\n",
       "             -0.00805664, 0.00250244],\n",
       "            [0.00160217, -0.0120239, -0.00817871, ..., 0.00564575,\n",
       "             -0.00309753, 0.00393677]],\n",
       "    \n",
       "           [[-0.00848389, 0.00222778, 0.00360107, ..., 0.00405884,\n",
       "             -0.00708008, -0.00769043],\n",
       "            [-0.00136566, -6.7234e-05, -0.00384521, ..., -0.0062561,\n",
       "             -0.00463867, -0.00631714],\n",
       "            [0.00112915, 0.0045166, 0.00726318, ..., -0.0108032,\n",
       "             -0.00183868, -0.00344849],\n",
       "            ...,\n",
       "            [-0.00482178, -0.00497437, 0.00161743, ..., 0.00534058,\n",
       "             -0.00415039, 0.010376],\n",
       "            [0.00424194, 0.0181885, 0.00485229, ..., -0.00344849,\n",
       "             -0.00457764, 0.00665283],\n",
       "            [0.00680542, 0.00482178, -0.0065918, ..., 0.00190735,\n",
       "             0.00302124, 0.010498]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00946045, 0.00714111, 0.0112305, ..., -0.00205994,\n",
       "            -0.0202637, 0.000368118],\n",
       "           [-0.000888824, 0.0150757, -0.00897217, ..., -0.00485229,\n",
       "            0.0143433, -0.0109863],\n",
       "           [0.00260925, 0.0198975, 0.0281982, ..., -0.012146, -0.00842285,\n",
       "            -0.00115967],\n",
       "           ...,\n",
       "           [-0.00616455, -0.03125, 0.00933838, ..., -0.00448608,\n",
       "            -0.0126953, 0.010437],\n",
       "           [0.00056076, -0.00312805, -0.00305176, ..., -0.00210571,\n",
       "            0.0131226, 0.010376],\n",
       "           [0.006073, -0.0106201, -0.000105858, ..., 0.00952148,\n",
       "            -0.00579834, -0.00756836]],\n",
       "   \n",
       "          [[-0.00775146, -0.00375366, -0.00421143, ..., -0.00224304,\n",
       "            -0.00344849, -0.00537109],\n",
       "           [-0.00125122, 0.000541687, -0.00369263, ..., 0.00982666,\n",
       "            0.0120239, -0.00367737],\n",
       "           [-0.00131989, -0.00866699, 0.0114136, ..., -0.0194092,\n",
       "            0.00183868, 0.00650024],\n",
       "           ...,\n",
       "           [-0.0140991, -0.00665283, -0.00604248, ..., 0.00267029,\n",
       "            0.00279236, -0.00396729],\n",
       "           [-0.00454712, -0.00331116, 0.0132446, ..., 0.00564575,\n",
       "            -0.00726318, 0.000785828],\n",
       "           [0.00643921, 0.0039978, 0.010376, ..., -0.000938416,\n",
       "            -0.00112152, 0.000827789]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.012085, 0.00479126, -0.00488281, ..., -0.00848389, -0.010376,\n",
       "           0.0062561],\n",
       "          [0.00113678, -0.00708008, -0.00592041, ..., 0.0145264, 0.00271606,\n",
       "           0.00308228],\n",
       "          [0.00156403, -0.00921631, 0.019043, ..., 0.00686646, -0.00364685,\n",
       "           -0.00259399],\n",
       "          ...,\n",
       "          [-0.00331116, 0.00233459, -0.00970459, ..., 0.00915527,\n",
       "           0.00689697, 0.00241089],\n",
       "          [-0.0181885, 0.00753784, 0.00424194, ..., 0.00253296, -0.0117188,\n",
       "           0.00289917],\n",
       "          [-0.00418091, -0.00244141, 0.00854492, ..., 0.00213623,\n",
       "           -0.00506592, 0.00424194]], dtype=bfloat16), a=Array([[-0.00788363,  0.00197184,  0.00437608, ...,  0.01334583,\n",
       "            0.00926806,  0.01390658],\n",
       "          [ 0.00132567, -0.00222159, -0.00384167, ..., -0.02493023,\n",
       "            0.00545663, -0.00319182]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.416016, 0.648438, 0.589844, ..., 0.335938, 0.133789, 0.298828],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.644531, 0.695312, 0.757812, ..., 0.589844, 0.589844, 0.507812],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.933594, 1.07812, 0.972656, ..., 0.863281, 0.0952148, 0.957031],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.0192871, 0.0976562, 0.0195312, ..., 0.10498, -0.239258,\n",
       "          0.0118408], dtype=bfloat16)}},\n",
       " 'layer_13': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0135498, 0.00506592, -0.00741577, ..., 0.00358582,\n",
       "             -0.00222778, -0.00854492],\n",
       "            [-0.0125122, -0.00457764, 0.00662231, ..., -0.0090332,\n",
       "             0.00787354, -0.00112152],\n",
       "            [0.00087738, 0.0088501, 0.0039978, ..., -0.00241089, 0.00187683,\n",
       "             -0.0103149],\n",
       "            ...,\n",
       "            [0.0050354, 0.00866699, -0.00946045, ..., 0.0150146, 0.00311279,\n",
       "             0.00274658],\n",
       "            [0.00558472, 0.00158691, 0.000904083, ..., 0.00537109,\n",
       "             -0.0224609, -0.00247192],\n",
       "            [-9.67979e-05, 0.00213623, 0.00337219, ..., -0.00640869,\n",
       "             0.0162354, -0.0246582]],\n",
       "    \n",
       "           [[-0.00378418, 0.0144043, -0.00680542, ..., 0.00817871,\n",
       "             -0.00357056, 0.00750732],\n",
       "            [0.00772095, 0.00296021, 0.00344849, ..., -0.0137939,\n",
       "             -0.00349426, 0.00549316],\n",
       "            [0.00897217, 0.00585938, -0.00300598, ..., -0.0206299,\n",
       "             0.000231743, -0.00361633],\n",
       "            ...,\n",
       "            [0.0129395, -0.00741577, 0.00631714, ..., 0.00762939, 0.0122681,\n",
       "             0.00485229],\n",
       "            [0.00637817, -0.00454712, -0.00193024, ..., 0.00268555,\n",
       "             -0.00952148, -0.000486374],\n",
       "            [-0.0050354, -0.00982666, 0.00376892, ..., 0.0045166,\n",
       "             0.00263977, -0.0025177]],\n",
       "    \n",
       "           [[0.0201416, 0.00872803, -0.00201416, ..., 0.0151367,\n",
       "             -0.00094223, -0.00415039],\n",
       "            [0.00598145, -0.0187988, 0.0112915, ..., 0.0117798, 0.0071106,\n",
       "             0.00148773],\n",
       "            [-0.00205994, 0.00933838, 0.00878906, ..., 0.0090332,\n",
       "             0.00564575, 0.00120544],\n",
       "            ...,\n",
       "            [0.00683594, -0.00793457, -0.012085, ..., 0.0168457,\n",
       "             -0.00150299, 0.0078125],\n",
       "            [-0.00349426, 0.0112915, 0.00361633, ..., -0.0115356,\n",
       "             0.00897217, -0.0252686],\n",
       "            [0.00512695, -0.00585938, -0.0128174, ..., -0.000459671,\n",
       "             0.020752, 0.0170898]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0141602, 0.0146484, -0.0205078, ..., 0.00265503, 0.00933838,\n",
       "             0.0299072],\n",
       "            [-0.0235596, 0.0172119, -0.00349426, ..., -0.00576782,\n",
       "             -0.00799561, 0.00314331],\n",
       "            [-0.013916, 0.0200195, -0.00860596, ..., -0.0269775,\n",
       "             0.000448227, -0.0107422],\n",
       "            ...,\n",
       "            [-0.0128174, -0.00921631, -0.00842285, ..., -0.000125885,\n",
       "             -0.00131226, -0.00250244],\n",
       "            [0.00482178, 0.0181885, 0.0189209, ..., -0.00239563, 0.0322266,\n",
       "             -0.0016098],\n",
       "            [0.00138855, -0.00328064, -0.0222168, ..., -0.0102539, 0.022583,\n",
       "             0.019043]],\n",
       "    \n",
       "           [[-0.0235596, 0.0108643, -0.0132446, ..., 0.00491333, 0.00982666,\n",
       "             -0.0244141],\n",
       "            [-0.00531006, -0.017334, -0.00579834, ..., -0.0166016,\n",
       "             -0.00643921, -0.0102539],\n",
       "            [0.00836182, 0.00537109, 0.00180054, ..., 0.0115967, 0.0239258,\n",
       "             -0.00543213],\n",
       "            ...,\n",
       "            [0.00485229, -0.00860596, 0.00160217, ..., 0.00222778,\n",
       "             -0.000507355, -0.0150146],\n",
       "            [0.00561523, -0.0143433, 0.00460815, ..., -0.00156403,\n",
       "             0.000846863, 0.010376],\n",
       "            [0.00909424, -0.00218201, -0.0162354, ..., 0.0140381,\n",
       "             -0.00668335, -0.0175781]],\n",
       "    \n",
       "           [[-0.017334, -0.00854492, 0.0183105, ..., 0.0088501, -0.00518799,\n",
       "             0.00598145],\n",
       "            [-0.00692749, -0.0130005, 0.00692749, ..., 0.0103149, 0.0157471,\n",
       "             -0.00387573],\n",
       "            [0.0122681, -0.0114746, -0.012207, ..., -0.0136719, -0.00494385,\n",
       "             0.00424194],\n",
       "            ...,\n",
       "            [0.000333786, 0.00247192, 0.0090332, ..., 0.000265121,\n",
       "             -0.0202637, 0.0263672],\n",
       "            [-0.00534058, 0.00958252, -0.00662231, ..., -0.0152588,\n",
       "             -0.0103149, 0.00579834],\n",
       "            [-0.00686646, 0.0045166, 0.0183105, ..., -0.00683594, 0.0128784,\n",
       "             0.0045166]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.000892639, 0.00201416, -0.00775146, ..., 0.000904083,\n",
       "              0.0071106, 0.00558472],\n",
       "             [-0.00891113, -0.00157166, 8.4877e-05, ..., -0.00939941,\n",
       "              0.0145264, -0.0100098],\n",
       "             [-0.00177765, -0.00106812, 0.00613403, ..., 0.0136108,\n",
       "              0.019043, -0.00375366],\n",
       "             ...,\n",
       "             [0.0067749, -0.000537872, -0.00546265, ..., 0.0090332,\n",
       "              -0.00445557, 0.0101318],\n",
       "             [-0.0218506, -0.0145874, 0.00244141, ..., -0.010498,\n",
       "              0.00127411, 0.00476074],\n",
       "             [-0.00364685, -0.000553131, 0.00390625, ..., -0.0184326,\n",
       "              0.0163574, -0.0163574]],\n",
       "    \n",
       "            [[-0.00619507, 0.000919342, -0.0022583, ..., -0.027832,\n",
       "              0.0132446, 0.0241699],\n",
       "             [0.00164032, -0.000831604, -0.000235558, ..., 0.00958252,\n",
       "              0.0118408, 0.0107422],\n",
       "             [-0.00430298, 0.00650024, -0.00656128, ..., -0.0118408,\n",
       "              -0.00280762, 0.0140991],\n",
       "             ...,\n",
       "             [0.00245667, -0.00169373, 0.00198364, ..., -0.00701904,\n",
       "              -0.0117188, -0.00082016],\n",
       "             [0.00335693, 0.0164795, 0.00104523, ..., -0.0147705,\n",
       "              0.0148926, -0.00328064],\n",
       "             [0.000257492, 0.000400543, -0.00280762, ..., -0.0120239,\n",
       "              0.0196533, -0.0158691]],\n",
       "    \n",
       "            [[0.00540161, -0.00411987, -8.82149e-05, ..., 0.0109253,\n",
       "              -0.0117798, 0.0201416],\n",
       "             [0.000103474, 0.00405884, 0.0098877, ..., 0.0106201, 0.017334,\n",
       "              0.0186768],\n",
       "             [-0.00830078, 0.00595093, 0.0071106, ..., -0.0118408,\n",
       "              0.00491333, 0.00543213],\n",
       "             ...,\n",
       "             [0.00665283, -0.00787354, 0.00170898, ..., -0.0258789,\n",
       "              0.00616455, 0.0111694],\n",
       "             [2.76566e-05, 0.00482178, 0.00234985, ..., 0.0112305,\n",
       "              0.00159454, 0.0145264],\n",
       "             [-0.00436401, 0.00343323, 0.00305176, ..., 0.0180664,\n",
       "              0.0181885, -0.0234375]],\n",
       "    \n",
       "            [[0.00549316, -0.00238037, 0.00151062, ..., 0.0177002,\n",
       "              0.000762939, 0.00270081],\n",
       "             [-0.00424194, -0.00306702, 0.00543213, ..., 0.00436401,\n",
       "              0.00500488, -0.00698853],\n",
       "             [0.00494385, 0.00775146, 0.00147247, ..., 0.00744629,\n",
       "              -0.0249023, 0.0043335],\n",
       "             ...,\n",
       "             [0.00653076, 0.00325012, -0.00701904, ..., -0.00872803,\n",
       "              -0.0088501, -0.00915527],\n",
       "             [0.00430298, 0.000637054, -0.00282288, ..., 0.0218506,\n",
       "              0.0241699, -0.0209961],\n",
       "             [-0.00604248, 0.00378418, -0.00469971, ..., 0.00726318,\n",
       "              -1.44839e-05, 0.00897217]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00866699, -0.00228882, 0.00964355, ..., 0.00418091,\n",
       "              0.00592041, 0.00341797],\n",
       "             [0.000333786, -0.00811768, 0.0100098, ..., 0.00372314,\n",
       "              0.00592041, 0.0114136],\n",
       "             [0.00701904, 0.00463867, 0.00756836, ..., 0.00854492,\n",
       "              -0.0088501, -0.00325012],\n",
       "             ...,\n",
       "             [0.0108643, -0.00854492, -0.0222168, ..., 0.00418091,\n",
       "              0.00173187, 0.00799561],\n",
       "             [-0.00534058, 0.00616455, 0.0251465, ..., -0.0100098,\n",
       "              -0.0111084, 0.0102539],\n",
       "             [0.000507355, 0.00289917, -0.00421143, ..., -0.00805664,\n",
       "              -0.0018158, 0.00259399]],\n",
       "    \n",
       "            [[0.000793457, -0.00221252, -0.00119019, ..., 0.00848389,\n",
       "              0.0105591, -0.00769043],\n",
       "             [0.00650024, 0.00982666, 0.00279236, ..., -0.00643921,\n",
       "              0.00628662, 0.00173187],\n",
       "             [-0.0252686, -0.00367737, 0.0100708, ..., 0.00125122,\n",
       "              0.019043, 0.0107422],\n",
       "             ...,\n",
       "             [-0.00230408, 0.00604248, 0.00848389, ..., 0.00909424,\n",
       "              -0.0185547, 0.00256348],\n",
       "             [-0.00872803, -0.00897217, -0.00509644, ..., -0.0101929,\n",
       "              0.0174561, 0.00506592],\n",
       "             [0.00387573, 0.0109863, -0.0224609, ..., 0.00805664,\n",
       "              -0.0090332, -0.0141602]],\n",
       "    \n",
       "            [[0.0283203, -0.0112305, -0.00714111, ..., 0.0222168,\n",
       "              -0.00183868, 0.0115967],\n",
       "             [0.0109253, 0.0289307, 0.015564, ..., -0.0130005, -0.00326538,\n",
       "              -0.00561523],\n",
       "             [0.00842285, 0.0109863, 0.000160217, ..., 0.00169373,\n",
       "              -0.0139771, 0.00518799],\n",
       "             ...,\n",
       "             [-0.00494385, -0.00244141, 0.0105591, ..., 0.00180054,\n",
       "              0.00405884, -0.0264893],\n",
       "             [0.0038147, -0.00927734, -0.00537109, ..., -0.0142822,\n",
       "              0.0110474, 0.0230713],\n",
       "             [0.00558472, -0.00198364, 0.0202637, ..., -0.00270081,\n",
       "              -0.0169678, 0.00494385]],\n",
       "    \n",
       "            [[-0.0109253, -0.00689697, 0.012085, ..., -0.0180664,\n",
       "              0.00125122, -0.0158691],\n",
       "             [-0.00534058, -0.0131226, -0.00665283, ..., -0.00325012,\n",
       "              0.020874, 0.00637817],\n",
       "             [-0.00564575, -0.017334, 0.0268555, ..., -0.00367737,\n",
       "              -0.000583649, -0.0107422],\n",
       "             ...,\n",
       "             [0.0111084, -0.00701904, 0.00836182, ..., -0.0147095,\n",
       "              -0.000888824, 0.00176239],\n",
       "             [0.0505371, -0.0151367, 0.0128784, ..., 0.00695801,\n",
       "              -0.00256348, 0.00445557],\n",
       "             [0.00842285, -0.0065918, -0.00540161, ..., -0.0127563,\n",
       "              0.00588989, -0.0247803]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.000207901, -0.00448608, -0.00363159, ..., 0.00964355,\n",
       "             0.00598145, -0.000116825],\n",
       "            [0.0103149, 0.0078125, -0.0137329, ..., -0.000747681,\n",
       "             0.00915527, -0.0141602],\n",
       "            [-0.00411987, 8.15392e-05, 0.000804901, ..., 0.000675201,\n",
       "             0.00567627, 0.0043335],\n",
       "            ...,\n",
       "            [0.00231934, -0.00101471, 0.000232697, ..., 0.00772095,\n",
       "             0.00171661, -0.0129395],\n",
       "            [0.000103951, -0.0269775, 0.00613403, ..., 0.00668335,\n",
       "             0.00370789, -0.0128784],\n",
       "            [-0.00454712, -0.00842285, -0.00704956, ..., -0.000341415,\n",
       "             -0.00726318, -0.0119629]],\n",
       "    \n",
       "           [[-0.00186157, 0.00299072, -0.0030365, ..., 0.000368118,\n",
       "             -0.00588989, 0.0192871],\n",
       "            [0.00497437, 0.000667572, -0.00622559, ..., -0.0400391,\n",
       "             0.0128174, 0.0118408],\n",
       "            [-0.00151062, -0.00234985, -0.00318909, ..., -0.00604248,\n",
       "             0.0205078, 0.00256348],\n",
       "            ...,\n",
       "            [0.000450134, 0.00138855, -0.00302124, ..., 0.0262451,\n",
       "             0.0018158, 0.0131226],\n",
       "            [0.00854492, -0.0143433, -0.00506592, ..., -0.000518799,\n",
       "             0.0123291, 0.0133057],\n",
       "            [4.98295e-05, 0.00156403, -0.0101318, ..., -0.0236816,\n",
       "             -0.0014801, -0.00166321]],\n",
       "    \n",
       "           [[0.00738525, 0.0181885, 0.00473022, ..., 0.000499725,\n",
       "             -0.00964355, -0.00570679],\n",
       "            [0.0123291, 0.00390625, 0.00213623, ..., 0.0263672, 0.0228271,\n",
       "             -0.000892639],\n",
       "            [-0.00619507, -0.00439453, -0.00138855, ..., 0.0194092,\n",
       "             -0.0137329, -0.000541687],\n",
       "            ...,\n",
       "            [-0.00175476, -0.00915527, 0.00561523, ..., 0.00231934,\n",
       "             -0.015625, 0.00674438],\n",
       "            [0.0030365, -0.00927734, 0.00778198, ..., -0.00640869,\n",
       "             -0.0130615, 0.029541],\n",
       "            [-0.0072937, -0.00306702, -0.00537109, ..., 0.0122681,\n",
       "             0.00787354, -0.0358887]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0124512, -0.000469208, -0.00135803, ..., 0.0184326,\n",
       "             -0.0187988, -0.0162354],\n",
       "            [0.00183105, 0.00527954, -0.0202637, ..., 0.0236816,\n",
       "             -0.000782013, -0.00158691],\n",
       "            [-0.00509644, -0.019165, 0.0100708, ..., -0.0130615, 0.0161133,\n",
       "             0.00787354],\n",
       "            ...,\n",
       "            [-0.0124512, 0.00163269, -0.00588989, ..., -0.0334473,\n",
       "             -0.0114746, 0.000595093],\n",
       "            [0.00848389, -0.00515747, 0.0147095, ..., 0.00340271,\n",
       "             -0.00939941, 0.0267334],\n",
       "            [0.00215149, 0.000640869, 0.00976562, ..., -0.0152588, 0.015564,\n",
       "             -0.00723267]],\n",
       "    \n",
       "           [[0.00367737, -0.0001688, 0.00402832, ..., -0.00982666,\n",
       "             0.0153198, 0.00267029],\n",
       "            [0.0122681, 0.00344849, -0.00671387, ..., -0.000534058,\n",
       "             0.0134888, -0.0180664],\n",
       "            [0.00439453, 0.00927734, -0.00137329, ..., 0.0332031, 0.0115967,\n",
       "             0.00585938],\n",
       "            ...,\n",
       "            [-0.000640869, -8.49366e-07, -0.0100098, ..., -0.00512695,\n",
       "             0.0181885, 0.0141602],\n",
       "            [0.00107574, -0.00204468, 0.00360107, ..., 0.0108643,\n",
       "             0.00338745, 0.0168457],\n",
       "            [0.010376, -0.00518799, 0.00153351, ..., -0.0140991, -0.0168457,\n",
       "             0.000663757]],\n",
       "    \n",
       "           [[-0.00595093, -0.00396729, 0.00445557, ..., 0.00192261,\n",
       "             -0.0106201, -0.0015564],\n",
       "            [-0.0055542, 0.00830078, 0.00488281, ..., 0.0078125, 0.00145721,\n",
       "             0.000461578],\n",
       "            [-0.00128937, 0.00738525, 0.00215149, ..., 0.00805664,\n",
       "             0.00153351, -0.00172424],\n",
       "            ...,\n",
       "            [0.00537109, -0.00622559, -0.00817871, ..., -0.000184059,\n",
       "             0.000843048, -0.0088501],\n",
       "            [-0.0022583, -0.00325012, -0.00306702, ..., 0.00239563,\n",
       "             0.0149536, 0.0300293],\n",
       "            [-0.00193787, 0.00534058, 0.00524902, ..., 0.000556946,\n",
       "             0.0159912, 0.00866699]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00717163, -0.00282288, -0.00683594, ..., -0.00196838,\n",
       "            -0.0148315, 0.0126343],\n",
       "           [0.00964355, -0.00750732, -0.0146484, ..., -0.00218201,\n",
       "            0.0102539, 0.000999451],\n",
       "           [-0.000774384, 0.00622559, 0.0106812, ..., -0.00842285,\n",
       "            -0.00631714, -0.00234985],\n",
       "           ...,\n",
       "           [0.00210571, -0.00141144, -0.00491333, ..., -0.00683594,\n",
       "            -0.0120239, 0.00891113],\n",
       "           [0.00224304, 0.00177765, -0.00637817, ..., -0.00189209,\n",
       "            -0.00171661, -0.0112915],\n",
       "           [-0.00276184, -0.00543213, -0.00415039, ..., -0.00741577,\n",
       "            0.00473022, -0.00759888]],\n",
       "   \n",
       "          [[-0.00823975, -0.00427246, 0.00817871, ..., -0.00088501,\n",
       "            0.0149536, 0.00375366],\n",
       "           [0.00747681, -0.0131836, 0.00421143, ..., -0.00183105,\n",
       "            -0.00958252, -0.00704956],\n",
       "           [-0.00126648, 0.00159454, -0.00836182, ..., 0.00439453,\n",
       "            -0.00288391, 0.0032196],\n",
       "           ...,\n",
       "           [-0.0101318, 0.017334, 0.000652313, ..., 0.00396729,\n",
       "            -0.000402451, 0.0117798],\n",
       "           [-0.0100708, -0.00674438, 0.0045166, ..., 0.00958252,\n",
       "            -0.0115356, -0.0011673],\n",
       "           [0.000629425, 0.00153351, -0.00119781, ..., 0.00653076,\n",
       "            0.00738525, -0.00463867]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00756836, -0.00531006, 0.00567627, ..., 0.00282288,\n",
       "           -0.0016098, -0.00387573],\n",
       "          [-0.00376892, -0.00121307, -0.00210571, ..., -0.00518799,\n",
       "           -0.00102997, 0.00302124],\n",
       "          [0.0157471, 0.0133667, -0.00637817, ..., 0.00382996, 0.00543213,\n",
       "           0.012085],\n",
       "          ...,\n",
       "          [-0.000934601, -0.00527954, -0.0100098, ..., -0.00309753,\n",
       "           0.0010376, -0.0126953],\n",
       "          [0.0169678, -0.0200195, -0.00241089, ..., -0.0050354, -0.00270081,\n",
       "           0.00854492],\n",
       "          [0.0103149, 0.00836182, 0.00531006, ..., 0.00616455, -1.87159e-05,\n",
       "           -0.00134277]], dtype=bfloat16), a=Array([[ 0.01005734,  0.01642189,  0.01510733, ...,  0.01328816,\n",
       "            0.00516436,  0.00271901],\n",
       "          [ 0.01016035, -0.00417797, -0.00903327, ..., -0.00616623,\n",
       "           -0.00244164, -0.01308654]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.742188, 0.71875, 0.671875, ..., 0.597656, 0.515625, 0.494141],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.875, 0.867188, 0.953125, ..., 0.859375, 0.839844, 0.679688],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.722656, 0.894531, 0.761719, ..., 0.726562, 0.0529785, 0.789062],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.126953, -0.0751953, -0.126953, ..., -0.0358887, -0.269531,\n",
       "          -0.0932617], dtype=bfloat16)}},\n",
       " 'layer_14': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00366211, 0.00842285, -0.0114746, ..., 0.0151367,\n",
       "             0.000350952, -0.00479126],\n",
       "            [-0.00025177, 0.0019455, 0.000900269, ..., 0.00250244, 0.010376,\n",
       "             -0.00442505],\n",
       "            [-0.0155029, -0.010437, 0.00148773, ..., -0.00286865,\n",
       "             0.00579834, -0.0035553],\n",
       "            ...,\n",
       "            [0.0098877, -0.00233459, -0.00723267, ..., -0.00830078,\n",
       "             0.0147095, -0.000432968],\n",
       "            [0.00473022, 0.000396729, 0.00927734, ..., -0.0137939,\n",
       "             -0.00331116, 0.0177002],\n",
       "            [0.0133667, -0.0142822, 0.00595093, ..., -0.00692749,\n",
       "             0.00747681, 0.00799561]],\n",
       "    \n",
       "           [[0.0071106, -0.00479126, -0.00182343, ..., -0.00114441,\n",
       "             0.00430298, -0.012085],\n",
       "            [-0.00154114, 0.0109253, -0.00927734, ..., -0.0103149,\n",
       "             -0.00823975, -0.00115204],\n",
       "            [-0.0147705, 0.000961304, 0.000155449, ..., 0.00631714,\n",
       "             0.00318909, 0.00276184],\n",
       "            ...,\n",
       "            [-0.00242615, -0.00198364, 0.0145264, ..., 0.0194092,\n",
       "             -0.00285339, -0.00457764],\n",
       "            [-0.00190735, 0.0130615, -0.00445557, ..., 0.0163574,\n",
       "             -0.0103149, -0.00491333],\n",
       "            [-0.00436401, 0.00588989, -0.0113525, ..., 0.0163574,\n",
       "             -0.0103149, -0.00585938]],\n",
       "    \n",
       "           [[-0.00570679, 0.00227356, -0.00128174, ..., -0.0108032,\n",
       "             -0.0154419, 0.00921631],\n",
       "            [-0.00866699, 0.00509644, -0.0129395, ..., -0.00248718,\n",
       "             -0.00402832, 0.00970459],\n",
       "            [-0.0158691, 0.00156403, 0.00665283, ..., -0.00442505,\n",
       "             -0.0115356, 0.000518799],\n",
       "            ...,\n",
       "            [-0.00352478, 0.00595093, 9.53674e-05, ..., 0.000263214,\n",
       "             0.0101318, -0.000320435],\n",
       "            [-0.00866699, 0.000682831, 0.0133667, ..., 0.0101318,\n",
       "             -0.00210571, 0.00396729],\n",
       "            [-0.012207, 0.00747681, -0.019165, ..., 0.0194092, -0.0103149,\n",
       "             0.000305176]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0106201, 0.00228882, 0.00714111, ..., 0.00579834,\n",
       "             0.00897217, -0.00518799],\n",
       "            [0.0130005, 0.010376, 0.0286865, ..., 0.00320435, 0.0161133,\n",
       "             0.0139771],\n",
       "            [0.00306702, 0.0103149, -0.0109863, ..., 0.0189209, 0.010498,\n",
       "             -0.0200195],\n",
       "            ...,\n",
       "            [0.00147247, -0.0238037, -0.00527954, ..., -0.00315857,\n",
       "             -0.00212097, -0.00915527],\n",
       "            [-0.000865936, 0.00741577, 0.00430298, ..., 0.00120544,\n",
       "             -0.00897217, -0.00823975],\n",
       "            [0.00775146, -0.00463867, -0.00964355, ..., 0.00294495,\n",
       "             -0.00022316, 0.00145721]],\n",
       "    \n",
       "           [[-0.0174561, -0.0239258, 0.00315857, ..., -0.0101318,\n",
       "             -0.0137329, -0.00216675],\n",
       "            [-0.00653076, 0.00222778, 0.00108337, ..., -0.00805664,\n",
       "             -0.00872803, -0.0125122],\n",
       "            [0.00285339, -0.0038147, -0.00909424, ..., -0.000785828,\n",
       "             0.00325012, 7.00951e-05],\n",
       "            ...,\n",
       "            [-0.0101929, 0.0150146, -0.0043335, ..., 0.00340271, 0.0090332,\n",
       "             0.00738525],\n",
       "            [0.019165, -0.026123, 0.00921631, ..., -0.0134277, -0.0180664,\n",
       "             0.0039978],\n",
       "            [0.0014267, 0.00170135, 0.00738525, ..., 0.00823975, 0.0107422,\n",
       "             0.00120544]],\n",
       "    \n",
       "           [[0.00671387, 0.00854492, -0.00279236, ..., 0.0159912,\n",
       "             0.00927734, 0.00765991],\n",
       "            [0.00994873, 0.00811768, -0.00101471, ..., 0.0114136,\n",
       "             0.000606537, -0.0108643],\n",
       "            [-0.00285339, -0.00891113, 0.00653076, ..., 0.0148926,\n",
       "             -0.00242615, -0.0108643],\n",
       "            ...,\n",
       "            [0.0126343, -0.00921631, 0.0067749, ..., 0.0072937, -0.0164795,\n",
       "             -0.00753784],\n",
       "            [-0.0128784, 0.00656128, -0.010498, ..., -0.00585938, 0.0144653,\n",
       "             -0.0128784],\n",
       "            [0.000198364, -0.0186768, -0.0108643, ..., 0.00247192,\n",
       "             -0.00592041, 0.00262451]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00674438, -0.00939941, 0.00112915, ..., 0.0203857,\n",
       "              0.0305176, -0.0172119],\n",
       "             [-0.00524902, -0.00127411, -0.000530243, ..., 0.0108643,\n",
       "              -0.00466919, -0.0246582],\n",
       "             [0.010376, 0.00631714, -0.0027771, ..., -0.00674438,\n",
       "              -0.00799561, -0.0102539],\n",
       "             ...,\n",
       "             [0.00122833, -0.00402832, -0.00463867, ..., -0.0218506,\n",
       "              -0.00674438, -0.0169678],\n",
       "             [-0.00430298, 0.0158691, 0.000427246, ..., -0.0294189,\n",
       "              -0.0150757, 0.00604248],\n",
       "             [-0.0109863, 0.00442505, -0.00222778, ..., -0.0107422,\n",
       "              -0.0148926, 0.0186768]],\n",
       "    \n",
       "            [[0.00337219, -0.000486374, -0.0088501, ..., 0.00762939,\n",
       "              -0.00402832, 0.0108643],\n",
       "             [-0.00244141, 0.00387573, 0.0030365, ..., -0.00344849,\n",
       "              -0.00680542, -0.0130615],\n",
       "             [0.00643921, 0.00616455, 0.00161743, ..., 0.0100708,\n",
       "              0.0103149, -0.00454712],\n",
       "             ...,\n",
       "             [-0.00386047, 0.0114746, -0.00744629, ..., -0.0088501,\n",
       "              0.00631714, -0.0159912],\n",
       "             [0.00177002, -0.00726318, -0.00494385, ..., 0.0281982,\n",
       "              -0.0115967, -0.00805664],\n",
       "             [0.000930786, 0.00125885, 0.00133514, ..., 0.00167847,\n",
       "              -0.00552368, 0.00396729]],\n",
       "    \n",
       "            [[-0.00102234, -0.00332642, -0.00708008, ..., 0.00823975,\n",
       "              0.0114136, -0.0198975],\n",
       "             [-0.00662231, -0.000305176, 0.00457764, ..., -0.0126953,\n",
       "              -0.000295639, -0.00274658],\n",
       "             [-0.00124359, -0.00379944, -0.0115967, ..., -0.00933838,\n",
       "              0.00291443, 0.0119019],\n",
       "             ...,\n",
       "             [-0.00244141, -0.00201416, -0.00436401, ..., 0.000804901,\n",
       "              -0.000679016, -0.000991821],\n",
       "             [-0.00778198, 0.00509644, -0.000511169, ..., -0.00164795,\n",
       "              0.0292969, -0.00363159],\n",
       "             [0.00439453, 0.00628662, 0.0012207, ..., 0.0239258,\n",
       "              -0.00927734, 0.0150757]],\n",
       "    \n",
       "            [[0.00778198, 0.00231934, 0.000440598, ..., -0.00187683,\n",
       "              0.00970459, -0.00708008],\n",
       "             [-0.000854492, -0.00570679, -0.00144958, ..., -0.0157471,\n",
       "              0.00242615, 0.00732422],\n",
       "             [7.18236e-06, 0.00305176, -0.000663757, ..., -0.00698853,\n",
       "              -0.00668335, 0.00396729],\n",
       "             ...,\n",
       "             [-0.00340271, -0.00296021, -0.00180054, ..., -0.00202942,\n",
       "              0.00219727, 0.0062561],\n",
       "             [0.00114441, 0.013855, -0.00430298, ..., 0.00982666,\n",
       "              0.0102539, -0.00127411],\n",
       "             [-0.00297546, 0.0055542, -0.000511169, ..., -0.0126953,\n",
       "              0.0126953, 0.000762939]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0123291, -0.019043, -0.000938416, ..., -0.012085,\n",
       "              -0.00598145, -0.0270996],\n",
       "             [-0.00466919, 0.00361633, -0.0106201, ..., -0.00704956,\n",
       "              0.00216675, 0.00595093],\n",
       "             [-0.00830078, -0.0166016, 0.00970459, ..., -0.00958252,\n",
       "              0.00500488, 0.00222778],\n",
       "             ...,\n",
       "             [0.00283813, 0.00418091, -0.013855, ..., 0.00769043,\n",
       "              -0.00460815, 0.0140991],\n",
       "             [0.0249023, 0.00836182, 0.0174561, ..., 0.00897217,\n",
       "              0.00994873, 0.00585938],\n",
       "             [-0.00350952, -0.00653076, 0.00184631, ..., -0.00119019,\n",
       "              -0.000522614, 0.000268936]],\n",
       "    \n",
       "            [[-0.0356445, -0.00549316, 0.00640869, ..., -0.00897217,\n",
       "              0.0236816, -0.0217285],\n",
       "             [0.00805664, 0.0100098, -0.00952148, ..., 0.00213623,\n",
       "              -0.00436401, 0.00759888],\n",
       "             [0.010498, 0.00735474, 0.0197754, ..., 0.00665283, 0.00543213,\n",
       "              0.0150146],\n",
       "             ...,\n",
       "             [-0.0111694, 0.00759888, -0.006073, ..., -0.0078125,\n",
       "              0.0131836, 0.00732422],\n",
       "             [0.0140991, -0.00793457, -0.000534058, ..., 0.000839233,\n",
       "              -0.000360489, 0.0101929],\n",
       "             [-0.00946045, 0.00323486, 0.00561523, ..., 0.00189209,\n",
       "              -0.00799561, 0.0134277]],\n",
       "    \n",
       "            [[0.00364685, -0.00891113, -0.0019989, ..., -0.0065918,\n",
       "              -0.00793457, -0.013916],\n",
       "             [-0.0114136, -0.00267029, -0.00186157, ..., 0.0175781,\n",
       "              -0.017334, -0.0195312],\n",
       "             [-0.00340271, -0.0125732, 0.00405884, ..., 0.0187988,\n",
       "              -0.00415039, 0.0107422],\n",
       "             ...,\n",
       "             [-0.00759888, -0.00188446, -0.013855, ..., 0.00241089,\n",
       "              0.000835419, 0.010498],\n",
       "             [-0.00610352, -0.0108032, -0.00122833, ..., -0.00110626,\n",
       "              0.0130005, 0.00259399],\n",
       "             [0.00866699, -0.00695801, 0.00643921, ..., -0.00262451,\n",
       "              0.0197754, -0.000831604]],\n",
       "    \n",
       "            [[0.00537109, -0.000865936, 0.0159912, ..., 0.00854492,\n",
       "              -0.00567627, 0.00119781],\n",
       "             [8.67844e-05, -0.0153198, 0.00169373, ..., 0.00759888,\n",
       "              0.00921631, -0.0244141],\n",
       "             [-0.0195312, -0.00909424, 0.0108643, ..., 0.0220947,\n",
       "              -0.00631714, 0.00352478],\n",
       "             ...,\n",
       "             [0.00927734, 0.0202637, 0.0117798, ..., -0.000455856,\n",
       "              0.00113678, 0.0098877],\n",
       "             [-0.00274658, -0.0112915, -0.000400543, ..., -0.0116577,\n",
       "              0.0201416, 0.000113487],\n",
       "             [0.00161743, -0.0112915, -0.0184326, ..., -0.0039978,\n",
       "              -0.00665283, 0.013916]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00778198, -0.00485229, 0.003479, ..., 0.0324707, 0.0151367,\n",
       "             0.0219727],\n",
       "            [-0.00166321, -0.00233459, 0.00817871, ..., 0.00318909,\n",
       "             0.0375977, 0.0115356],\n",
       "            [-0.00616455, 0.00466919, 0.00662231, ..., -0.00631714,\n",
       "             0.00361633, -0.00369263],\n",
       "            ...,\n",
       "            [-0.000177383, -0.00402832, 0.00665283, ..., -0.0227051,\n",
       "             0.0105591, -0.0251465],\n",
       "            [0.00994873, -0.0038147, -0.00872803, ..., -0.017334,\n",
       "             -0.00138092, 0.0163574],\n",
       "            [-0.00598145, -0.0020752, 0.00296021, ..., -0.024292,\n",
       "             -0.00387573, 0.010498]],\n",
       "    \n",
       "           [[-0.00799561, 0.00952148, -0.0043335, ..., 0.019165,\n",
       "             -0.00558472, 0.0039978],\n",
       "            [0.00189972, -0.00110626, -0.00457764, ..., 0.00221252,\n",
       "             0.020752, 0.0088501],\n",
       "            [-0.0163574, 0.00946045, 0.00289917, ..., 0.00289917,\n",
       "             0.00105286, 0.00106049],\n",
       "            ...,\n",
       "            [-0.000778198, -0.00294495, 0.00958252, ..., 0.00056076,\n",
       "             0.00637817, -0.0463867],\n",
       "            [0.0239258, -0.0043335, -0.0150757, ..., -0.0127563,\n",
       "             -6.96182e-05, -0.0140381],\n",
       "            [-0.00500488, 0.00250244, -0.00390625, ..., -0.0327148,\n",
       "             0.000206947, 0.0088501]],\n",
       "    \n",
       "           [[-0.00488281, 0.00671387, 0.00118256, ..., 0.0175781, 0.0300293,\n",
       "             -0.0106812],\n",
       "            [-0.00157166, -0.0126343, 0.00273132, ..., 0.000253677,\n",
       "             0.000637054, 0.00062561],\n",
       "            [-0.00101471, -0.00619507, -0.000482559, ..., -0.0341797,\n",
       "             -0.00878906, 0.0272217],\n",
       "            ...,\n",
       "            [0.0057373, 0.00389099, -0.00674438, ..., -0.0127563,\n",
       "             0.00346375, 0.0198975],\n",
       "            [0.0128174, 0.00836182, 0.0103149, ..., -0.00121307,\n",
       "             -0.00106049, 0.0158691],\n",
       "            [0.00271606, 0.000720978, 0.0016098, ..., -0.00366211,\n",
       "             -0.0395508, 0.0167236]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00671387, -0.000911713, -0.0136108, ..., -0.0098877,\n",
       "             0.0032196, -0.000701904],\n",
       "            [-0.00234985, -0.00231934, -0.010437, ..., -0.00469971,\n",
       "             -0.0120239, -0.00267029],\n",
       "            [-0.00717163, 0.00139618, -0.00640869, ..., -0.00119781,\n",
       "             0.00384521, -0.00158691],\n",
       "            ...,\n",
       "            [0.00756836, 0.0133057, -0.00592041, ..., -0.00634766,\n",
       "             0.00117493, 0.00216675],\n",
       "            [-0.00402832, 0.00775146, -0.00872803, ..., -0.00634766,\n",
       "             0.00352478, -0.00811768],\n",
       "            [-0.0022583, -0.0055542, -0.0203857, ..., 0.00473022,\n",
       "             0.00479126, 0.0180664]],\n",
       "    \n",
       "           [[-0.00173187, -0.0186768, -0.0128784, ..., -0.00250244,\n",
       "             -0.0202637, -0.0175781],\n",
       "            [-0.00848389, 0.00680542, 0.00460815, ..., -0.0262451,\n",
       "             0.0153198, -0.0071106],\n",
       "            [-0.00294495, 0.00176239, 0.00219727, ..., 0.000984192,\n",
       "             -0.0147705, -0.00854492],\n",
       "            ...,\n",
       "            [-0.00370789, 0.00656128, 0.00346375, ..., 0.0030365,\n",
       "             -0.0012207, 0.0101929],\n",
       "            [-0.00216675, -0.00531006, -9.65595e-06, ..., 0.0144653,\n",
       "             -0.00386047, -0.0120239],\n",
       "            [-0.00958252, 0.00279236, 0.00854492, ..., -0.00445557,\n",
       "             0.0270996, -0.00257874]],\n",
       "    \n",
       "           [[0.00133514, 0.00344849, 0.00378418, ..., 0.00921631, 0.0231934,\n",
       "             0.000178337],\n",
       "            [0.0137939, 0.00402832, -0.00288391, ..., -0.0119629, 0.0141602,\n",
       "             0.00787354],\n",
       "            [-0.000329971, 0.00411987, -0.00567627, ..., 0.0175781,\n",
       "             -0.00378418, 0.00300598],\n",
       "            ...,\n",
       "            [0.00576782, -0.00112152, -0.0088501, ..., -0.00698853,\n",
       "             0.0164795, 0.00506592],\n",
       "            [0.00564575, -0.00286865, 0.010376, ..., 0.0314941, -0.0150146,\n",
       "             -0.00866699],\n",
       "            [0.000617981, 7.77245e-05, 0.0101318, ..., 0.0169678,\n",
       "             0.00308228, 0.00891113]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.0110474, -0.00537109, 0.00787354, ..., 0.00279236,\n",
       "            -0.00376892, -0.00744629],\n",
       "           [0.012085, 0.000492096, 0.0119629, ..., -0.00466919, 0.012146,\n",
       "            -0.00171661],\n",
       "           [-0.00149536, -0.00811768, -0.000320435, ..., -0.0163574,\n",
       "            -0.00117493, 0.00952148],\n",
       "           ...,\n",
       "           [0.0105591, -0.00221252, 0.00518799, ..., -0.00506592,\n",
       "            -0.0078125, 0.00292969],\n",
       "           [-0.00994873, -0.00805664, 0.00418091, ..., -0.000709534,\n",
       "            -0.00823975, 0.000770569],\n",
       "           [-0.00421143, 0.00585938, 0.010437, ..., -0.000850677,\n",
       "            -0.00915527, -0.00823975]],\n",
       "   \n",
       "          [[0.00183868, -0.00198364, -0.00527954, ..., 0.00866699,\n",
       "            -0.00148773, -0.00239563],\n",
       "           [-0.00152588, 0.00976562, 0.00631714, ..., -0.000274658,\n",
       "            -0.0139771, -0.0090332],\n",
       "           [0.00512695, -0.00448608, -0.00224304, ..., -0.00793457,\n",
       "            0.00280762, -0.00411987],\n",
       "           ...,\n",
       "           [0.013916, -0.00714111, -0.00141144, ..., -0.0118408,\n",
       "            0.00379944, 0.00787354],\n",
       "           [-0.00224304, -0.00946045, -0.000938416, ..., -0.00250244,\n",
       "            -0.000972748, 0.0168457],\n",
       "           [-0.00402832, 0.00289917, 0.0022583, ..., -0.00723267,\n",
       "            0.00650024, -0.00430298]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00448608, -0.00750732, 0.000961304, ..., -0.00720215,\n",
       "           -0.00308228, -0.00463867],\n",
       "          [0.0072937, -0.0126953, 0.00170898, ..., 0.00762939, 0.00668335,\n",
       "           -0.00415039],\n",
       "          [0.00726318, -0.00241089, -0.00753784, ..., 0.00952148,\n",
       "           0.00256348, -0.000511169],\n",
       "          ...,\n",
       "          [-0.00393677, -0.00762939, -0.010437, ..., -0.0071106,\n",
       "           -0.00775146, -0.00108337],\n",
       "          [0.00836182, -0.00994873, -0.00283813, ..., -0.00386047,\n",
       "           0.00262451, 0.00759888],\n",
       "          [-0.0126953, -0.00424194, 0.0045166, ..., 0.00787354, 0.0133057,\n",
       "           -0.00854492]], dtype=bfloat16), a=Array([[ 0.00014633,  0.00200139, -0.00434174, ..., -0.001957  ,\n",
       "           -0.01323679, -0.00078773],\n",
       "          [ 0.00267099, -0.01303148,  0.02141839, ..., -0.00115613,\n",
       "           -0.01118799, -0.00374962]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.882812, 0.957031, 0.742188, ..., 0.757812, 0.648438, 0.628906],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([1.14844, 1.125, 1.20312, ..., 1.07031, 1.04688, 0.898438],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.878906, 1.07812, 0.859375, ..., 0.964844, 0.373047, 0.929688],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.185547, -0.140625, -0.193359, ..., -0.111328, -0.271484,\n",
       "          -0.130859], dtype=bfloat16)}},\n",
       " 'layer_15': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.0168457, -0.00282288, -0.00848389, ..., -0.000402451,\n",
       "             0.00836182, 0.00297546],\n",
       "            [-0.000614166, -0.00144196, -0.0137329, ..., 0.0151978,\n",
       "             -0.0101318, -0.00854492],\n",
       "            [-0.0120239, -0.000213623, 0.0101318, ..., 0.0107422,\n",
       "             -0.00123596, 0.00125122],\n",
       "            ...,\n",
       "            [0.00402832, -8.44002e-05, -0.00552368, ..., -0.00778198,\n",
       "             0.0175781, 0.0107422],\n",
       "            [-0.000610352, 0.00182343, 0.00952148, ..., -0.00363159,\n",
       "             -0.0035553, 0.00653076],\n",
       "            [0.00115204, 0.00149536, 0.00094223, ..., 0.000331879,\n",
       "             -0.00921631, -0.0115967]],\n",
       "    \n",
       "           [[0.00964355, 0.00242615, 0.0151367, ..., -0.000629425,\n",
       "             0.0194092, -0.010437],\n",
       "            [0.00637817, -0.0272217, 0.00279236, ..., 0.00326538,\n",
       "             0.00588989, 8.05855e-05],\n",
       "            [0.0366211, -0.012207, -0.0181885, ..., 0.00311279, -0.00558472,\n",
       "             -0.00257874],\n",
       "            ...,\n",
       "            [0.012207, -0.00418091, -0.00692749, ..., -0.0189209,\n",
       "             0.000314713, -0.0322266],\n",
       "            [0.00848389, -0.00180817, 0.00202942, ..., -0.00561523,\n",
       "             -0.0185547, -0.0117188],\n",
       "            [-0.000291824, -0.0101318, 0.00212097, ..., -0.0181885,\n",
       "             0.0168457, 0.0027771]],\n",
       "    \n",
       "           [[-0.0294189, -0.017334, -0.0128784, ..., 0.00878906,\n",
       "             -0.00260925, 0.0148926],\n",
       "            [-0.000396729, -0.0090332, 0.0127563, ..., -0.0164795,\n",
       "             -0.00476074, -0.00689697],\n",
       "            [0.0030365, 0.0119629, -0.00891113, ..., 0.00854492,\n",
       "             -0.00178528, 0.00817871],\n",
       "            ...,\n",
       "            [-0.00112152, 0.000385284, 0.0012207, ..., 0.0174561,\n",
       "             -0.0101929, -0.0123901],\n",
       "            [-0.00195312, 0.0170898, -0.0115356, ..., 0.0123901, -0.0206299,\n",
       "             0.00714111],\n",
       "            [-0.020874, -0.00610352, -0.00704956, ..., -0.00130463,\n",
       "             -0.0114746, -0.0154419]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.000160217, 0.00378418, -0.00205994, ..., -0.0115356,\n",
       "             -0.00546265, 0.000394821],\n",
       "            [0.000583649, -0.00378418, -0.0238037, ..., -0.0062561,\n",
       "             -0.000118732, 0.0108643],\n",
       "            [-0.0158691, -0.019043, -0.00595093, ..., -0.00259399,\n",
       "             0.0192871, 0.00299072],\n",
       "            ...,\n",
       "            [-0.0114746, 0.00939941, -0.00909424, ..., -0.0103149,\n",
       "             -0.00100708, 0.0146484],\n",
       "            [0.012085, 0.0106201, -0.0164795, ..., -0.0213623, 0.00344849,\n",
       "             -0.00439453],\n",
       "            [-0.00756836, 0.00210571, 0.0174561, ..., 0.000762939, 0.010498,\n",
       "             -0.00174713]],\n",
       "    \n",
       "           [[0.00650024, -0.0157471, -0.00491333, ..., 0.00576782,\n",
       "             -0.0112305, 0.0142822],\n",
       "            [-0.00750732, -0.00418091, -0.00151062, ..., 0.00854492,\n",
       "             0.0119019, 0.00772095],\n",
       "            [0.000701904, 0.00153351, 0.00354004, ..., -0.00708008,\n",
       "             0.000659943, -0.0027771],\n",
       "            ...,\n",
       "            [0.0131226, 0.00128174, -0.00595093, ..., 0.00527954,\n",
       "             -0.0168457, -0.00643921],\n",
       "            [-0.000240326, -0.00805664, -0.0112305, ..., 0.00952148,\n",
       "             -0.00744629, -0.00817871],\n",
       "            [0.0195312, 0.00105286, 0.0105591, ..., 0.0164795, -0.0114136,\n",
       "             0.000831604]],\n",
       "    \n",
       "           [[-0.0111694, 0.0155029, 0.00958252, ..., -0.00132751, 0.0262451,\n",
       "             -0.0183105],\n",
       "            [0.00361633, 0.012085, -0.00445557, ..., -0.0174561, -0.0140991,\n",
       "             -0.0101929],\n",
       "            [-0.00546265, 0.00640869, 0.00332642, ..., 0.0133667,\n",
       "             0.00149536, 0.00162506],\n",
       "            ...,\n",
       "            [-0.00927734, -0.00698853, -0.00805664, ..., 0.00842285,\n",
       "             0.0115967, 0.015564],\n",
       "            [0.0185547, 0.00113678, 0.0134888, ..., -0.00811768, 0.00891113,\n",
       "             0.0218506],\n",
       "            [-0.0115356, 0.00744629, -0.0175781, ..., -0.000427246,\n",
       "             0.00393677, 0.0115356]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00140381, -0.00793457, -0.0098877, ..., 0.00331116,\n",
       "              -0.0317383, 0.0133667],\n",
       "             [0.0025177, 0.00622559, -0.00466919, ..., 0.0270996,\n",
       "              -0.00500488, -0.0158691],\n",
       "             [0.00543213, 0.00257874, -0.0139771, ..., 0.00561523,\n",
       "              -0.0177002, -0.00506592],\n",
       "             ...,\n",
       "             [0.00521851, 6.91414e-05, 0.00297546, ..., 0.0257568,\n",
       "              0.0149536, -0.0114136],\n",
       "             [-0.00285339, -0.00704956, -0.00491333, ..., 0.000789642,\n",
       "              0.0239258, 0.0136719],\n",
       "             [-0.00640869, 0.00297546, 0.00335693, ..., -0.0230713,\n",
       "              0.0157471, 0.00848389]],\n",
       "    \n",
       "            [[-0.00714111, -0.00170135, -0.00370789, ..., -0.00292969,\n",
       "              -0.0194092, 0.0212402],\n",
       "             [-0.00619507, -0.0107422, 0.00166321, ..., 0.00170898,\n",
       "              -0.0090332, 0.000923157],\n",
       "             [0.00524902, -0.00787354, -0.010498, ..., -0.00185394,\n",
       "              -0.017334, -0.00233459],\n",
       "             ...,\n",
       "             [0.00811768, -0.00765991, 0.0039978, ..., -0.00151825,\n",
       "              0.00193787, 0.00933838],\n",
       "             [0.00616455, -0.0065918, 0.00285339, ..., -0.00540161,\n",
       "              -0.0112305, -0.012207],\n",
       "             [0.00637817, -0.00643921, -0.00552368, ..., 0.00405884,\n",
       "              -0.00695801, -0.0013504]],\n",
       "    \n",
       "            [[0.00396729, -0.0071106, 0.00131226, ..., -0.0266113,\n",
       "              0.0129395, -0.00921631],\n",
       "             [-0.0117798, -0.00102997, -0.00939941, ..., 0.0166016,\n",
       "              -0.017334, -0.0189209],\n",
       "             [-0.00656128, -0.0123901, -0.000701904, ..., 0.00279236,\n",
       "              0.0203857, 0.0144043],\n",
       "             ...,\n",
       "             [-0.00656128, -0.00592041, -0.00167084, ..., -0.0230713,\n",
       "              0.00202942, -0.00631714],\n",
       "             [-0.00110626, 0.010376, -0.00650024, ..., -0.000541687,\n",
       "              0.0262451, -0.0327148],\n",
       "             [0.00268555, -0.00405884, -0.0144653, ..., 0.0126953,\n",
       "              0.0219727, -0.00186157]],\n",
       "    \n",
       "            [[-0.00193787, -0.00332642, -0.00141144, ..., -0.0227051,\n",
       "              -0.019165, -0.00735474],\n",
       "             [0.00753784, -0.000900269, 0.00686646, ..., 0.00153351,\n",
       "              -0.0019455, -0.0256348],\n",
       "             [0.00114441, -0.00747681, -0.0183105, ..., -0.00665283,\n",
       "              0.020752, 0.000352859],\n",
       "             ...,\n",
       "             [-0.00366211, 0.00704956, 0.0194092, ..., -0.0124512,\n",
       "              0.0112305, 0.00970459],\n",
       "             [-0.00210571, 0.00656128, -0.0100098, ..., -0.00274658,\n",
       "              -0.0106201, -0.00515747],\n",
       "             [-0.00190735, 0.00151825, 0.0144043, ..., 0.0181885,\n",
       "              0.00300598, -0.0183105]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00549316, -0.000341415, 0.00297546, ..., -0.0134277,\n",
       "              0.000637054, -0.0101318],\n",
       "             [-0.0123901, -0.0050354, 0.00540161, ..., 0.00836182,\n",
       "              0.00595093, -0.0101318],\n",
       "             [-0.00756836, 0.0131226, -0.000322342, ..., 0.0100708,\n",
       "              -0.00823975, -0.00248718],\n",
       "             ...,\n",
       "             [0.0183105, 0.00466919, -0.00485229, ..., 0.00326538,\n",
       "              -0.012146, 0.0142212],\n",
       "             [-0.00744629, -0.0186768, -0.00212097, ..., 0.017334,\n",
       "              0.00708008, -0.0222168],\n",
       "             [-0.00842285, -0.00534058, -0.00109863, ..., -0.00460815,\n",
       "              0.017334, -0.00087738]],\n",
       "    \n",
       "            [[-0.0166016, -0.00775146, 0.00352478, ..., -0.0125122,\n",
       "              -0.00613403, -0.00637817],\n",
       "             [-0.0219727, -0.0236816, 0.0327148, ..., -0.0088501,\n",
       "              -0.0153198, -0.0180664],\n",
       "             [-0.00466919, 0.00337219, 0.00866699, ..., -0.0116577,\n",
       "              0.0120239, 0.00558472],\n",
       "             ...,\n",
       "             [-0.000896454, -0.00153351, -0.00139618, ..., 0.00460815,\n",
       "              0.0177002, -0.0118408],\n",
       "             [-0.000135422, 0.00509644, 0.00958252, ..., -0.0203857,\n",
       "              4.29153e-05, -0.0111694],\n",
       "             [0.00939941, 0.00479126, -0.0072937, ..., 0.0129395,\n",
       "              0.0184326, -0.00151062]],\n",
       "    \n",
       "            [[0.00842285, 0.00534058, 0.0116577, ..., -0.00585938,\n",
       "              -0.00656128, -0.0057373],\n",
       "             [-0.0112915, 0.0100098, -0.0231934, ..., 0.00686646,\n",
       "              0.0115356, 0.0180664],\n",
       "             [-0.00485229, 0.00282288, 0.0218506, ..., -0.0037384,\n",
       "              -0.00619507, 0.0110474],\n",
       "             ...,\n",
       "             [-0.0166016, 0.010376, -0.00830078, ..., 0.00567627,\n",
       "              -0.00173187, 0.000255585],\n",
       "             [0.0124512, 0.006073, 0.0107422, ..., 0.0100098, 0.00104523,\n",
       "              0.0101318],\n",
       "             [-0.0175781, 0.00692749, -0.00769043, ..., -0.00921631,\n",
       "              -0.00897217, 0.000991821]],\n",
       "    \n",
       "            [[0.000105858, -0.000778198, -0.00296021, ..., -0.00613403,\n",
       "              0.00473022, -0.0202637],\n",
       "             [0.017334, 0.00811768, -0.00634766, ..., -0.000999451,\n",
       "              0.0214844, 0.00150299],\n",
       "             [0.00546265, 0.00154114, -0.0119019, ..., -0.00312805,\n",
       "              -3.86238e-05, -0.00640869],\n",
       "             ...,\n",
       "             [-0.00230408, -0.0150146, 0.0177002, ..., 0.0027771,\n",
       "              -0.0184326, -0.0180664],\n",
       "             [0.00101471, -0.0164795, -0.00289917, ..., 0.0162354,\n",
       "              0.00650024, 0.00527954],\n",
       "             [-0.0236816, -0.0136108, 0.00946045, ..., 0.00125122,\n",
       "              0.0147095, -0.00994873]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00256348, 0.00549316, 0.00212097, ..., -0.0311279,\n",
       "             -0.050293, 0.0174561],\n",
       "            [-0.00634766, 0.00346375, 0.00292969, ..., 0.00616455,\n",
       "             -0.032959, 0.0307617],\n",
       "            [0.00218201, -0.00286865, 0.00202942, ..., 0.00866699,\n",
       "             -0.00686646, -0.0062561],\n",
       "            ...,\n",
       "            [0.0032196, 0.00312805, 0.000907898, ..., 0.0311279,\n",
       "             -0.00122833, -0.00927734],\n",
       "            [0.00102997, 0.00021553, -0.00421143, ..., -0.00878906,\n",
       "             0.00964355, 0.00279236],\n",
       "            [0.00112152, 0.0032959, -0.00160217, ..., -0.00436401,\n",
       "             0.0371094, -0.0268555]],\n",
       "    \n",
       "           [[0.0116577, -0.00552368, -0.00335693, ..., 0.00497437,\n",
       "             0.00177765, 0.000587463],\n",
       "            [-0.00518799, 0.0101929, -0.000181198, ..., -0.00878906,\n",
       "             -0.012085, -0.00154877],\n",
       "            [-0.0245361, -0.00576782, 0.00897217, ..., 0.00695801,\n",
       "             -0.0022583, -0.000181198],\n",
       "            ...,\n",
       "            [0.000816345, -0.00588989, -0.00190735, ..., 0.0035553,\n",
       "             0.0111084, 0.00213623],\n",
       "            [0.00482178, 0.00558472, 0.00921631, ..., 0.00141907,\n",
       "             0.00289917, 0.000244141],\n",
       "            [0.0238037, -0.0123291, -0.0181885, ..., 0.012085, -0.00595093,\n",
       "             -0.0159912]],\n",
       "    \n",
       "           [[-0.0010376, 0.0113525, 0.00588989, ..., 0.0227051, 0.00515747,\n",
       "             0.0127563],\n",
       "            [0.00479126, 0.001297, 0.00308228, ..., 0.0187988, -0.00601196,\n",
       "             0.0072937],\n",
       "            [0.00034523, 0.0140991, 0.00631714, ..., -0.0266113, 0.00291443,\n",
       "             0.0090332],\n",
       "            ...,\n",
       "            [0.0072937, -0.0122681, -0.00286865, ..., 0.00171661,\n",
       "             0.00430298, 0.00497437],\n",
       "            [0.00118256, 0.0098877, 0.00205994, ..., 0.00656128, 0.00418091,\n",
       "             -0.0109863],\n",
       "            [0.00025177, 0.00189209, -0.0101318, ..., 0.00823975,\n",
       "             -0.000272751, 0.0239258]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00241089, 0.00402832, 0.00317383, ..., -0.0456543,\n",
       "             0.00854492, -0.0238037],\n",
       "            [-0.00170135, 0.0115356, -0.00216675, ..., 0.0505371, 0.0230713,\n",
       "             0.0183105],\n",
       "            [-0.00153351, -0.00799561, -0.00222778, ..., 0.0229492,\n",
       "             -0.0187988, 0.0422363],\n",
       "            ...,\n",
       "            [0.00188446, 0.00619507, -0.00326538, ..., -0.0598145,\n",
       "             -0.0125732, 0.00125122],\n",
       "            [4.22001e-05, -0.00245667, 0.00946045, ..., -0.000888824,\n",
       "             -0.00411987, 0.027832],\n",
       "            [-0.00154877, -0.00656128, 0.0062561, ..., 0.0183105, 0.0108032,\n",
       "             -0.0137939]],\n",
       "    \n",
       "           [[0.0170898, -0.00360107, 0.00909424, ..., -0.0106201,\n",
       "             -0.00704956, 0.00317383],\n",
       "            [-0.0119629, -0.0169678, -0.00222778, ..., 0.00102234,\n",
       "             0.0114746, -0.00958252],\n",
       "            [-0.000522614, -0.00601196, -0.0280762, ..., 0.0162354,\n",
       "             -0.00257874, 0.0100098],\n",
       "            ...,\n",
       "            [-0.0012207, 0.00994873, 0.00656128, ..., -0.00227356,\n",
       "             -0.00101471, 0.00274658],\n",
       "            [-0.00680542, 0.00396729, -0.0150757, ..., 0.0140991,\n",
       "             -0.00317383, -0.0133667],\n",
       "            [-0.00564575, -0.00387573, 0.0308838, ..., 0.00976562,\n",
       "             -0.00460815, -0.00328064]],\n",
       "    \n",
       "           [[0.00421143, 0.000881195, 0.00094986, ..., 0.0126953,\n",
       "             0.00177002, -0.0185547],\n",
       "            [-0.00616455, 0.00248718, -0.00100708, ..., 0.00296021,\n",
       "             0.0209961, -0.0461426],\n",
       "            [-0.00259399, 0.00366211, 0.000778198, ..., -0.0133057,\n",
       "             0.0110474, -0.00830078],\n",
       "            ...,\n",
       "            [-0.00154877, -0.00187683, 0.00184631, ..., -0.0172119,\n",
       "             -0.0142822, -0.0283203],\n",
       "            [0.00585938, -0.0010376, 0.00527954, ..., 0.00540161,\n",
       "             -0.00787354, -0.013916],\n",
       "            [-0.0019989, 0.00224304, -0.00396729, ..., 0.00744629,\n",
       "             -0.00343323, 0.00250244]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.0158691, -0.00306702, -0.0169678, ..., -0.00346375,\n",
       "            -0.00723267, 0.0071106],\n",
       "           [0.00154114, 0.0124512, -0.00494385, ..., -0.0050354,\n",
       "            0.00292969, 0.00830078],\n",
       "           [0.00976562, 0.0098877, 0.00415039, ..., 0.00436401, 0.00518799,\n",
       "            0.00274658],\n",
       "           ...,\n",
       "           [0.00238037, -0.00686646, -0.00427246, ..., -0.00216675,\n",
       "            -0.00653076, -0.00130463],\n",
       "           [0.0108032, -0.00337219, 0.00323486, ..., -0.00646973,\n",
       "            -0.00509644, 0.00180817],\n",
       "           [0.00248718, -0.0102539, -0.000656128, ..., 0.006073,\n",
       "            0.00549316, -0.0161133]],\n",
       "   \n",
       "          [[0.00247192, -0.000621796, 0.0150146, ..., 0.00136566,\n",
       "            -0.00390625, -0.00204468],\n",
       "           [-0.0035553, -0.00488281, -0.000709534, ..., 0.0038147,\n",
       "            0.0020752, -0.00534058],\n",
       "           [0.00165558, 0.000364304, 0.00063324, ..., -0.00494385,\n",
       "            -0.012146, -0.00248718],\n",
       "           ...,\n",
       "           [-0.0127563, -0.00415039, 0.000648499, ..., -0.00117493,\n",
       "            0.00454712, -0.00260925],\n",
       "           [-0.00787354, -0.00140381, 0.00805664, ..., 0.00994873,\n",
       "            -0.00527954, 0.00239563],\n",
       "           [-0.0130615, 0.00297546, 0.0130615, ..., -0.00296021,\n",
       "            0.00732422, 0.0103149]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00221252, -0.00897217, -0.00634766, ..., -0.0098877,\n",
       "           0.000938416, 0.00341797],\n",
       "          [0.00756836, 0.0078125, -0.00595093, ..., 0.00372314, -0.00233459,\n",
       "           -0.00744629],\n",
       "          [0.00286865, -0.000667572, -0.00567627, ..., -0.000865936,\n",
       "           -0.00744629, 0.00106049],\n",
       "          ...,\n",
       "          [-0.000312805, 0.00146484, -4.26769e-05, ..., -0.00289917,\n",
       "           0.00549316, -0.0110474],\n",
       "          [-0.00363159, 0.000465393, -0.00878906, ..., 0.00512695,\n",
       "           -0.0153198, -0.00315857],\n",
       "          [-0.00222778, 0.0050354, -0.000159264, ..., 0.000162125,\n",
       "           -0.00457764, -0.00518799]], dtype=bfloat16), a=Array([[ 0.00193953,  0.00879681, -0.02188212, ...,  0.00268727,\n",
       "            0.00692501, -0.02095343],\n",
       "          [-0.01345678,  0.01583269,  0.00739929, ...,  0.00684354,\n",
       "           -0.01523105,  0.00528662]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([1.125, 1.09375, 1.17969, ..., 1.22656, 0.921875, 0.847656],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([1.42188, 1.45312, 1.50781, ..., 1.46094, 1.53125, 1.23438],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.589844, 0.570312, 0.498047, ..., 0.628906, 0.259766, 0.570312],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.176758, -0.133789, -0.176758, ..., -0.145508, -0.251953,\n",
       "          -0.133789], dtype=bfloat16)}},\n",
       " 'layer_16': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00282288, -0.00491333, 0.00744629, ..., -0.013855,\n",
       "             -0.0124512, 0.00215149],\n",
       "            [-0.00564575, 0.00302124, 0.00509644, ..., -0.00497437,\n",
       "             -0.00494385, 0.0125122],\n",
       "            [0.0194092, -0.017334, -0.0115967, ..., -0.006073, -0.000450134,\n",
       "             0.00485229],\n",
       "            ...,\n",
       "            [-0.00531006, 0.00254822, 0.00154114, ..., 0.00196838,\n",
       "             -0.00180054, -0.00136566],\n",
       "            [-0.00259399, -0.0110474, 0.0270996, ..., 0.0019989, 0.0102539,\n",
       "             -0.0157471],\n",
       "            [0.00411987, -0.0177002, 0.00878906, ..., -0.000873566,\n",
       "             -0.0050354, 0.00320435]],\n",
       "    \n",
       "           [[-0.00143433, -0.00588989, 0.00817871, ..., -0.00421143,\n",
       "             -0.00512695, -0.0218506],\n",
       "            [0.00524902, -0.00442505, 0.00817871, ..., 0.00163269,\n",
       "             -0.00509644, 0.00558472],\n",
       "            [-0.00939941, -0.012207, 0.0101318, ..., 0.00460815, 0.00267029,\n",
       "             -0.00497437],\n",
       "            ...,\n",
       "            [0.00567627, 0.0126953, -0.00714111, ..., -0.0122681, 0.0314941,\n",
       "             -0.00326538],\n",
       "            [0.0151978, 0.00338745, -0.00497437, ..., 0.00830078,\n",
       "             -0.000114918, 0.0129395],\n",
       "            [0.00698853, 0.0189209, 0.000946045, ..., 0.00233459,\n",
       "             0.00976562, 0.0116577]],\n",
       "    \n",
       "           [[-0.0131836, 0.020874, 0.0127563, ..., -0.00842285, -0.043457,\n",
       "             0.0125122],\n",
       "            [-0.00585938, 0.00543213, -0.00250244, ..., -0.00878906,\n",
       "             0.00811768, -0.00179291],\n",
       "            [0.00897217, 0.0322266, -0.0128784, ..., -0.0249023, -0.0395508,\n",
       "             0.00479126],\n",
       "            ...,\n",
       "            [0.017334, -0.017334, -0.00921631, ..., -0.0115967, 0.00117493,\n",
       "             0.0137939],\n",
       "            [-0.00515747, 0.0117188, 0.00643921, ..., -0.0098877,\n",
       "             -0.0178223, 0.00735474],\n",
       "            [0.0349121, 0.0117798, -0.0339355, ..., -0.00183105, 0.00245667,\n",
       "             -0.0153198]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00193787, 0.00515747, 0.0117188, ..., -0.0144653,\n",
       "             -0.00613403, 0.0192871],\n",
       "            [0.00518799, 0.00744629, 0.00231934, ..., -0.00909424,\n",
       "             -0.0230713, -0.0112915],\n",
       "            [-0.00222778, 0.00460815, 0.0135498, ..., 0.0150757, 0.00231934,\n",
       "             -0.00358582],\n",
       "            ...,\n",
       "            [-0.00500488, 0.00720215, 0.017334, ..., -0.00994873,\n",
       "             -0.0158691, 0.0098877],\n",
       "            [-0.012146, 0.00671387, 0.00982666, ..., -0.0267334,\n",
       "             -0.00148773, -0.000459671],\n",
       "            [-0.00799561, -0.00622559, 0.000614166, ..., 0.0137329,\n",
       "             0.00665283, -0.00921631]],\n",
       "    \n",
       "           [[0.00117493, 0.00332642, -0.00921631, ..., 0.00982666,\n",
       "             0.00192261, 0.00106812],\n",
       "            [-0.0172119, 0.00393677, 0.00695801, ..., 0.0105591, 0.0020752,\n",
       "             0.000473022],\n",
       "            [-0.012146, -0.0144043, 0.00328064, ..., 0.0178223, 0.00897217,\n",
       "             0.00221252],\n",
       "            ...,\n",
       "            [0.0030365, -0.000972748, -0.000484467, ..., 0.00643921,\n",
       "             0.00994873, 0.00952148],\n",
       "            [-0.00668335, 0.00747681, 0.0286865, ..., -0.0038147,\n",
       "             -0.0128784, -0.00306702],\n",
       "            [0.00491333, 0.00222778, 0.00616455, ..., -0.0129395, 0.0119019,\n",
       "             0.00982666]],\n",
       "    \n",
       "           [[-0.0157471, -0.0125122, -0.00671387, ..., -0.00466919,\n",
       "             0.0111084, 0.0144043],\n",
       "            [0.00190735, 0.00411987, 0.0039978, ..., 0.000326157,\n",
       "             -0.00102997, 0.0220947],\n",
       "            [-0.00637817, 0.00656128, 0.0111694, ..., -0.00976562,\n",
       "             -0.00408936, -0.0157471],\n",
       "            ...,\n",
       "            [-0.00650024, 0.015625, -0.000671387, ..., 0.00720215,\n",
       "             -9.77516e-06, -0.00872803],\n",
       "            [-0.00202942, -0.000404358, -0.0201416, ..., 0.00650024,\n",
       "             -0.000720978, -0.0175781],\n",
       "            [0.00595093, -0.00958252, -0.0264893, ..., 0.00215149,\n",
       "             -0.00653076, 0.017334]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00704956, -0.000284195, 0.00430298, ..., 0.0123901,\n",
       "              -0.000141144, -0.0114746],\n",
       "             [-0.00708008, -0.00482178, 0.00476074, ..., 0.0172119,\n",
       "              0.0106812, 0.00723267],\n",
       "             [0.00726318, 0.000553131, 0.00622559, ..., 0.0166016,\n",
       "              0.00811768, -0.00124359],\n",
       "             ...,\n",
       "             [-0.000476837, -0.000751495, 0.00970459, ..., 0.0110474,\n",
       "              -0.00360107, -0.034668],\n",
       "             [0.00276184, 0.00101471, 0.00370789, ..., -0.00848389,\n",
       "              -0.0205078, -0.00662231],\n",
       "             [0.00242615, -0.000389099, 0.00601196, ..., -0.0159912,\n",
       "              -0.00442505, -0.0192871]],\n",
       "    \n",
       "            [[-0.00245667, 0.00866699, -0.00540161, ..., -0.00145721,\n",
       "              0.00454712, -0.00120544],\n",
       "             [-0.000175476, -0.00390625, 0.00744629, ..., 0.0123901,\n",
       "              0.0140381, 0.0039978],\n",
       "             [0.00817871, 0.00476074, -0.003479, ..., 0.0159912,\n",
       "              -0.00436401, 0.0203857],\n",
       "             ...,\n",
       "             [0.0016098, 0.0039978, 0.00756836, ..., -0.00549316,\n",
       "              0.00405884, -0.000831604],\n",
       "             [-0.00778198, -0.00656128, -0.00500488, ..., -0.00848389,\n",
       "              0.00238037, -0.00318909],\n",
       "             [-0.00187683, 0.00558472, 0.0043335, ..., -0.00274658,\n",
       "              0.00473022, -0.00309753]],\n",
       "    \n",
       "            [[0.0101318, 0.00640869, 0.00442505, ..., 0.0222168, 0.020752,\n",
       "              0.00616455],\n",
       "             [-0.00558472, -0.00683594, 0.00334167, ..., -0.0155029,\n",
       "              -0.00762939, 0.00582886],\n",
       "             [0.000717163, -0.00173187, -0.00613403, ..., 0.00860596,\n",
       "              0.00239563, -0.0110474],\n",
       "             ...,\n",
       "             [0.00334167, 0.00151062, -0.00445557, ..., 0.0144043,\n",
       "              0.0123901, 0.00488281],\n",
       "             [-0.00759888, 0.00105286, -0.00179291, ..., -0.0170898,\n",
       "              0.00157928, -0.00204468],\n",
       "             [0.0018158, -0.00358582, 0.000831604, ..., 0.006073,\n",
       "              0.0043335, -0.0106812]],\n",
       "    \n",
       "            [[-0.00075531, 0.00386047, -0.000291824, ..., 0.0132446,\n",
       "              0.00546265, -0.0206299],\n",
       "             [0.000185966, -0.0109253, 0.00159454, ..., -0.0214844,\n",
       "              -0.0129395, 0.00195312],\n",
       "             [0.00187683, 0.00132751, 0.00144958, ..., -0.0198975,\n",
       "              -0.0157471, 0.0126953],\n",
       "             ...,\n",
       "             [0.00830078, 0.0016861, -0.00170135, ..., -0.0151367,\n",
       "              0.0220947, -0.0252686],\n",
       "             [-0.00271606, 0.00411987, -0.00102234, ..., -0.00106812,\n",
       "              -0.0228271, 0.0198975],\n",
       "             [-0.00382996, 0.000243187, -0.0101318, ..., 0.00579834,\n",
       "              0.0114136, 0.00102997]]],\n",
       "    \n",
       "    \n",
       "           [[[0.000991821, -0.0109253, 0.0150757, ..., -0.00259399,\n",
       "              0.00674438, 0.00927734],\n",
       "             [-0.00233459, -0.00285339, -0.00393677, ..., 0.00769043,\n",
       "              -0.0151367, -0.00622559],\n",
       "             [-0.00185394, 0.0189209, -0.00254822, ..., -0.00680542,\n",
       "              0.00386047, 0.0187988],\n",
       "             ...,\n",
       "             [-0.00723267, 0.0114136, 0.00976562, ..., -0.00537109,\n",
       "              0.0126343, 0.0112915],\n",
       "             [-0.019043, -0.00622559, -0.00521851, ..., 0.00193787,\n",
       "              -0.0032959, -0.000301361],\n",
       "             [-0.0227051, -0.0105591, 0.0050354, ..., 0.00457764,\n",
       "              0.00628662, 0.0108032]],\n",
       "    \n",
       "            [[-0.000839233, -0.00549316, 0.00153351, ..., -0.00735474,\n",
       "              0.00341797, -0.0142212],\n",
       "             [-0.0107422, -0.0117188, -0.00230408, ..., -0.0187988,\n",
       "              -0.0150757, -0.00823975],\n",
       "             [-0.0195312, -0.00132751, 0.00476074, ..., 0.00186157,\n",
       "              0.0125122, 0.0189209],\n",
       "             ...,\n",
       "             [-0.00634766, 0.0158691, 0.00257874, ..., 0.0106201,\n",
       "              0.0137939, -0.0246582],\n",
       "             [0.0142822, -0.0111694, 0.00439453, ..., -0.00358582,\n",
       "              0.00830078, 0.00268555],\n",
       "             [-0.00224304, 0.0202637, 0.00302124, ..., -0.0172119,\n",
       "              -0.000915527, 0.00689697]],\n",
       "    \n",
       "            [[-0.00454712, -0.00282288, -0.00366211, ..., 0.00552368,\n",
       "              -0.00337219, -0.00427246],\n",
       "             [-0.00256348, 0.0103149, 0.00775146, ..., 0.0098877,\n",
       "              0.00631714, -0.0144043],\n",
       "             [-0.000759125, 0.00662231, 1.61678e-06, ..., -0.00506592,\n",
       "              0.0108643, 0.00312805],\n",
       "             ...,\n",
       "             [-0.0150146, -0.00585938, 0.012207, ..., -0.00254822,\n",
       "              -0.0148315, 0.0106812],\n",
       "             [-0.00509644, -0.0270996, 0.00778198, ..., -0.0050354,\n",
       "              -0.00872803, 0.0203857],\n",
       "             [0.00382996, 0.00024128, 0.00866699, ..., -0.0174561,\n",
       "              0.0115356, -0.00173187]],\n",
       "    \n",
       "            [[-0.0106812, -0.00576782, -0.00564575, ..., 0.00308228,\n",
       "              -0.00747681, 0.0130615],\n",
       "             [-0.0217285, -0.00244141, -0.00640869, ..., 0.010437,\n",
       "              0.000126839, -0.000383377],\n",
       "             [0.0146484, -0.00144958, 0.0111694, ..., -0.00176239,\n",
       "              -0.00291443, -0.0114746],\n",
       "             ...,\n",
       "             [0.00244141, 0.00311279, -0.00141907, ..., -0.00231934,\n",
       "              -0.00619507, 0.00421143],\n",
       "             [-0.00202942, 0.0172119, -0.000196457, ..., 0.0161133,\n",
       "              -0.00619507, -0.00909424],\n",
       "             [0.0167236, 0.0112305, -0.00836182, ..., -0.00588989,\n",
       "              -0.00714111, 0.00491333]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00270081, -0.0148926, 0.013916, ..., 0.00193024, 0.0117798,\n",
       "             0.0299072],\n",
       "            [0.010376, -0.00279236, -0.00582886, ..., -0.0109863, 0.0164795,\n",
       "             -0.0249023],\n",
       "            [-0.00576782, -0.00265503, 0.00540161, ..., 0.0234375,\n",
       "             0.00732422, -0.0114136],\n",
       "            ...,\n",
       "            [0.00775146, -0.000617981, -0.000740051, ..., 0.0142822,\n",
       "             0.0339355, 0.0218506],\n",
       "            [0.00209045, -0.00174713, 0.00188446, ..., -0.0200195,\n",
       "             -0.0012207, 0.012207],\n",
       "            [0.012207, 0.00205994, 0.00613403, ..., 0.00343323, 0.0114746,\n",
       "             0.00848389]],\n",
       "    \n",
       "           [[-0.00830078, -8.10623e-05, 0.0101929, ..., -0.00747681,\n",
       "             0.00631714, 0.0177002],\n",
       "            [0.00915527, -0.00598145, -0.00964355, ..., -0.0166016,\n",
       "             0.0205078, -0.0358887],\n",
       "            [-0.00662231, 0.00585938, 0.001297, ..., 0.0154419, 0.0153198,\n",
       "             -0.0192871],\n",
       "            ...,\n",
       "            [0.00714111, 0.00769043, -0.00180054, ..., 0.017334, 0.0100098,\n",
       "             0.0227051],\n",
       "            [-0.0155029, -0.00497437, 0.0247803, ..., -0.0112915,\n",
       "             0.00169373, 0.000591278],\n",
       "            [0.00994873, -0.00152588, 0.000804901, ..., 0.00300598,\n",
       "             0.0019455, -0.00836182]],\n",
       "    \n",
       "           [[-0.00683594, 0.0025177, 0.00325012, ..., -0.00735474,\n",
       "             -0.0123291, -0.0153198],\n",
       "            [0.00302124, -0.00765991, -0.0016098, ..., 0.013916,\n",
       "             -0.00473022, 0.0172119],\n",
       "            [0.00291443, -0.00601196, -0.0109253, ..., 0.0132446,\n",
       "             -0.00662231, -0.00759888],\n",
       "            ...,\n",
       "            [0.00112152, -0.00186157, 0.00775146, ..., 0.019043, 0.0016861,\n",
       "             -0.0233154],\n",
       "            [-0.0038147, -0.00389099, -0.00540161, ..., 0.0090332,\n",
       "             -0.000778198, 0.00187683],\n",
       "            [-0.00239563, 0.00328064, -0.00799561, ..., -0.0111694,\n",
       "             -0.00866699, 0.0128784]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.000705719, 0.0032196, 0.00668335, ..., 0.0239258,\n",
       "             -0.00741577, 0.00108337],\n",
       "            [0.00595093, -0.0234375, 0.0124512, ..., -0.00680542,\n",
       "             -0.00762939, 0.0169678],\n",
       "            [0.00714111, -0.00320435, 0.00866699, ..., -0.0288086, 0.013916,\n",
       "             0.0187988],\n",
       "            ...,\n",
       "            [-0.00174713, 0.0055542, 0.00619507, ..., -0.00154877,\n",
       "             0.00631714, -0.00063324],\n",
       "            [0.00671387, -0.000444412, -0.0018692, ..., -0.00598145,\n",
       "             -0.0166016, 0.0166016],\n",
       "            [0.00415039, 0.00720215, -0.000312805, ..., -0.00512695,\n",
       "             0.0055542, -0.019043]],\n",
       "    \n",
       "           [[-0.015625, 0.00430298, 0.00805664, ..., 0.024292, -0.0214844,\n",
       "             -0.00765991],\n",
       "            [0.00588989, 0.00369263, -0.0110474, ..., -0.0354004,\n",
       "             0.00799561, -0.0194092],\n",
       "            [0.00387573, 0.00164795, 0.0109253, ..., -0.000648499,\n",
       "             -0.0291748, 0.00759888],\n",
       "            ...,\n",
       "            [-0.012146, 0.00750732, -0.00280762, ..., 0.00714111,\n",
       "             -0.00312805, 0.00750732],\n",
       "            [0.00210571, -0.000339508, 0.0101929, ..., 0.00622559,\n",
       "             -0.00350952, -0.00479126],\n",
       "            [-0.00662231, 0.000377655, -0.00101471, ..., -0.0142822,\n",
       "             0.0235596, 0.001091]],\n",
       "    \n",
       "           [[-0.0078125, 0.00811768, 0.00311279, ..., 0.00328064,\n",
       "             -0.0522461, -0.029541],\n",
       "            [-0.0110474, 0.0152588, -0.000161171, ..., -0.0167236,\n",
       "             -0.0143433, -0.0122681],\n",
       "            [0.000170708, 0.00405884, 0.000545502, ..., 0.000583649,\n",
       "             -0.0272217, 0.0130615],\n",
       "            ...,\n",
       "            [-0.0145874, 0.00396729, 0.000488281, ..., -0.0112305,\n",
       "             0.0038147, -0.00448608],\n",
       "            [0.0116577, 0.00285339, 0.00130463, ..., -0.00325012, 0.029541,\n",
       "             -0.0187988],\n",
       "            [-0.0133667, 0.0126343, 0.019165, ..., -0.0169678, 0.0198975,\n",
       "             -0.013916]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00106049, -0.0136108, -0.00315857, ..., 0.00205994,\n",
       "            0.0202637, -0.00112915],\n",
       "           [-0.00866699, 0.00778198, 0.00350952, ..., 0.00312805,\n",
       "            -0.00454712, 0.012146],\n",
       "           [0.00958252, -0.00154877, -0.0101318, ..., 0.00415039,\n",
       "            -0.00650024, 0.00376892],\n",
       "           ...,\n",
       "           [-0.0108643, -0.00299072, 0.012085, ..., 0.00637817,\n",
       "            -0.00457764, 0.00167084],\n",
       "           [0.0065918, 0.0032196, 0.00130463, ..., 0.00878906, -0.00418091,\n",
       "            0.0067749],\n",
       "           [0.00309753, -0.0119629, -0.00732422, ..., -0.00280762,\n",
       "            0.00454712, 0.000349045]],\n",
       "   \n",
       "          [[0.00952148, -0.0090332, 0.0032196, ..., -0.00366211,\n",
       "            -0.00823975, 0.00186157],\n",
       "           [0.00927734, -0.000930786, 0.0142822, ..., 0.00188446,\n",
       "            0.00306702, -0.0157471],\n",
       "           [-0.00341797, -0.00379944, -0.00598145, ..., 0.00582886,\n",
       "            0.0147095, -0.00708008],\n",
       "           ...,\n",
       "           [0.0016861, 0.00259399, -0.000118732, ..., -0.00289917,\n",
       "            -0.00476074, -0.00382996],\n",
       "           [-0.00741577, -0.003479, 0.000694275, ..., 0.00209045,\n",
       "            -0.00299072, 0.0122681],\n",
       "           [-0.00836182, -0.0144043, 0.00823975, ..., -0.00540161,\n",
       "            -0.00982666, 0.00424194]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00172424, -0.00161743, -0.00848389, ..., -0.00291443,\n",
       "           0.00527954, 0.00119019],\n",
       "          [-0.00860596, -0.00769043, -0.00497437, ..., 0.0038147,\n",
       "           0.00157166, -0.0187988],\n",
       "          [0.00671387, 0.00686646, -0.0110474, ..., 0.00595093,\n",
       "           -0.000713348, 0.000938416],\n",
       "          ...,\n",
       "          [-0.00582886, 0.0067749, 0.00124359, ..., -0.00720215,\n",
       "           -0.00762939, -0.0102539],\n",
       "          [-0.00579834, 0.00897217, 0.0119629, ..., 0.00188446, 0.00151825,\n",
       "           0.00209045],\n",
       "          [0.00674438, 0.00418091, 0.00909424, ..., 0.0129395, 0.00224304,\n",
       "           -0.000789642]], dtype=bfloat16), a=Array([[-0.00321405, -0.01531544,  0.01043977, ...,  0.01724594,\n",
       "           -0.00019943, -0.00515615],\n",
       "          [-0.00242979, -0.00892317, -0.00779914, ...,  0.01742655,\n",
       "            0.00521834,  0.00618159]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([1.25781, 1.17969, 1.125, ..., 0.96875, 1.0625, 0.910156], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([1.8125, 1.82812, 1.90625, ..., 1.71094, 1.84375, 1.57031],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.871094, 0.992188, 0.765625, ..., 0.648438, 0.5625, 0.960938],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.108398, -0.0561523, -0.0947266, ..., -0.074707, -0.150391,\n",
       "          -0.0505371], dtype=bfloat16)}},\n",
       " 'layer_17': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0317383, 0.0122681, 0.00708008, ..., -0.00114441, -0.0109863,\n",
       "             -0.0137329],\n",
       "            [-0.0032196, 0.00421143, -0.00300598, ..., -0.00148773,\n",
       "             0.022583, 0.00244141],\n",
       "            [-0.0183105, 0.0147095, 0.0153809, ..., 0.00364685, -0.00582886,\n",
       "             0.0088501],\n",
       "            ...,\n",
       "            [-0.012085, 0.00151825, -0.00445557, ..., -0.00270081,\n",
       "             -0.0141602, -0.00202942],\n",
       "            [-0.00415039, 0.0164795, -0.00891113, ..., -0.00759888,\n",
       "             0.0157471, 0.0017395],\n",
       "            [-0.013916, -0.0183105, 0.0150146, ..., -0.00158691, 0.00245667,\n",
       "             0.00976562]],\n",
       "    \n",
       "           [[-0.0118408, -0.00198364, 0.00976562, ..., -0.000541687,\n",
       "             0.0178223, -0.00332642],\n",
       "            [-0.0109253, 0.00325012, -0.0285645, ..., -0.00891113,\n",
       "             -0.0111084, 0.0119629],\n",
       "            [0.0088501, -0.0219727, 0.0115967, ..., -0.00891113, 0.015625,\n",
       "             0.00427246],\n",
       "            ...,\n",
       "            [-0.00350952, 0.0212402, -0.0180664, ..., -0.00561523,\n",
       "             0.00939941, -0.00276184],\n",
       "            [0.00473022, 0.019043, -0.00772095, ..., 0.0123291, 0.00110626,\n",
       "             -0.00352478],\n",
       "            [0.0101929, 0.0319824, 0.0158691, ..., 0.0143433, 0.0107422,\n",
       "             0.0162354]],\n",
       "    \n",
       "           [[0.00582886, -0.00970459, -0.00854492, ..., 0.00878906,\n",
       "             0.00570679, 0.0113525],\n",
       "            [0.0114136, 0.000610352, -0.0090332, ..., 0.0247803, -0.0090332,\n",
       "             0.00454712],\n",
       "            [-8.53539e-05, 0.0194092, 0.00233459, ..., -0.0137939,\n",
       "             0.00567627, -0.0209961],\n",
       "            ...,\n",
       "            [0.00958252, 0.00674438, 0.00337219, ..., -0.00294495, 0.012146,\n",
       "             -0.00352478],\n",
       "            [0.00753784, -0.00872803, -0.00469971, ..., -0.0143433,\n",
       "             0.00732422, 0.0125732],\n",
       "            [-0.017334, 0.0196533, -0.00891113, ..., -0.0115356, 0.00259399,\n",
       "             -0.00927734]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0125122, -0.00297546, -0.0196533, ..., 0.00482178,\n",
       "             0.0117188, 0.0150146],\n",
       "            [-0.00836182, -0.00866699, 0.0142212, ..., 0.00756836,\n",
       "             -0.0251465, -0.00109863],\n",
       "            [-0.00366211, -0.00415039, 0.0230713, ..., 0.0071106,\n",
       "             0.000556946, -0.0106812],\n",
       "            ...,\n",
       "            [0.0145874, 0.0196533, 0.0196533, ..., 0.0238037, 0.0216064,\n",
       "             -0.00463867],\n",
       "            [0.00157166, -0.00334167, 0.013855, ..., -0.00436401,\n",
       "             0.00297546, -0.00154877],\n",
       "            [-0.00482178, -0.000984192, 0.00152588, ..., -0.000324249,\n",
       "             0.0136719, -0.000839233]],\n",
       "    \n",
       "           [[-0.0027771, -0.0115356, 0.00367737, ..., 0.00125885, 0.0101929,\n",
       "             -0.000766754],\n",
       "            [0.00976562, -0.0267334, -0.00469971, ..., 0.0233154,\n",
       "             0.00209045, 0.0175781],\n",
       "            [-0.000938416, -0.000587463, -0.00491333, ..., 0.0222168,\n",
       "             0.00552368, -0.0134277],\n",
       "            ...,\n",
       "            [0.0125732, 0.00872803, 0.0194092, ..., 0.0011673, -0.006073,\n",
       "             0.00891113],\n",
       "            [-0.00268555, -0.00352478, 0.00366211, ..., 0.00164032,\n",
       "             0.0213623, -0.00640869],\n",
       "            [0.0134888, -0.00772095, -0.0172119, ..., 0.00196838,\n",
       "             -0.00367737, 0.00479126]],\n",
       "    \n",
       "           [[0.00952148, 0.0117188, -0.00805664, ..., 0.0117798,\n",
       "             -0.00405884, -0.00314331],\n",
       "            [-0.00360107, 0.0174561, -0.00491333, ..., -0.0281982,\n",
       "             -0.00358582, -0.0181885],\n",
       "            [-0.00933838, -0.00212097, 0.000314713, ..., -0.0175781,\n",
       "             -0.00421143, 0.017334],\n",
       "            ...,\n",
       "            [0.000135422, -0.0018692, -0.0158691, ..., -0.00408936,\n",
       "             0.00457764, 0.0108032],\n",
       "            [-0.000572205, -0.00271606, -0.0101318, ..., 0.00878906,\n",
       "             -0.019165, -0.000774384],\n",
       "            [-0.00585938, 0.00531006, 0.000314713, ..., -6.94394e-06,\n",
       "             0.00479126, -0.00190735]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0192871, 0.00017643, 0.0133667, ..., 0.00613403,\n",
       "              0.0174561, 0.00860596],\n",
       "             [0.00372314, 0.0108643, 0.00494385, ..., -0.00488281,\n",
       "              -0.00485229, 0.00616455],\n",
       "             [-0.00564575, -0.00165558, -0.00241089, ..., 0.000965118,\n",
       "              -0.000172615, 0.0109863],\n",
       "             ...,\n",
       "             [0.00650024, 0.00958252, -0.0100708, ..., -0.0322266,\n",
       "              -0.00756836, -0.00494385],\n",
       "             [-0.0123901, 0.00540161, 0.00897217, ..., 0.00878906,\n",
       "              -0.0142212, 0.000303268],\n",
       "             [5.93662e-05, 0.0157471, -0.00799561, ..., -0.0149536,\n",
       "              -0.0106812, -0.0250244]],\n",
       "    \n",
       "            [[-0.00756836, -0.00488281, 0.0124512, ..., -0.00946045,\n",
       "              -0.00576782, 0.00289917],\n",
       "             [-9.82285e-05, 0.0011673, 0.00028801, ..., 0.00640869,\n",
       "              0.0111084, 0.00674438],\n",
       "             [0.00506592, 0.000450134, -0.00448608, ..., -0.00119781,\n",
       "              0.000888824, -0.00257874],\n",
       "             ...,\n",
       "             [-0.00361633, 0.00439453, 0.0050354, ..., 0.00704956,\n",
       "              -0.00430298, -0.0202637],\n",
       "             [0.00674438, -0.00454712, -0.00830078, ..., 0.00221252,\n",
       "              0.00939941, -0.00222778],\n",
       "             [0.00363159, -0.00534058, -0.00265503, ..., -0.00628662,\n",
       "              -0.0148315, 0.0185547]],\n",
       "    \n",
       "            [[-0.00668335, 0.00610352, 0.00341797, ..., -0.00662231,\n",
       "              0.00747681, -0.00970459],\n",
       "             [-0.00726318, -0.00151825, -0.00445557, ..., 0.000142097,\n",
       "              -0.000349045, -0.0125122],\n",
       "             [0.00302124, -0.000762939, 0.00145721, ..., -0.00115967,\n",
       "              -0.00671387, -0.00500488],\n",
       "             ...,\n",
       "             [-0.00028801, -0.00158691, -0.00518799, ..., -0.00282288,\n",
       "              -0.00224304, 0.0152588],\n",
       "             [0.00127411, 0.00196838, -0.00482178, ..., -0.0108643,\n",
       "              -0.0141602, 0.00134277],\n",
       "             [0.0018692, -0.00137329, 0.00424194, ..., -0.00161743,\n",
       "              0.00933838, -0.00744629]],\n",
       "    \n",
       "            [[-0.00723267, -0.00704956, -0.00787354, ..., 0.0213623,\n",
       "              0.0012207, -0.00133514],\n",
       "             [-0.00488281, -0.00241089, 0.00430298, ..., -0.00285339,\n",
       "              -0.00245667, 0.00872803],\n",
       "             [-0.00878906, 0.00300598, 0.0098877, ..., 0.0150757,\n",
       "              0.00183105, 0.000364304],\n",
       "             ...,\n",
       "             [0.0136719, -0.00866699, -0.00241089, ..., 0.0125122,\n",
       "              0.0172119, 0.0178223],\n",
       "             [-0.0108032, 0.0057373, -0.00708008, ..., -0.00111389,\n",
       "              0.00166321, -0.00131226],\n",
       "             [-0.00427246, 0.0163574, -0.00204468, ..., -0.0177002,\n",
       "              0.0062561, 0.0213623]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00601196, 0.0183105, 0.00151825, ..., -0.00418091,\n",
       "              0.0288086, 0.00558472],\n",
       "             [-0.00118256, -0.0030365, -0.00317383, ..., 0.00418091,\n",
       "              0.00915527, 0.0129395],\n",
       "             [0.00228882, 0.00289917, 0.015564, ..., -0.000640869,\n",
       "              -0.000185013, 0.0161133],\n",
       "             ...,\n",
       "             [-0.00643921, -0.0303955, 0.010376, ..., -0.0152588,\n",
       "              -0.00165558, 0.00610352],\n",
       "             [0.0250244, 0.0141602, 0.00671387, ..., 0.00537109,\n",
       "              0.00994873, -0.000679016],\n",
       "             [-0.00958252, -0.0032196, 0.00921631, ..., -0.000295639,\n",
       "              -0.00735474, 0.0197754]],\n",
       "    \n",
       "            [[0.012146, 0.00765991, 0.00309753, ..., 0.00376892, 0.0102539,\n",
       "              0.0101929],\n",
       "             [0.0151367, 0.00860596, 0.0151978, ..., 0.00952148,\n",
       "              0.00579834, -0.000602722],\n",
       "             [0.012146, -0.00424194, 0.00279236, ..., 0.00582886,\n",
       "              0.0234375, -0.013855],\n",
       "             ...,\n",
       "             [0.00915527, 0.0090332, -0.0115356, ..., -0.00680542,\n",
       "              0.0189209, 0.00454712],\n",
       "             [0.0187988, -0.0155029, -0.0115967, ..., 0.0149536, 0.0196533,\n",
       "              0.0107422],\n",
       "             [-0.0125732, 0.00224304, -0.000415802, ..., 0.0195312,\n",
       "              0.00315857, -0.0100098]],\n",
       "    \n",
       "            [[0.00312805, -0.010498, 0.00149536, ..., 0.0090332,\n",
       "              -0.00323486, -0.00708008],\n",
       "             [0.00263977, 0.00430298, -1.38879e-05, ..., 0.000553131,\n",
       "              0.0112305, 0.00927734],\n",
       "             [0.003479, 0.000839233, -0.00216675, ..., 0.00288391,\n",
       "              0.00320435, 0.00952148],\n",
       "             ...,\n",
       "             [0.00588989, 0.00860596, 0.00360107, ..., 0.0231934,\n",
       "              -0.000398636, 0.0244141],\n",
       "             [0.020752, -0.00253296, -0.00543213, ..., 0.00848389,\n",
       "              -0.0116577, 0.00756836],\n",
       "             [-0.0110474, -0.022583, -0.00994873, ..., 0.0187988,\n",
       "              0.00393677, 0.00448608]],\n",
       "    \n",
       "            [[0.0324707, -0.0140381, 0.00110626, ..., -0.0122681,\n",
       "              0.00170898, -0.0126953],\n",
       "             [0.00909424, 0.0281982, 0.00382996, ..., -0.00604248,\n",
       "              -0.00236511, 0.00361633],\n",
       "             [-0.0178223, -0.00439453, 0.00720215, ..., -0.0253906,\n",
       "              0.0043335, 0.0107422],\n",
       "             ...,\n",
       "             [-0.00836182, -0.0245361, -0.022583, ..., -0.00323486,\n",
       "              0.0153809, -0.00151825],\n",
       "             [-0.00656128, 0.00366211, -0.00866699, ..., 0.0065918,\n",
       "              -0.0252686, 0.00512695],\n",
       "             [-0.00689697, -0.0197754, 0.0317383, ..., -0.0020752,\n",
       "              0.00823975, -0.00512695]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00518799, -0.00567627, -0.00671387, ..., -0.00190735,\n",
       "             -0.000797272, 0.0127563],\n",
       "            [-0.00300598, 0.00149536, -0.00622559, ..., -0.0444336,\n",
       "             0.026001, -0.03125],\n",
       "            [-0.00244141, 0.0112915, -0.00848389, ..., 0.0180664, 0.0197754,\n",
       "             0.017334],\n",
       "            ...,\n",
       "            [0.00601196, 0.00402832, 0.0163574, ..., 0.00265503, 0.00650024,\n",
       "             -0.019165],\n",
       "            [0.00309753, -0.00500488, -0.00224304, ..., -0.0131226,\n",
       "             0.0123291, -0.00314331],\n",
       "            [-0.00415039, 0.0055542, 0.00317383, ..., 0.00241089,\n",
       "             -0.0280762, -0.0170898]],\n",
       "    \n",
       "           [[0.0062561, -0.00698853, -0.0107422, ..., -0.00817871,\n",
       "             -0.00139618, -0.00271606],\n",
       "            [0.0014801, 0.0163574, 0.00964355, ..., -0.00153351, 0.00376892,\n",
       "             -0.00299072],\n",
       "            [-0.00236511, 0.00811768, 0.00415039, ..., 0.00166321,\n",
       "             0.00311279, 0.0201416],\n",
       "            ...,\n",
       "            [0.0252686, -0.00595093, 0.00482178, ..., 0.00509644,\n",
       "             -0.00656128, -0.0147705],\n",
       "            [0.00128937, -0.0169678, -0.00552368, ..., 0.013916,\n",
       "             -0.00601196, 0.0111694],\n",
       "            [0.00346375, 0.00137329, -0.00315857, ..., -0.00567627,\n",
       "             -0.00270081, -0.00970459]],\n",
       "    \n",
       "           [[0.00257874, -0.00204468, -3.6478e-05, ..., 0.010376,\n",
       "             0.00160217, 0.0273438],\n",
       "            [-0.0136108, 0.00393677, -0.00982666, ..., 0.000972748,\n",
       "             0.00262451, -0.012146],\n",
       "            [-0.00369263, -0.00604248, -0.00619507, ..., -0.00393677,\n",
       "             0.00177002, 0.00028038],\n",
       "            ...,\n",
       "            [-0.00543213, 0.00473022, 0.000663757, ..., -0.0032196,\n",
       "             0.0240479, -0.0020752],\n",
       "            [0.00646973, 0.0142212, 0.00328064, ..., -0.0111084, -0.0133057,\n",
       "             -0.00344849],\n",
       "            [-0.0119019, -0.000999451, 0.0038147, ..., 0.00121307,\n",
       "             -0.0150757, 0.00497437]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.000214577, 0.00283813, -0.00328064, ..., 0.00430298,\n",
       "             0.00221252, -0.00265503],\n",
       "            [0.00485229, 0.00389099, 0.00552368, ..., -0.000307083,\n",
       "             0.0110474, 0.00122833],\n",
       "            [0.0189209, -0.0189209, 0.0236816, ..., 0.00939941, -0.00113678,\n",
       "             -0.00592041],\n",
       "            ...,\n",
       "            [-0.00598145, 0.00640869, -0.0212402, ..., -0.00088501,\n",
       "             -0.00387573, 0.000171661],\n",
       "            [0.0111694, -0.0106201, 0.0098877, ..., -0.003479, -5.72205e-05,\n",
       "             -0.00418091],\n",
       "            [-0.000234604, 0.00927734, -0.0245361, ..., 0.00408936,\n",
       "             0.00262451, 0.00325012]],\n",
       "    \n",
       "           [[-0.00291443, -0.0035553, 0.0101318, ..., 0.0106812, 0.00588989,\n",
       "             0.0170898],\n",
       "            [0.00460815, 0.00231934, 0.00245667, ..., 0.00527954, 0.0065918,\n",
       "             0.0134888],\n",
       "            [0.0067749, 0.00445557, 0.0137329, ..., 0.00382996, 0.0126953,\n",
       "             -0.00634766],\n",
       "            ...,\n",
       "            [-0.00227356, 0.00527954, 0.0110474, ..., 0.00750732, 0.0016861,\n",
       "             0.0218506],\n",
       "            [-0.00570679, 0.00338745, 0.017334, ..., -0.00405884,\n",
       "             -0.0100098, 0.00628662],\n",
       "            [-0.00772095, -0.00622559, -0.0105591, ..., -0.0168457,\n",
       "             0.0065918, 0.0147095]],\n",
       "    \n",
       "           [[0.000831604, 0.0102539, -0.0020752, ..., 0.00588989, 0.0161133,\n",
       "             -0.0098877],\n",
       "            [-0.00138855, 0.00509644, 0.00946045, ..., 0.00439453,\n",
       "             -0.00370789, 0.00613403],\n",
       "            [-0.00946045, -0.00558472, -0.00521851, ..., 0.0115967,\n",
       "             0.0065918, 0.0114746],\n",
       "            ...,\n",
       "            [-0.00842285, 0.000572205, -0.00144196, ..., 0.00689697,\n",
       "             0.00524902, 0.0148315],\n",
       "            [-0.00946045, -0.00314331, -0.00665283, ..., 0.00497437,\n",
       "             0.010376, 0.00656128],\n",
       "            [-0.00665283, -0.00527954, -0.0078125, ..., -0.0195312,\n",
       "             -0.0106812, 0.0128784]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.000762939, 0.000923157, 0.0124512, ..., 0.0088501,\n",
       "            -0.00473022, -0.00534058],\n",
       "           [-0.00778198, -0.00637817, -0.00735474, ..., 0.00604248,\n",
       "            0.00136566, 0.00665283],\n",
       "           [0.00897217, 0.000124931, -0.000396729, ..., 0.0118408,\n",
       "            -0.00245667, -0.000808716],\n",
       "           ...,\n",
       "           [0.00805664, 0.00159454, 0.00805664, ..., -0.00488281,\n",
       "            0.00570679, -0.0102539],\n",
       "           [0.00643921, -0.00396729, -0.00704956, ..., 0.00271606,\n",
       "            -0.0198975, 0.00637817],\n",
       "           [-0.0126953, 0.00253296, -0.00190735, ..., -0.00170135,\n",
       "            0.00411987, 0.0100708]],\n",
       "   \n",
       "          [[-0.00891113, -0.00860596, 0.00540161, ..., 0.00170135,\n",
       "            0.00665283, -0.00180817],\n",
       "           [-0.0130615, 0.00717163, 0.0109863, ..., -0.00312805,\n",
       "            0.00164795, 0.00747681],\n",
       "           [5.29289e-05, -0.0050354, -0.00424194, ..., -0.00144958,\n",
       "            0.00274658, -0.0252686],\n",
       "           ...,\n",
       "           [-0.00805664, 0.006073, 0.000946045, ..., -0.00299072,\n",
       "            0.00460815, 0.00393677],\n",
       "           [-0.00982666, 0.00111389, -0.00509644, ..., -0.00683594,\n",
       "            -0.00112152, 0.00717163],\n",
       "           [-0.00289917, 0.0169678, 0.000934601, ..., 0.00732422,\n",
       "            0.0143433, 0.00704956]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00213623, -0.00421143, -0.000114918, ..., -0.00062561,\n",
       "           -0.00126648, 0.00830078],\n",
       "          [0.0128174, 0.00976562, -0.00543213, ..., -0.00656128,\n",
       "           -0.00646973, 0.0153809],\n",
       "          [0.00427246, -0.00823975, -0.00216675, ..., 0.00115967,\n",
       "           0.00267029, 0.00753784],\n",
       "          ...,\n",
       "          [-0.010498, 0.00167847, 0.0109863, ..., -0.00778198, 0.000522614,\n",
       "           -0.000385284],\n",
       "          [-0.00634766, -0.0045166, -0.00172424, ..., -0.00308228,\n",
       "           0.00230408, 0.0115967],\n",
       "          [0.00367737, 0.00604248, -0.0290527, ..., -0.00247192, 0.00361633,\n",
       "           0.00732422]], dtype=bfloat16), a=Array([[ 0.00229674,  0.00096951,  0.00196753, ...,  0.00066601,\n",
       "            0.00454113, -0.01169481],\n",
       "          [-0.00571106, -0.00023862, -0.00663244, ...,  0.00123321,\n",
       "           -0.01802823,  0.00163148]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([1.17188, 1.17188, 1.03125, ..., 1.05469, 0.980469, 1.01562],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([2.125, 2.04688, 2.1875, ..., 2, 2.15625, 1.875], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.535156, 0.675781, 0.472656, ..., 0.484375, 0.423828, 0.667969],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.0554199, -0.00891113, -0.0585938, ..., -0.0483398, -0.0942383,\n",
       "          -0.000480652], dtype=bfloat16)}},\n",
       " 'layer_18': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00476074, -0.00531006, 0.0158691, ..., -0.00159454,\n",
       "             -0.00141144, 0.00190735],\n",
       "            [-0.0219727, 0.010376, -0.00674438, ..., -0.0142822, 0.00604248,\n",
       "             -0.0180664],\n",
       "            [-0.0105591, 0.000965118, 0.00817871, ..., 0.00358582,\n",
       "             -0.00759888, -0.0233154],\n",
       "            ...,\n",
       "            [0.0159912, 0.0162354, -0.00531006, ..., -0.00830078,\n",
       "             -0.000839233, -0.00909424],\n",
       "            [-0.0275879, 0.0137329, 0.0078125, ..., 0.0062561, 0.00366211,\n",
       "             -0.0115967],\n",
       "            [0.0119019, 0.00939941, 0.000579834, ..., 0.00219727,\n",
       "             -0.00309753, 0.010498]],\n",
       "    \n",
       "           [[0.0116577, -0.020752, 0.000831604, ..., -0.00305176,\n",
       "             -0.00306702, 0.00102997],\n",
       "            [-0.00154877, 0.00171661, 0.000991821, ..., -0.00233459,\n",
       "             0.0137939, -0.00469971],\n",
       "            [-0.0251465, 1.86265e-06, -0.0179443, ..., -0.0253906,\n",
       "             0.0118408, -0.0025177],\n",
       "            ...,\n",
       "            [0.00592041, -0.0220947, 0.00491333, ..., -0.00689697, 0.015625,\n",
       "             0.0112915],\n",
       "            [-0.00212097, 0.0141602, -0.0131836, ..., -0.0209961,\n",
       "             -0.00964355, 0.0224609],\n",
       "            [-0.00543213, 0.000159264, 0.00340271, ..., 0.0209961,\n",
       "             0.0136108, -0.0164795]],\n",
       "    \n",
       "           [[0.00427246, 0.00927734, 0.0111084, ..., 0.0118408, -0.0272217,\n",
       "             0.00891113],\n",
       "            [0.00138855, -0.019043, 0.0130005, ..., 0.0349121, 0.00442505,\n",
       "             0.00289917],\n",
       "            [-0.00188446, 0.0126953, 0.00323486, ..., -0.00153351,\n",
       "             -0.006073, 0.00952148],\n",
       "            ...,\n",
       "            [-0.0157471, -0.00497437, 0.00224304, ..., 0.00209045,\n",
       "             0.00176239, 0.00159454],\n",
       "            [-0.00364685, -0.00396729, 0.0150146, ..., -0.00485229,\n",
       "             -0.00897217, -0.00769043],\n",
       "            [0.000461578, -0.0103149, -0.0117188, ..., -0.00143433,\n",
       "             -0.0102539, 0.00726318]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00564575, 0.00291443, 0.00210571, ..., -0.00331116,\n",
       "             0.00616455, 0.0134888],\n",
       "            [0.00088501, 0.00289917, 0.00463867, ..., -0.00274658,\n",
       "             -0.010376, 0.00271606],\n",
       "            [0.00595093, -0.0178223, -0.00259399, ..., -2.32458e-05,\n",
       "             0.0268555, -0.00769043],\n",
       "            ...,\n",
       "            [-0.00488281, 0.0180664, 0.017334, ..., 0.00379944, 0.0161133,\n",
       "             0.0117188],\n",
       "            [0.000522614, 0.0159912, -0.00408936, ..., -0.0098877,\n",
       "             0.00726318, -0.00860596],\n",
       "            [-0.000583649, -0.00384521, 0.0114136, ..., -0.00169373,\n",
       "             0.00393677, 0.0043335]],\n",
       "    \n",
       "           [[-0.00616455, -0.0022583, -0.00148773, ..., -0.00227356,\n",
       "             -0.010498, 0.000396729],\n",
       "            [0.00604248, -0.00378418, -0.00891113, ..., -0.00579834,\n",
       "             -0.0224609, -0.00167847],\n",
       "            [0.010498, 0.0209961, 0.00308228, ..., -0.00405884, -0.00387573,\n",
       "             0.00588989],\n",
       "            ...,\n",
       "            [-0.000161171, -0.0134277, 0.00540161, ..., 0.00744629,\n",
       "             0.00366211, -0.00402832],\n",
       "            [0.000881195, -0.00144196, -0.000179291, ..., -0.00299072,\n",
       "             0.0109863, -0.00331116],\n",
       "            [-0.00418091, 3.40939e-05, 0.0105591, ..., 0.0216064,\n",
       "             0.00230408, -0.0019989]],\n",
       "    \n",
       "           [[0.0067749, -0.0119019, -0.00285339, ..., 0.0019989, 0.00604248,\n",
       "             0.010437],\n",
       "            [-0.00170898, 0.00650024, 0.010376, ..., -0.00106049, 0.024292,\n",
       "             -0.00466919],\n",
       "            [-0.010437, -0.0354004, -0.0129395, ..., -0.00182343,\n",
       "             -0.000984192, -0.00537109],\n",
       "            ...,\n",
       "            [-0.00274658, 0.0118408, -0.0100098, ..., -0.0163574,\n",
       "             0.00469971, 0.013855],\n",
       "            [0.0184326, -0.00418091, -0.0148315, ..., 0.00982666,\n",
       "             -0.0148926, 0.00723267],\n",
       "            [0.00982666, 0.00256348, -0.00738525, ..., -0.0290527,\n",
       "             -0.00595093, 0.00463867]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00123596, 0.00038147, 0.001297, ..., 0.000425339,\n",
       "              0.0184326, 0.0088501],\n",
       "             [-0.0112305, 0.00179291, -0.00723267, ..., 0.0224609,\n",
       "              0.0117798, -0.00296021],\n",
       "             [-0.0119629, 0.00326538, -0.00933838, ..., -0.022583,\n",
       "              -0.00239563, -0.00512695],\n",
       "             ...,\n",
       "             [-0.000923157, 0.00717163, 0.0120239, ..., 0.00753784,\n",
       "              0.00250244, 0.00141144],\n",
       "             [-0.00204468, -0.000526428, 0.00227356, ..., 0.0106201,\n",
       "              -0.000166893, 0.0055542],\n",
       "             [-0.00823975, 0.0014801, -0.000545502, ..., -0.0198975,\n",
       "              -0.00448608, 0.0123291]],\n",
       "    \n",
       "            [[0.00201416, -0.000640869, 0.0125122, ..., 0.00325012,\n",
       "              0.00115967, 0.00263977],\n",
       "             [-0.00830078, 0.00491333, 0.00174713, ..., -0.00082016,\n",
       "              0.00878906, -0.0236816],\n",
       "             [-0.00104523, 0.000644684, 0.0147095, ..., 0.00328064,\n",
       "              -0.00354004, 0.0238037],\n",
       "             ...,\n",
       "             [0.00848389, 0.00050354, 0.00349426, ..., 0.00909424,\n",
       "              -0.00744629, -0.00595093],\n",
       "             [-0.00656128, 0.00567627, 0.00738525, ..., -0.00245667,\n",
       "              -0.0167236, 0.00218201],\n",
       "             [-0.00665283, 0.0090332, 0.00094986, ..., -0.00253296,\n",
       "              0.00314331, 0.0105591]],\n",
       "    \n",
       "            [[-0.0118408, 0.00274658, -0.0206299, ..., -0.0255127,\n",
       "              -0.00939941, 0.0148926],\n",
       "             [-0.00952148, 0.0131836, 0.0013504, ..., 0.00332642,\n",
       "              -0.0274658, 0.00595093],\n",
       "             [-0.0050354, 0.00643921, 0.0117798, ..., 0.00683594,\n",
       "              -0.0178223, -0.0015564],\n",
       "             ...,\n",
       "             [0.00384521, -0.00592041, -0.000701904, ..., 0.000371933,\n",
       "              -0.00139618, -0.00164795],\n",
       "             [-0.000640869, -0.0178223, -0.0111694, ..., -0.0239258,\n",
       "              -0.0067749, -0.0195312],\n",
       "             [-0.00112152, 0.00723267, -0.0164795, ..., -0.0187988,\n",
       "              0.010376, -0.0175781]],\n",
       "    \n",
       "            [[0.00463867, -0.00112915, 0.0065918, ..., -0.013855,\n",
       "              -0.00585938, 0.00167084],\n",
       "             [0.00878906, -0.0161133, -0.00598145, ..., -0.000184059,\n",
       "              0.0214844, -0.00842285],\n",
       "             [0.0062561, -0.00375366, -0.00201416, ..., 0.0189209,\n",
       "              -0.003479, -0.00515747],\n",
       "             ...,\n",
       "             [-0.00891113, -0.00289917, -0.00823975, ..., -0.00242615,\n",
       "              0.00285339, -0.0112305],\n",
       "             [-0.0062561, -0.00500488, -0.00238037, ..., 0.00485229,\n",
       "              0.0197754, 0.0161133],\n",
       "             [0.00408936, 0.000163078, -0.0078125, ..., 0.00320435,\n",
       "              0.00970459, 0.0125732]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0016098, -0.0163574, -0.022583, ..., 0.0281982,\n",
       "              -0.00866699, 0.00279236],\n",
       "             [-0.0183105, 0.0101318, 0.00130463, ..., 0.0192871, 0.0236816,\n",
       "              0.0130615],\n",
       "             [0.0361328, 0.00939941, -0.00830078, ..., -0.0229492,\n",
       "              0.013916, 0.00946045],\n",
       "             ...,\n",
       "             [-0.0200195, -0.0205078, -0.000429153, ..., -0.0169678,\n",
       "              -0.00102997, 0.00579834],\n",
       "             [-0.0211182, 0.00488281, -0.00128174, ..., 0.00396729,\n",
       "              0.0161133, -0.0108643],\n",
       "             [-0.00662231, -0.013855, -0.0230713, ..., 0.0045166,\n",
       "              0.00143433, 0.00723267]],\n",
       "    \n",
       "            [[0.00765991, 0.0253906, -0.00463867, ..., 0.000134468,\n",
       "              0.0088501, -0.00144196],\n",
       "             [0.00375366, -0.0224609, 0.00271606, ..., 0.0039978,\n",
       "              0.0045166, -0.00732422],\n",
       "             [0.0209961, 0.00747681, 0.00982666, ..., 0.0279541,\n",
       "              0.000938416, -0.00921631],\n",
       "             ...,\n",
       "             [0.0159912, 0.00576782, -0.00817871, ..., 0.0126953,\n",
       "              -0.0050354, -0.00282288],\n",
       "             [-0.0251465, 0.00772095, -0.0186768, ..., 0.00799561,\n",
       "              0.00106049, -0.0198975],\n",
       "             [0.0144043, -0.0217285, 0.0185547, ..., 0.0244141, 0.00121307,\n",
       "              0.00964355]],\n",
       "    \n",
       "            [[0.00543213, -0.0088501, 0.000219345, ..., -0.00366211,\n",
       "              -0.0101318, -0.0145874],\n",
       "             [0.003479, 0.00811768, 0.00582886, ..., 0.00117493,\n",
       "              -0.0032196, 0.0115356],\n",
       "             [-0.00120544, -0.00469971, 0.0020752, ..., 0.00540161,\n",
       "              -0.0103149, -0.00271606],\n",
       "             ...,\n",
       "             [-0.00288391, -0.000701904, 0.00595093, ..., -0.00292969,\n",
       "              0.00165558, -0.0150757],\n",
       "             [0.0125122, 0.00741577, 0.0229492, ..., -0.00256348,\n",
       "              -0.00793457, -0.00576782],\n",
       "             [-0.00101471, -0.00113678, -0.0112915, ..., 0.0151978,\n",
       "              -4.41074e-05, 0.0147095]],\n",
       "    \n",
       "            [[0.0101929, -0.00300598, 0.000782013, ..., -0.00769043,\n",
       "              -0.0050354, 0.00135803],\n",
       "             [7.45058e-06, 0.000114441, -0.00479126, ..., 0.00576782,\n",
       "              -0.00028038, 0.00131226],\n",
       "             [0.00891113, 0.00509644, 0.00872803, ..., -0.0037384,\n",
       "              0.0262451, -0.00686646],\n",
       "             ...,\n",
       "             [8.58307e-06, 0.00167847, -0.00619507, ..., -0.00509644,\n",
       "              0.0067749, 0.00112915],\n",
       "             [0.00418091, 0.00476074, -0.0071106, ..., 0.0117798,\n",
       "              0.0273438, 0.0212402],\n",
       "             [0.000151634, -0.00408936, 0.00299072, ..., -0.00491333,\n",
       "              -0.00190735, 0.00970459]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00411987, -0.0011673, 0.00509644, ..., 0.00524902,\n",
       "             0.00285339, 0.00744629],\n",
       "            [0.00485229, 0.0132446, 0.0067749, ..., -0.00878906,\n",
       "             -0.00854492, 0.00656128],\n",
       "            [-0.00897217, 0.0212402, 0.00288391, ..., 0.000797272,\n",
       "             0.00050354, -0.027832],\n",
       "            ...,\n",
       "            [0.0164795, 0.00167847, -0.00326538, ..., -0.0143433,\n",
       "             0.00131989, -0.000789642],\n",
       "            [-0.00105286, -0.00671387, -0.0128784, ..., 0.0167236,\n",
       "             -0.00171661, -0.00561523],\n",
       "            [-0.0114746, 0.0111694, 0.00147247, ..., -0.00106812,\n",
       "             -0.00210571, 0.0180664]],\n",
       "    \n",
       "           [[0.00210571, -0.0115356, 0.00274658, ..., -0.015564, 0.0112915,\n",
       "             -0.0125732],\n",
       "            [0.000137329, -0.00231934, -0.00793457, ..., -0.00643921,\n",
       "             0.00191498, -0.012085],\n",
       "            [0.0030365, 0.00283813, 0.0011673, ..., -0.00515747, 0.00364685,\n",
       "             -0.000530243],\n",
       "            ...,\n",
       "            [0.0164795, 0.00161743, -0.000476837, ..., -0.00114441,\n",
       "             -0.0203857, -0.0212402],\n",
       "            [0.000583649, -0.00276184, -0.0110474, ..., 0.0214844,\n",
       "             -0.00335693, 0.0120239],\n",
       "            [-0.0114746, 0.0114136, 0.010437, ..., -0.00500488,\n",
       "             -0.000526428, -0.00185394]],\n",
       "    \n",
       "           [[0.0120239, -0.00238037, 0.00982666, ..., 0.0159912, -0.0158691,\n",
       "             0.00811768],\n",
       "            [-0.0144043, 0.0202637, 0.012207, ..., -0.0170898, -0.0123901,\n",
       "             -0.00552368],\n",
       "            [0.00233459, 0.00476074, 0.0198975, ..., 0.0172119, 0.0131836,\n",
       "             -0.0192871],\n",
       "            ...,\n",
       "            [-0.0111694, 0.00512695, -0.0018692, ..., 0.0108643, 0.00346375,\n",
       "             -0.00579834],\n",
       "            [0.00411987, -0.00221252, -0.00817871, ..., -0.0124512,\n",
       "             -0.0184326, -0.000595093],\n",
       "            [-0.00717163, -0.00357056, 0.00497437, ..., 0.0014801,\n",
       "             -0.0332031, 0.0133667]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0037384, 0.00805664, 0.0146484, ..., -0.0336914, -0.0101318,\n",
       "             0.0145264],\n",
       "            [0.0065918, 0.00102234, 0.00787354, ..., 0.0292969, 0.00318909,\n",
       "             -0.026001],\n",
       "            [0.00370789, -0.0174561, 0.0145264, ..., -0.00349426, 0.0120239,\n",
       "             0.00891113],\n",
       "            ...,\n",
       "            [0.00775146, -0.000371933, 0.00708008, ..., -0.0245361,\n",
       "             0.0407715, 0.000526428],\n",
       "            [-0.0151978, -0.00259399, -0.000728607, ..., -0.00921631,\n",
       "             0.00309753, -0.020752],\n",
       "            [-0.0022583, 0.00775146, 0.00265503, ..., -0.0101318,\n",
       "             -0.00946045, -0.0161133]],\n",
       "    \n",
       "           [[-0.000142097, 0.00286865, 0.0126343, ..., 0.00439453,\n",
       "             -0.00357056, -0.00172424],\n",
       "            [-0.00817871, 0.00518799, 0.0106201, ..., 0.0177002, 0.0157471,\n",
       "             -0.00131226],\n",
       "            [-0.00982666, -0.00878906, -0.000457764, ..., -0.0108032,\n",
       "             0.0159912, -0.0102539],\n",
       "            ...,\n",
       "            [0.0140381, 0.00546265, -0.0078125, ..., -0.00714111,\n",
       "             0.00534058, 0.00708008],\n",
       "            [0.00506592, 0.00424194, 0.000736237, ..., -0.00976562,\n",
       "             0.00735474, -0.0100708],\n",
       "            [-0.0022583, 0.0030365, 0.0107422, ..., 0.0125122, 0.0181885,\n",
       "             -0.0268555]],\n",
       "    \n",
       "           [[-0.00994873, 0.00778198, -0.00534058, ..., 0.0120239,\n",
       "             -0.0119629, 0.0136108],\n",
       "            [0.00473022, -0.0127563, -0.0032196, ..., 0.00166321,\n",
       "             0.00338745, -0.00108337],\n",
       "            [-0.00159454, -0.00379944, 0.00769043, ..., -0.00294495,\n",
       "             -0.00369263, -0.00213623],\n",
       "            ...,\n",
       "            [0.0016098, 0.00952148, -0.0192871, ..., 0.00509644,\n",
       "             -0.00189972, 0.00692749],\n",
       "            [-0.00463867, 0.0123901, 0.00454712, ..., 0.0108643, 0.00964355,\n",
       "             0.00616455],\n",
       "            [0.00570679, -0.00354004, -0.00726318, ..., 0.00726318,\n",
       "             0.00011158, 0.00439453]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00238037, 0.015625, -0.00811768, ..., 0.00692749,\n",
       "            0.00759888, 0.00279236],\n",
       "           [-0.0115967, -0.00695801, -0.0098877, ..., 0.00476074,\n",
       "            -0.000191689, 0.0125732],\n",
       "           [0.00698853, -0.00994873, 0.00366211, ..., -0.00364685,\n",
       "            0.000926971, 0.0032959],\n",
       "           ...,\n",
       "           [0.000195503, -0.0105591, -0.00463867, ..., 0.00469971,\n",
       "            -0.00671387, -0.00759888],\n",
       "           [0.00285339, 0.0129395, -0.00497437, ..., -0.00182343,\n",
       "            -0.00216675, -0.0067749],\n",
       "           [0.0137329, 0.00518799, 0.00325012, ..., 0.0101929, -0.00056839,\n",
       "            0.000640869]],\n",
       "   \n",
       "          [[-0.00704956, 0.0164795, -0.0167236, ..., -0.0130005,\n",
       "            -0.00579834, 0.00747681],\n",
       "           [0.0128784, -0.00267029, 0.00619507, ..., 0.000946045,\n",
       "            -0.0016861, 0.00427246],\n",
       "           [-0.000858307, 0.00601196, -0.0013504, ..., -0.00741577,\n",
       "            -0.00927734, 0.0115967],\n",
       "           ...,\n",
       "           [0.00982666, -0.000402451, 0.0098877, ..., 0.00891113,\n",
       "            0.00564575, -0.0050354],\n",
       "           [-0.00830078, -0.00175476, 0.00276184, ..., 0.00292969,\n",
       "            -0.0109863, 0.00405884],\n",
       "           [0.00175476, -0.0106812, -0.00378418, ..., 6.19888e-05,\n",
       "            -0.00361633, 0.0106201]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00424194, 0.00421143, -0.00646973, ..., -0.00610352,\n",
       "           -0.00107574, 0.00671387],\n",
       "          [0.00817871, 0.00123596, 0.00230408, ..., 0.00741577, -0.00878906,\n",
       "           0.00331116],\n",
       "          [-0.012085, -0.00415039, -0.0150146, ..., 0.00367737, -0.00738525,\n",
       "           -0.0032196],\n",
       "          ...,\n",
       "          [-0.00762939, 0.0129395, -0.0129395, ..., 0.00970459, 0.0116577,\n",
       "           0.00994873],\n",
       "          [-0.00241089, -0.000701904, 0.00732422, ..., 0.00280762,\n",
       "           0.000246048, 0.00210571],\n",
       "          [0.00576782, -0.00817871, 0.0120239, ..., -0.00363159, 0.00442505,\n",
       "           -0.00546265]], dtype=bfloat16), a=Array([[-0.01076485, -0.01254259,  0.00719575, ..., -0.01088936,\n",
       "            0.02172294,  0.00355693],\n",
       "          [-0.00358216, -0.01947643, -0.00234379, ..., -0.00571739,\n",
       "            0.02209909,  0.01588861]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([1.36719, 1.41406, 1.35938, ..., 1.39062, 1.60938, 1.26562],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([2.46875, 2.42188, 2.48438, ..., 2.34375, 2.53125, 2.3125],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.443359, 0.570312, 0.347656, ..., 0.453125, 0.388672, 0.5625],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.160156, 0.269531, 0.191406, ..., 0.158203, 0.11377, 0.259766],      dtype=bfloat16)}},\n",
       " 'layer_19': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00750732, -0.0223389, -0.0175781, ..., 0.00497437,\n",
       "             -0.00921631, 0.00454712],\n",
       "            [0.00891113, -0.00183868, 0.00268555, ..., 0.00430298,\n",
       "             -0.000682831, -0.0246582],\n",
       "            [-0.00296021, 0.0268555, -0.00227356, ..., 2.11e-05,\n",
       "             -0.00108337, -0.0115967],\n",
       "            ...,\n",
       "            [0.00183868, 0.0186768, 0.0125122, ..., 0.00291443, 0.00198364,\n",
       "             0.0100098],\n",
       "            [0.0014267, -0.00778198, 0.0117188, ..., -0.0055542,\n",
       "             -0.00970459, 0.00402832],\n",
       "            [0.000923157, 0.0194092, -0.0078125, ..., -0.00656128,\n",
       "             -0.0098877, 0.0175781]],\n",
       "    \n",
       "           [[-0.0230713, 0.00787354, 0.00418091, ..., -0.0014267,\n",
       "             -0.0128784, 0.0206299],\n",
       "            [-0.0334473, -0.0140381, -0.00408936, ..., 0.00376892,\n",
       "             -0.00482178, -0.0142822],\n",
       "            [0.0122681, -0.00680542, 0.00732422, ..., -0.0112305,\n",
       "             -0.0130615, -0.00598145],\n",
       "            ...,\n",
       "            [0.0183105, -0.00396729, -0.00860596, ..., -0.00396729,\n",
       "             0.00643921, -0.00121307],\n",
       "            [0.0117798, -0.0212402, -0.0203857, ..., -0.00491333,\n",
       "             0.00136566, 0.0106201],\n",
       "            [-0.0255127, 0.000686646, 0.00723267, ..., -0.00125122,\n",
       "             -0.00231934, -0.0175781]],\n",
       "    \n",
       "           [[0.02771, -0.00946045, 0.00805664, ..., -0.0241699, 0.010437,\n",
       "             0.0202637],\n",
       "            [0.00120544, 0.0100098, -0.0168457, ..., 0.00753784, -0.0117188,\n",
       "             -0.0157471],\n",
       "            [-0.00891113, 0.00213623, 0.00683594, ..., -0.00069809,\n",
       "             -0.00469971, 0.0050354],\n",
       "            ...,\n",
       "            [0.00230408, 0.00958252, -0.000648499, ..., 0.00558472,\n",
       "             0.0299072, 0.00866699],\n",
       "            [0.00787354, -0.00708008, -0.0201416, ..., -0.000511169,\n",
       "             -0.00952148, -0.019165],\n",
       "            [-0.00037384, 0.0161133, -0.00952148, ..., -0.012207,\n",
       "             -0.0179443, 0.00561523]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.019165, -0.00248718, 0.00157166, ..., -0.0025177, 0.0145874,\n",
       "             -0.00315857],\n",
       "            [-0.0236816, -0.0134888, 0.0142212, ..., 0.00695801,\n",
       "             -0.00848389, -0.00891113],\n",
       "            [-0.000518799, -0.00393677, 0.0213623, ..., 0.0167236,\n",
       "             -0.010437, -0.00561523],\n",
       "            ...,\n",
       "            [0.0126343, 0.00306702, 0.0200195, ..., -0.00909424, 0.0136108,\n",
       "             -0.0109253],\n",
       "            [-0.000797272, -0.00427246, -0.00860596, ..., -0.00491333,\n",
       "             0.00201416, 0.0145264],\n",
       "            [0.00671387, -0.0174561, -0.0134277, ..., -0.00836182,\n",
       "             -0.0174561, -0.0187988]],\n",
       "    \n",
       "           [[0.000854492, -0.0142822, -0.0130615, ..., -0.000839233,\n",
       "             -0.00363159, -0.00866699],\n",
       "            [-0.00668335, -0.00921631, 0.0113525, ..., -0.006073,\n",
       "             -9.71556e-06, 0.0032959],\n",
       "            [0.0149536, 0.00120544, 0.00325012, ..., -0.0109863,\n",
       "             -0.00775146, -0.000915527],\n",
       "            ...,\n",
       "            [-0.0294189, 0.0045166, -0.0039978, ..., -0.00343323,\n",
       "             0.00634766, -0.00720215],\n",
       "            [0.00939941, -0.00162506, 0.0154419, ..., -0.000239372,\n",
       "             -0.010437, 6.19888e-05],\n",
       "            [0.00982666, 0.0112915, 0.00579834, ..., 8.58307e-05,\n",
       "             -0.0090332, 0.00262451]],\n",
       "    \n",
       "           [[0.00340271, 0.00123596, 0.0136108, ..., 0.00515747, 0.00390625,\n",
       "             0.00811768],\n",
       "            [0.0253906, -0.0181885, -0.00634766, ..., -0.00112152,\n",
       "             0.0078125, -0.00579834],\n",
       "            [-0.0144653, -0.0142822, -0.00509644, ..., 0.0209961,\n",
       "             0.00482178, -0.0131836],\n",
       "            ...,\n",
       "            [0.0110474, -0.0105591, 0.00842285, ..., 0.0001688, 0.0119019,\n",
       "             -0.00836182],\n",
       "            [-0.0113525, -0.00646973, -0.0157471, ..., -0.0179443,\n",
       "             -0.00201416, 0.0198975],\n",
       "            [0.00408936, 0.00482178, 0.00363159, ..., 0.00267029, 0.013916,\n",
       "             -0.0098877]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00921631, 0.0206299, 0.00215149, ..., -0.00518799,\n",
       "              -0.0263672, 0.00195312],\n",
       "             [0.00430298, 0.00476074, -0.00124359, ..., -0.00842285,\n",
       "              0.0212402, -0.00393677],\n",
       "             [-0.00309753, 0.0020752, 0.00312805, ..., 0.00291443,\n",
       "              -0.00753784, -0.000436783],\n",
       "             ...,\n",
       "             [0.00270081, 0.00358582, 0.00228882, ..., -0.0151367,\n",
       "              -0.00280762, 0.00836182],\n",
       "             [-0.00521851, -0.0103149, 0.00390625, ..., 0.000900269,\n",
       "              0.00111389, -0.00390625],\n",
       "             [0.000724792, 0.00375366, 0.00372314, ..., 0.00518799,\n",
       "              -0.0169678, 0.00215149]],\n",
       "    \n",
       "            [[-0.0113525, 0.00367737, -0.00192261, ..., -0.0162354,\n",
       "              -0.0170898, 0.00558472],\n",
       "             [-0.0117798, -0.00976562, 0.00274658, ..., 0.0106812,\n",
       "              0.0018158, 0.00946045],\n",
       "             [0.00133514, 0.00244141, -0.000157356, ..., -0.00209045,\n",
       "              0.0181885, 0.00482178],\n",
       "             ...,\n",
       "             [0.000128746, 0.0057373, -0.0119019, ..., -0.00198364,\n",
       "              0.00161743, 0.000211716],\n",
       "             [0.00288391, 0.010498, 0.0109253, ..., 0.00361633,\n",
       "              -0.00427246, -0.0189209],\n",
       "             [0.00482178, -0.00268555, -0.0106201, ..., 0.0150146,\n",
       "              -0.00662231, 0.015564]],\n",
       "    \n",
       "            [[-0.006073, -0.00389099, -0.0109863, ..., 0.0114746,\n",
       "              0.0290527, 0.00308228],\n",
       "             [-0.00714111, -0.00933838, 0.00250244, ..., 0.00927734,\n",
       "              -0.00460815, 0.0336914],\n",
       "             [0.0037384, -0.00704956, -0.000667572, ..., -0.0223389,\n",
       "              0.00717163, -0.0118408],\n",
       "             ...,\n",
       "             [0.00149536, 0.00405884, -0.00518799, ..., 0.00567627,\n",
       "              0.0249023, 0.00860596],\n",
       "             [-0.00369263, -0.00213623, 0.0115967, ..., 0.000896454,\n",
       "              0.00473022, -0.00506592],\n",
       "             [-0.00436401, -4.14848e-05, -0.000850677, ..., 0.00485229,\n",
       "              0.019043, -0.00164795]],\n",
       "    \n",
       "            [[-0.00683594, -0.0154419, -0.0166016, ..., -0.0126953,\n",
       "              0.0152588, 0.0168457],\n",
       "             [-0.00628662, 0.00741577, -0.00775146, ..., -0.00891113,\n",
       "              0.0134888, -0.000356674],\n",
       "             [-0.0140991, 0.00769043, -0.00634766, ..., -0.022583,\n",
       "              -0.00188446, 0.00717163],\n",
       "             ...,\n",
       "             [-0.00686646, 0.00588989, -0.0157471, ..., 0.00735474,\n",
       "              -0.00946045, 0.00619507],\n",
       "             [0.0032959, 0.0149536, -0.00650024, ..., 0.0142212,\n",
       "              -0.00466919, 0.00964355],\n",
       "             [-0.00056076, -0.0213623, -0.0270996, ..., -0.00506592,\n",
       "              -0.00595093, -0.0115356]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0098877, 0.00341797, -0.00494385, ..., -0.0136108,\n",
       "              -0.00245667, 0.0106812],\n",
       "             [0.00488281, 0.00494385, -0.00891113, ..., -0.00248718,\n",
       "              -0.0136108, -0.0143433],\n",
       "             [0.000720978, -0.0157471, -0.00358582, ..., -0.00759888,\n",
       "              0.0118408, -0.00247192],\n",
       "             ...,\n",
       "             [0.00402832, 0.0101318, 0.0134888, ..., -0.00549316,\n",
       "              0.0167236, 0.00034523],\n",
       "             [-0.006073, 0.00121307, -0.0177002, ..., 0.00964355,\n",
       "              -0.0117798, -0.0143433],\n",
       "             [-0.00114441, -0.00268555, -0.00585938, ..., -0.00759888,\n",
       "              -0.0137329, -0.0169678]],\n",
       "    \n",
       "            [[-0.00442505, -0.00340271, 0.00190735, ..., 0.00132751,\n",
       "              -0.000686646, -0.0132446],\n",
       "             [-0.00126648, 0.0126343, 0.0147095, ..., 0.00823975,\n",
       "              0.0126953, -0.00332642],\n",
       "             [0.0010376, 0.0146484, 0.000629425, ..., -0.00909424,\n",
       "              -0.00341797, 0.00352478],\n",
       "             ...,\n",
       "             [-0.012207, -0.00958252, -0.00300598, ..., 0.00927734,\n",
       "              0.0019989, -0.00209045],\n",
       "             [-0.0184326, 0.0136719, 0.0249023, ..., 0.00527954,\n",
       "              -0.00811768, 0.0038147],\n",
       "             [-3.47197e-06, 0.00540161, 0.00244141, ..., -0.000724792,\n",
       "              0.0151978, 0.00268555]],\n",
       "    \n",
       "            [[-0.0256348, -0.00891113, -0.00276184, ..., 0.0212402,\n",
       "              0.00588989, 0.00598145],\n",
       "             [0.00338745, 0.010498, -0.00102234, ..., 0.00509644,\n",
       "              -0.0025177, -0.0112305],\n",
       "             [0.00186157, -0.00689697, 0.0106201, ..., 0.0286865,\n",
       "              -0.00196838, -0.0162354],\n",
       "             ...,\n",
       "             [-0.0125732, 0.00186157, 0.0172119, ..., -0.0107422,\n",
       "              -0.000385284, 0.00527954],\n",
       "             [0.00242615, -0.00628662, -0.0142822, ..., 0.0030365,\n",
       "              -0.00219727, -0.0181885],\n",
       "             [-0.00393677, -0.0184326, -0.00939941, ..., -0.00817871,\n",
       "              0.000299454, -0.0128174]],\n",
       "    \n",
       "            [[0.00524902, 0.00946045, 0.0100708, ..., -0.010498,\n",
       "              -0.00190735, 0.0139771],\n",
       "             [-0.0159912, -0.0268555, -0.00631714, ..., -0.00671387,\n",
       "              -0.00335693, -0.00216675],\n",
       "             [-0.00411987, 0.00891113, -0.00367737, ..., 0.00582886,\n",
       "              0.000226021, 0.0114746],\n",
       "             ...,\n",
       "             [-0.00106049, -0.00830078, 0.0205078, ..., 0.00805664,\n",
       "              -0.017334, -4.76837e-05],\n",
       "             [-0.00527954, 0.0123291, 0.00518799, ..., 0.00872803,\n",
       "              -0.0253906, 0.00793457],\n",
       "             [0.0115356, -4.22001e-05, -0.0114136, ..., -0.0078125,\n",
       "              0.0219727, -0.0050354]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00717163, 0.00741577, -0.0159912, ..., 0.013855, -0.0158691,\n",
       "             -0.0354004],\n",
       "            [-0.00299072, 0.000965118, 0.00640869, ..., -0.00445557,\n",
       "             0.012207, -0.0200195],\n",
       "            [0.00598145, -0.00518799, 0.0100098, ..., -0.0202637,\n",
       "             0.000105858, 0.000583649],\n",
       "            ...,\n",
       "            [-0.00860596, -0.00970459, 0.006073, ..., -0.0253906,\n",
       "             -0.00891113, 0.00357056],\n",
       "            [0.015564, 0.0088501, 0.0027771, ..., -0.0115356, 0.00897217,\n",
       "             -0.0368652],\n",
       "            [-0.0123901, -0.00421143, -0.00506592, ..., 0.0144043,\n",
       "             0.00430298, 0.0507812]],\n",
       "    \n",
       "           [[0.00817871, 0.00683594, -0.0252686, ..., 0.0419922, -0.0166016,\n",
       "             0.00558472],\n",
       "            [-0.00704956, -0.00537109, 0.00127411, ..., -0.00352478,\n",
       "             0.00854492, -0.00546265],\n",
       "            [-0.0117188, -0.00349426, 0.0122681, ..., -0.0388184,\n",
       "             -0.0126343, 0.0195312],\n",
       "            ...,\n",
       "            [-0.0159912, 0.00515747, -4.33922e-05, ..., -0.0228271,\n",
       "             -0.00692749, -0.00964355],\n",
       "            [0.0126343, -0.00674438, 0.003479, ..., -0.00386047,\n",
       "             -0.000272751, 0.00242615],\n",
       "            [-0.0130005, 0.00817871, -0.00588989, ..., 0.012085, 0.0123291,\n",
       "             0.0144043]],\n",
       "    \n",
       "           [[-0.00267029, -0.00860596, 0.00436401, ..., -0.0250244,\n",
       "             -0.0437012, -0.0180664],\n",
       "            [0.00735474, -0.00430298, 0.000808716, ..., -0.032959,\n",
       "             -0.0112915, 0.00439453],\n",
       "            [-0.00506592, -0.00196838, -0.006073, ..., 0.0126343,\n",
       "             -0.0119629, -0.00946045],\n",
       "            ...,\n",
       "            [0.000720978, 0.0114746, 0.0157471, ..., -0.00830078,\n",
       "             -0.00680542, 0.000366211],\n",
       "            [0.00720215, 0.00958252, -0.00182343, ..., 0.00976562,\n",
       "             -0.0122681, -0.00778198],\n",
       "            [-0.00317383, 0.0100098, -0.00448608, ..., -0.0146484,\n",
       "             -0.00628662, 0.0444336]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00149536, -0.00405884, 0.00205994, ..., -0.00302124,\n",
       "             -0.0045166, -0.0131226],\n",
       "            [0.00567627, 0.00213623, -0.00491333, ..., 0.00738525,\n",
       "             -0.00469971, 0.00866699],\n",
       "            [-0.0062561, 0.000370026, -0.00056839, ..., 0.00239563,\n",
       "             0.00653076, 0.00778198],\n",
       "            ...,\n",
       "            [-0.00759888, -0.00268555, -2.43187e-05, ..., 0.00592041,\n",
       "             0.0224609, -0.00331116],\n",
       "            [-0.00445557, -0.00686646, -0.000709534, ..., -0.00196838,\n",
       "             -0.0174561, -0.00328064],\n",
       "            [0.00121307, -0.00436401, 0.00656128, ..., 0.026123, 0.0209961,\n",
       "             -0.00188446]],\n",
       "    \n",
       "           [[-0.00138855, -0.006073, 0.0102539, ..., -0.0234375, 0.0108032,\n",
       "             0.0334473],\n",
       "            [-0.00357056, 0.0055542, -0.00106812, ..., -0.00939941,\n",
       "             -0.00141144, 0.00424194],\n",
       "            [-0.00836182, -2.2769e-05, -0.00582886, ..., -8.63075e-05,\n",
       "             -0.00769043, 0.00253296],\n",
       "            ...,\n",
       "            [0.00805664, -0.000648499, -0.012085, ..., 0.0216064,\n",
       "             -0.0227051, 0.00915527],\n",
       "            [-0.0198975, 0.0181885, -0.00143433, ..., -0.0161133,\n",
       "             -0.00114441, 0.0127563],\n",
       "            [-0.00396729, 0.0050354, 0.000537872, ..., 0.0181885,\n",
       "             0.00408936, 0.0105591]],\n",
       "    \n",
       "           [[0.00564575, -0.026123, -0.00163269, ..., 0.0200195,\n",
       "             -0.00176239, 0.0251465],\n",
       "            [0.00323486, -0.0239258, 0.00190735, ..., -0.00683594,\n",
       "             -0.0100708, 0.0280762],\n",
       "            [0.00552368, 0.00723267, 0.00646973, ..., 0.0144043,\n",
       "             -0.00909424, -0.0200195],\n",
       "            ...,\n",
       "            [0.00148773, -0.0244141, 0.000946045, ..., 0.00328064,\n",
       "             0.0127563, -0.0107422],\n",
       "            [-0.0112305, 0.0062561, -0.0102539, ..., 0.00263977, 0.0112305,\n",
       "             0.00454712],\n",
       "            [-0.00341797, -0.0139771, -0.00537109, ..., 0.0198975,\n",
       "             0.00445557, 0.0258789]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00408936, 0.00610352, -0.00308228, ..., 0.00424194,\n",
       "            -0.00604248, -0.0163574],\n",
       "           [0.00424194, -0.00402832, 0.0131226, ..., 0.00219727,\n",
       "            -0.00704956, -0.00805664],\n",
       "           [0.00302124, 0.00546265, -0.00137329, ..., -0.00292969,\n",
       "            0.00302124, 0.00130463],\n",
       "           ...,\n",
       "           [-0.00306702, 0.000694275, -0.00509644, ..., -0.0114746,\n",
       "            -0.0107422, 0.00115967],\n",
       "           [-0.0133667, 0.00823975, -0.00133514, ..., -0.00171661,\n",
       "            -0.00386047, 0.0274658],\n",
       "           [0.000307083, 0.00482178, 0.00187683, ..., -0.00891113,\n",
       "            0.00588989, 0.00698853]],\n",
       "   \n",
       "          [[-0.0153198, -0.0194092, 0.00585938, ..., 0.00134277,\n",
       "            0.00314331, 0.00427246],\n",
       "           [0.00186157, -0.00909424, 0.00546265, ..., 0.00163269,\n",
       "            -0.0128174, 0.00549316],\n",
       "           [0.00204468, 0.0125732, 0.00592041, ..., -0.0109253, 0.0039978,\n",
       "            -0.00170135],\n",
       "           ...,\n",
       "           [-0.00402832, -0.0131226, 0.0112305, ..., 0.00866699,\n",
       "            -0.0098877, -0.00506592],\n",
       "           [0.0174561, -0.00570679, -0.0114136, ..., -0.00241089,\n",
       "            0.0144653, 0.0130615],\n",
       "           [0.00147247, -0.00063324, -0.00390625, ..., -0.00576782,\n",
       "            0.0131226, -0.0062561]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.0167236, -0.00549316, 0.012085, ..., -0.000341415, 0.00144196,\n",
       "           0.00224304],\n",
       "          [-0.0109253, -0.00775146, -0.00131226, ..., -0.0147705,\n",
       "           -0.0090332, -0.0127563],\n",
       "          [0.00320435, 0.00165558, -0.00338745, ..., -0.00567627, 0.0043335,\n",
       "           0.00250244],\n",
       "          ...,\n",
       "          [0.00169373, -2.93255e-05, 0.000782013, ..., -0.00326538,\n",
       "           -0.00546265, -0.0108032],\n",
       "          [-0.000270844, 0.00552368, 0.00241089, ..., -0.00364685,\n",
       "           0.0109863, 0.00244141],\n",
       "          [0.00204468, 0.00463867, 0.0017395, ..., -0.00337219,\n",
       "           -0.000480652, -1.07288e-05]], dtype=bfloat16), a=Array([[-0.01803358, -0.00303927,  0.00691553, ...,  0.00371117,\n",
       "            0.00372419,  0.00021878],\n",
       "          [ 0.00078573, -0.00061509, -0.0201269 , ...,  0.01225177,\n",
       "            0.00519481,  0.00182117]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([1.25, 1.07812, 1.29688, ..., 1.35156, 1.29688, 1.14062], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([2.64062, 2.625, 2.73438, ..., 2.51562, 2.625, 2.3125], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.414062, 0.59375, 0.5, ..., 0.451172, 0.375, 0.554688], dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.175781, 0.236328, 0.203125, ..., 0.168945, 0.128906, 0.248047],      dtype=bfloat16)}},\n",
       " 'layer_2': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0179443, -0.00765991, 0.000134468, ..., 0.00238037,\n",
       "             0.00204468, -0.00454712],\n",
       "            [-0.0106812, 0.0088501, -0.0234375, ..., 0.0123901, 0.0126953,\n",
       "             -0.00958252],\n",
       "            [-0.0106812, -0.00132751, 0.0142822, ..., 0.00848389,\n",
       "             0.00247192, -0.00479126],\n",
       "            ...,\n",
       "            [0.000219345, -0.00680542, -0.00891113, ..., 0.0174561,\n",
       "             -0.00689697, -0.00141144],\n",
       "            [0.00671387, 0.0116577, 0.0183105, ..., 0.0170898, -0.00218201,\n",
       "             0.00595093],\n",
       "            [-0.00133514, 0.00509644, 0.000167847, ..., 0.0203857,\n",
       "             0.00964355, 0.0043335]],\n",
       "    \n",
       "           [[0.00111389, -0.0143433, -0.00133514, ..., -0.00105286,\n",
       "             -0.000720978, -0.00686646],\n",
       "            [0.0197754, 0.00570679, 0.00402832, ..., 0.0039978, 0.00854492,\n",
       "             -0.0187988],\n",
       "            [-0.00769043, -0.00308228, -0.0142212, ..., 0.024292, 0.0110474,\n",
       "             -0.00297546],\n",
       "            ...,\n",
       "            [-0.00994873, -0.0161133, -0.000617981, ..., 0.0200195,\n",
       "             -0.00273132, 0.00227356],\n",
       "            [0.0123291, 0.0071106, -0.0158691, ..., -0.00842285,\n",
       "             -0.00174713, -0.00717163],\n",
       "            [-0.0236816, -0.00167084, -0.0101929, ..., -0.0045166,\n",
       "             0.0162354, -0.00723267]],\n",
       "    \n",
       "           [[-0.00136566, 0.000253677, 0.0108032, ..., -0.000656128,\n",
       "             0.0194092, -0.001091],\n",
       "            [0.0250244, 0.00592041, 0.0168457, ..., 0.0263672, -0.0256348,\n",
       "             0.0163574],\n",
       "            [-0.00512695, 0.0201416, 0.000267029, ..., -0.0102539,\n",
       "             -0.0161133, -5.50747e-05],\n",
       "            ...,\n",
       "            [0.00167847, -0.0090332, -0.022583, ..., -0.00350952, 0.0118408,\n",
       "             0.015625],\n",
       "            [-0.00939941, 0.00350952, -0.00263977, ..., 0.0045166,\n",
       "             -0.00216675, -0.00811768],\n",
       "            [0.0124512, -0.00726318, -0.00292969, ..., 0.020752, -0.0133057,\n",
       "             -0.00280762]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00811768, -0.0158691, 0.0117188, ..., -0.0120239, 0.0187988,\n",
       "             0.00613403],\n",
       "            [-0.00213623, 0.00958252, -0.034668, ..., -0.00579834,\n",
       "             -0.0167236, 0.00567627],\n",
       "            [-0.0297852, 0.0114746, -0.00305176, ..., 0.0072937, 0.00970459,\n",
       "             -0.00317383],\n",
       "            ...,\n",
       "            [-0.00282288, -0.00491333, -0.00424194, ..., 0.00512695,\n",
       "             0.0118408, 0.00564575],\n",
       "            [0.000312805, 0.000450134, 0.00341797, ..., 0.0045166,\n",
       "             -0.00375366, -0.00592041],\n",
       "            [0.00289917, 0.00671387, 0.00159454, ..., 0.00872803,\n",
       "             0.00793457, 0.00540161]],\n",
       "    \n",
       "           [[0.0140991, -0.013855, -0.006073, ..., -0.026123, -0.00082016,\n",
       "             -0.00157928],\n",
       "            [0.000160217, 0.00915527, -0.00546265, ..., 0.0102539,\n",
       "             0.0015564, -0.0117798],\n",
       "            [-0.00726318, -0.0314941, -0.00228882, ..., -0.0197754,\n",
       "             -0.00352478, 0.0211182],\n",
       "            ...,\n",
       "            [0.00778198, -0.0045166, -0.00582886, ..., -0.000717163,\n",
       "             -0.00805664, -0.0123901],\n",
       "            [0.013916, 0.000169754, -0.00222778, ..., -0.00921631,\n",
       "             0.0113525, 0.00534058],\n",
       "            [-0.00775146, 0.00418091, 0.00970459, ..., 0.00445557,\n",
       "             -0.00463867, 0.00619507]],\n",
       "    \n",
       "           [[0.00088501, 0.00958252, 0.0150146, ..., 0.0014267, -0.0100708,\n",
       "             -0.0128784],\n",
       "            [-0.0090332, -0.00689697, -0.0128784, ..., 0.0235596,\n",
       "             -0.0302734, -0.00476074],\n",
       "            [0.00454712, -0.0140991, 0.0037384, ..., -0.00149536,\n",
       "             -0.0168457, -0.000778198],\n",
       "            ...,\n",
       "            [0.00149536, 0.012085, 0.00436401, ..., 0.0209961, -0.0344238,\n",
       "             -0.00540161],\n",
       "            [0.00958252, -0.013916, -0.0106201, ..., -0.0163574, 0.0125732,\n",
       "             0.0183105],\n",
       "            [-0.00463867, -0.00518799, 0.00701904, ..., 0.0148926,\n",
       "             0.00473022, 0.0151978]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00317383, 0.0146484, -0.0119019, ..., 0.0163574,\n",
       "              0.00218201, -0.0238037],\n",
       "             [-0.0131836, -0.0285645, -0.0101318, ..., -0.0187988,\n",
       "              0.0247803, 0.00741577],\n",
       "             [-8.10623e-05, -0.0163574, -0.00125122, ..., 0.00546265,\n",
       "              0.0110474, 0.0151367],\n",
       "             ...,\n",
       "             [0.000873566, 4.60148e-05, -0.0217285, ..., -0.0183105,\n",
       "              0.0057373, 0.0209961],\n",
       "             [0.0114136, -0.00701904, -0.010437, ..., 0.0124512,\n",
       "              -0.0120239, 0.000789642],\n",
       "             [0.00741577, 0.00585938, 0.0045166, ..., -0.00424194,\n",
       "              -0.0035553, -0.00512695]],\n",
       "    \n",
       "            [[-0.000177383, -0.0206299, -0.00276184, ..., 0.00233459,\n",
       "              -2.75373e-05, 0.0181885],\n",
       "             [-0.00109863, 0.00592041, -0.00180054, ..., -0.0114136,\n",
       "              0.0125732, 0.0139771],\n",
       "             [-0.0189209, 0.00161743, 0.00823975, ..., 0.0109863,\n",
       "              0.0162354, 0.00524902],\n",
       "             ...,\n",
       "             [-0.00534058, 0.00367737, 0.00167847, ..., 0.0142212,\n",
       "              0.0127563, -0.026123],\n",
       "             [-0.0090332, 0.0167236, 0.00469971, ..., 0.0043335, 0.0157471,\n",
       "              0.00585938],\n",
       "             [0.00209045, -0.0098877, 0.00445557, ..., -0.0090332,\n",
       "              0.0163574, -0.0187988]],\n",
       "    \n",
       "            [[-0.00112152, 0.0072937, 0.0142212, ..., -0.0181885,\n",
       "              -0.00263977, 0.0129395],\n",
       "             [-0.00442505, -0.00686646, 0.00753784, ..., -0.00135803,\n",
       "              0.0444336, -0.03125],\n",
       "             [-0.000184059, -0.00662231, -0.0131226, ..., 0.0170898,\n",
       "              0.00424194, 0.0354004],\n",
       "             ...,\n",
       "             [-0.00326538, -0.0181885, -0.00668335, ..., 0.000862122,\n",
       "              -0.0148926, -0.0122681],\n",
       "             [0.0164795, -0.0071106, 0.0222168, ..., 0.0114746,\n",
       "              -0.00793457, -0.0153198],\n",
       "             [-0.00024128, 0.0114136, 0.0016861, ..., -0.0119019,\n",
       "              0.0219727, 0.0246582]],\n",
       "    \n",
       "            [[-0.0124512, 0.000232697, -0.0169678, ..., 0.0017395,\n",
       "              -0.0157471, 0.0108032],\n",
       "             [0.000946045, 0.00964355, 0.00741577, ..., -0.0164795,\n",
       "              0.0189209, -0.00811768],\n",
       "             [-0.00176239, -0.0113525, -0.0126343, ..., 0.00112915,\n",
       "              -0.00159454, 0.00421143],\n",
       "             ...,\n",
       "             [-0.00218201, 0.00897217, 0.019043, ..., 0.00494385,\n",
       "              -0.00671387, -0.00631714],\n",
       "             [0.0314941, 0.00308228, 0.0150757, ..., -0.00634766,\n",
       "              -0.00476074, 0.000198364],\n",
       "             [-0.000244141, -0.00769043, 0.0166016, ..., 0.0150757,\n",
       "              0.000117302, 0.0125732]]],\n",
       "    \n",
       "    \n",
       "           [[[0.00939941, -0.00668335, 0.00512695, ..., 0.026123,\n",
       "              0.000907898, -0.00689697],\n",
       "             [-0.00294495, -0.00588989, -0.00830078, ..., -0.00830078,\n",
       "              -0.00424194, 0.0011673],\n",
       "             [0.00393677, -0.00546265, -0.0140991, ..., 0.0030365,\n",
       "              0.0043335, 0.00424194],\n",
       "             ...,\n",
       "             [-0.0128174, 0.00543213, 0.0118408, ..., -0.0218506,\n",
       "              -0.0115967, -0.00680542],\n",
       "             [0.00247192, 0.00138092, 0.000991821, ..., 0.00285339,\n",
       "              0.00151062, 0.00128937],\n",
       "             [0.00149536, 0.00823975, -0.0127563, ..., 0.00714111,\n",
       "              -0.0018158, -0.00994873]],\n",
       "    \n",
       "            [[-0.0107422, 0.0197754, -0.00994873, ..., 0.0108643,\n",
       "              -0.0131226, 0.0154419],\n",
       "             [-0.00282288, 0.0194092, 0.000267029, ..., -0.0172119,\n",
       "              -0.00628662, -0.0132446],\n",
       "             [-0.00215149, 0.0130005, -0.00698853, ..., -0.0356445,\n",
       "              0.00222778, -0.000827789],\n",
       "             ...,\n",
       "             [0.00150299, 0.00482178, -0.00112915, ..., -0.00270081,\n",
       "              0.0072937, -0.0163574],\n",
       "             [0.00442505, -0.0145264, 0.000972748, ..., 0.00219727,\n",
       "              -0.000226974, 0.0155029],\n",
       "             [0.0115356, 0.0198975, 0.00897217, ..., 0.00854492,\n",
       "              0.000968933, 0.00952148]],\n",
       "    \n",
       "            [[0.00793457, 0.0072937, 0.0385742, ..., 0.000576019,\n",
       "              -0.00320435, -0.00297546],\n",
       "             [0.0134277, -0.0148926, -0.010498, ..., 0.0240479,\n",
       "              -0.00415039, 0.00674438],\n",
       "             [-0.0142822, 0.045166, 0.00131989, ..., 0.00375366,\n",
       "              -0.00270081, -0.00726318],\n",
       "             ...,\n",
       "             [0.00811768, 0.0101929, -0.0108032, ..., -0.0088501,\n",
       "              0.00227356, -0.0220947],\n",
       "             [-0.013855, -0.00115204, -0.00318909, ..., -0.00270081,\n",
       "              0.00259399, -0.00634766],\n",
       "             [-0.0055542, 0.00216675, -0.000564575, ..., -0.00726318,\n",
       "              0.00488281, -0.00448608]],\n",
       "    \n",
       "            [[0.0108643, 0.00631714, -0.0090332, ..., -0.000185966,\n",
       "              -0.00836182, -0.0128784],\n",
       "             [0.00305176, 0.00872803, -0.015625, ..., 0.00147247,\n",
       "              0.00320435, 0.00358582],\n",
       "             [-0.00558472, 0.0101929, -0.00744629, ..., 0.0117798,\n",
       "              0.00189972, -0.010437],\n",
       "             ...,\n",
       "             [-0.00382996, 0.00151825, -0.00136566, ..., -0.00119019,\n",
       "              0.0107422, -0.0247803],\n",
       "             [0.0111694, 0.00308228, 0.00823975, ..., -0.0115967,\n",
       "              0.0103149, 0.00683594],\n",
       "             [0.0119019, -0.00286865, 0.00137329, ..., 0.00146484,\n",
       "              -0.0108643, 0.00393677]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00762939, 0.00537109, 0.00680542, ..., -0.00151062,\n",
       "             -0.0045166, 0.00384521],\n",
       "            [-0.00163269, 0.0178223, 0.00485229, ..., -0.0140991,\n",
       "             -0.0124512, -0.015564],\n",
       "            [0.00933838, 0.00933838, 0.00830078, ..., 0.00994873,\n",
       "             0.00111389, -0.00723267],\n",
       "            ...,\n",
       "            [0.00393677, -0.00708008, -0.00216675, ..., -0.00069046,\n",
       "             0.0120239, -0.0126343],\n",
       "            [0.0194092, 0.0162354, -0.0198975, ..., 0.00964355, 0.00637817,\n",
       "             0.00952148],\n",
       "            [-0.00178528, 0.0101929, 0.00196838, ..., 0.0148926,\n",
       "             -0.00357056, -0.0168457]],\n",
       "    \n",
       "           [[-0.0115967, -0.0105591, -0.0062561, ..., 0.00162506,\n",
       "             -0.00147247, -0.0170898],\n",
       "            [0.00793457, 0.00741577, -0.0134888, ..., 0.0103149,\n",
       "             -0.00325012, -0.024292],\n",
       "            [-0.00221252, 0.0120239, -0.00276184, ..., -0.00994873,\n",
       "             -0.0014801, -0.0308838],\n",
       "            ...,\n",
       "            [0.0269775, -0.00262451, 0.00491333, ..., 0.0136108, -0.0018692,\n",
       "             0.0217285],\n",
       "            [4.55379e-05, 0.0183105, -0.0133667, ..., -0.0100098, -0.013916,\n",
       "             -0.00628662],\n",
       "            [-0.00811768, 0.0114746, -0.00119781, ..., 0.0055542,\n",
       "             -0.00695801, 0.0223389]],\n",
       "    \n",
       "           [[0.000957489, -0.00418091, -0.00668335, ..., 0.0317383,\n",
       "             -0.0043335, -0.0205078],\n",
       "            [0.00946045, 0.00205994, -0.0088501, ..., -0.0112915, -0.036377,\n",
       "             -0.0269775],\n",
       "            [0.00191498, 0.00141907, -0.00389099, ..., -0.00387573,\n",
       "             -0.0551758, -0.00579834],\n",
       "            ...,\n",
       "            [0.032959, -0.0344238, 0.000368118, ..., 0.00228882, 0.0170898,\n",
       "             0.0473633],\n",
       "            [-0.0118408, 0.00308228, 0.00402832, ..., 0.00149536,\n",
       "             0.00720215, -0.00378418],\n",
       "            [-0.015564, 0.000793457, -0.00927734, ..., 0.00823975,\n",
       "             -0.00976562, 0.0291748]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00262451, 0.00811768, 0.00616455, ..., 0.0125732,\n",
       "             -0.00811768, 0.00958252],\n",
       "            [-0.00927734, 0.0133057, -0.00964355, ..., -0.0118408,\n",
       "             0.0152588, -0.000153542],\n",
       "            [0.00613403, 0.0196533, -0.0155029, ..., -0.0119629, 0.0103149,\n",
       "             -0.00189209],\n",
       "            ...,\n",
       "            [-0.0253906, 0.0341797, -0.0245361, ..., -0.00201416,\n",
       "             -0.00546265, 0.00292969],\n",
       "            [0.00292969, -0.0137329, 0.000843048, ..., -0.0150146,\n",
       "             0.00442505, -0.0133057],\n",
       "            [0.0194092, 0.0336914, -0.0177002, ..., 0.0111694, 0.0201416,\n",
       "             -0.00376892]],\n",
       "    \n",
       "           [[-0.00613403, 0.0100098, 0.00494385, ..., -0.0246582,\n",
       "             0.00135803, -0.00994873],\n",
       "            [0.0118408, 0.00421143, -0.0289307, ..., 0.00334167, -0.0200195,\n",
       "             -0.0113525],\n",
       "            [-0.00866699, 0.0136108, -0.0145264, ..., 0.0213623, -0.0252686,\n",
       "             -0.00352478],\n",
       "            ...,\n",
       "            [0.00540161, 0.00131989, -0.00747681, ..., -0.00872803,\n",
       "             -0.000576019, 0.0038147],\n",
       "            [0.0202637, -0.0119019, -0.0235596, ..., 0.0157471, 0.00222778,\n",
       "             0.00823975],\n",
       "            [-0.00183868, -0.010498, -0.000139236, ..., 0.00161743,\n",
       "             0.0137329, -0.0134277]],\n",
       "    \n",
       "           [[0.0012207, -0.00120544, 0.00518799, ..., 1.70469e-05,\n",
       "             -0.000579834, -0.00314331],\n",
       "            [0.00136566, 0.0100098, -0.00463867, ..., -0.00512695,\n",
       "             0.00680542, 0.00280762],\n",
       "            [0.00335693, 0.00387573, -0.00169373, ..., 0.0196533, 0.0123901,\n",
       "             -0.00244141],\n",
       "            ...,\n",
       "            [-0.00131226, 0.00933838, -0.00216675, ..., 0.00300598,\n",
       "             0.00160217, -0.0125732],\n",
       "            [0.00265503, -0.00692749, 0.00372314, ..., -0.00282288,\n",
       "             0.00897217, 0.00933838],\n",
       "            [-0.00265503, 0.00708008, 0.00205994, ..., 0.00891113,\n",
       "             -0.0111694, 0.0155029]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00469971, 0.0118408, 0.0032959, ..., -0.00427246, 0.0030365,\n",
       "            0.00741577],\n",
       "           [-0.00228882, -0.00170135, -0.00753784, ..., -0.0129395,\n",
       "            0.00726318, 0.00878906],\n",
       "           [-0.00695801, -0.0100708, -0.0103149, ..., 0.00460815,\n",
       "            -0.00244141, -0.00534058],\n",
       "           ...,\n",
       "           [-0.000804901, -2.63453e-05, -0.00242615, ..., -0.0120239,\n",
       "            -0.000541687, 0.00430298],\n",
       "           [0.0142212, -0.00415039, -0.00183868, ..., 0.012207,\n",
       "            -0.00463867, 0.0062561],\n",
       "           [0.00360107, -0.00897217, 0.0107422, ..., -0.0107422, 0.0098877,\n",
       "            -0.00570679]],\n",
       "   \n",
       "          [[-0.00445557, 0.00024128, 0.00317383, ..., -0.00291443,\n",
       "            0.00273132, 0.00473022],\n",
       "           [-0.0113525, -0.000762939, 0.00344849, ..., 0.00653076,\n",
       "            0.0158691, 0.00405884],\n",
       "           [0.0032196, -0.0159912, -0.00386047, ..., 0.0144043,\n",
       "            -0.00350952, -0.00294495],\n",
       "           ...,\n",
       "           [0.00334167, -0.00285339, -0.00041008, ..., 0.0149536,\n",
       "            0.00204468, -0.00170898],\n",
       "           [-0.00137329, -0.00534058, 0.00860596, ..., -0.00408936,\n",
       "            0.00509644, -0.00466919],\n",
       "           [-0.00201416, -0.00982666, 0.00180817, ..., 0.00191498,\n",
       "            0.000337601, -0.00576782]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00933838, 0.00193024, -0.0123291, ..., 0.00848389, 0.0016098,\n",
       "           -0.0016098],\n",
       "          [-0.00610352, 0.00439453, -0.00933838, ..., -0.0180664, -0.012085,\n",
       "           -0.00595093],\n",
       "          [0.000587463, 0.000507355, 0.00582886, ..., 0.00244141,\n",
       "           -0.00236511, 0.00350952],\n",
       "          ...,\n",
       "          [0.000671387, 0.00939941, 0.00823975, ..., -0.00537109, 0.0020752,\n",
       "           -0.0136719],\n",
       "          [-0.00512695, 0.0159912, -0.00854492, ..., -0.0137329,\n",
       "           -0.000907898, -0.0090332],\n",
       "          [-0.0123291, -0.00537109, 0.010437, ..., 0.00189209, -0.0038147,\n",
       "           0.00291443]], dtype=bfloat16), a=Array([[-0.01155356,  0.00352542, -0.00475057, ...,  0.00461095,\n",
       "            0.00289454, -0.0215128 ],\n",
       "          [ 0.00688512, -0.00726845, -0.00535207, ...,  0.00995815,\n",
       "            0.00537037,  0.00453264]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([-0.232422, -0.229492, -0.160156, ..., -0.414062, 0.0179443,\n",
       "          -0.265625], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.131836, 0.105469, 0.139648, ..., -0.141602, 0.326172, 0.135742],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.714844, 0.667969, 0.71875, ..., 1.07812, 0.300781, 0.515625],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.5, 0.511719, 0.53125, ..., 0.941406, 0.00320435, 0.40625],      dtype=bfloat16)}},\n",
       " 'layer_20': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00756836, -0.00601196, -0.00952148, ..., 0.0114136,\n",
       "             -0.00830078, -0.00546265],\n",
       "            [-0.00179291, -0.006073, -0.000801086, ..., 0.00212097,\n",
       "             -0.00817871, -0.00640869],\n",
       "            [-0.000724792, 0.0166016, -0.00154877, ..., -0.00344849,\n",
       "             0.019043, -0.0019455],\n",
       "            ...,\n",
       "            [0.00778198, -0.0098877, -0.00139618, ..., 0.0174561,\n",
       "             -0.0107422, 0.00497437],\n",
       "            [-0.00378418, -0.00352478, 0.00100708, ..., 0.0101929,\n",
       "             0.00653076, -0.0043335],\n",
       "            [-0.00352478, 0.00154877, 0.00714111, ..., 0.00291443,\n",
       "             -0.00872803, 0.0057373]],\n",
       "    \n",
       "           [[-0.00158691, -0.00390625, 0.00430298, ..., 0.000968933,\n",
       "             -0.00189972, -0.00187683],\n",
       "            [0.00216675, 0.00302124, 0.0227051, ..., -0.0184326,\n",
       "             -0.00274658, -0.00227356],\n",
       "            [-0.0098877, -0.010498, 0.00138855, ..., -0.000701904,\n",
       "             0.0106201, 0.0136719],\n",
       "            ...,\n",
       "            [-0.00106049, -0.00154114, 0.00830078, ..., 0.000740051,\n",
       "             -0.00717163, -0.0022583],\n",
       "            [-0.00156403, -0.0141602, -0.00662231, ..., -0.00506592,\n",
       "             0.00717163, 0.00315857],\n",
       "            [0.00793457, 0.00494385, -0.00469971, ..., -0.0161133,\n",
       "             0.00656128, 0.0229492]],\n",
       "    \n",
       "           [[-0.0123901, 0.00105286, 0.0206299, ..., -0.0088501, -0.0241699,\n",
       "             0.00653076],\n",
       "            [-0.00921631, 0.00191498, 0.0162354, ..., -0.0126343,\n",
       "             0.00164032, -0.00454712],\n",
       "            [0.00811768, 0.0183105, -0.019043, ..., -0.0131836, 0.0135498,\n",
       "             -0.0128784],\n",
       "            ...,\n",
       "            [-0.0146484, 0.0251465, -0.0205078, ..., 0.00202942,\n",
       "             -0.00106812, -0.00350952],\n",
       "            [-0.0142212, 0.0219727, 0.00280762, ..., 0.00970459, 0.00247192,\n",
       "             0.000272751],\n",
       "            [-0.00267029, -0.00494385, 0.0020752, ..., 0.00308228,\n",
       "             0.0141602, 0.00698853]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00662231, -0.00270081, -0.00424194, ..., 0.00332642,\n",
       "             -0.00848389, -0.0211182],\n",
       "            [-0.00775146, -0.0108032, -0.0155029, ..., -0.0222168,\n",
       "             0.0131836, -0.000682831],\n",
       "            [-0.000541687, 0.00866699, 0.0227051, ..., 0.00031662,\n",
       "             -0.019165, 0.00878906],\n",
       "            ...,\n",
       "            [0.0012207, -0.00328064, 0.0125732, ..., 0.0088501, -0.0136108,\n",
       "             0.00878906],\n",
       "            [0.00183868, 0.00396729, 0.00762939, ..., -0.00315857,\n",
       "             0.00187683, -0.00337219],\n",
       "            [-0.00595093, -0.0045166, 0.0108032, ..., -0.00299072,\n",
       "             -0.00836182, 0.0125732]],\n",
       "    \n",
       "           [[-0.012146, -0.00759888, 0.00744629, ..., -0.0162354,\n",
       "             -0.00634766, -0.00187683],\n",
       "            [-0.00631714, -0.00524902, 0.0222168, ..., 0.00595093,\n",
       "             -0.0159912, 0.0098877],\n",
       "            [-0.00576782, -0.000743866, -0.0125122, ..., -0.000206947,\n",
       "             -0.00165558, -0.00564575],\n",
       "            ...,\n",
       "            [-0.00485229, 0.0150146, -0.00382996, ..., 0.0145264,\n",
       "             0.00946045, 0.0114136],\n",
       "            [0.0109863, -0.00601196, 0.0106201, ..., -0.0194092,\n",
       "             -0.00631714, 0.0134888],\n",
       "            [-0.000572205, -0.00125122, -0.0103149, ..., 0.00753784,\n",
       "             0.00363159, 0.0149536]],\n",
       "    \n",
       "           [[0.0109863, 0.00238037, -0.0090332, ..., 0.0166016, 0.0159912,\n",
       "             -0.00187683],\n",
       "            [0.00964355, 0.00854492, -0.0109253, ..., -0.0159912,\n",
       "             0.00747681, -0.0140381],\n",
       "            [0.00964355, -0.00479126, 0.00164795, ..., 0.0118408,\n",
       "             -0.0105591, 0.0148315],\n",
       "            ...,\n",
       "            [-0.0090332, -0.0133667, 0.00131226, ..., -0.00650024,\n",
       "             -0.00830078, -0.00259399],\n",
       "            [-0.00540161, 0.00537109, -0.0170898, ..., 0.00872803,\n",
       "             -0.00939941, -0.00506592],\n",
       "            [0.00263977, -0.00154877, 0.00939941, ..., -0.00346375,\n",
       "             -0.0281982, 0.00939941]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0022583, -0.00382996, -0.00463867, ..., -0.0157471,\n",
       "              -0.0196533, -0.000295639],\n",
       "             [-0.00445557, -0.0114746, 0.00848389, ..., -0.0134888,\n",
       "              0.00158691, 0.000934601],\n",
       "             [0.00430298, -0.00389099, -0.0177002, ..., 0.00582886,\n",
       "              0.00357056, -0.0186768],\n",
       "             ...,\n",
       "             [-0.00601196, 0.0078125, 0.00141907, ..., 0.0195312,\n",
       "              0.00921631, -0.0231934],\n",
       "             [0.0103149, 0.0264893, -0.0057373, ..., -0.000440598,\n",
       "              -0.0098877, 0.00674438],\n",
       "             [0.0019989, 0.000709534, 0.00379944, ..., -0.000789642,\n",
       "              0.00616455, -0.00271606]],\n",
       "    \n",
       "            [[0.000831604, 0.0112915, -0.00111389, ..., -0.0131836,\n",
       "              0.000356674, 0.000659943],\n",
       "             [-0.00173187, 0.00276184, 0.00588989, ..., 0.00314331,\n",
       "              -0.0115356, -0.00291443],\n",
       "             [-0.00111389, -0.00994873, -0.00137329, ..., -0.0236816,\n",
       "              -0.00250244, -0.0159912],\n",
       "             ...,\n",
       "             [-0.00610352, 0.0103149, -0.000255585, ..., -0.022583,\n",
       "              0.00107574, 0.000614166],\n",
       "             [0.0170898, 0.0152588, 0.0055542, ..., 0.0178223, 0.0142212,\n",
       "              0.00570679],\n",
       "             [-0.00182343, -0.00482178, 2.90871e-05, ..., 0.0383301,\n",
       "              -0.00497437, -0.00836182]],\n",
       "    \n",
       "            [[-0.0167236, -0.0247803, 0.0178223, ..., 0.0217285,\n",
       "              -0.00512695, 0.00010252],\n",
       "             [-0.0107422, -0.0245361, -0.000125885, ..., -0.00346375,\n",
       "              -0.00442505, -0.0181885],\n",
       "             [0.000991821, 0.00970459, 0.000541687, ..., -0.024292,\n",
       "              -0.00393677, -0.00872803],\n",
       "             ...,\n",
       "             [-0.00634766, 0.00939941, 0.00704956, ..., 0.0119629,\n",
       "              -0.00245667, -0.013855],\n",
       "             [0.00300598, 0.00549316, 0.00854492, ..., 0.0111084,\n",
       "              -0.00439453, 0.012146],\n",
       "             [-0.00650024, -0.00279236, -0.00311279, ..., -0.00107574,\n",
       "              -0.00121307, -0.0108643]],\n",
       "    \n",
       "            [[-0.0027771, -0.017334, -0.00360107, ..., 0.0163574,\n",
       "              0.00704956, -0.0139771],\n",
       "             [-0.0117798, -0.00604248, 0.00186157, ..., 0.0212402,\n",
       "              0.00674438, 0.0137939],\n",
       "             [-0.00811768, 0.00537109, -0.00305176, ..., -0.0305176,\n",
       "              0.00518799, 0.0150757],\n",
       "             ...,\n",
       "             [-0.00619507, 0.00370789, 0.00970459, ..., 9.0003e-06,\n",
       "              -0.00558472, -0.0108032],\n",
       "             [0.00228882, 0.0179443, -0.0114746, ..., 0.000747681,\n",
       "              -0.0131836, 0.00704956],\n",
       "             [-0.0098877, 0.00811768, 0.00830078, ..., -0.00823975,\n",
       "              0.00537109, -0.00346375]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0129395, -0.0135498, -0.0120239, ..., -0.00179291,\n",
       "              0.00756836, -0.00915527],\n",
       "             [0.00717163, 0.00637817, 0.0123291, ..., 0.00326538,\n",
       "              0.0146484, 0.00915527],\n",
       "             [0.0196533, -0.00964355, 0.00668335, ..., 0.0115967,\n",
       "              -0.00134277, 0.00515747],\n",
       "             ...,\n",
       "             [-0.00817871, 0.0113525, -0.00982666, ..., 0.000930786,\n",
       "              0.0228271, 0.0103149],\n",
       "             [-0.00238037, -0.020874, 0.0100098, ..., -0.00634766,\n",
       "              0.00643921, -0.0126953],\n",
       "             [-0.0119629, -0.00592041, 0.00265503, ..., 1.15037e-05,\n",
       "              -0.0115967, -0.00349426]],\n",
       "    \n",
       "            [[0.0131836, -0.00415039, -0.0100708, ..., 0.00805664,\n",
       "              0.029541, -0.0168457],\n",
       "             [-0.00300598, -0.00878906, -0.012085, ..., -0.00811768,\n",
       "              -0.00787354, 0.0280762],\n",
       "             [-0.00680542, -0.0107422, 0.000667572, ..., 0.0109863,\n",
       "              -0.00228882, 0.0111084],\n",
       "             ...,\n",
       "             [-0.0177002, -0.00598145, 0.000142097, ..., -0.00811768,\n",
       "              -0.00286865, 0.0150146],\n",
       "             [0.0339355, 0.00323486, -0.0169678, ..., 0.019043,\n",
       "              -0.00695801, -0.00631714],\n",
       "             [-0.0168457, 0.00759888, 0.0218506, ..., -0.00173187,\n",
       "              -0.0115967, 0.0141602]],\n",
       "    \n",
       "            [[0.0285645, -0.0152588, -0.00915527, ..., 0.00836182,\n",
       "              -0.0153809, 0.0078125],\n",
       "             [-0.0219727, -0.00714111, 0.0178223, ..., -0.0105591,\n",
       "              -0.0103149, 0.0153198],\n",
       "             [-0.0115356, -0.00622559, -0.0212402, ..., -0.0167236,\n",
       "              -0.00601196, 0.0119019],\n",
       "             ...,\n",
       "             [-0.0119019, -0.00634766, -0.0185547, ..., 0.000675201,\n",
       "              0.00775146, -0.00421143],\n",
       "             [-0.0157471, 0.0088501, 0.0140381, ..., -0.0214844,\n",
       "              -0.00540161, 0.00367737],\n",
       "             [0.00592041, 0.00765991, 0.00209045, ..., 0.000295639,\n",
       "              0.00662231, 0.00312805]],\n",
       "    \n",
       "            [[-0.0100708, -0.0109863, -0.00698853, ..., -0.00915527,\n",
       "              0.00189209, 0.00396729],\n",
       "             [-0.000953674, -0.00418091, 0.00558472, ..., 0.00552368,\n",
       "              0.00189209, -0.0071106],\n",
       "             [0.00102997, 0.0148926, 0.00927734, ..., -0.00231934,\n",
       "              0.00866699, -0.00335693],\n",
       "             ...,\n",
       "             [-0.00248718, -0.00765991, -0.0140991, ..., 0.0120239,\n",
       "              -0.000549316, 0.00762939],\n",
       "             [0.0137939, -0.0178223, -0.0118408, ..., 0.0233154,\n",
       "              -0.00469971, -0.0065918],\n",
       "             [-3.3617e-05, 0.00279236, -0.0115356, ..., -0.000297546,\n",
       "              -0.000957489, 0.00497437]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00193024, -0.00836182, -0.00127411, ..., -0.00482178,\n",
       "             -0.0319824, 0.0105591],\n",
       "            [-0.00236511, 0.00860596, -0.00686646, ..., 0.0235596,\n",
       "             -0.0115356, -0.0177002],\n",
       "            [-0.0135498, 0.00204468, 0.000249863, ..., -0.00854492,\n",
       "             -0.0214844, -0.0050354],\n",
       "            ...,\n",
       "            [-0.0135498, -0.00723267, -0.00701904, ..., -0.00772095,\n",
       "             0.0107422, 0.00183105],\n",
       "            [-0.00698853, 0.0162354, 0.000495911, ..., 0.0067749,\n",
       "             -0.0158691, -0.00145721],\n",
       "            [0.00439453, -0.00469971, -0.000816345, ..., -0.00604248,\n",
       "             0.0172119, 0.00970459]],\n",
       "    \n",
       "           [[0.00521851, -0.00506592, -0.0144653, ..., -0.0149536,\n",
       "             0.0136719, 0.012146],\n",
       "            [0.00500488, 0.00195312, 0.00793457, ..., -0.00512695,\n",
       "             0.00683594, -0.0107422],\n",
       "            [0.00387573, 0.00778198, 0.0101318, ..., 0.0158691, -0.0152588,\n",
       "             -0.00561523],\n",
       "            ...,\n",
       "            [-0.0122681, 0.0103149, -0.0107422, ..., 0.00958252, 0.00610352,\n",
       "             -0.00494385],\n",
       "            [0.00150299, 0.00299072, 0.000976562, ..., 0.000377655,\n",
       "             0.000286102, -0.00701904],\n",
       "            [0.0107422, -0.00854492, 0.0183105, ..., -0.00494385,\n",
       "             0.00424194, -0.00674438]],\n",
       "    \n",
       "           [[-0.00263977, -0.0158691, -0.00958252, ..., 0.00421143,\n",
       "             -0.0209961, -0.00248718],\n",
       "            [0.00976562, 0.0220947, 0.0189209, ..., -0.0192871, -0.0168457,\n",
       "             0.015625],\n",
       "            [-0.00872803, -5.62668e-05, 0.0109863, ..., 0.00332642,\n",
       "             -0.0039978, -0.0065918],\n",
       "            ...,\n",
       "            [0.00860596, -0.0292969, -0.00094223, ..., 0.0239258, 0.0109253,\n",
       "             0.00570679],\n",
       "            [-0.00056076, 0.00680542, 0.0234375, ..., -0.0115356,\n",
       "             0.00308228, 0.0157471],\n",
       "            [0.000216484, 0.00411987, -0.0167236, ..., 0.00300598,\n",
       "             -0.0110474, -0.00982666]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0043335, -0.00154877, 0.0158691, ..., 0.0258789,\n",
       "             -0.00738525, 0.00799561],\n",
       "            [0.010498, 0.0088501, 0.0114746, ..., 0.00273132, -0.00158691,\n",
       "             -0.0266113],\n",
       "            [0.00994873, -0.0123901, -0.00683594, ..., -0.00897217,\n",
       "             -0.00222778, 0.0130615],\n",
       "            ...,\n",
       "            [-0.0128784, -0.00218201, 0.00741577, ..., 0.00379944,\n",
       "             0.00119019, -0.00405884],\n",
       "            [-0.0145264, -0.00119019, -0.0100708, ..., -0.0246582,\n",
       "             0.0144043, 0.0103149],\n",
       "            [-0.00305176, -0.00946045, 0.00750732, ..., 0.00191498,\n",
       "             -0.0136108, -0.0143433]],\n",
       "    \n",
       "           [[0.00296021, -0.0206299, 0.0163574, ..., -0.00285339,\n",
       "             -0.00872803, -0.0166016],\n",
       "            [0.0168457, 4.1008e-05, -0.00909424, ..., -0.00891113,\n",
       "             0.00340271, 0.0169678],\n",
       "            [-0.0179443, -0.00964355, 0.0057373, ..., 0.0113525,\n",
       "             -0.00408936, 0.003479],\n",
       "            ...,\n",
       "            [-0.0180664, 0.00111389, -3.48091e-05, ..., -0.0198975,\n",
       "             -0.00100708, -0.00159454],\n",
       "            [0.00891113, 0.00866699, 0.00747681, ..., -0.00601196,\n",
       "             -0.00063324, 0.00291443],\n",
       "            [-0.00521851, 0.00668335, -0.0127563, ..., 0.010437, 0.00216675,\n",
       "             0.000896454]],\n",
       "    \n",
       "           [[0.00518799, -0.00056839, 0.00460815, ..., -0.0129395,\n",
       "             -0.0045166, 0.00915527],\n",
       "            [-0.001297, 0.00415039, -0.00233459, ..., -0.0202637, 0.0198975,\n",
       "             0.00346375],\n",
       "            [-0.00524902, -0.00102997, 0.0126343, ..., 0.020874, 0.0119019,\n",
       "             0.00717163],\n",
       "            ...,\n",
       "            [-0.00250244, -0.010498, -0.012207, ..., -0.0109253, 0.0206299,\n",
       "             -0.0098877],\n",
       "            [0.00454712, -0.00212097, -0.00241089, ..., -0.0137329,\n",
       "             0.010376, -0.00247192],\n",
       "            [0.00279236, -0.00215149, -0.0012207, ..., -0.00927734,\n",
       "             -0.015625, -0.0150757]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00689697, 0.0146484, 0.00717163, ..., 0.00154877, 0.00634766,\n",
       "            -0.00582886],\n",
       "           [-0.00279236, -0.00576782, -0.00228882, ..., 0.006073,\n",
       "            -0.00370789, -0.00312805],\n",
       "           [0.00430298, 0.00222778, -0.00585938, ..., -0.00860596,\n",
       "            0.00692749, 0.00128174],\n",
       "           ...,\n",
       "           [0.00662231, 0.00494385, -0.00982666, ..., -0.00145721,\n",
       "            0.00546265, -0.00970459],\n",
       "           [-0.00524902, 0.0027771, -0.00482178, ..., 0.00125122,\n",
       "            0.0147095, 0.0030365],\n",
       "           [-0.00123596, -0.00318909, 0.0146484, ..., 0.000352859,\n",
       "            -0.00564575, -0.00291443]],\n",
       "   \n",
       "          [[-0.00570679, 0.0039978, -0.00357056, ..., -0.00473022,\n",
       "            0.0117798, 0.0223389],\n",
       "           [-0.00192261, 0.0078125, 0.00230408, ..., -0.00185394,\n",
       "            0.000358582, 0.00302124],\n",
       "           [0.00164032, 0.00325012, -0.00714111, ..., 0.00878906,\n",
       "            -0.00500488, -0.00408936],\n",
       "           ...,\n",
       "           [-0.00112915, 0.0137329, -0.00637817, ..., 0.00145721,\n",
       "            -0.0133667, -0.00328064],\n",
       "           [-0.00325012, -0.0057373, 0.00509644, ..., 0.00878906,\n",
       "            0.0105591, 0.0133667],\n",
       "           [-0.00411987, 0.00126648, -0.00872803, ..., -0.00088501,\n",
       "            0.00140381, 0.0100708]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00915527, 0.00689697, -0.00189972, ..., -0.00546265,\n",
       "           0.00509644, 0.000930786],\n",
       "          [-0.0124512, -0.0078125, 0.00325012, ..., 0.0147705, 0.000320435,\n",
       "           -0.00552368],\n",
       "          [0.0035553, 0.00112915, -0.00585938, ..., -0.0151367, 0.00549316,\n",
       "           0.00169373],\n",
       "          ...,\n",
       "          [0.00292969, -0.00210571, -0.00390625, ..., 0.00123596,\n",
       "           -9.25064e-05, -0.0071106],\n",
       "          [0.00726318, 0.0186768, 0.00289917, ..., -0.0159912, 0.0107422,\n",
       "           -0.0132446],\n",
       "          [0.0148315, 0.0125732, -0.0025177, ..., 0.00946045, -0.00424194,\n",
       "           0.0115967]], dtype=bfloat16), a=Array([[-0.00383564, -0.00756023, -0.01255484, ...,  0.01498562,\n",
       "           -0.01903302,  0.02186585],\n",
       "          [-0.00933835,  0.0013327 ,  0.01779663, ..., -0.00167542,\n",
       "            0.00606556, -0.00059748]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([1.39062, 1.32031, 1.55469, ..., 1.32031, 1.50781, 1.29688],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([2.84375, 2.875, 2.90625, ..., 2.64062, 2.78125, 2.5625], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.359375, 0.330078, 0.347656, ..., 0.306641, 0.318359, 0.5],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.0220947, 0.0688477, 0.0303955, ..., 0.0279541, 0.0133057,\n",
       "          0.108887], dtype=bfloat16)}},\n",
       " 'layer_21': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00692749, 0.0206299, -0.00121307, ..., 0.00306702,\n",
       "             0.00421143, -0.00147247],\n",
       "            [0.00878906, 0.0067749, -0.000530243, ..., 0.0213623, 0.0128784,\n",
       "             0.00209045],\n",
       "            [0.0123291, -0.0161133, -0.0114136, ..., -0.00393677,\n",
       "             -0.0213623, 0.0153198],\n",
       "            ...,\n",
       "            [0.00558472, 0.00848389, -0.0152588, ..., 0.0109253,\n",
       "             -0.00640869, 0.00136566],\n",
       "            [-0.0124512, 0.00445557, -0.0162354, ..., -0.0288086,\n",
       "             -0.00354004, -0.00787354],\n",
       "            [-0.0117188, 0.00579834, 3.69549e-05, ..., 0.0147705,\n",
       "             -0.00143433, 0.0164795]],\n",
       "    \n",
       "           [[-0.00282288, 0.000257492, 0.00479126, ..., -0.0135498,\n",
       "             0.00125885, 0.00141907],\n",
       "            [0.0062561, -0.00122833, 0.00466919, ..., 0.00340271,\n",
       "             -0.000919342, 0.00738525],\n",
       "            [-0.00131226, 0.00037384, 0.0158691, ..., -0.00753784,\n",
       "             -0.00216675, 0.010437],\n",
       "            ...,\n",
       "            [0.00628662, 0.00634766, -0.00836182, ..., 0.00524902, 0.012207,\n",
       "             0.00241089],\n",
       "            [-0.0133057, -0.00101471, 0.0108643, ..., 0.00817871, 0.0117798,\n",
       "             -0.00308228],\n",
       "            [0.00296021, -0.0175781, 0.000478745, ..., -0.00411987,\n",
       "             -0.012085, 0.0098877]],\n",
       "    \n",
       "           [[-0.0027771, -0.00915527, -0.00878906, ..., -0.00210571,\n",
       "             0.00309753, 0.0174561],\n",
       "            [0.00531006, -0.0154419, -0.0123291, ..., 0.00643921,\n",
       "             -0.0283203, 0.00497437],\n",
       "            [-0.0123901, 0.0038147, -0.0246582, ..., 0.0107422, 0.00201416,\n",
       "             0.0167236],\n",
       "            ...,\n",
       "            [-0.0236816, -0.00415039, 0.0183105, ..., -0.0322266,\n",
       "             -0.00231934, 0.0405273],\n",
       "            [-0.00646973, -0.0167236, 0.0180664, ..., 0.00488281,\n",
       "             -0.00418091, -0.0113525],\n",
       "            [0.00537109, 0.0146484, -0.00112915, ..., 0.00613403,\n",
       "             -0.0123291, 0.0112305]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00306702, 0.00842285, -0.00202942, ..., -0.0139771,\n",
       "             0.019165, 0.0108032],\n",
       "            [0.0035553, -0.00364685, -0.00811768, ..., 0.0144653,\n",
       "             -0.000400543, 0.0126343],\n",
       "            [0.000564575, -0.00402832, -0.00141907, ..., -0.00558472,\n",
       "             -0.00366211, 0.000205994],\n",
       "            ...,\n",
       "            [-0.00340271, 0.00958252, -0.0152588, ..., -0.00494385,\n",
       "             0.00799561, -0.00312805],\n",
       "            [0.00372314, -0.00534058, 0.0105591, ..., -0.00534058,\n",
       "             0.0116577, -0.0145874],\n",
       "            [0.00543213, -0.0130005, -0.00448608, ..., 0.00735474,\n",
       "             0.000180244, -0.0035553]],\n",
       "    \n",
       "           [[-0.00386047, -0.000926971, 0.012146, ..., 0.0098877, 0.015625,\n",
       "             0.0150146],\n",
       "            [-0.0100708, -0.00964355, 0.00228882, ..., 0.00308228,\n",
       "             -0.00187683, -0.00643921],\n",
       "            [-0.00338745, -0.00234985, 0.0161133, ..., -0.012207,\n",
       "             -0.00775146, 0.00088501],\n",
       "            ...,\n",
       "            [0.00515747, 0.026123, 0.0203857, ..., -0.000804901, 0.00891113,\n",
       "             -0.00915527],\n",
       "            [-0.0163574, -0.0241699, 0.00891113, ..., 0.0067749, 0.00909424,\n",
       "             0.0150146],\n",
       "            [-0.00171661, -0.00787354, -0.0140381, ..., -0.00357056,\n",
       "             -0.00537109, -0.0201416]],\n",
       "    \n",
       "           [[0.0147705, 0.00933838, -0.006073, ..., -0.0116577, -0.0050354,\n",
       "             -0.0159912],\n",
       "            [0.0157471, 0.0140991, 0.00167084, ..., -0.00328064, 0.00759888,\n",
       "             0.0131836],\n",
       "            [0.00111389, 0.019043, -0.00769043, ..., 0.00836182, 0.00582886,\n",
       "             0.0177002],\n",
       "            ...,\n",
       "            [-0.000522614, -0.0134277, -0.0300293, ..., 0.0129395,\n",
       "             -0.0285645, 0.0144653],\n",
       "            [0.000984192, 0.0126343, 0.00415039, ..., -0.012085, 0.0004673,\n",
       "             -0.00909424],\n",
       "            [0.000265121, 0.00726318, 0.0129395, ..., 0.00389099,\n",
       "             -0.00314331, 0.00445557]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0141602, 0.00115204, 0.00933838, ..., 0.0134277,\n",
       "              -0.00177765, 0.00280762],\n",
       "             [0.000257492, 0.0025177, -0.0012207, ..., -0.00543213,\n",
       "              -0.000656128, -0.0251465],\n",
       "             [-0.00488281, 0.00262451, 0.00604248, ..., 0.00521851,\n",
       "              0.00646973, -0.019165],\n",
       "             ...,\n",
       "             [-0.0197754, 0.0110474, -0.00218201, ..., -0.0224609,\n",
       "              0.0144043, 0.00315857],\n",
       "             [0.012207, 0.0151978, -0.00546265, ..., -0.00402832,\n",
       "              -0.0134888, -0.00247192],\n",
       "             [0.0115967, -0.0166016, -0.00805664, ..., 0.00842285,\n",
       "              0.00653076, -0.00152588]],\n",
       "    \n",
       "            [[-0.006073, -0.00976562, -0.00445557, ..., -0.00189209,\n",
       "              0.00585938, -0.00683594],\n",
       "             [6.81877e-05, -0.0134277, 0.0126343, ..., 0.0130005,\n",
       "              0.0175781, 0.020752],\n",
       "             [-0.00909424, -0.00427246, 0.0109863, ..., -0.00299072,\n",
       "              -0.00933838, 0.0115967],\n",
       "             ...,\n",
       "             [0.00427246, -0.00491333, 0.0045166, ..., -0.00101471,\n",
       "              0.00811768, 0.0354004],\n",
       "             [0.00328064, 0.00933838, -0.00860596, ..., -0.00921631,\n",
       "              -0.0174561, -0.0181885],\n",
       "             [0.0131836, -0.0101929, -0.00147247, ..., 0.00860596,\n",
       "              -0.00952148, -0.00469971]],\n",
       "    \n",
       "            [[0.00210571, -0.00357056, -0.00124359, ..., -0.00439453,\n",
       "              -0.0118408, -0.0178223],\n",
       "             [0.00386047, 0.00411987, 0.000282288, ..., -0.00909424,\n",
       "              0.000286102, 0.00836182],\n",
       "             [-0.00159454, -0.0123291, 0.00279236, ..., 0.0125122,\n",
       "              0.0132446, 0.00312805],\n",
       "             ...,\n",
       "             [0.00708008, 0.00793457, 0.00219727, ..., -0.0115356,\n",
       "              0.00218201, 0.00604248],\n",
       "             [-0.00830078, -0.00279236, 0.00222778, ..., -0.0019989,\n",
       "              -0.0110474, 0.00958252],\n",
       "             [-0.000873566, -0.00263977, -0.00427246, ..., -0.0168457,\n",
       "              -0.0175781, 0.00106049]],\n",
       "    \n",
       "            [[-0.00793457, -0.00653076, 0.00120544, ..., 0.00292969,\n",
       "              -0.00646973, -0.00323486],\n",
       "             [0.017334, 0.00619507, -0.0184326, ..., 8.4877e-05,\n",
       "              0.00386047, 0.00436401],\n",
       "             [-0.00622559, -0.0112305, 0.000518799, ..., -0.00191498,\n",
       "              0.00671387, -0.0124512],\n",
       "             ...,\n",
       "             [0.00034523, 0.0103149, -0.0100708, ..., -0.015564,\n",
       "              -0.00376892, 0.00494385],\n",
       "             [-0.00970459, -0.000297546, 0.00376892, ..., -0.00354004,\n",
       "              0.0110474, 0.0114136],\n",
       "             [-0.0078125, -0.00161743, -0.00775146, ..., -0.0110474,\n",
       "              0.00512695, -0.0019989]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0025177, 0.0257568, 0.00714111, ..., 0.00952148,\n",
       "              -0.020874, -0.000991821],\n",
       "             [0.0153809, 0.0126953, -0.012207, ..., 0.0071106, 0.00689697,\n",
       "              -0.0117798],\n",
       "             [0.0098877, -0.00418091, 0.00309753, ..., -0.022583,\n",
       "              -0.0169678, 0.00717163],\n",
       "             ...,\n",
       "             [0.0067749, 0.02771, 3.50475e-05, ..., 0.0112915, -0.0103149,\n",
       "              0.00735474],\n",
       "             [-0.00421143, 0.00189209, -0.0196533, ..., 0.0128174,\n",
       "              0.0090332, -0.000617981],\n",
       "             [-0.00384521, 0.0177002, 0.0126953, ..., -0.00634766,\n",
       "              0.00994873, 0.0174561]],\n",
       "    \n",
       "            [[0.00933838, -0.00193787, -0.00159454, ..., -0.00897217,\n",
       "              -0.00689697, 0.0107422],\n",
       "             [0.00915527, -0.0224609, 0.00230408, ..., -0.00169373,\n",
       "              -0.019043, 0.00469971],\n",
       "             [0.0101318, -0.00320435, -0.0230713, ..., 0.0146484, 0.020752,\n",
       "              0.0101929],\n",
       "             ...,\n",
       "             [-0.0098877, 0.00280762, 0.0157471, ..., -0.0172119,\n",
       "              -0.00320435, 0.00188446],\n",
       "             [0.0130615, -0.00262451, -0.00115967, ..., -0.0223389,\n",
       "              -0.0148926, -0.00259399],\n",
       "             [0.0187988, -0.0117188, 0.00582886, ..., 0.0108643,\n",
       "              -0.00497437, 0.015625]],\n",
       "    \n",
       "            [[-0.00485229, 0.0045166, 0.00543213, ..., 0.00878906,\n",
       "              0.0117188, 0.00656128],\n",
       "             [-0.0129395, 0.00738525, -0.00227356, ..., 0.0150757,\n",
       "              -0.00634766, 0.0166016],\n",
       "             [-0.00334167, -0.0151978, 0.00561523, ..., -0.00878906,\n",
       "              -0.0174561, -0.0114746],\n",
       "             ...,\n",
       "             [-0.00759888, -0.0045166, 0.00723267, ..., 0.000911713,\n",
       "              -0.00897217, -0.0200195],\n",
       "             [-0.00170898, -0.00860596, -0.00302124, ..., -0.00628662,\n",
       "              -0.00106049, 0.00236511],\n",
       "             [0.0220947, 0.012146, -0.00753784, ..., -0.00369263,\n",
       "              0.0106812, 0.00613403]],\n",
       "    \n",
       "            [[0.00454712, 0.000138283, -0.0115356, ..., 0.0117188,\n",
       "              0.00552368, 0.00915527],\n",
       "             [0.00561523, -0.0114136, 0.00460815, ..., 0.0124512,\n",
       "              -0.00588989, -0.0169678],\n",
       "             [-0.00952148, 0.0117188, 0.0162354, ..., 0.0131836, 0.0140991,\n",
       "              -0.00842285],\n",
       "             ...,\n",
       "             [0.00689697, -0.00265503, -0.0103149, ..., 0.0118408,\n",
       "              0.000207901, -0.0107422],\n",
       "             [0.0150757, 0.0136108, 0.010376, ..., 0.0149536, 0.00062561,\n",
       "              -0.00994873],\n",
       "             [0.010376, -0.0159912, -0.00125885, ..., -0.00717163,\n",
       "              0.0147095, -0.0133667]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00183105, 0.0106812, -0.00762939, ..., -0.00634766,\n",
       "             0.00509644, -0.0039978],\n",
       "            [0.0148926, 0.00183105, 0.000583649, ..., 0.00376892,\n",
       "             -0.0236816, -0.0139771],\n",
       "            [-0.0203857, -0.0275879, 0.000511169, ..., -0.00294495,\n",
       "             0.00195312, 0.0154419],\n",
       "            ...,\n",
       "            [0.0151367, 0.00378418, 0.00717163, ..., -0.00958252,\n",
       "             0.00830078, -0.00646973],\n",
       "            [-0.012085, -0.0124512, 0.00537109, ..., 0.000478745,\n",
       "             -0.00854492, -0.0185547],\n",
       "            [-0.00604248, -0.000991821, -0.000667572, ..., 0.0143433,\n",
       "             -0.00872803, 0.000141144]],\n",
       "    \n",
       "           [[-0.00183868, -0.0101929, -0.000610352, ..., -0.00463867,\n",
       "             0.0233154, 0.0209961],\n",
       "            [-7.67708e-05, -0.000762939, -0.00680542, ..., 0.0136108,\n",
       "             -0.0366211, -0.0344238],\n",
       "            [-0.00213623, -0.0192871, -0.0175781, ..., -0.0106201,\n",
       "             0.0283203, -0.00656128],\n",
       "            ...,\n",
       "            [-0.00668335, -0.0257568, -0.00430298, ..., -0.00582886,\n",
       "             0.0334473, 0.0155029],\n",
       "            [0.00671387, 0.000350952, 0.00271606, ..., -0.00939941,\n",
       "             -0.00485229, -0.0025177],\n",
       "            [-0.00110626, 0.00299072, 0.0203857, ..., -0.017334, -0.0119019,\n",
       "             0.00242615]],\n",
       "    \n",
       "           [[-0.0134277, 0.0130615, 0.00473022, ..., 0.00830078,\n",
       "             -0.00131226, 0.00872803],\n",
       "            [0.0130615, -0.0162354, -0.00656128, ..., 0.0119019, 0.00390625,\n",
       "             0.00970459],\n",
       "            [0.00445557, -0.00150299, -0.00665283, ..., 0.00224304,\n",
       "             0.0170898, -0.0189209],\n",
       "            ...,\n",
       "            [-0.012085, -0.00701904, -0.00515747, ..., -0.0177002,\n",
       "             -0.00537109, -0.0192871],\n",
       "            [-0.013855, 0.00921631, 0.00619507, ..., -0.00262451,\n",
       "             0.00482178, 0.0067749],\n",
       "            [0.0019989, -0.000839233, 0.00195312, ..., 0.00238037,\n",
       "             0.0133667, -0.00325012]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00637817, 0.00375366, -0.000957489, ..., -0.0124512,\n",
       "             -0.00946045, -0.0113525],\n",
       "            [0.00604248, 0.00082016, -0.0115356, ..., 0.0183105, 0.0119019,\n",
       "             0.0234375],\n",
       "            [0.0088501, -0.00561523, -0.000173569, ..., -0.0200195,\n",
       "             0.00726318, 0.00665283],\n",
       "            ...,\n",
       "            [0.00643921, -0.0037384, 0.000115395, ..., -0.000766754,\n",
       "             -0.00340271, -0.0012207],\n",
       "            [-0.00769043, 0.00854492, -0.0111084, ..., 0.0270996,\n",
       "             -0.0211182, -0.0017395],\n",
       "            [0.00476074, -0.0014267, 0.0072937, ..., 0.0186768, 0.017334,\n",
       "             -0.00305176]],\n",
       "    \n",
       "           [[-0.00215149, -0.00349426, 0.00976562, ..., 0.0106201,\n",
       "             0.00854492, -0.0117188],\n",
       "            [-0.00671387, 0.000553131, -0.00610352, ..., -0.00854492,\n",
       "             0.0142822, 0.00384521],\n",
       "            [-0.00811768, 0.00842285, 0.00927734, ..., -0.019165,\n",
       "             0.00656128, -0.00479126],\n",
       "            ...,\n",
       "            [0.00170898, -0.00106049, -0.00506592, ..., 0.00964355,\n",
       "             -0.0222168, 0.00585938],\n",
       "            [0.00236511, 0.00747681, 0.00915527, ..., 0.00604248,\n",
       "             -0.00643921, -0.0153198],\n",
       "            [-0.0057373, -0.00619507, 0.00331116, ..., 0.00132751,\n",
       "             0.00686646, -0.00701904]],\n",
       "    \n",
       "           [[-0.0157471, 0.0027771, 0.0136719, ..., 0.0043335, -0.00144958,\n",
       "             -0.00527954],\n",
       "            [-0.0020752, 0.00463867, -0.0037384, ..., -0.00946045,\n",
       "             -0.00131989, -0.0125732],\n",
       "            [-0.00183868, 0.0088501, -0.00970459, ..., -0.0163574,\n",
       "             -0.00424194, -0.0157471],\n",
       "            ...,\n",
       "            [0.0172119, -0.00939941, -0.00250244, ..., 0.00204468,\n",
       "             0.0107422, 0.000352859],\n",
       "            [-0.00196838, 0.010376, -0.000263214, ..., -0.00561523,\n",
       "             0.0111694, 0.0131226],\n",
       "            [0.00442505, -0.00872803, -0.00469971, ..., 0.00411987,\n",
       "             0.00224304, 0.00836182]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00723267, 0.00106812, -0.0110474, ..., 0.0136719,\n",
       "            -0.00854492, -0.00500488],\n",
       "           [-0.0027771, -0.0148926, 0.00454712, ..., 0.00701904,\n",
       "            -0.0101929, -0.000617981],\n",
       "           [-0.000182152, -0.0107422, 0.0032959, ..., 0.0116577,\n",
       "            -0.0101929, -0.0119629],\n",
       "           ...,\n",
       "           [-0.00151062, -0.0037384, -0.00585938, ..., -0.000541687,\n",
       "            0.00189209, 0.00424194],\n",
       "           [0.0020752, 0.00158691, 0.000522614, ..., 0.00280762,\n",
       "            -0.0174561, 0.0103149],\n",
       "           [0.00527954, 0.00244141, 0.00102997, ..., 0.00171661,\n",
       "            -0.00132751, 0.000736237]],\n",
       "   \n",
       "          [[-0.000545502, 0.00354004, -0.00552368, ..., 0.00402832,\n",
       "            0.00787354, 0.00592041],\n",
       "           [0.0100098, 0.00204468, 0.00442505, ..., 0.0136719, -0.0111694,\n",
       "            -0.0118408],\n",
       "           [0.00454712, 0.0016098, -0.012085, ..., -0.00500488, -0.0144043,\n",
       "            0.00213623],\n",
       "           ...,\n",
       "           [0.00056839, 0.000366211, 0.000511169, ..., 0.00238037,\n",
       "            0.000923157, -0.0125732],\n",
       "           [-0.00469971, -0.00069809, -0.00793457, ..., 0.0018692,\n",
       "            0.00769043, -0.0175781],\n",
       "           [0.00759888, -0.00137329, 0.0055542, ..., -0.00212097,\n",
       "            0.00588989, 0.00891113]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00314331, 0.0147705, -0.00466919, ..., 0.00262451, -0.00154114,\n",
       "           0.00112152],\n",
       "          [-0.00227356, -0.0139771, 0.000432968, ..., 0.00161743, 0.0137939,\n",
       "           0.0107422],\n",
       "          [-0.00878906, 0.00561523, -0.00198364, ..., -0.00326538,\n",
       "           0.00354004, -0.00424194],\n",
       "          ...,\n",
       "          [0.00415039, -0.00100708, 0.0177002, ..., 0.0088501, -0.010376,\n",
       "           0.000713348],\n",
       "          [0.0144043, -0.000417709, -0.00613403, ..., 0.003479, 0.00114441,\n",
       "           -0.00628662],\n",
       "          [0.00248718, -0.0116577, 0.00793457, ..., 0.00177765, -0.0147095,\n",
       "           0.0202637]], dtype=bfloat16), a=Array([[-0.00473069, -0.01229254,  0.00118823, ...,  0.00760194,\n",
       "           -0.01410474, -0.00785806],\n",
       "          [-0.00138563, -0.00167912,  0.01098308, ...,  0.01268801,\n",
       "            0.0018889 , -0.00222404]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([1.34375, 1.36719, 1.53906, ..., 1.33594, 1.35156, 1.24219],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([3.1875, 3.34375, 3.375, ..., 3.04688, 3.32812, 3.03125], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.421875, 0.402344, 0.400391, ..., 0.457031, 0.480469, 0.53125],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.0605469, -0.0107422, -0.0512695, ..., -0.0512695, -0.0771484,\n",
       "          0.0262451], dtype=bfloat16)}},\n",
       " 'layer_22': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0078125, -0.00454712, -0.00616455, ..., 0.00674438,\n",
       "             -0.0180664, 0.00726318],\n",
       "            [-0.0151978, 0.00622559, -0.00735474, ..., -0.000341415,\n",
       "             -0.0103149, -0.0038147],\n",
       "            [0.0227051, 0.0100098, 0.00187683, ..., 0.0175781, 0.00117493,\n",
       "             0.000652313],\n",
       "            ...,\n",
       "            [0.00317383, 0.00262451, 0.00970459, ..., -0.0146484,\n",
       "             -0.0163574, -0.012146],\n",
       "            [-0.00491333, 8.82149e-05, -0.000953674, ..., -0.0197754,\n",
       "             -0.000747681, -0.00473022],\n",
       "            [-0.00836182, -0.00239563, 0.00361633, ..., 0.0118408,\n",
       "             -0.0164795, 0.00769043]],\n",
       "    \n",
       "           [[-0.00759888, -0.00302124, -0.00153351, ..., 0.00601196,\n",
       "             0.00384521, 0.013916],\n",
       "            [0.00234985, 0.00031662, -0.0159912, ..., 0.00274658, -0.017334,\n",
       "             -0.00643921],\n",
       "            [-0.000341415, 0.00579834, 0.0118408, ..., -0.0145874,\n",
       "             0.0071106, -0.0126953],\n",
       "            ...,\n",
       "            [-0.000904083, 0.00302124, -0.00196838, ..., 0.00108337,\n",
       "             -0.00515747, -0.00952148],\n",
       "            [-0.00891113, -0.00662231, 0.000206947, ..., -0.00150299,\n",
       "             0.00823975, -0.00120544],\n",
       "            [0.012207, -0.00582886, -0.00744629, ..., 0.0122681, -0.0100708,\n",
       "             0.0162354]],\n",
       "    \n",
       "           [[0.0162354, 0.00279236, 0.0108032, ..., -0.0236816, 0.00138855,\n",
       "             -0.000440598],\n",
       "            [0.0197754, -0.00312805, -0.00964355, ..., -0.00267029,\n",
       "             0.0114746, 0.0148926],\n",
       "            [0.00153351, -0.00732422, -0.00466919, ..., 0.00286865,\n",
       "             0.00756836, 0.00811768],\n",
       "            ...,\n",
       "            [0.0137329, 0.00273132, 0.00424194, ..., 0.032959, 0.020874,\n",
       "             0.00408936],\n",
       "            [-0.0135498, -0.0161133, 0.00286865, ..., -0.00595093,\n",
       "             0.0131226, 0.00717163],\n",
       "            [0.0111694, 0.0139771, -0.0098877, ..., -0.012085, 0.00598145,\n",
       "             -0.00204468]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00454712, -0.0219727, -0.00558472, ..., -0.00958252,\n",
       "             0.0223389, 0.0032959],\n",
       "            [0.0162354, 0.00393677, 0.001091, ..., -0.00115204, -0.00842285,\n",
       "             -0.00964355],\n",
       "            [-0.0159912, -0.00692749, -0.00772095, ..., 0.0057373,\n",
       "             -0.00653076, -0.00482178],\n",
       "            ...,\n",
       "            [0.00288391, 0.00247192, 0.0119629, ..., 0.00314331, 0.012085,\n",
       "             -0.0120239],\n",
       "            [0.00805664, -0.00335693, 0.0126953, ..., -0.00512695,\n",
       "             0.0106812, -0.00146484],\n",
       "            [-0.0147095, -0.0157471, 0.0198975, ..., -0.00107574,\n",
       "             -0.000656128, -0.0112305]],\n",
       "    \n",
       "           [[0.026001, -0.00854492, 0.00125122, ..., 0.0148926, 0.0019455,\n",
       "             0.00787354],\n",
       "            [0.0144043, 0.00164795, -0.00976562, ..., -0.00720215,\n",
       "             0.0108643, -0.00482178],\n",
       "            [-0.0105591, -0.0112305, 0.00891113, ..., -0.00622559,\n",
       "             0.00695801, -0.00921631],\n",
       "            ...,\n",
       "            [-0.0019455, -0.0111084, -0.019165, ..., -0.019165, -0.0211182,\n",
       "             -0.0108643],\n",
       "            [0.00860596, 0.00222778, 0.020752, ..., 0.00476074, -0.00848389,\n",
       "             0.00695801],\n",
       "            [0.00259399, 0.00213623, 0.00109863, ..., 0.00753784,\n",
       "             -0.00140381, -0.00772095]],\n",
       "    \n",
       "           [[-0.0275879, -0.00193024, 0.0137329, ..., -0.00946045,\n",
       "             -0.0039978, -0.00527954],\n",
       "            [-0.0246582, -0.0153809, 0.00132751, ..., 0.0164795, -0.0187988,\n",
       "             0.00282288],\n",
       "            [0.0072937, 0.020874, 0.00592041, ..., 0.00592041, -0.00320435,\n",
       "             0.0124512],\n",
       "            ...,\n",
       "            [-0.0128784, 0.00270081, 0.00598145, ..., 0.00836182, 0.0184326,\n",
       "             -0.0038147],\n",
       "            [-0.013855, -0.00662231, -0.0143433, ..., 0.00107574,\n",
       "             -0.00695801, -0.0255127],\n",
       "            [0.00263977, -0.00411987, -0.00244141, ..., -0.00335693,\n",
       "             -0.00172424, -0.000972748]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00689697, -0.00328064, -0.00402832, ..., -0.00262451,\n",
       "              -0.000362396, -0.00653076],\n",
       "             [0.00662231, 0.000375748, -0.00552368, ..., 0.00379944,\n",
       "              -0.0308838, -0.00546265],\n",
       "             [0.0102539, -0.0140381, -0.0238037, ..., -0.00756836,\n",
       "              0.00442505, -0.00872803],\n",
       "             ...,\n",
       "             [-0.0129395, -0.0137939, 0.00125885, ..., -0.0162354,\n",
       "              0.0122681, 0.0162354],\n",
       "             [0.00390625, 0.000873566, -0.0106812, ..., 0.0166016,\n",
       "              -0.000522614, 0.0233154],\n",
       "             [-0.00653076, 0.00765991, -0.000946045, ..., 0.00765991,\n",
       "              -0.0163574, 0.00312805]],\n",
       "    \n",
       "            [[-0.00101471, -0.00376892, -0.00878906, ..., -0.000354767,\n",
       "              -0.00105286, 0.0035553],\n",
       "             [0.00650024, -0.00769043, 0.00466919, ..., 0.00805664,\n",
       "              -0.00331116, 0.0194092],\n",
       "             [5.55515e-05, 0.0043335, 0.00457764, ..., 0.00665283,\n",
       "              0.00159454, -0.00582886],\n",
       "             ...,\n",
       "             [0.00294495, 0.00479126, -0.00387573, ..., 0.00171661,\n",
       "              -0.000297546, -0.00952148],\n",
       "             [0.00326538, 0.0043335, 0.0057373, ..., -0.00595093,\n",
       "              0.00604248, -0.0115967],\n",
       "             [0.00552368, -0.00631714, -0.0039978, ..., 0.00799561,\n",
       "              -0.0106812, -0.00750732]],\n",
       "    \n",
       "            [[0.00543213, -0.00521851, -0.00161743, ..., -0.0106812,\n",
       "              0.00946045, 0.00653076],\n",
       "             [-0.00213623, -0.00515747, 0.0071106, ..., -0.00460815,\n",
       "              -0.00153351, -0.00239563],\n",
       "             [0.0032959, 0.00643921, -0.00014782, ..., 0.0170898,\n",
       "              -0.00701904, 0.00915527],\n",
       "             ...,\n",
       "             [0.00273132, -0.00154114, 0.00439453, ..., -0.0170898,\n",
       "              -0.00823975, -0.000854492],\n",
       "             [-0.000488281, -0.00143433, -0.00476074, ..., 0.0123291,\n",
       "              -0.0219727, -0.00430298],\n",
       "             [-0.00161743, -0.0055542, -0.00747681, ..., -0.0205078,\n",
       "              -0.0133667, -0.00933838]],\n",
       "    \n",
       "            [[-0.00166321, 0.0027771, -0.00254822, ..., 0.00595093,\n",
       "              -0.0112915, -0.024292],\n",
       "             [4.69685e-05, 0.00909424, -0.0106812, ..., 0.00144196,\n",
       "              -0.00836182, 0.0218506],\n",
       "             [0.00531006, -0.00354004, 0.00860596, ..., 0.0168457,\n",
       "              -0.00285339, 0.000740051],\n",
       "             ...,\n",
       "             [0.000444412, -0.00976562, -0.00285339, ..., -0.0107422,\n",
       "              0.0112305, 0.0125122],\n",
       "             [0.0103149, -0.00598145, -0.00334167, ..., -0.00473022,\n",
       "              -0.0195312, -0.00427246],\n",
       "             [-0.0045166, 0.00411987, -0.012146, ..., 0.00306702, 0.017334,\n",
       "              0.0027771]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0180664, -0.00692749, 0.00382996, ..., -0.000455856,\n",
       "              -0.0168457, -0.00191498],\n",
       "             [-0.00315857, -0.00726318, 0.00817871, ..., 0.0120239,\n",
       "              -0.00643921, -0.00772095],\n",
       "             [-0.0144043, -0.00473022, 0.010376, ..., -0.00283813,\n",
       "              -0.00637817, -0.00537109],\n",
       "             ...,\n",
       "             [0.00289917, 0.00598145, -0.00897217, ..., 0.00720215,\n",
       "              0.000751495, 0.0129395],\n",
       "             [-0.00891113, -0.0250244, 0.00424194, ..., -0.0126343,\n",
       "              0.0072937, -0.019043],\n",
       "             [0.00610352, -0.00291443, -0.0106201, ..., -0.0166016,\n",
       "              0.000591278, 0.0247803]],\n",
       "    \n",
       "            [[0.00191498, -0.012207, 0.00300598, ..., -0.00138855,\n",
       "              0.00408936, -0.00300598],\n",
       "             [0.015564, 0.00527954, -0.00506592, ..., -0.00927734,\n",
       "              0.000907898, 0.0050354],\n",
       "             [-0.00254822, -0.00765991, 0.00370789, ..., -0.013855,\n",
       "              0.0088501, -0.00515747],\n",
       "             ...,\n",
       "             [-0.0090332, 0.0317383, 0.000648499, ..., -0.0107422,\n",
       "              -0.000200272, 0.000495911],\n",
       "             [0.0102539, 0.00188446, -0.00683594, ..., 0.0167236,\n",
       "              -0.0106201, 0.0203857],\n",
       "             [0.0057373, -0.00689697, 0.00872803, ..., 0.00469971,\n",
       "              0.00588989, -0.000576019]],\n",
       "    \n",
       "            [[-0.00848389, -0.0050354, -0.00552368, ..., -0.00805664,\n",
       "              -0.00756836, 0.00500488],\n",
       "             [-0.0109253, -0.0229492, -0.00185394, ..., -0.0126953,\n",
       "              0.0116577, -0.0169678],\n",
       "             [-0.0183105, 0.00552368, -0.00762939, ..., -0.00872803,\n",
       "              -0.000915527, 0.00674438],\n",
       "             ...,\n",
       "             [-0.00473022, -0.0119629, -0.0154419, ..., 0.00476074,\n",
       "              -0.00964355, 0.000911713],\n",
       "             [-0.0090332, 0.0167236, 0.00488281, ..., 0.00273132,\n",
       "              -0.0151978, 0.00567627],\n",
       "             [-0.0128784, 0.00540161, 0.00765991, ..., -0.0185547,\n",
       "              -0.00527954, -0.00964355]],\n",
       "    \n",
       "            [[-0.00692749, -0.0162354, 0.00939941, ..., -0.0140991,\n",
       "              0.0148315, -0.0201416],\n",
       "             [0.0018158, 4.64916e-05, 0.00976562, ..., 0.0303955,\n",
       "              0.00643921, 0.0114136],\n",
       "             [0.0245361, 0.0144653, 0.0055542, ..., 0.0147705, -0.00915527,\n",
       "              0.000480652],\n",
       "             ...,\n",
       "             [-0.001091, -0.00976562, -0.0019989, ..., -0.00585938,\n",
       "              -0.00506592, -0.00689697],\n",
       "             [0.00372314, -0.0240479, -0.0100098, ..., 0.0065918,\n",
       "              -0.0120239, -0.0109253],\n",
       "             [0.0223389, -0.00765991, 0.00325012, ..., 0.00921631,\n",
       "              -0.00515747, 0.0111694]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.0062561, 0.0123291, 0.0133057, ..., 0.0137329, 2.80142e-05,\n",
       "             -0.00144196],\n",
       "            [-0.012146, 0.00387573, 0.0106201, ..., -0.0341797, 0.0163574,\n",
       "             0.0172119],\n",
       "            [-0.00842285, 0.00424194, 6.4373e-05, ..., -0.00389099,\n",
       "             -0.0317383, 0.0253906],\n",
       "            ...,\n",
       "            [0.0140381, -0.000843048, -0.020874, ..., 0.00393677,\n",
       "             -0.00793457, 0.0284424],\n",
       "            [-0.0126953, 0.0212402, -0.0127563, ..., -0.000904083,\n",
       "             0.0105591, -0.0314941],\n",
       "            [0.00175476, -0.00891113, -0.0388184, ..., -0.0136719,\n",
       "             0.0144043, 0.0181885]],\n",
       "    \n",
       "           [[-0.00349426, -0.00564575, 0.0177002, ..., 0.013916,\n",
       "             -0.00817871, -0.00218201],\n",
       "            [-0.00430298, 0.00970459, -0.00787354, ..., 0.00241089,\n",
       "             -0.000846863, 0.0211182],\n",
       "            [-0.00543213, 0.00787354, 0.0253906, ..., 0.0273438,\n",
       "             -0.00363159, 0.00222778],\n",
       "            ...,\n",
       "            [0.00509644, -0.00297546, 0.00460815, ..., 0.0299072,\n",
       "             -0.0144043, -0.0126343],\n",
       "            [-0.00344849, 0.00747681, 0.0088501, ..., -0.0164795, 0.0157471,\n",
       "             -0.0145264],\n",
       "            [-0.0098877, -0.00747681, 0.0211182, ..., -0.0147705, 0.0115967,\n",
       "             0.0161133]],\n",
       "    \n",
       "           [[2.49147e-05, 0.00156403, 0.00202942, ..., -0.00280762,\n",
       "             0.00160217, 0.0495605],\n",
       "            [-0.00311279, 0.012207, 0.00134277, ..., 0.00230408,\n",
       "             -0.00689697, -0.02771],\n",
       "            [0.00927734, 0.0072937, 0.00469971, ..., -0.00723267,\n",
       "             -0.0151367, 0.00897217],\n",
       "            ...,\n",
       "            [-0.00178528, -0.00793457, -0.00817871, ..., 0.0339355,\n",
       "             -0.00958252, -0.00598145],\n",
       "            [-0.00442505, -0.00952148, -0.0150757, ..., 0.0187988,\n",
       "             0.00747681, -0.0247803],\n",
       "            [0.00282288, -0.0032959, -0.0100098, ..., -0.0183105,\n",
       "             -0.0179443, -0.0169678]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00830078, 0.00595093, -0.0206299, ..., -0.00349426,\n",
       "             -0.0183105, -0.00775146],\n",
       "            [-0.00439453, 0.000976562, 0.00747681, ..., -0.0305176,\n",
       "             0.0131226, -0.00537109],\n",
       "            [0.000572205, 0.0123291, -0.0133667, ..., 0.00549316,\n",
       "             -0.000482559, 0.00424194],\n",
       "            ...,\n",
       "            [0.00390625, -0.00619507, -0.0212402, ..., -0.0179443,\n",
       "             -0.00976562, -0.000123024],\n",
       "            [-0.00708008, 0.00534058, -0.00411987, ..., 0.00735474,\n",
       "             -0.00133514, -0.00184631],\n",
       "            [-0.00515747, -0.0130615, 0.0158691, ..., -0.0098877,\n",
       "             -0.00534058, 0.020874]],\n",
       "    \n",
       "           [[-0.00370789, -0.000587463, -0.00457764, ..., -0.0143433,\n",
       "             0.0045166, 0.0181885],\n",
       "            [-0.00653076, 0.0270996, -0.00436401, ..., 0.00643921,\n",
       "             0.000425339, -0.0334473],\n",
       "            [0.00056839, -0.0158691, -0.00735474, ..., -0.0112305,\n",
       "             0.00396729, 0.0105591],\n",
       "            ...,\n",
       "            [-0.00683594, -0.00408936, -0.00215149, ..., -0.00415039,\n",
       "             -0.0262451, 0.00939941],\n",
       "            [0.0147705, -0.0136719, -3.93391e-05, ..., 0.019165, 0.0123901,\n",
       "             -0.0119629],\n",
       "            [-0.00230408, 0.0134888, 0.00179291, ..., 0.0158691, 0.0043335,\n",
       "             -0.00897217]],\n",
       "    \n",
       "           [[0.00257874, -0.00384521, -0.00231934, ..., -0.0279541,\n",
       "             0.00653076, 0.0219727],\n",
       "            [0.00274658, -0.00311279, -0.00180817, ..., -0.0189209,\n",
       "             0.00952148, -0.0358887],\n",
       "            [-0.00860596, 0.00408936, -0.00479126, ..., -0.0203857,\n",
       "             0.0322266, 0.0378418],\n",
       "            ...,\n",
       "            [-0.000991821, 0.00921631, 0.00561523, ..., 0.00878906,\n",
       "             -0.041748, -0.00653076],\n",
       "            [-0.00595093, 0.010437, 0.000118256, ..., 0.0111084, 0.0336914,\n",
       "             -0.00195312],\n",
       "            [-0.00860596, 0.00188446, -0.00161743, ..., 0.0216064,\n",
       "             0.0157471, -0.0268555]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00372314, 0.00527954, -0.00463867, ..., 0.00141144,\n",
       "            0.00518799, -0.00280762],\n",
       "           [0.00244141, 0.00454712, -0.00302124, ..., 0.00637817,\n",
       "            0.00411987, 0.00332642],\n",
       "           [0.000312805, -0.00970459, 0.00497437, ..., 0.00817871,\n",
       "            -0.00668335, -0.0100708],\n",
       "           ...,\n",
       "           [0.00128174, -0.00793457, 0.0103149, ..., 0.00601196,\n",
       "            -0.00360107, 0.0141602],\n",
       "           [0.0131836, -0.0124512, -0.000495911, ..., 0.0062561, 0.0201416,\n",
       "            -0.00263977],\n",
       "           [-0.00823975, 0.00212097, 0.00811768, ..., -0.00939941,\n",
       "            -0.00457764, -0.00242615]],\n",
       "   \n",
       "          [[0.00110626, -0.00113678, -0.001091, ..., 0.00363159,\n",
       "            0.00610352, -0.00210571],\n",
       "           [0.0109863, -0.00479126, 0.00286865, ..., 0.00860596,\n",
       "            -0.00445557, -0.0050354],\n",
       "           [0.00328064, 0.00915527, 0.00753784, ..., 0.0125732,\n",
       "            -0.00970459, -0.00222778],\n",
       "           ...,\n",
       "           [-0.00202942, 0.00171661, 7.43866e-05, ..., -1.62125e-05,\n",
       "            -0.0198975, -0.0164795],\n",
       "           [0.00075531, 0.0045166, 0.00872803, ..., 0.0088501, -0.0090332,\n",
       "            0.0136108],\n",
       "           [-0.00506592, 0.00182343, 0.00778198, ..., -0.00149536,\n",
       "            -0.0071106, 0.00524902]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00393677, 0.00209045, -0.0140991, ..., -0.00386047,\n",
       "           -0.0123901, 0.00726318],\n",
       "          [-0.000331879, 0.00204468, -0.0101318, ..., -0.00121307,\n",
       "           0.0088501, -0.0050354],\n",
       "          [0.00126648, 0.000553131, 0.00234985, ..., -0.00521851,\n",
       "           -0.00653076, -0.0112305],\n",
       "          ...,\n",
       "          [-0.00242615, -0.00778198, -0.000192642, ..., -0.00717163,\n",
       "           0.00897217, 0.00274658],\n",
       "          [-0.00402832, -0.00273132, 0.00485229, ..., 0.00445557,\n",
       "           -0.0030365, -0.00927734],\n",
       "          [0.00236511, 0.00588989, 0.00753784, ..., 0.00762939, 0.00259399,\n",
       "           0.00494385]], dtype=bfloat16), a=Array([[ 0.00068823,  0.00820747,  0.00691753, ..., -0.01032871,\n",
       "            0.01214039, -0.01452747],\n",
       "          [-0.00807814, -0.00087587,  0.01156158, ..., -0.00500905,\n",
       "            0.0198493 ,  0.00917682]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([2.54688, 2.875, 2.70312, ..., 2.375, 2.73438, 2.35938], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([3.73438, 3.75, 3.84375, ..., 3.57812, 3.89062, 3.48438], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.232422, 0.261719, 0.180664, ..., 0.330078, 0.298828, 0.355469],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.090332, -0.0563965, -0.0976562, ..., -0.104004, -0.11084,\n",
       "          -0.0168457], dtype=bfloat16)}},\n",
       " 'layer_23': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.0125122, -0.0043335, -0.000934601, ..., -0.0128784,\n",
       "             0.003479, 0.00340271],\n",
       "            [0.00946045, -0.0143433, -0.0109253, ..., 0.00334167,\n",
       "             -0.00372314, 0.00442505],\n",
       "            [0.00139618, 0.00994873, 0.000694275, ..., 0.00265503,\n",
       "             0.0152588, -0.00473022],\n",
       "            ...,\n",
       "            [-0.0088501, 0.00952148, -0.012146, ..., 0.00165558, -0.0151367,\n",
       "             -0.00175476],\n",
       "            [-0.00476074, 0.00341797, -0.00167084, ..., 0.0133057,\n",
       "             -0.0145264, -0.0125732],\n",
       "            [-0.00209045, 0.0127563, -0.00561523, ..., 0.00191498,\n",
       "             -0.00427246, 0.000195503]],\n",
       "    \n",
       "           [[0.00628662, 0.00836182, -0.000455856, ..., 0.0166016,\n",
       "             0.00726318, -0.00427246],\n",
       "            [-0.0144043, 0.0177002, 0.0183105, ..., -0.0030365, 0.0136719,\n",
       "             -0.00604248],\n",
       "            [0.0014267, -0.010437, -0.0116577, ..., -0.00872803, -0.0168457,\n",
       "             0.00315857],\n",
       "            ...,\n",
       "            [0.0106812, -0.0105591, 0.0153809, ..., -0.0106201, 0.00759888,\n",
       "             0.000915527],\n",
       "            [-0.00897217, -0.00750732, -0.00457764, ..., -0.0133667,\n",
       "             0.0128784, 0.00332642],\n",
       "            [0.00680542, -0.0116577, 0.00854492, ..., -0.00285339,\n",
       "             0.00585938, 0.00294495]],\n",
       "    \n",
       "           [[-0.00256348, 0.00306702, -0.00415039, ..., 0.0166016,\n",
       "             -0.0133667, -0.00294495],\n",
       "            [-0.00506592, -0.0164795, 0.00479126, ..., -0.0241699,\n",
       "             0.000299454, 0.00515747],\n",
       "            [0.0140991, 0.010498, 0.00753784, ..., -0.00253296, -0.00686646,\n",
       "             -5.36442e-05],\n",
       "            ...,\n",
       "            [-0.00692749, -0.00927734, 0.0280762, ..., -0.00279236,\n",
       "             -0.00643921, -0.00601196],\n",
       "            [0.0170898, 0.00506592, 0.000450134, ..., 0.000846863, 0.019043,\n",
       "             0.00595093],\n",
       "            [0.0109863, 0.00105286, 0.0133057, ..., 0.0143433, -0.00162506,\n",
       "             -0.000816345]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0144043, 0.00396729, -0.0065918, ..., -0.00561523, 0.0180664,\n",
       "             0.0101929],\n",
       "            [-0.00402832, -0.0194092, 0.00218201, ..., 0.0123291, 0.0108643,\n",
       "             -0.00107574],\n",
       "            [0.0127563, -0.00878906, 0.00701904, ..., 0.019043, -0.00616455,\n",
       "             0.00022316],\n",
       "            ...,\n",
       "            [-0.0114746, -0.00193024, 0.0158691, ..., 0.00315857,\n",
       "             -0.00276184, 0.0130005],\n",
       "            [-0.00289917, 0.00518799, -0.00445557, ..., 0.00735474,\n",
       "             0.00370789, -0.00811768],\n",
       "            [0.00221252, -0.0065918, 0.00160217, ..., -0.00723267,\n",
       "             -0.00552368, 0.0137939]],\n",
       "    \n",
       "           [[5.76973e-05, -0.0018692, -0.00811768, ..., -0.00970459,\n",
       "             0.00102997, 0.010498],\n",
       "            [-0.0178223, 0.0115356, 0.00119019, ..., -0.0108643, -0.0161133,\n",
       "             -0.00189209],\n",
       "            [0.0136719, 0.0214844, 0.0162354, ..., 0.017334, -0.00069809,\n",
       "             -0.00778198],\n",
       "            ...,\n",
       "            [0.00344849, -0.0119629, -0.019165, ..., -0.000865936,\n",
       "             -0.00227356, 0.00933838],\n",
       "            [0.010376, -0.0129395, 0.00994873, ..., -0.000709534, 0.0136108,\n",
       "             0.0130005],\n",
       "            [-0.00273132, 0.00147247, 0.0132446, ..., 0.00723267,\n",
       "             0.00933838, -0.00717163]],\n",
       "    \n",
       "           [[0.00637817, 0.00735474, 0.000268936, ..., -0.00704956,\n",
       "             -0.00717163, -0.000843048],\n",
       "            [-0.00253296, -0.00558472, -0.0071106, ..., 0.015625,\n",
       "             -7.58171e-05, 0.00119781],\n",
       "            [0.00927734, -0.0117798, -0.00325012, ..., -0.0117798,\n",
       "             0.00854492, -0.0134888],\n",
       "            ...,\n",
       "            [-0.0239258, -0.00193024, 0.00921631, ..., -0.00628662,\n",
       "             -0.0142822, -0.00778198],\n",
       "            [-0.00215149, -0.0103149, -0.0247803, ..., -0.0035553,\n",
       "             0.0112915, 0.0126343],\n",
       "            [-0.00297546, -0.0217285, -0.00689697, ..., -0.00263977,\n",
       "             0.0098877, 0.0198975]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.015564, 0.00558472, 0.00100708, ..., 0.0016098,\n",
       "              -0.0285645, -0.0078125],\n",
       "             [0.0179443, -0.0249023, 0.0014267, ..., 0.00695801,\n",
       "              0.00860596, 0.0139771],\n",
       "             [-0.00805664, -0.00680542, -0.00151062, ..., -0.00570679,\n",
       "              0.00448608, 0.00927734],\n",
       "             ...,\n",
       "             [0.00741577, -0.00482178, 0.00448608, ..., 0.0186768,\n",
       "              0.00805664, -0.00238037],\n",
       "             [0.0014801, 0.0158691, -0.00753784, ..., -0.00674438,\n",
       "              -0.0045166, -0.00369263],\n",
       "             [-0.0057373, 0.0132446, 0.0103149, ..., 0.00558472,\n",
       "              0.00799561, -0.00222778]],\n",
       "    \n",
       "            [[0.0062561, 0.00288391, 0.00334167, ..., -0.0102539,\n",
       "              0.00294495, -0.0184326],\n",
       "             [0.00289917, 0.000282288, 0.0072937, ..., 0.00221252,\n",
       "              0.00552368, 0.00231934],\n",
       "             [0.00283813, 0.020752, 0.0125122, ..., 0.0110474, 0.0117188,\n",
       "              0.00878906],\n",
       "             ...,\n",
       "             [-0.0112915, -0.00817871, -0.00424194, ..., 0.00570679,\n",
       "              -0.0132446, 0.00970459],\n",
       "             [0.00952148, 0.0131836, -0.00180054, ..., -0.00909424,\n",
       "              -0.00376892, 0.0130615],\n",
       "             [0.00527954, -0.0186768, -0.00488281, ..., -0.00720215,\n",
       "              -0.0128784, 0.0310059]],\n",
       "    \n",
       "            [[-0.00231934, 0.000329971, 0.00897217, ..., 0.00964355,\n",
       "              -0.00939941, -0.00595093],\n",
       "             [-0.00473022, 0.0057373, 0.0115356, ..., -0.00106812,\n",
       "              0.0219727, -0.00172424],\n",
       "             [0.00123596, 0.00418091, 0.0137329, ..., -0.00326538,\n",
       "              -0.00332642, -0.0150757],\n",
       "             ...,\n",
       "             [-0.00601196, 0.00121307, 0.00396729, ..., -0.0109863,\n",
       "              -0.00299072, 0.0126953],\n",
       "             [0.00759888, 0.00860596, -0.00328064, ..., -0.00756836,\n",
       "              -0.00830078, -0.0283203],\n",
       "             [-0.0100098, -0.00817871, -0.000370026, ..., -0.0268555,\n",
       "              0.00334167, -0.0256348]],\n",
       "    \n",
       "            [[0.00717163, 0.00415039, 0.00494385, ..., 0.0148315,\n",
       "              0.00122833, -0.00262451],\n",
       "             [-0.0132446, -0.00430298, 0.00494385, ..., 0.00485229,\n",
       "              0.0140991, 0.0072937],\n",
       "             [-0.00921631, -0.00515747, 0.0072937, ..., -0.00830078,\n",
       "              0.0131836, 0.00680542],\n",
       "             ...,\n",
       "             [0.0119019, -2.45571e-05, -0.00561523, ..., 0.0118408,\n",
       "              0.0308838, -0.00105286],\n",
       "             [0.0116577, -0.0032959, -0.00236511, ..., -0.000865936,\n",
       "              0.00488281, 0.00497437],\n",
       "             [0.00726318, 0.00823975, 0.00292969, ..., 0.00289917,\n",
       "              0.00331116, -0.0122681]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0115356, 0.0196533, -0.00463867, ..., -0.00769043,\n",
       "              -0.00628662, -0.00537109],\n",
       "             [-0.00921631, -0.00457764, 0.026123, ..., 0.0209961,\n",
       "              0.0187988, 0.00436401],\n",
       "             [-0.00372314, -0.0112915, 0.0131226, ..., -0.0137329,\n",
       "              -0.00259399, -0.00817871],\n",
       "             ...,\n",
       "             [-0.0157471, 0.00750732, 0.00939941, ..., 0.00274658,\n",
       "              0.0101929, 0.00201416],\n",
       "             [0.00177765, -0.00318909, 0.0127563, ..., -0.0108643,\n",
       "              -0.0194092, -0.00136566],\n",
       "             [0.00717163, -0.00854492, -0.00656128, ..., 0.000682831,\n",
       "              -0.00698853, 0.0019989]],\n",
       "    \n",
       "            [[0.00823975, -0.00549316, 0.00257874, ..., -0.0159912,\n",
       "              0.00933838, 0.00482178],\n",
       "             [0.0100708, -0.0101318, -0.0185547, ..., 0.00778198,\n",
       "              -0.00836182, 0.00271606],\n",
       "             [-0.00708008, -0.00325012, -0.0157471, ..., -0.0161133,\n",
       "              -0.00714111, -0.00628662],\n",
       "             ...,\n",
       "             [-0.0136719, 0.00646973, 0.00239563, ..., -0.0264893,\n",
       "              0.0123291, 0.00674438],\n",
       "             [-0.00300598, -0.00909424, -0.00787354, ..., 0.0262451,\n",
       "              3.01003e-06, 0.0272217],\n",
       "             [-0.00970459, 0.0143433, 0.00787354, ..., -0.0216064,\n",
       "              0.00369263, -0.0222168]],\n",
       "    \n",
       "            [[0.0128174, 0.0072937, 0.0128174, ..., -0.0120239, -0.0155029,\n",
       "              -0.000843048],\n",
       "             [-0.000637054, -0.0106812, -0.00257874, ..., -0.0123291,\n",
       "              -0.00588989, 0.0019989],\n",
       "             [-0.00564575, 0.00744629, -0.00747681, ..., 0.00491333,\n",
       "              0.00753784, -0.00842285],\n",
       "             ...,\n",
       "             [0.0123901, 0.00750732, -0.00619507, ..., -0.00244141,\n",
       "              -0.00909424, -0.00157166],\n",
       "             [0.019043, 0.019165, -0.00250244, ..., 0.00848389,\n",
       "              -0.000328064, 0.012207],\n",
       "             [0.0200195, -0.0110474, 0.00141144, ..., 0.0200195, 0.0162354,\n",
       "              -0.0236816]],\n",
       "    \n",
       "            [[-0.00366211, -0.0146484, -0.00144958, ..., -0.000197411,\n",
       "              -0.0187988, -0.0106812],\n",
       "             [0.0161133, 0.00994873, 0.000205994, ..., 0.0114746,\n",
       "              -0.00141907, -0.00320435],\n",
       "             [-0.00582886, 0.00842285, -0.0067749, ..., -0.00613403,\n",
       "              -0.0134888, -0.00854492],\n",
       "             ...,\n",
       "             [0.0115356, -0.0253906, 0.0098877, ..., -0.0125732,\n",
       "              -0.00202942, 0.0200195],\n",
       "             [-0.0214844, -0.00598145, -0.00306702, ..., 0.00350952,\n",
       "              0.0100098, -0.00650024],\n",
       "             [0.019165, 0.0128784, -0.00418091, ..., -0.0319824,\n",
       "              0.00576782, 0.0112305]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00866699, 7.27177e-06, -0.00256348, ..., 0.0162354,\n",
       "             -0.0301514, 0.00227356],\n",
       "            [0.00166321, 0.00708008, -0.00482178, ..., 0.000196457,\n",
       "             0.0223389, 0.0214844],\n",
       "            [-0.00671387, -0.0062561, -0.0144653, ..., -0.00720215,\n",
       "             -0.022583, -0.00534058],\n",
       "            ...,\n",
       "            [-0.00344849, -0.00212097, -0.00778198, ..., 0.00283813,\n",
       "             -0.0153809, -0.0039978],\n",
       "            [0.00488281, 0.0014801, 0.00188446, ..., -0.00178528,\n",
       "             -0.0124512, 0.00811768],\n",
       "            [-0.00227356, 0.00445557, 0.00115204, ..., -0.00457764,\n",
       "             -0.00613403, -0.0195312]],\n",
       "    \n",
       "           [[-0.0108032, -0.00909424, 0.010376, ..., 0.0169678, -0.00772095,\n",
       "             -0.00775146],\n",
       "            [0.000816345, -0.00759888, -0.00891113, ..., -0.00346375,\n",
       "             0.003479, 0.00842285],\n",
       "            [-0.000675201, 0.00891113, -0.0166016, ..., -0.003479,\n",
       "             -0.000747681, 0.000644684],\n",
       "            ...,\n",
       "            [0.00457764, 0.0200195, 0.010498, ..., -0.017334, 0.00265503,\n",
       "             -0.00686646],\n",
       "            [-0.00343323, 0.00689697, -0.00842285, ..., -0.00686646,\n",
       "             -0.00665283, 0.00326538],\n",
       "            [-0.0129395, 0.00154114, 0.0098877, ..., -0.00476074,\n",
       "             -0.0101929, 0.00334167]],\n",
       "    \n",
       "           [[0.000272751, -0.00518799, 0.00375366, ..., -0.0305176,\n",
       "             -0.0189209, 0.00726318],\n",
       "            [-0.000299454, 0.000923157, 0.00257874, ..., -0.0223389,\n",
       "             -0.00872803, -0.00326538],\n",
       "            [-0.000339508, -0.00062561, 0.0030365, ..., -0.0324707,\n",
       "             -0.0126343, 0.00372314],\n",
       "            ...,\n",
       "            [1.18613e-05, 0.0016861, 0.00267029, ..., 0.000850677,\n",
       "             0.00424194, -0.0136719],\n",
       "            [0.000858307, 0.000701904, -0.0106201, ..., -0.0167236,\n",
       "             0.00753784, -0.0336914],\n",
       "            [-0.00445557, 0.000127792, 0.00177002, ..., 0.00488281,\n",
       "             -0.00463867, -0.0186768]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.000797272, -0.00375366, 0.0163574, ..., -0.00332642,\n",
       "             0.000152588, -0.0105591],\n",
       "            [-0.00343323, 0.00297546, -0.00405884, ..., 0.012146,\n",
       "             -0.0032959, 0.00141907],\n",
       "            [0.0098877, 0.00637817, -0.00491333, ..., 0.00582886,\n",
       "             -0.0072937, 0.00656128],\n",
       "            ...,\n",
       "            [0.000322342, 0.00244141, 0.00415039, ..., -0.0018692, 0.010498,\n",
       "             0.0192871],\n",
       "            [-0.00616455, 0.000249863, 0.00970459, ..., -0.00637817,\n",
       "             0.00357056, 0.00094986],\n",
       "            [0.00579834, -0.00260925, 0.000679016, ..., 0.00540161,\n",
       "             0.00601196, 0.0279541]],\n",
       "    \n",
       "           [[-0.000595093, -0.0088501, -0.0144043, ..., -0.0159912,\n",
       "             -0.0299072, 0.0262451],\n",
       "            [0.00268555, -0.00817871, 0.00579834, ..., 4.36306e-05,\n",
       "             0.00637817, 0.00221252],\n",
       "            [-0.000206947, 0.00497437, 0.010498, ..., -5.126e-05,\n",
       "             -0.00588989, 0.0412598],\n",
       "            ...,\n",
       "            [0.0045166, 0.0019989, -0.00140381, ..., -0.0062561,\n",
       "             -0.00878906, -0.0170898],\n",
       "            [-0.00139618, 0.0139771, -0.00176239, ..., -0.0244141,\n",
       "             0.00361633, 0.0071106],\n",
       "            [-0.00436401, -0.00842285, -0.00187683, ..., -0.00106049,\n",
       "             -0.00491333, 0.0106201]],\n",
       "    \n",
       "           [[-0.00285339, 0.00970459, -0.00842285, ..., -0.0108032,\n",
       "             -0.0292969, 0.0375977],\n",
       "            [-0.0179443, 0.0169678, 0.0161133, ..., 0.00166321, 0.00296021,\n",
       "             0.012207],\n",
       "            [0.00367737, 0.00439453, -0.00738525, ..., 0.00643921,\n",
       "             -0.0257568, 0.0109253],\n",
       "            ...,\n",
       "            [0.0157471, 0.00723267, 0.00133514, ..., -0.0105591, -0.019165,\n",
       "             0.0125122],\n",
       "            [0.000717163, 0.0151978, 0.00708008, ..., -0.0285645,\n",
       "             0.00866699, 0.00427246],\n",
       "            [-0.0159912, -0.0197754, 0.0128784, ..., -0.00448608,\n",
       "             -0.00354004, 0.00735474]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.001297, 0.00415039, 0.000614166, ..., -0.00891113,\n",
       "            -0.0113525, -0.013855],\n",
       "           [0.00167084, -0.00411987, 0.00518799, ..., -0.00466919,\n",
       "            0.00497437, 0.00169373],\n",
       "           [0.00546265, 0.00170135, 0.00372314, ..., 0.00744629,\n",
       "            0.00933838, 0.00236511],\n",
       "           ...,\n",
       "           [0.0122681, 0.00576782, -0.00579834, ..., 0.0050354, 0.00233459,\n",
       "            -0.00174713],\n",
       "           [0.00482178, -0.00195312, 0.00104523, ..., -0.00424194,\n",
       "            -0.0102539, 0.0120239],\n",
       "           [-0.0149536, 0.00439453, 0.00230408, ..., 0.00860596,\n",
       "            -0.00695801, 0.0147095]],\n",
       "   \n",
       "          [[-0.0131226, 0.000778198, 0.0140381, ..., -0.00778198,\n",
       "            -0.00248718, -0.000667572],\n",
       "           [0.00613403, -0.00204468, 0.00332642, ..., 0.00171661,\n",
       "            -0.00524902, -0.000797272],\n",
       "           [0.00415039, 0.000109196, -0.0205078, ..., 0.010498, 0.00546265,\n",
       "            0.00170135],\n",
       "           ...,\n",
       "           [-0.00717163, 0.00326538, 0.010376, ..., -0.00424194,\n",
       "            -0.00174713, 0.00202942],\n",
       "           [0.0189209, -0.00939941, -0.00531006, ..., -0.00386047,\n",
       "            -0.00527954, -0.00558472],\n",
       "           [-0.00204468, -0.00222778, 0.00549316, ..., 0.00463867,\n",
       "            -0.00187683, -0.00387573]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00427246, -0.0030365, -0.00289917, ..., 0.00360107,\n",
       "           -0.00704956, -0.00637817],\n",
       "          [-0.00165558, -0.0067749, -0.0055542, ..., -0.00305176,\n",
       "           -0.0101929, -0.00793457],\n",
       "          [0.000318527, 0.0168457, -0.0045166, ..., 0.0150757, -0.00173187,\n",
       "           -0.00817871],\n",
       "          ...,\n",
       "          [0.00762939, -0.00921631, 2.75373e-05, ..., -0.00393677,\n",
       "           0.00860596, -0.0032196],\n",
       "          [-0.0022583, 0.00933838, 0.003479, ..., 0.00717163, 0.00778198,\n",
       "           0.013916],\n",
       "          [-0.00534058, -0.00933838, -0.00469971, ..., -0.00762939,\n",
       "           0.00482178, -0.0150757]], dtype=bfloat16), a=Array([[ 0.00148038,  0.0081275 ,  0.0149825 , ...,  0.00171928,\n",
       "           -0.0045339 ,  0.00112129],\n",
       "          [-0.01026383,  0.0025746 , -0.02289991, ..., -0.00131096,\n",
       "            0.00538384, -0.00893523]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([2.21875, 2.28125, 2.20312, ..., 2.07812, 2.29688, 2.03125],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([4.15625, 4.28125, 4.34375, ..., 4.25, 4.53125, 4], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.306641, 0.337891, 0.300781, ..., 0.367188, 0.396484, 0.429688],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.158203, -0.146484, -0.166016, ..., -0.147461, -0.173828,\n",
       "          -0.10791], dtype=bfloat16)}},\n",
       " 'layer_24': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00497437, 0.020874, 0.00302124, ..., 0.0132446, 0.0116577,\n",
       "             0.00646973],\n",
       "            [0.00631714, -0.00579834, -0.00897217, ..., 0.00726318,\n",
       "             0.0117188, 0.00854492],\n",
       "            [-0.00946045, 0.0185547, 0.00367737, ..., 0.00233459,\n",
       "             0.00558472, -0.00610352],\n",
       "            ...,\n",
       "            [0.0169678, 0.0125732, 0.0244141, ..., 0.0131226, 0.0279541,\n",
       "             -0.0105591],\n",
       "            [0.00176239, -0.0257568, 0.0108643, ..., -0.00860596,\n",
       "             -0.0130005, -0.00799561],\n",
       "            [0.00326538, -0.0111084, 0.00473022, ..., -3.09944e-05,\n",
       "             0.0184326, 0.00662231]],\n",
       "    \n",
       "           [[0.00958252, 0.0240479, -0.0124512, ..., -0.0098877, -0.010376,\n",
       "             0.00289917],\n",
       "            [0.0157471, -0.00799561, -0.00378418, ..., 0.0206299, 0.0136719,\n",
       "             -0.00872803],\n",
       "            [0.0145264, -0.00805664, 0.015625, ..., 0.00283813, -0.0145874,\n",
       "             0.00650024],\n",
       "            ...,\n",
       "            [-0.00799561, -0.00799561, -5.126e-05, ..., -0.0144043,\n",
       "             -0.00466919, 0.00598145],\n",
       "            [-0.0038147, -0.00234985, -0.00982666, ..., 0.0172119,\n",
       "             0.0130005, 0.0111694],\n",
       "            [-0.0222168, -0.00234985, -0.00476074, ..., -0.00497437,\n",
       "             -0.0223389, -0.00254822]],\n",
       "    \n",
       "           [[0.0203857, -0.022583, 0.0131226, ..., 0.0273438, -0.00878906,\n",
       "             -0.00830078],\n",
       "            [-0.00186157, -0.00747681, -0.010376, ..., 0.0158691, 0.0167236,\n",
       "             -0.000671387],\n",
       "            [0.00157928, 0.0147705, -0.0155029, ..., -0.00031662,\n",
       "             0.00939941, 0.0220947],\n",
       "            ...,\n",
       "            [0.00823975, 0.00741577, 0.00309753, ..., 0.0133057, 0.00848389,\n",
       "             -0.00340271],\n",
       "            [-0.00674438, -0.0128784, 0.00805664, ..., -0.000154495,\n",
       "             0.00469971, 0.0172119],\n",
       "            [-0.0212402, -0.0147705, -0.00860596, ..., 0.0297852, 0.0090332,\n",
       "             0.00582886]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00976562, 0.0168457, 0.010498, ..., 0.0107422, 0.0234375,\n",
       "             -0.00665283],\n",
       "            [-0.0244141, -0.0132446, 0.0223389, ..., 0.00823975, -0.0144043,\n",
       "             0.0167236],\n",
       "            [0.00337219, 0.0132446, -0.0194092, ..., -0.0134277, 0.00219727,\n",
       "             -0.012085],\n",
       "            ...,\n",
       "            [-0.00370789, 0.0022583, -0.0019455, ..., 0.0202637, 0.0114746,\n",
       "             -0.00227356],\n",
       "            [0.0125732, -0.00125885, -0.00744629, ..., 0.0101929,\n",
       "             -0.0203857, 0.0114746],\n",
       "            [-0.0290527, 0.00842285, 0.000793457, ..., -0.00302124,\n",
       "             0.0071106, -0.0177002]],\n",
       "    \n",
       "           [[-0.000322342, -0.00592041, 0.00145721, ..., 0.00402832,\n",
       "             0.00619507, -0.0045166],\n",
       "            [0.00144196, -0.00482178, 0.0015564, ..., -0.00531006,\n",
       "             -0.00872803, -0.0198975],\n",
       "            [0.0129395, -0.00515747, -0.00405884, ..., 0.0115967,\n",
       "             -0.00326538, 0.00872803],\n",
       "            ...,\n",
       "            [-0.00970459, 0.0134277, -0.00402832, ..., -0.00338745,\n",
       "             -0.0019989, -0.012085],\n",
       "            [-0.0105591, -0.00692749, 0.00262451, ..., 0.0109253,\n",
       "             -0.0112915, -0.00491333],\n",
       "            [0.0128784, -0.00601196, -0.00198364, ..., -0.00159454,\n",
       "             -0.0166016, -0.00320435]],\n",
       "    \n",
       "           [[0.00552368, 0.00366211, 0.00245667, ..., -0.0146484,\n",
       "             -0.00561523, 0.00221252],\n",
       "            [0.00299072, -0.0101929, -0.00439453, ..., 0.000961304,\n",
       "             -0.00191498, 0.0234375],\n",
       "            [0.0146484, -0.0125732, -0.0272217, ..., 0.00202942, 0.0170898,\n",
       "             -0.000583649],\n",
       "            ...,\n",
       "            [0.00570679, -0.0174561, 0.022583, ..., 0.0236816, 0.000946045,\n",
       "             0.0116577],\n",
       "            [-0.00708008, -0.0169678, -0.00106049, ..., 0.00982666,\n",
       "             0.00170135, -0.00927734],\n",
       "            [0.00445557, 0.0137329, 0.000823975, ..., -0.00567627, 0.010376,\n",
       "             0.00714111]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00221252, 0.00494385, -0.00315857, ..., -0.00166321,\n",
       "              -0.00515747, 0.00872803],\n",
       "             [-0.00174713, -0.00152588, 0.00558472, ..., -0.00415039,\n",
       "              0.00460815, -0.00787354],\n",
       "             [2.53916e-05, -0.00202942, -0.00384521, ..., -0.00512695,\n",
       "              0.0146484, -0.015625],\n",
       "             ...,\n",
       "             [0.0112915, 0.00296021, -0.0183105, ..., -0.0109863,\n",
       "              -0.0101929, 0.000862122],\n",
       "             [-0.00680542, -0.00765991, 0.000364304, ..., -0.0102539,\n",
       "              0.00631714, 0.0050354],\n",
       "             [-0.0140991, 0.00958252, 0.00190735, ..., -0.00454712,\n",
       "              -0.015625, 0.00994873]],\n",
       "    \n",
       "            [[-0.0245361, -0.0100098, 0.0117188, ..., 0.0180664, 0.0327148,\n",
       "              -0.0291748],\n",
       "             [-0.00326538, -0.00744629, 0.00769043, ..., 0.00952148,\n",
       "              -0.000968933, 0.00778198],\n",
       "             [0.00509644, -0.0174561, 0.0114136, ..., 0.00156403,\n",
       "              0.0216064, 0.000237465],\n",
       "             ...,\n",
       "             [0.0109863, -0.00393677, -0.00271606, ..., -0.0317383,\n",
       "              -0.0129395, 0.010498],\n",
       "             [-0.0241699, 0.00595093, 0.0112915, ..., -0.000621796,\n",
       "              0.0125122, -0.00430298],\n",
       "             [0.00668335, -0.00270081, -0.0113525, ..., -0.0136108,\n",
       "              -0.0157471, 0.0251465]],\n",
       "    \n",
       "            [[-0.00469971, 0.00296021, 0.0206299, ..., 0.010498, 0.0142212,\n",
       "              -0.00454712],\n",
       "             [-0.0351562, 0.0174561, 0.0126343, ..., -0.00442505,\n",
       "              0.00494385, 0.00561523],\n",
       "             [-0.00296021, -0.0148926, 0.0124512, ..., -0.00561523,\n",
       "              -0.0122681, -0.00273132],\n",
       "             ...,\n",
       "             [0.012146, -0.0140991, 0.0196533, ..., 0.0103149, -0.00601196,\n",
       "              -0.0101318],\n",
       "             [0.00366211, -0.000991821, 0.00260925, ..., 0.0142212,\n",
       "              -0.000406265, -0.00897217],\n",
       "             [0.020752, -0.00358582, 0.0132446, ..., 0.000112534, 0.026001,\n",
       "              0.0185547]],\n",
       "    \n",
       "            [[-0.00817871, 0.00043869, -0.00579834, ..., -0.0145874,\n",
       "              0.0020752, 0.00842285],\n",
       "             [0.00376892, -0.0238037, -0.0071106, ..., -0.00210571,\n",
       "              -0.0157471, 0.00436401],\n",
       "             [-0.00136566, 4.3869e-05, -0.00848389, ..., -0.00109863,\n",
       "              -0.00317383, 0.0147095],\n",
       "             ...,\n",
       "             [-0.00482178, -0.00610352, 0.000461578, ..., 0.00695801,\n",
       "              0.0181885, -0.00120544],\n",
       "             [0.00328064, -0.00427246, -0.00405884, ..., 0.00805664,\n",
       "              0.0289307, 0.000774384],\n",
       "             [-0.0161133, 0.0179443, -0.0152588, ..., -0.0153809,\n",
       "              -0.0159912, -0.00564575]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0159912, 0.0115967, 0.0071106, ..., -0.0122681, 0.00357056,\n",
       "              -0.022583],\n",
       "             [0.0157471, -0.0131836, -0.00958252, ..., -0.00267029,\n",
       "              -0.00646973, -0.00665283],\n",
       "             [-0.00424194, -0.00958252, 0.0187988, ..., 0.0109253,\n",
       "              -0.00634766, 0.00172424],\n",
       "             ...,\n",
       "             [0.00164795, 0.0102539, 0.00860596, ..., 0.00367737,\n",
       "              0.0106201, -0.00830078],\n",
       "             [-0.00753784, 0.0178223, -0.00179291, ..., 0.00506592,\n",
       "              -0.0148315, -0.0130615],\n",
       "             [0.0117188, -0.000341415, -0.0013504, ..., 0.00408936,\n",
       "              -0.00233459, 0.00488281]],\n",
       "    \n",
       "            [[-0.0196533, 0.0159912, 0.000858307, ..., -0.00759888,\n",
       "              0.00540161, 0.0286865],\n",
       "             [0.0285645, 0.0175781, -0.00756836, ..., -0.00631714,\n",
       "              4.73857e-06, 0.0256348],\n",
       "             [-0.00994873, 0.00427246, 0.0120239, ..., -0.017334,\n",
       "              0.00270081, 0.0180664],\n",
       "             ...,\n",
       "             [-0.0234375, -0.017334, -0.0123291, ..., -0.0142212,\n",
       "              -0.0123291, -0.0336914],\n",
       "             [0.0143433, -0.00909424, -0.0139771, ..., -0.0107422,\n",
       "              -0.00970459, -0.00358582],\n",
       "             [0.00964355, -0.000171661, -0.0136719, ..., 0.00656128,\n",
       "              -0.0180664, -0.0186768]],\n",
       "    \n",
       "            [[0.0010376, -0.0019989, 0.00497437, ..., -0.00337219,\n",
       "              0.00375366, -0.0222168],\n",
       "             [0.00405884, 0.00376892, 0.0144043, ..., -0.00601196,\n",
       "              -0.00326538, 0.0131226],\n",
       "             [0.000488281, 0.015564, 0.00382996, ..., 0.00915527,\n",
       "              0.0107422, -0.00958252],\n",
       "             ...,\n",
       "             [0.0106812, 0.0090332, 0.0205078, ..., -0.00115204,\n",
       "              -0.00909424, 0.00787354],\n",
       "             [0.00628662, -0.00762939, 0.00866699, ..., 0.00860596,\n",
       "              0.00108337, -0.000115871],\n",
       "             [-0.0161133, 0.0147095, -0.0143433, ..., 0.0105591,\n",
       "              -0.00793457, 0.00531006]],\n",
       "    \n",
       "            [[0.00958252, 0.00439453, 0.0112305, ..., 0.00653076,\n",
       "              0.00180054, 0.0128174],\n",
       "             [-3.95775e-05, 0.0126953, -0.00180817, ..., 0.00640869,\n",
       "              -0.0150146, -0.0211182],\n",
       "             [-0.00570679, -0.00585938, -0.0111694, ..., 0.00588989,\n",
       "              -0.0189209, 0.00127411],\n",
       "             ...,\n",
       "             [0.00723267, -0.000389099, 0.0185547, ..., 0.0140381,\n",
       "              0.000843048, 0.0112305],\n",
       "             [0.00302124, -0.00170898, -0.0102539, ..., 0.00628662,\n",
       "              -0.00848389, -0.00167084],\n",
       "             [0.0201416, -0.00891113, -0.0132446, ..., -0.00848389,\n",
       "              0.00634766, 0.0090332]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00372314, -0.000329971, 0.000394821, ..., 0.00280762,\n",
       "             0.0111084, 0.0108643],\n",
       "            [0.00222778, -0.00069046, 0.00268555, ..., -0.00367737,\n",
       "             0.00570679, -0.0375977],\n",
       "            [0.00150299, 0.00238037, 0.00448608, ..., 0.0397949, 0.00218201,\n",
       "             -0.00723267],\n",
       "            ...,\n",
       "            [-0.00020504, -0.0018158, -0.00213623, ..., 0.0136108,\n",
       "             0.0202637, -0.0197754],\n",
       "            [0.00415039, 0.00735474, 0.00805664, ..., 0.0150757,\n",
       "             0.000976562, -0.00891113],\n",
       "            [0.0019989, -0.00270081, 0.00546265, ..., -0.0177002,\n",
       "             -0.0272217, 0.0137329]],\n",
       "    \n",
       "           [[0.0109863, -0.0155029, -0.00148773, ..., 0.00382996, 0.0194092,\n",
       "             0.0125122],\n",
       "            [0.0101318, -0.0126343, 0.00133514, ..., 0.0144653, -0.00430298,\n",
       "             0.00218201],\n",
       "            [-0.0126953, 0.00454712, 0.0136108, ..., 0.00738525, 0.0108643,\n",
       "             -0.015625],\n",
       "            ...,\n",
       "            [0.000926971, -0.0235596, 0.0125122, ..., 0.00531006, 0.0114136,\n",
       "             0.00561523],\n",
       "            [-0.00338745, 0.0162354, -0.00157928, ..., 0.0100098,\n",
       "             -0.0170898, -0.0164795],\n",
       "            [0.00811768, 0.0123291, 0.0101929, ..., -0.00497437, -0.0112915,\n",
       "             -0.0145874]],\n",
       "    \n",
       "           [[-0.0147705, -0.00540161, -0.00387573, ..., -0.000196457,\n",
       "             0.00205994, -0.00521851],\n",
       "            [-0.00224304, -0.00159454, 0.00952148, ..., -0.0187988,\n",
       "             0.00683594, 0.0111694],\n",
       "            [-0.00552368, -0.0118408, 0.0213623, ..., 0.00457764,\n",
       "             0.00860596, -0.00254822],\n",
       "            ...,\n",
       "            [-0.00186157, -0.00512695, 0.00378418, ..., -0.0305176,\n",
       "             0.0022583, 0.0178223],\n",
       "            [0.00552368, 0.0037384, -0.0106812, ..., 0.0194092, 0.00376892,\n",
       "             -0.0196533],\n",
       "            [-0.0019989, -0.00231934, 0.00157928, ..., -0.0131226,\n",
       "             -0.0110474, -0.00436401]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00279236, -0.00811768, -0.00320435, ..., 0.00524902,\n",
       "             0.0115356, 0.00482178],\n",
       "            [-0.00153351, -0.00367737, -0.0100708, ..., -0.00933838,\n",
       "             0.0164795, 0.0164795],\n",
       "            [0.000263214, -0.00137329, -0.00221252, ..., -0.000137329,\n",
       "             0.0148926, -0.0184326],\n",
       "            ...,\n",
       "            [0.00163269, 0.0125122, 0.0144653, ..., -0.00640869,\n",
       "             -0.00939941, 0.00552368],\n",
       "            [0.00125885, -0.00772095, 0.00025177, ..., 0.0220947,\n",
       "             0.00878906, 0.00166321],\n",
       "            [-0.00294495, 0.00177002, 0.0065918, ..., -0.0027771,\n",
       "             0.00747681, 0.0339355]],\n",
       "    \n",
       "           [[-0.00592041, 0.0043335, 0.0078125, ..., -0.0123901, -0.0194092,\n",
       "             0.0163574],\n",
       "            [-0.0133667, -0.00189972, 0.015564, ..., -0.00860596,\n",
       "             0.00805664, 0.00332642],\n",
       "            [0.00382996, -0.00588989, -0.00265503, ..., -0.015564,\n",
       "             0.0229492, -1.3113e-05],\n",
       "            ...,\n",
       "            [9.9659e-05, -0.0123901, 0.0146484, ..., -0.00747681,\n",
       "             0.00364685, -0.00360107],\n",
       "            [0.0117798, 0.00023365, -0.000295639, ..., 0.00363159,\n",
       "             -0.00193024, -0.00189972],\n",
       "            [0.0116577, 0.0012207, -0.00747681, ..., 0.00842285, 0.00317383,\n",
       "             0.0114746]],\n",
       "    \n",
       "           [[0.00198364, 0.00698853, -0.0174561, ..., -0.00485229,\n",
       "             -0.00415039, -0.00897217],\n",
       "            [0.00457764, -0.00506592, 0.00131226, ..., -0.0213623,\n",
       "             -0.0500488, 0.0127563],\n",
       "            [0.00184631, -0.00130463, 0.000679016, ..., 0.00317383,\n",
       "             -0.013916, -0.032959],\n",
       "            ...,\n",
       "            [0.00212097, 0.00793457, -0.00750732, ..., 0.00689697,\n",
       "             0.0322266, 0.0200195],\n",
       "            [-0.000211716, -0.00552368, -0.000448227, ..., -0.00491333,\n",
       "             -0.00343323, -0.00473022],\n",
       "            [0.000694275, -0.00628662, 0.00469971, ..., -0.00457764,\n",
       "             0.00564575, -0.00128937]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00430298, 0.0016861, -0.0071106, ..., 0.0150757, 0.0130005,\n",
       "            0.00210571],\n",
       "           [-0.00549316, -0.00268555, 0.00460815, ..., -0.00448608,\n",
       "            0.00500488, -0.00549316],\n",
       "           [0.00823975, 0.00326538, -0.00153351, ..., 0.0101929, 0.0111694,\n",
       "            -0.00185394],\n",
       "           ...,\n",
       "           [-0.00671387, -0.0129395, 0.0249023, ..., 0.0108643, 0.00741577,\n",
       "            -0.00836182],\n",
       "           [-0.00631714, 0.0140991, 0.00915527, ..., -0.0112305,\n",
       "            0.000347137, -0.0043335],\n",
       "           [0.00265503, -0.0043335, -0.00958252, ..., -0.00579834,\n",
       "            0.00643921, 0.0045166]],\n",
       "   \n",
       "          [[-0.00292969, 0.00933838, 0.0136719, ..., -0.00671387,\n",
       "            0.00082016, -0.00521851],\n",
       "           [-0.0043335, -0.000457764, -0.0115356, ..., -0.00043869,\n",
       "            -0.0030365, 0.00543213],\n",
       "           [-0.0111084, -0.017334, -0.00357056, ..., 0.00460815,\n",
       "            -0.00454712, 0.00799561],\n",
       "           ...,\n",
       "           [0.00585938, 0.00817871, -0.00308228, ..., -0.00866699,\n",
       "            -0.00723267, -0.000858307],\n",
       "           [0.00418091, -0.0120239, 0.00242615, ..., 0.0032959,\n",
       "            -7.34329e-05, 0.000499725],\n",
       "           [0.0067749, -0.00531006, -0.00872803, ..., 0.0071106,\n",
       "            0.00613403, 0.00799561]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.000617981, 0.00732422, 0.012085, ..., -0.00393677,\n",
       "           -0.00442505, -0.0090332],\n",
       "          [0.0147705, 0.010498, -0.00524902, ..., 0.00778198, -0.00952148,\n",
       "           0.00671387],\n",
       "          [-0.00787354, -0.010498, -0.000862122, ..., -0.0162354,\n",
       "           -0.00921631, -0.00415039],\n",
       "          ...,\n",
       "          [0.0113525, -0.00836182, 0.00159454, ..., 0.00460815,\n",
       "           -0.000349045, -0.0137329],\n",
       "          [0.00185394, 0.00137329, -0.00756836, ..., 0.00860596, 0.00543213,\n",
       "           0.00915527],\n",
       "          [-0.0150757, -0.00402832, 0.00286865, ..., -0.000164032,\n",
       "           0.00543213, -0.0152588]], dtype=bfloat16), a=Array([[ 0.0118248 ,  0.00209964,  0.00429165, ...,  0.00531876,\n",
       "            0.0007639 , -0.01389843],\n",
       "          [ 0.00161521,  0.01745081, -0.0089213 , ...,  0.01427022,\n",
       "           -0.00016093,  0.01795714]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([2.5625, 2.40625, 2.51562, ..., 2.625, 2.76562, 2.46875], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([4.75, 4.78125, 4.90625, ..., 5.59375, 5.34375, 4.6875], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.248047, 0.223633, 0.21582, ..., 0.345703, 0.259766, 0.339844],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.188477, -0.169922, -0.19043, ..., -0.158203, -0.195312,\n",
       "          -0.142578], dtype=bfloat16)}},\n",
       " 'layer_25': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.00209045, -0.00415039, -0.000907898, ..., -0.0712891,\n",
       "             -0.012085, -0.000808716],\n",
       "            [0.000637054, 0.0110474, -0.00257874, ..., 0.00187683,\n",
       "             -0.00485229, 0.0177002],\n",
       "            [0.000518799, -0.0141602, 0.00421143, ..., -0.0125122,\n",
       "             -0.0264893, -0.00254822],\n",
       "            ...,\n",
       "            [-0.00250244, -0.0202637, 0.00671387, ..., -0.0234375,\n",
       "             0.0113525, 0.00488281],\n",
       "            [-0.00219727, 0.00726318, 0.00138855, ..., 0.0118408,\n",
       "             -0.0161133, -0.0120239],\n",
       "            [0.0135498, 0.00123596, -0.00418091, ..., -0.00518799,\n",
       "             0.00549316, 0.00140381]],\n",
       "    \n",
       "           [[-0.00344849, 0.0055542, 0.0201416, ..., -0.024292, 0.012207,\n",
       "             0.00260925],\n",
       "            [0.00915527, -0.00396729, -0.00772095, ..., -0.00372314,\n",
       "             0.000119209, 0.0197754],\n",
       "            [0.00305176, 0.0100098, -0.00701904, ..., 0.0115967, 0.00674438,\n",
       "             0.0149536],\n",
       "            ...,\n",
       "            [0.00640869, 0.0241699, -0.0107422, ..., 0.00222778,\n",
       "             -0.00157928, 0.00332642],\n",
       "            [0.00601196, 0.00270081, 0.00314331, ..., -0.00939941,\n",
       "             -0.00708008, 0.00360107],\n",
       "            [0.0174561, 0.00762939, 0.0078125, ..., -0.0162354, 0.00634766,\n",
       "             0.00515747]],\n",
       "    \n",
       "           [[0.0164795, 0.0155029, -0.00268555, ..., -0.00457764, 0.0155029,\n",
       "             0.00964355],\n",
       "            [-0.000679016, -0.0111694, 0.0178223, ..., -0.017334,\n",
       "             -0.00741577, -0.0339355],\n",
       "            [-0.00723267, -0.0228271, -0.0162354, ..., 0.0201416,\n",
       "             -0.00939941, 0.00294495],\n",
       "            ...,\n",
       "            [0.0233154, 0.000736237, -0.03125, ..., -0.013855, 0.00159454,\n",
       "             0.0115356],\n",
       "            [0.00735474, 0.0167236, -0.00665283, ..., -0.000343323,\n",
       "             0.00135803, -0.0175781],\n",
       "            [-0.00650024, -0.0108032, -0.00518799, ..., -0.00595093,\n",
       "             -0.0020752, -0.0122681]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.022583, -0.00340271, -0.0022583, ..., 0.00872803,\n",
       "             0.00958252, -0.0101318],\n",
       "            [-0.0136108, 0.00231934, 0.0131226, ..., 0.0125122, 0.00297546,\n",
       "             -0.000452042],\n",
       "            [-0.0202637, 0.0200195, -0.0132446, ..., 0.0107422, 0.0181885,\n",
       "             0.00439453],\n",
       "            ...,\n",
       "            [0.0137939, -0.00271606, -0.0102539, ..., -0.00244141,\n",
       "             0.000230789, 0.00463867],\n",
       "            [-0.00146484, -0.00695801, 0.019165, ..., -0.00132751,\n",
       "             0.00366211, -0.00836182],\n",
       "            [-0.0314941, 0.0140381, 0.0137939, ..., -0.00604248,\n",
       "             0.000411987, -0.00349426]],\n",
       "    \n",
       "           [[-0.00570679, 0.0164795, -0.0136108, ..., 0.00915527, 0.0098877,\n",
       "             0.00488281],\n",
       "            [-0.00491333, -0.00106812, 0.00189972, ..., 0.00245667,\n",
       "             -4.52995e-05, 0.00285339],\n",
       "            [0.00101471, -0.0119019, -0.00564575, ..., 0.00695801,\n",
       "             -0.00448608, -0.0169678],\n",
       "            ...,\n",
       "            [0.00527954, 0.0251465, 0.0133057, ..., -0.00842285, 0.00396729,\n",
       "             0.00616455],\n",
       "            [-0.00166321, 0.0148926, 0.00753784, ..., 0.00689697,\n",
       "             0.00970459, 0.00613403],\n",
       "            [0.00836182, 0.0161133, -0.0120239, ..., 0.000896454,\n",
       "             -0.0067749, -0.00119019]],\n",
       "    \n",
       "           [[0.00405884, 0.00212097, 0.0154419, ..., -0.00927734,\n",
       "             0.000349045, -0.0185547],\n",
       "            [0.0170898, -0.00738525, -0.000200272, ..., -0.00747681,\n",
       "             0.00909424, -0.00552368],\n",
       "            [0.00162506, 0.00191498, 0.00172424, ..., -0.0016861, 0.017334,\n",
       "             -0.00732422],\n",
       "            ...,\n",
       "            [0.00270081, -0.0018692, 0.00610352, ..., 0.00273132,\n",
       "             -0.00247192, -0.0126343],\n",
       "            [-0.000915527, -0.010437, 0.00720215, ..., 0.0027771,\n",
       "             0.00509644, -0.00476074],\n",
       "            [0.00512695, -0.0137329, 0.00306702, ..., 0.00402832,\n",
       "             -0.00860596, 0.00448608]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.0196533, -0.00787354, 0.00144196, ..., -0.0155029,\n",
       "              -0.0220947, -0.00457764],\n",
       "             [0.0145264, 0.00842285, -0.0135498, ..., -0.0148315,\n",
       "              0.0117798, -0.0122681],\n",
       "             [0.0032196, 0.013855, -0.00239563, ..., 0.0126953, 0.0129395,\n",
       "              0.0157471],\n",
       "             ...,\n",
       "             [-0.000180244, 0.0134888, 0.00138855, ..., 0.00915527,\n",
       "              0.00280762, 0.00338745],\n",
       "             [0.00285339, -0.00405884, -0.00878906, ..., 0.00891113,\n",
       "              -0.0128784, -0.00184631],\n",
       "             [-0.00283813, -0.00619507, -0.00445557, ..., 0.00561523,\n",
       "              -0.0238037, 0.0112305]],\n",
       "    \n",
       "            [[-0.00588989, 0.0124512, -0.000211716, ..., -0.00442505,\n",
       "              -0.00601196, 0.00238037],\n",
       "             [-0.0057373, -0.0174561, -0.00265503, ..., 0.00616455,\n",
       "              -1.84774e-05, 0.00279236],\n",
       "             [0.00125885, 0.013855, -0.00297546, ..., 0.0134888,\n",
       "              -0.00872803, 0.0027771],\n",
       "             ...,\n",
       "             [-0.0255127, -0.00023365, -0.0230713, ..., 0.00860596,\n",
       "              0.00430298, -0.0065918],\n",
       "             [0.000862122, 0.00540161, -0.000356674, ..., 0.00372314,\n",
       "              0.0149536, 0.0123291],\n",
       "             [0.00145721, -0.0153198, -0.00285339, ..., 0.0130615,\n",
       "              0.00442505, -0.00952148]],\n",
       "    \n",
       "            [[-0.000128746, 0.0228271, -0.000640869, ..., -0.00830078,\n",
       "              0.0045166, 0.00741577],\n",
       "             [0.00946045, -0.00112152, -0.00256348, ..., -0.0189209,\n",
       "              -0.010498, -0.00775146],\n",
       "             [-0.00701904, -0.0117798, -0.0112915, ..., -0.0134277,\n",
       "              -0.00537109, -0.00576782],\n",
       "             ...,\n",
       "             [0.0220947, -0.0192871, 0.00372314, ..., 0.00219727,\n",
       "              0.000274658, 0.00457764],\n",
       "             [-0.0090332, 0.00634766, -0.0108032, ..., -0.00131989,\n",
       "              0.0168457, 0.00787354],\n",
       "             [0.00326538, -0.00616455, 0.00759888, ..., -0.00131226,\n",
       "              -0.0115967, -0.0162354]],\n",
       "    \n",
       "            [[0.00567627, -0.0108032, -0.00646973, ..., -0.000965118,\n",
       "              -0.00256348, 0.00188446],\n",
       "             [0.00772095, 0.0177002, 0.00836182, ..., 0.0128784,\n",
       "              -0.00778198, -0.0116577],\n",
       "             [-0.0128784, 0.0134277, 0.00415039, ..., -0.00247192,\n",
       "              -0.0194092, -0.00357056],\n",
       "             ...,\n",
       "             [-0.0166016, -0.0119629, -0.0168457, ..., -0.00188446,\n",
       "              -0.0244141, 0.00153351],\n",
       "             [0.00415039, -0.00270081, 0.00854492, ..., -0.0119629,\n",
       "              0.0134277, 0.0163574],\n",
       "             [0.0112915, -0.0219727, -0.00102997, ..., 0.00878906,\n",
       "              -0.00604248, 0.0067749]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.0219727, 0.000953674, -0.00442505, ..., -0.00616455,\n",
       "              0.0141602, 0.00946045],\n",
       "             [0.00509644, 0.00476074, 0.0153198, ..., 0.00750732,\n",
       "              0.0116577, 0.00582886],\n",
       "             [0.0294189, 0.00104523, -0.017334, ..., -0.00153351,\n",
       "              0.00759888, 0.0151367],\n",
       "             ...,\n",
       "             [-0.0175781, -0.0015564, 0.00830078, ..., -0.00723267,\n",
       "              0.00445557, 0.00363159],\n",
       "             [0.0100708, -0.0127563, -0.00379944, ..., -0.000595093,\n",
       "              -0.00738525, 0.0118408],\n",
       "             [-0.00872803, 0.00656128, 0.0107422, ..., -0.000919342,\n",
       "              -0.00350952, 0.00799561]],\n",
       "    \n",
       "            [[0.0231934, 0.00183868, 0.00476074, ..., 0.0107422,\n",
       "              -0.00247192, -0.0106201],\n",
       "             [0.00933838, -0.00512695, -0.03125, ..., 0.00128937,\n",
       "              0.0131226, 0.00454712],\n",
       "             [-0.00062561, 0.0219727, -0.00241089, ..., -0.0174561,\n",
       "              -0.0133667, -0.00482178],\n",
       "             ...,\n",
       "             [-0.0088501, -0.00970459, 0.0197754, ..., 0.000303268,\n",
       "              0.0233154, -0.00772095],\n",
       "             [0.0144043, -0.00793457, -0.0110474, ..., 0.00976562,\n",
       "              0.00604248, -0.00860596],\n",
       "             [0.00695801, -0.0178223, -0.0035553, ..., 0.0117188,\n",
       "              -0.0129395, 0.00257874]],\n",
       "    \n",
       "            [[0.0241699, 0.0057373, 0.0167236, ..., -0.0117188, 0.00112152,\n",
       "              0.027832],\n",
       "             [0.0088501, 0.000411987, -0.0284424, ..., -0.00463867,\n",
       "              0.0148926, -0.0252686],\n",
       "             [0.00485229, -0.00540161, 0.0108643, ..., 0.0236816,\n",
       "              -0.0214844, -0.0155029],\n",
       "             ...,\n",
       "             [-0.0146484, -0.0268555, -0.00909424, ..., 0.0162354,\n",
       "              0.00811768, 0.00982666],\n",
       "             [-0.0134888, 0.00418091, -0.0150757, ..., 0.00640869,\n",
       "              -0.0109253, 0.00216675],\n",
       "             [0.0109863, -4.48227e-05, -0.00177765, ..., -0.0197754,\n",
       "              0.012146, 0.00497437]],\n",
       "    \n",
       "            [[-0.0129395, -0.0135498, 0.0148926, ..., -0.00714111,\n",
       "              0.0164795, 0.0140991],\n",
       "             [0.00476074, -0.000452042, 0.000478745, ..., 0.0065918,\n",
       "              0.0137329, 0.0154419],\n",
       "             [-0.00723267, 0.000930786, -0.0112915, ..., 0.006073,\n",
       "              0.0123291, -0.00479126],\n",
       "             ...,\n",
       "             [0.0140381, -0.0045166, -0.0035553, ..., 0.00230408, 0.012146,\n",
       "              -0.0039978],\n",
       "             [0.00308228, -0.00939941, -0.0140991, ..., 0.000329971,\n",
       "              -0.00317383, -0.00585938],\n",
       "             [0.0032196, 0.019043, 0.00260925, ..., 0.00787354, 0.0164795,\n",
       "              -0.00665283]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00360107, -0.0090332, -0.0025177, ..., 0.00239563,\n",
       "             -0.00735474, 0.00689697],\n",
       "            [0.00543213, -0.00297546, -0.00231934, ..., -0.0122681,\n",
       "             0.00241089, -0.012207],\n",
       "            [-0.00723267, 9.67979e-05, 0.0114746, ..., -0.00247192,\n",
       "             0.00524902, -0.0130005],\n",
       "            ...,\n",
       "            [-0.000492096, -0.000682831, -0.000747681, ..., -0.0168457,\n",
       "             -0.0303955, -0.00759888],\n",
       "            [-0.00154114, 0.0078125, 0.00454712, ..., -0.00537109,\n",
       "             -0.0134277, 0.0220947],\n",
       "            [0.00540161, -0.000324249, -0.00402832, ..., 0.010437,\n",
       "             0.0170898, 0.00219727]],\n",
       "    \n",
       "           [[0.0229492, 0.0130615, -0.0170898, ..., 0.00494385, 0.0184326,\n",
       "             -0.0180664],\n",
       "            [-0.0119019, 0.00640869, 0.0222168, ..., -0.00738525,\n",
       "             0.00799561, -0.00384521],\n",
       "            [0.0109253, 0.00367737, -0.0078125, ..., -0.00683594,\n",
       "             0.00897217, -0.000926971],\n",
       "            ...,\n",
       "            [-0.0150757, -0.0324707, 0.0175781, ..., -0.0167236, -0.0159912,\n",
       "             0.00227356],\n",
       "            [0.0071106, 0.015625, -0.00537109, ..., 0.0217285, 0.00976562,\n",
       "             -0.00100708],\n",
       "            [0.00897217, -0.0122681, -0.0128174, ..., -0.000153542,\n",
       "             -0.00601196, 0.00405884]],\n",
       "    \n",
       "           [[-0.000408173, 0.00717163, -0.0179443, ..., 0.000150681,\n",
       "             0.0264893, -0.0147095],\n",
       "            [-0.000469208, -0.00349426, 0.00350952, ..., 0.0270996,\n",
       "             0.00836182, 0.012146],\n",
       "            [-0.00151062, 0.00128174, 0.00970459, ..., 0.0184326,\n",
       "             0.00582886, -0.0106812],\n",
       "            ...,\n",
       "            [0.0114136, 0.00302124, 0.00952148, ..., -0.0222168,\n",
       "             -0.00778198, 0.0135498],\n",
       "            [0.0166016, 0.000740051, -0.00152588, ..., -0.00726318,\n",
       "             -0.00233459, 0.0130615],\n",
       "            [0.0111694, 0.00157928, 0.00273132, ..., 0.00921631, 0.0103149,\n",
       "             -0.0218506]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00860596, 0.0155029, -0.0322266, ..., -0.0161133,\n",
       "             0.00531006, 0.00112152],\n",
       "            [0.00308228, 0.00445557, 0.00695801, ..., 6.58035e-05,\n",
       "             -0.00164032, -0.00378418],\n",
       "            [-0.0072937, 0.00340271, -0.0251465, ..., 0.00750732,\n",
       "             -1.71661e-05, 0.0120239],\n",
       "            ...,\n",
       "            [0.00360107, 0.00558472, -0.00723267, ..., -3.79086e-05,\n",
       "             -0.00546265, 0.000201225],\n",
       "            [0.00245667, 0.00131226, -0.0151367, ..., -0.00192261,\n",
       "             0.00842285, 0.0112915],\n",
       "            [0.00595093, 0.00482178, 0.0228271, ..., 0.00500488, -0.0112915,\n",
       "             -0.0166016]],\n",
       "    \n",
       "           [[-0.0038147, 0.00524902, -0.00234985, ..., 0.0103149,\n",
       "             0.000938416, 0.00750732],\n",
       "            [-0.00616455, 0.00485229, 0.00279236, ..., 0.0172119,\n",
       "             -0.00994873, -0.00674438],\n",
       "            [-0.001297, 0.00162506, 0.0065918, ..., -0.00183105, -0.0134888,\n",
       "             -0.0196533],\n",
       "            ...,\n",
       "            [-0.00245667, -0.00485229, -0.00335693, ..., -0.0098877,\n",
       "             -0.000705719, -0.00218201],\n",
       "            [-0.00540161, 0.000793457, 0.000892639, ..., 0.00186157,\n",
       "             -0.000448227, -0.00430298],\n",
       "            [-0.0030365, -0.0119019, -0.00811768, ..., -0.0112915,\n",
       "             0.0209961, 0.00817871]],\n",
       "    \n",
       "           [[0.00364685, -0.00375366, 0.00726318, ..., 0.00836182,\n",
       "             -0.00592041, -0.00189972],\n",
       "            [-0.00379944, 0.00173187, -0.00460815, ..., -0.0078125,\n",
       "             -0.00811768, -0.0110474],\n",
       "            [0.00424194, 0.00674438, -0.00296021, ..., 0.0100708, -0.026001,\n",
       "             0.00772095],\n",
       "            ...,\n",
       "            [0.00227356, 0.00946045, -0.00494385, ..., 0.00479126,\n",
       "             -0.0202637, -0.000843048],\n",
       "            [0.000801086, -0.00427246, -0.00117493, ..., 0.000976562,\n",
       "             -0.000873566, -0.0100098],\n",
       "            [0.00643921, -0.0045166, 0.0100098, ..., 0.00576782, 0.00567627,\n",
       "             -0.0142822]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00134277, -0.0019989, -0.00135803, ..., 0.00349426,\n",
       "            0.006073, -0.00616455],\n",
       "           [-0.00325012, -0.0118408, 0.00141907, ..., 0.00158691,\n",
       "            -0.0088501, 0.00375366],\n",
       "           [-0.00500488, 0.00619507, 0.000537872, ..., 0.00613403,\n",
       "            -0.0141602, 9.67979e-05],\n",
       "           ...,\n",
       "           [-0.00210571, 0.00927734, -0.00171661, ..., -0.0108032,\n",
       "            0.00457764, -0.00524902],\n",
       "           [0.00187683, -0.0043335, 0.00047493, ..., 0.00805664,\n",
       "            -0.00582886, 0.00121307],\n",
       "           [-0.00512695, 0.0189209, 0.00549316, ..., 0.0090332, 0.0112305,\n",
       "            -0.00180054]],\n",
       "   \n",
       "          [[-0.000442505, 0.00631714, -0.0145264, ..., 0.0116577,\n",
       "            -0.0285645, 0.0109863],\n",
       "           [-0.00811768, 0.00735474, 0.000740051, ..., 0.00543213,\n",
       "            0.0159912, -0.00104523],\n",
       "           [0.000354767, 0.00460815, 0.00811768, ..., -0.00714111,\n",
       "            0.000473022, -0.00463867],\n",
       "           ...,\n",
       "           [0.00567627, 0.00294495, 0.000293732, ..., -0.00643921,\n",
       "            -0.0001688, 0.00521851],\n",
       "           [-0.00044632, -0.0162354, -0.0045166, ..., -0.0133667,\n",
       "            0.00102997, 0.00460815],\n",
       "           [0.000747681, 0.00662231, -0.00585938, ..., 0.0136108,\n",
       "            -0.0057373, 0.00769043]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00257874, 0.00442505, -0.00585938, ..., -0.000991821,\n",
       "           -0.00772095, -0.010437],\n",
       "          [0.00349426, -0.00023365, 0.0017395, ..., -0.00118256,\n",
       "           0.000984192, 0.00157928],\n",
       "          [-0.00170898, 0.00787354, -0.00218201, ..., 0.00439453,\n",
       "           -0.00270081, 0.00552368],\n",
       "          ...,\n",
       "          [0.0108032, 0.00576782, 0.00878906, ..., 0.00213623, 0.000214577,\n",
       "           0.00247192],\n",
       "          [-0.00750732, 0.00897217, 0.0100098, ..., -0.0163574, 0.0020752,\n",
       "           0.00190735],\n",
       "          [-0.00193787, 0.00216675, 0.00515747, ..., 0.0039978, -0.00384521,\n",
       "           -0.0078125]], dtype=bfloat16), a=Array([[-0.005503  , -0.00465591,  0.02688703, ...,  0.00167953,\n",
       "           -0.00383867,  0.01666052],\n",
       "          [ 0.00788943, -0.01279993, -0.01336973, ...,  0.00526251,\n",
       "           -0.00046879,  0.01022278]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([2.39062, 2.375, 2.32812, ..., 3.42188, 2.84375, 2.29688], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([4.6875, 4.84375, 4.9375, ..., 5.9375, 4.5625, 4.6875], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.296875, 0.261719, 0.265625, ..., 0.380859, 0.296875, 0.373047],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([-0.136719, -0.134766, -0.133789, ..., -0.0761719, -0.129883,\n",
       "          -0.105957], dtype=bfloat16)}},\n",
       " 'layer_3': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.015625, -0.0299072, 0.0206299, ..., -0.0202637, 0.0197754,\n",
       "             -0.012207],\n",
       "            [-0.0192871, 0.0227051, 0.0184326, ..., 0.0123291, 0.00288391,\n",
       "             0.0112305],\n",
       "            [0.000459671, 0.00396729, -0.0102539, ..., -0.0130615,\n",
       "             0.00952148, -0.0108032],\n",
       "            ...,\n",
       "            [0.019043, -0.00643921, -0.0116577, ..., -0.00726318,\n",
       "             0.00836182, -0.00267029],\n",
       "            [-0.0019989, 0.0212402, -0.00149536, ..., -0.00289917,\n",
       "             0.0106812, 0.00469971],\n",
       "            [0.00921631, -0.00738525, -0.00189209, ..., 0.00689697,\n",
       "             -5.36442e-05, 0.000396729]],\n",
       "    \n",
       "           [[0.000303268, -0.0166016, -0.00671387, ..., 0.0151367,\n",
       "             0.0283203, 0.00352478],\n",
       "            [-0.00448608, 0.0101318, 0.0255127, ..., -0.0157471, 0.00933838,\n",
       "             0.0114746],\n",
       "            [0.0178223, 0.00769043, -0.0124512, ..., -0.00701904,\n",
       "             0.00369263, 0.00765991],\n",
       "            ...,\n",
       "            [-0.00765991, 0.00127411, 0.0045166, ..., 0.00567627, 0.0152588,\n",
       "             0.0078125],\n",
       "            [-0.00262451, 0.00268555, -0.00546265, ..., 0.0234375,\n",
       "             0.00167084, -0.0037384],\n",
       "            [-0.0136108, -0.0147705, 0.00442505, ..., 0.00778198,\n",
       "             -0.00196838, 0.0117188]],\n",
       "    \n",
       "           [[0.0196533, 0.00656128, -0.0249023, ..., -0.0224609, 0.00595093,\n",
       "             0.00218201],\n",
       "            [0.012085, 0.00817871, -0.00970459, ..., -0.00288391,\n",
       "             0.00878906, -0.0071106],\n",
       "            [0.0180664, -0.0157471, 0.00909424, ..., 0.00019455,\n",
       "             -0.00714111, -0.00159454],\n",
       "            ...,\n",
       "            [-0.00897217, 0.0113525, 0.0065918, ..., -0.000667572,\n",
       "             -0.0148926, -0.00170898],\n",
       "            [-0.00817871, -0.00382996, -0.00653076, ..., -0.00267029,\n",
       "             -0.00714111, 0.0131836],\n",
       "            [0.006073, 0.00588989, -0.00927734, ..., 0.00872803,\n",
       "             -0.00552368, 0.00308228]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00656128, -0.000621796, -0.00131989, ..., 0.0110474,\n",
       "             0.00418091, -0.00683594],\n",
       "            [0.00747681, 0.0103149, 0.00285339, ..., 0.00650024,\n",
       "             -0.00318909, 0.00897217],\n",
       "            [0.00823975, 0.00567627, -0.0119629, ..., -0.000549316,\n",
       "             -0.000310898, -0.0043335],\n",
       "            ...,\n",
       "            [0.00500488, 0.00698853, -0.00050354, ..., 0.00386047,\n",
       "             0.00830078, -0.00112915],\n",
       "            [-0.00244141, -0.00263977, -0.00915527, ..., -0.00872803,\n",
       "             0.00189209, 0.0195312],\n",
       "            [0.0197754, -0.00939941, 0.00701904, ..., -0.0270996,\n",
       "             -0.0119629, -0.00369263]],\n",
       "    \n",
       "           [[0.00216675, 0.00140381, -0.00817871, ..., 0.00256348,\n",
       "             0.0105591, 0.0100708],\n",
       "            [0.0115967, -0.00701904, -0.00531006, ..., 0.0222168,\n",
       "             -0.00101471, 0.0219727],\n",
       "            [0.00430298, 0.0114746, -0.000157356, ..., 0.0114136,\n",
       "             -0.00276184, -0.0336914],\n",
       "            ...,\n",
       "            [-0.00527954, -0.00546265, -6.62804e-05, ..., -0.00131226,\n",
       "             -0.00326538, -0.00167084],\n",
       "            [0.020874, -0.00933838, 0.0129395, ..., -0.0189209, 0.00668335,\n",
       "             -0.0167236],\n",
       "            [0.00172424, 0.0139771, 0.0115356, ..., 0.00473022, 0.0186768,\n",
       "             0.00897217]],\n",
       "    \n",
       "           [[-0.0109253, 0.000478745, -0.00268555, ..., 0.00378418,\n",
       "             0.0123901, 0.00787354],\n",
       "            [0.00976562, 0.00482178, 0.0078125, ..., -0.000762939,\n",
       "             0.00805664, -0.001297],\n",
       "            [-0.00418091, -0.00546265, -0.00238037, ..., 0.00588989,\n",
       "             0.0158691, 0.00292969],\n",
       "            ...,\n",
       "            [-0.00260925, -0.00537109, -0.00239563, ..., 0.00393677,\n",
       "             -0.0136108, 0.0102539],\n",
       "            [0.00515747, 0.0222168, 0.0203857, ..., 0.00292969, -0.001091,\n",
       "             -0.0126953],\n",
       "            [-0.0140991, 0.0140991, -0.0122681, ..., -0.00309753,\n",
       "             -0.0112305, -0.00823975]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00799561, 0.00439453, 0.0146484, ..., 0.00332642,\n",
       "              -0.00872803, 0.00245667],\n",
       "             [0.00144196, 0.000379562, 0.0100708, ..., 0.00619507,\n",
       "              0.0202637, -0.0181885],\n",
       "             [-0.0039978, -0.00389099, 0.00952148, ..., -0.0145264,\n",
       "              -0.00448608, -0.00946045],\n",
       "             ...,\n",
       "             [-0.00671387, -0.00314331, -0.00933838, ..., 0.00708008,\n",
       "              -0.000869751, -0.00619507],\n",
       "             [-0.0039978, 0.00305176, 0.00212097, ..., 0.000107288,\n",
       "              0.00308228, 0.00463867],\n",
       "             [-0.00720215, -0.00915527, -0.00386047, ..., 0.00759888,\n",
       "              0.010376, 0.00497437]],\n",
       "    \n",
       "            [[-0.00897217, 0.0106201, 0.0142212, ..., -0.0098877,\n",
       "              0.0187988, 0.00328064],\n",
       "             [0.00543213, -0.0126953, 0.000207901, ..., 0.0140991,\n",
       "              -0.000507355, 0.00750732],\n",
       "             [-0.00482178, -0.000507355, 0.00265503, ..., -0.0211182,\n",
       "              -0.00196838, 0.0098877],\n",
       "             ...,\n",
       "             [-0.0123291, 0.0194092, -0.0166016, ..., -0.017334, 0.0296631,\n",
       "              0.00244141],\n",
       "             [0.00543213, 0.00132751, 0.00524902, ..., 0.00127411,\n",
       "              -0.00166321, -0.0163574],\n",
       "             [-0.000159264, -0.0131226, 0.000957489, ..., 0.0155029,\n",
       "              0.0169678, -0.0109253]],\n",
       "    \n",
       "            [[-0.00494385, 0.020752, -0.00315857, ..., -0.0137939,\n",
       "              -0.00698853, 0.0125732],\n",
       "             [0.00178528, 0.00836182, -0.00297546, ..., -0.0145874,\n",
       "              -0.0163574, 0.00102997],\n",
       "             [-0.00939941, 0.0120239, -0.00469971, ..., -0.0169678,\n",
       "              -0.00205994, -0.00271606],\n",
       "             ...,\n",
       "             [-0.0134277, 0.0150146, 0.0115967, ..., -0.000663757,\n",
       "              -0.00230408, 0.0109863],\n",
       "             [0.0212402, -0.00799561, -0.00402832, ..., -0.00927734,\n",
       "              0.00161743, -0.00323486],\n",
       "             [-0.0098877, 0.00370789, -0.0158691, ..., 0.0145264,\n",
       "              0.0211182, 0.00653076]],\n",
       "    \n",
       "            [[0.00543213, 0.00634766, 0.0136719, ..., 0.00124359,\n",
       "              -0.0019989, -0.00836182],\n",
       "             [0.000747681, 0.0111084, 0.00717163, ..., -0.0067749,\n",
       "              0.0045166, 0.0105591],\n",
       "             [0.00389099, 0.0107422, -0.0137329, ..., -0.0159912,\n",
       "              -0.0107422, 0.00613403],\n",
       "             ...,\n",
       "             [0.00408936, 0.00527954, 0.00378418, ..., -0.00463867,\n",
       "              0.0314941, -0.00524902],\n",
       "             [-0.0235596, -0.0186768, 0.00671387, ..., 0.00650024,\n",
       "              0.013855, -0.00221252],\n",
       "             [0.0131226, -0.00570679, 0.00376892, ..., 0.00765991,\n",
       "              -0.0140381, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[6.10352e-05, -0.0125122, -0.0101318, ..., 0.0174561,\n",
       "              -0.00221252, -0.0045166],\n",
       "             [0.00180817, 0.00753784, -0.0037384, ..., -0.0101318,\n",
       "              0.00260925, -0.00622559],\n",
       "             [0.0153809, 0.000652313, -0.00750732, ..., -0.00390625,\n",
       "              0.00668335, -0.000930786],\n",
       "             ...,\n",
       "             [-0.0253906, -0.0145264, 0.0108032, ..., -0.00842285,\n",
       "              -0.00970459, 0.0222168],\n",
       "             [-0.0163574, 0.00564575, 0.000514984, ..., -0.00476074,\n",
       "              0.0177002, 0.00361633],\n",
       "             [-0.0129395, -0.0133667, -0.00805664, ..., 0.00424194,\n",
       "              0.00439453, -0.0196533]],\n",
       "    \n",
       "            [[-0.0136719, -0.0129395, -0.0105591, ..., 0.0134888,\n",
       "              0.00775146, -0.00772095],\n",
       "             [-0.010498, 0.000766754, 0.0175781, ..., -0.00270081,\n",
       "              -0.00253296, 0.000911713],\n",
       "             [0.0247803, 0.0186768, -0.00402832, ..., 0.0011673, 0.0131836,\n",
       "              0.0143433],\n",
       "             ...,\n",
       "             [0.0154419, 0.000701904, 0.00387573, ..., -0.00247192,\n",
       "              0.0090332, -0.0149536],\n",
       "             [-0.00765991, -0.0134277, 0.00396729, ..., 0.00787354,\n",
       "              0.0038147, -0.00793457],\n",
       "             [-0.00436401, 0.00994873, 0.000455856, ..., -0.000923157,\n",
       "              -0.00878906, 0.00421143]],\n",
       "    \n",
       "            [[-0.00159454, -0.0257568, 0.00592041, ..., -0.0032196,\n",
       "              0.00302124, 0.00204468],\n",
       "             [0.00964355, -0.0222168, 0.0112915, ..., -0.00357056,\n",
       "              -0.00927734, -0.00140381],\n",
       "             [0.0111084, -0.00402832, -0.0109863, ..., -0.00524902,\n",
       "              0.0150146, 0.000471115],\n",
       "             ...,\n",
       "             [0.00518799, -0.0159912, -0.0123291, ..., -0.0180664,\n",
       "              -0.00213623, -0.0192871],\n",
       "             [-0.00769043, 0.00769043, 0.00872803, ..., 0.000686646,\n",
       "              0.00982666, 0.00415039],\n",
       "             [0.00254822, -0.00337219, -0.0112915, ..., 0.00202942,\n",
       "              -0.00305176, -0.00479126]],\n",
       "    \n",
       "            [[-0.00921631, 0.00309753, -0.00172424, ..., -0.0137329,\n",
       "              0.000972748, 0.00183105],\n",
       "             [-0.00570679, -0.00765991, -0.00056076, ..., 0.00656128,\n",
       "              0.00111389, 0.0307617],\n",
       "             [-0.0123901, 0.00805664, 0.00546265, ..., 0.000911713,\n",
       "              -0.00897217, 0.000644684],\n",
       "             ...,\n",
       "             [0.0163574, 0.0103149, -0.0157471, ..., -0.00389099,\n",
       "              -0.00643921, 0.012146],\n",
       "             [0.0055542, 0.0114746, 0.0133667, ..., 0.00439453,\n",
       "              -0.000429153, 0.0106201],\n",
       "             [0.0050354, 0.0088501, -0.00704956, ..., -0.00485229,\n",
       "              -0.0255127, 0.00921631]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.0116577, 0.00300598, 0.0112305, ..., 0.000368118,\n",
       "             -0.00994873, -0.00274658],\n",
       "            [0.0219727, 0.019043, -0.006073, ..., -0.00280762, -0.00668335,\n",
       "             0.0152588],\n",
       "            [-0.00592041, 0.00576782, 0.0205078, ..., 0.00512695,\n",
       "             0.00546265, -0.000368118],\n",
       "            ...,\n",
       "            [0.00186157, 0.000762939, 0.00479126, ..., -0.00897217,\n",
       "             0.00823975, 0.00524902],\n",
       "            [0.0062561, 0.00357056, -0.00866699, ..., 0.0153198, 0.00134277,\n",
       "             -0.012146],\n",
       "            [-0.0112915, -0.00485229, -0.0055542, ..., 0.00970459,\n",
       "             0.00198364, 0.00151825]],\n",
       "    \n",
       "           [[0.0016098, -0.00738525, -0.0153809, ..., 0.0133667, -0.010437,\n",
       "             0.00457764],\n",
       "            [0.00723267, 0.00952148, -0.00640869, ..., -0.00567627,\n",
       "             0.0272217, -0.00674438],\n",
       "            [-0.00193787, 0.00338745, 0.00154114, ..., -0.0123901,\n",
       "             -0.0229492, -0.00775146],\n",
       "            ...,\n",
       "            [-0.00595093, -0.0153198, 0.0102539, ..., 0.0174561, 0.00588989,\n",
       "             -0.00367737],\n",
       "            [0.00695801, -0.00106049, -0.00927734, ..., -0.00650024,\n",
       "             0.00680542, -0.00579834],\n",
       "            [-0.00034523, -0.00227356, -0.00147247, ..., 0.00311279,\n",
       "             -0.0113525, -0.012085]],\n",
       "    \n",
       "           [[-0.00732422, 0.00527954, 0.000640869, ..., -0.00537109,\n",
       "             0.0149536, -0.00671387],\n",
       "            [0.000991821, -0.00421143, -0.00335693, ..., -0.00174713,\n",
       "             0.0109863, -0.00457764],\n",
       "            [0.00118256, 0.00167084, 0.00793457, ..., -0.00793457,\n",
       "             0.00686646, 0.0103149],\n",
       "            ...,\n",
       "            [0.000511169, -0.00466919, -0.00570679, ..., -0.0236816,\n",
       "             0.00769043, 0.0131836],\n",
       "            [0.000930786, -0.00111389, 0.00331116, ..., 0.0167236,\n",
       "             0.00982666, -0.00509644],\n",
       "            [7.29561e-05, -0.0013504, 0.00279236, ..., 0.00300598,\n",
       "             0.0197754, 0.0109253]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00601196, -0.0158691, -0.0122681, ..., -0.00897217,\n",
       "             -0.00309753, 0.00387573],\n",
       "            [0.0178223, -0.00994873, 0.0229492, ..., -0.00311279, -0.024292,\n",
       "             0.0172119],\n",
       "            [-0.0186768, -0.00224304, -0.0133667, ..., -0.0241699,\n",
       "             0.00265503, -0.00628662],\n",
       "            ...,\n",
       "            [-0.00120544, -0.0019989, -0.0174561, ..., -0.012207,\n",
       "             -0.0148315, -0.00656128],\n",
       "            [0.0251465, -0.00506592, 0.00062561, ..., 0.00665283,\n",
       "             -0.00215149, 0.00167847],\n",
       "            [-0.0137329, 0.0150757, -0.0223389, ..., -0.00198364,\n",
       "             -0.00939941, 0.00515747]],\n",
       "    \n",
       "           [[-0.00263977, -0.0107422, -0.00349426, ..., 0.015564, -0.010376,\n",
       "             0.0218506],\n",
       "            [0.00482178, -0.0150146, -0.0151978, ..., 0.00747681, 0.0116577,\n",
       "             -0.00221252],\n",
       "            [-0.000556946, 0.00192261, 0.000352859, ..., -0.00056839,\n",
       "             0.0214844, -0.00775146],\n",
       "            ...,\n",
       "            [0.024292, 0.00946045, -0.0134888, ..., 0.0179443, 0.00106812,\n",
       "             0.0137939],\n",
       "            [-0.00358582, 0.000610352, -0.00509644, ..., -0.00411987,\n",
       "             -0.000896454, -0.0113525],\n",
       "            [-0.00222778, 0.00418091, -0.00634766, ..., -0.00119781,\n",
       "             0.0145874, -0.0105591]],\n",
       "    \n",
       "           [[0.00830078, 0.0169678, 0.00180054, ..., 0.0111084, -0.00151825,\n",
       "             0.0145874],\n",
       "            [-0.032959, 0.00222778, -0.0115356, ..., -0.0145874, 0.0111084,\n",
       "             -0.0123291],\n",
       "            [0.00735474, 0.0118408, 0.000335693, ..., 0.000514984,\n",
       "             -0.00311279, -0.0179443],\n",
       "            ...,\n",
       "            [-0.00162506, -0.0179443, -0.012085, ..., -0.0252686,\n",
       "             -0.00958252, 0.00268555],\n",
       "            [-0.00805664, -0.000915527, 0.0055542, ..., 0.00418091,\n",
       "             0.00909424, -0.0213623],\n",
       "            [0.0211182, 0.0119629, 0.00262451, ..., -0.00546265,\n",
       "             0.000679016, 0.0116577]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.0014801, -0.0143433, 0.00695801, ..., 0.012146, 0.00023365,\n",
       "            0.0136719],\n",
       "           [0.00289917, 0.0139771, 0.00445557, ..., -0.0205078,\n",
       "            -0.000701904, 0.0143433],\n",
       "           [-0.00491333, 0.00331116, -0.00842285, ..., -0.00366211,\n",
       "            -0.00939941, 0.000350952],\n",
       "           ...,\n",
       "           [0.0181885, -0.00546265, -0.0146484, ..., 0.00830078,\n",
       "            -0.00576782, -0.000362396],\n",
       "           [0.00364685, 0.00326538, 0.0132446, ..., -0.00183868,\n",
       "            0.00262451, 0.00878906],\n",
       "           [0.00830078, 0.00946045, -0.000115395, ..., 0.00213623,\n",
       "            -0.0119019, 0.0100098]],\n",
       "   \n",
       "          [[0.00500488, -0.00418091, 0.00485229, ..., 0.0114136,\n",
       "            2.67029e-05, 0.00567627],\n",
       "           [0.00346375, -0.00171661, -0.0170898, ..., -0.00897217,\n",
       "            0.0159912, 0.00927734],\n",
       "           [0.000652313, -0.00653076, -0.00534058, ..., -0.00982666,\n",
       "            0.0112305, 0.00402832],\n",
       "           ...,\n",
       "           [-0.00552368, -0.00457764, 0.0168457, ..., 0.0150146,\n",
       "            -0.00671387, -0.0106812],\n",
       "           [0.00436401, 0.0136108, 0.00341797, ..., 0.0038147, 0.00561523,\n",
       "            -0.00891113],\n",
       "           [-0.000225067, -0.000610352, -0.0218506, ..., 0.00540161,\n",
       "            -0.020874, 0.006073]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.0088501, -0.000556946, -0.000946045, ..., -0.0131226,\n",
       "           0.0123901, -0.0098877],\n",
       "          [-0.00291443, -0.00637817, 0.000459671, ..., -0.0131226,\n",
       "           0.0115967, -0.000145912],\n",
       "          [0.00283813, -0.0108643, -0.00254822, ..., 0.0130005, 0.0150146,\n",
       "           -0.0141602],\n",
       "          ...,\n",
       "          [0.0125732, -0.0057373, -0.00263977, ..., 0.0128784, -0.0127563,\n",
       "           0.00408936],\n",
       "          [0.00213623, 0.0135498, 0.00668335, ..., 0.00769043, 0.00402832,\n",
       "           -0.0148315],\n",
       "          [0.00242615, 0.0039978, -0.0019989, ..., -0.0148926, -0.000553131,\n",
       "           0.00582886]], dtype=bfloat16), a=Array([[-0.00757848,  0.00208123, -0.0095167 , ...,  0.01346242,\n",
       "            0.01381325, -0.00154688],\n",
       "          [-0.01088316, -0.00166531, -0.02113895, ..., -0.00199354,\n",
       "            0.00065937,  0.00700611]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([-0.166992, -0.209961, -0.139648, ..., -0.363281, -0.0634766,\n",
       "          -0.261719], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.361328, 0.380859, 0.306641, ..., 0.0698242, 0.480469, 0.386719],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.617188, 0.453125, 0.699219, ..., 0.785156, 0.363281, 0.527344],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.859375, 0.824219, 0.894531, ..., 1.19531, 0.0356445, 0.714844],      dtype=bfloat16)}},\n",
       " 'layer_4': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00259399, 0.0158691, -0.00891113, ..., -0.00567627,\n",
       "             -0.00279236, 0.0189209],\n",
       "            [-0.0251465, 0.00376892, 0.00233459, ..., 0.0015564,\n",
       "             -0.00531006, 0.0140991],\n",
       "            [-0.00817871, -0.00141907, -0.00140381, ..., -0.00107574,\n",
       "             0.000276566, 0.00308228],\n",
       "            ...,\n",
       "            [-0.00946045, 0.0183105, 0.0145874, ..., -0.00793457,\n",
       "             -0.0045166, -0.0289307],\n",
       "            [0.00836182, 0.00315857, 0.00286865, ..., -0.00561523,\n",
       "             -0.000976562, 0.00254822],\n",
       "            [0.00964355, 0.00242615, 0.00306702, ..., 0.000713348,\n",
       "             -0.00386047, -0.0183105]],\n",
       "    \n",
       "           [[-0.0107422, -0.00476074, -0.00515747, ..., -0.000923157,\n",
       "             0.00650024, -0.00674438],\n",
       "            [0.00689697, 0.00640869, 0.0037384, ..., 0.0120239, 0.00665283,\n",
       "             -0.00534058],\n",
       "            [-0.00921631, 0.0032959, 0.0114746, ..., 0.0233154, -0.006073,\n",
       "             0.00537109],\n",
       "            ...,\n",
       "            [0.00970459, 0.0273438, 0.006073, ..., 0.00692749, 0.0213623,\n",
       "             0.00656128],\n",
       "            [0.0166016, -0.0107422, 2.22921e-05, ..., -0.000862122,\n",
       "             -0.00686646, 0.00297546],\n",
       "            [-0.00558472, 0.0234375, 0.000579834, ..., 0.00171661,\n",
       "             -0.0178223, 0.00527954]],\n",
       "    \n",
       "           [[-0.00524902, -0.00897217, 0.00915527, ..., -0.0203857,\n",
       "             0.000713348, -0.00167084],\n",
       "            [-0.00726318, -0.0115356, -0.00205994, ..., 0.00561523,\n",
       "             -0.00338745, -0.00274658],\n",
       "            [-0.0151978, -0.00263977, -0.00271606, ..., 0.00994873,\n",
       "             -0.00479126, 0.000193596],\n",
       "            ...,\n",
       "            [-0.0219727, 0.00765991, 0.0185547, ..., -0.00454712,\n",
       "             -0.00891113, 0.0050354],\n",
       "            [-0.00515747, 0.0117188, 0.0112305, ..., -0.00469971,\n",
       "             -0.00473022, 0.00476074],\n",
       "            [-0.00738525, -0.0126343, 0.0140381, ..., 0.00527954,\n",
       "             0.00415039, 0.010437]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00848389, 0.00230408, -0.00427246, ..., -0.0187988,\n",
       "             0.00479126, 0.00512695],\n",
       "            [0.000869751, -0.000356674, -0.0022583, ..., -0.00390625,\n",
       "             0.0217285, -0.00314331],\n",
       "            [0.0180664, 0.012085, -0.00994873, ..., -0.00198364,\n",
       "             -0.00473022, -0.0236816],\n",
       "            ...,\n",
       "            [-0.0109253, 0.0017395, 0.00257874, ..., -0.000326157,\n",
       "             0.00787354, -0.00485229],\n",
       "            [-0.00817871, -0.0114136, 0.0128174, ..., -0.00300598,\n",
       "             -0.0127563, -0.00247192],\n",
       "            [-0.00622559, 0.00296021, 0.00830078, ..., -0.00259399,\n",
       "             -0.0195312, -0.00257874]],\n",
       "    \n",
       "           [[-0.0088501, 0.00439453, 0.00109863, ..., -0.00389099,\n",
       "             0.00415039, 0.0015564],\n",
       "            [-0.00469971, -0.00787354, 0.000728607, ..., -0.00506592,\n",
       "             -0.0235596, -0.0172119],\n",
       "            [-0.0071106, -0.000896454, -0.00195312, ..., 0.00393677,\n",
       "             -0.00299072, -0.00306702],\n",
       "            ...,\n",
       "            [-0.00576782, 0.00157928, -0.0136719, ..., 0.0174561,\n",
       "             0.00188446, -0.00421143],\n",
       "            [0.000606537, 0.0179443, -0.0280762, ..., 0.0114746, -0.0163574,\n",
       "             0.00946045],\n",
       "            [-0.0030365, 0.0170898, -0.00104523, ..., 0.00564575,\n",
       "             -0.00933838, 0.0166016]],\n",
       "    \n",
       "           [[-0.00375366, 0.00228882, 0.0088501, ..., -0.0011673,\n",
       "             -0.000455856, -0.0112305],\n",
       "            [0.00704956, 0.0108032, -0.00799561, ..., -0.00300598,\n",
       "             -0.00087738, -0.00296021],\n",
       "            [-0.00259399, -0.0106812, 0.00335693, ..., -0.000976562,\n",
       "             -0.00357056, -0.00735474],\n",
       "            ...,\n",
       "            [0.00338745, 0.0151978, 0.00823975, ..., -0.00708008,\n",
       "             0.00762939, -0.00122833],\n",
       "            [-0.00732422, -0.00836182, 0.00149536, ..., -0.0163574,\n",
       "             -0.0137329, -0.00518799],\n",
       "            [0.00300598, -0.0148315, 0.022583, ..., -0.0148315, 0.0250244,\n",
       "             -0.00753784]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00939941, 0.00136566, 0.0114746, ..., -0.00131989,\n",
       "              -0.00726318, 0.00236511],\n",
       "             [-0.000113964, -0.00466919, -0.00756836, ..., -0.0162354,\n",
       "              0.00113678, 0.00248718],\n",
       "             [-0.00157928, 0.00799561, -0.0139771, ..., -0.00202942,\n",
       "              -0.0205078, -0.0102539],\n",
       "             ...,\n",
       "             [-0.00772095, -0.0209961, -0.00387573, ..., 0.00436401,\n",
       "              0.00610352, -0.0155029],\n",
       "             [0.0269775, -0.0123901, -0.0132446, ..., -0.00939941,\n",
       "              -0.00387573, -0.0130005],\n",
       "             [-0.0102539, -0.0245361, 0.010376, ..., 0.0106812,\n",
       "              -0.00222778, -0.0220947]],\n",
       "    \n",
       "            [[0.00427246, -0.00297546, 0.000284195, ..., -0.0164795,\n",
       "              0.0147095, -0.0169678],\n",
       "             [0.00708008, 0.000326157, -0.00296021, ..., -0.0078125,\n",
       "              0.0285645, -0.00567627],\n",
       "             [0.00714111, -0.00285339, -0.0131226, ..., -0.00878906,\n",
       "              -0.0181885, -0.0358887],\n",
       "             ...,\n",
       "             [0.00701904, 0.0132446, -0.00848389, ..., -0.0172119,\n",
       "              -0.00656128, -0.02771],\n",
       "             [-0.0235596, -0.00169373, -0.029541, ..., -0.00421143,\n",
       "              0.0285645, 0.0106812],\n",
       "             [0.0241699, 0.0118408, 0.00540161, ..., -0.00848389,\n",
       "              -0.000816345, -0.0114746]],\n",
       "    \n",
       "            [[0.00921631, 0.00735474, 0.00297546, ..., -0.00454712,\n",
       "              0.013855, -0.0119629],\n",
       "             [0.00634766, 0.00854492, -0.0223389, ..., 0.00328064,\n",
       "              -0.0444336, -0.00576782],\n",
       "             [0.015564, 0.0126953, -0.00102997, ..., -0.0106201,\n",
       "              -0.00891113, 0.00964355],\n",
       "             ...,\n",
       "             [0.000644684, 0.00500488, 0.0090332, ..., 0.00204468,\n",
       "              -0.000149727, 0.015564],\n",
       "             [0.012146, -0.00964355, -0.0141602, ..., 0.0361328,\n",
       "              -0.00285339, 0.0216064],\n",
       "             [0.0126953, 0.0065918, -0.00704956, ..., -0.00598145,\n",
       "              -0.00836182, 0.0301514]],\n",
       "    \n",
       "            [[0.00500488, -0.00683594, -0.00662231, ..., -0.0178223,\n",
       "              -0.0124512, 0.00695801],\n",
       "             [0.00212097, -0.00646973, 0.00927734, ..., -0.00473022,\n",
       "              0.0125732, -0.0144043],\n",
       "             [0.00236511, -0.00379944, 0.00463867, ..., -0.000213623,\n",
       "              0.00933838, 0.0186768],\n",
       "             ...,\n",
       "             [0.0139771, -0.0111694, -0.00415039, ..., 0.0167236,\n",
       "              -0.00921631, -0.0220947],\n",
       "             [-0.0115967, 0.0123901, 5.05447e-05, ..., 0.00860596,\n",
       "              0.00415039, 0.00122833],\n",
       "             [0.00201416, -0.00209045, -0.00476074, ..., -0.0149536,\n",
       "              -0.012146, 0.0184326]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00970459, 0.0101318, 0.000556946, ..., -0.00817871,\n",
       "              0.0111694, 0.00524902],\n",
       "             [-0.0072937, -0.00494385, 0.0170898, ..., -0.00692749,\n",
       "              -0.00521851, 0.0223389],\n",
       "             [-0.000778198, 0.00830078, 0.00860596, ..., 0.0139771,\n",
       "              -0.0027771, -0.00408936],\n",
       "             ...,\n",
       "             [-0.00370789, -0.0100098, 0.00476074, ..., -0.0098877,\n",
       "              0.0151367, -0.00387573],\n",
       "             [0.0123901, 0.00588989, 0.00369263, ..., -0.00360107,\n",
       "              0.015625, -0.00848389],\n",
       "             [-0.00698853, -0.0175781, 0.0100708, ..., -0.0202637,\n",
       "              -0.00308228, 0.000930786]],\n",
       "    \n",
       "            [[0.0163574, 0.0027771, -0.00248718, ..., -0.0266113,\n",
       "              -0.00701904, 0.00130463],\n",
       "             [-0.0137329, -0.00830078, -0.0050354, ..., 0.0140381,\n",
       "              0.00588989, -0.00476074],\n",
       "             [0.0174561, 0.00613403, -0.0106812, ..., 0.0101318,\n",
       "              0.000637054, 0.00146484],\n",
       "             ...,\n",
       "             [-0.00686646, -0.0131226, 0.0206299, ..., 0.00854492,\n",
       "              0.00872803, 0.00114441],\n",
       "             [0.00171661, 0.00680542, 0.00201416, ..., 0.00579834,\n",
       "              0.00245667, 0.0124512],\n",
       "             [0.0172119, -0.0132446, -0.0018158, ..., 0.00662231,\n",
       "              0.00866699, 0.010498]],\n",
       "    \n",
       "            [[0.0113525, 0.00558472, -0.0164795, ..., 0.00239563,\n",
       "              0.00156403, 0.0133057],\n",
       "             [0.00123596, -0.00769043, -0.00939941, ..., 0.00671387,\n",
       "              0.0228271, 0.000862122],\n",
       "             [0.00376892, -0.00424194, 0.0123291, ..., -0.00732422,\n",
       "              -0.00964355, -0.0126953],\n",
       "             ...,\n",
       "             [0.0147705, 0.0200195, 0.0161133, ..., -0.00512695,\n",
       "              -0.00592041, 0.00668335],\n",
       "             [-0.000839233, -0.0235596, 0.00448608, ..., -0.000785828,\n",
       "              0.0132446, 0.0214844],\n",
       "             [-0.00674438, 0.000946045, 0.0134888, ..., 0.00643921,\n",
       "              -0.00341797, -0.000368118]],\n",
       "    \n",
       "            [[-0.0108032, 0.0145874, -0.00601196, ..., 0.00201416,\n",
       "              0.00698853, -0.00209045],\n",
       "             [-0.000904083, -0.0123901, 0.0114136, ..., 0.00156403,\n",
       "              -0.00543213, 0.0235596],\n",
       "             [-0.00193787, 0.00219727, 0.000652313, ..., 0.00878906,\n",
       "              -0.0302734, 0.00701904],\n",
       "             ...,\n",
       "             [0.0266113, 0.00964355, 0.0196533, ..., 0.0189209, 0.00836182,\n",
       "              -0.0032196],\n",
       "             [0.0135498, -0.0109863, -0.0170898, ..., -0.00714111,\n",
       "              -0.0102539, 0.00115967],\n",
       "             [-0.00613403, -0.00332642, 0.00341797, ..., 0.00946045,\n",
       "              0.0308838, 0.0206299]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.0043335, 0.0185547, -0.00393677, ..., -0.0256348,\n",
       "             -0.00582886, 0.0195312],\n",
       "            [-0.00364685, -0.0148315, 0.0123291, ..., -0.0136108,\n",
       "             -0.0288086, -0.0100708],\n",
       "            [0.00494385, -0.010437, 0.0137939, ..., 0.00765991, -0.0218506,\n",
       "             -0.020752],\n",
       "            ...,\n",
       "            [0.00156403, 0.0327148, -0.0163574, ..., -0.00198364, 0.0299072,\n",
       "             -0.00256348],\n",
       "            [0.0130005, -0.00213623, 0.00726318, ..., -0.00848389,\n",
       "             -0.0144653, 0.0162354],\n",
       "            [0.0037384, 0.0117798, -0.022583, ..., -0.0112305, -0.0169678,\n",
       "             -0.0161133]],\n",
       "    \n",
       "           [[0.0107422, -0.0129395, 0.00279236, ..., 0.00439453, 0.00292969,\n",
       "             -0.00132751],\n",
       "            [-0.000182152, -0.00315857, -0.00387573, ..., 0.0180664,\n",
       "             0.00765991, 0.0236816],\n",
       "            [-0.0122681, -0.00878906, -0.00262451, ..., -0.00285339,\n",
       "             -0.00436401, -0.0142822],\n",
       "            ...,\n",
       "            [0.0120239, 0.020752, 0.00601196, ..., -0.012146, 0.0167236,\n",
       "             -0.00358582],\n",
       "            [-0.00233459, -0.00964355, 0.000118732, ..., -0.00122833,\n",
       "             -0.00212097, 0.012207],\n",
       "            [0.0045166, -0.0022583, -0.0142212, ..., -0.00546265,\n",
       "             0.00646973, 0.0115967]],\n",
       "    \n",
       "           [[-0.0200195, -0.0130615, 0.00765991, ..., -0.00430298,\n",
       "             0.00405884, 0.003479],\n",
       "            [0.00543213, 0.00408936, -0.00787354, ..., -0.00126648,\n",
       "             -0.0169678, 0.000545502],\n",
       "            [0.010437, 0.00738525, -0.00179291, ..., 0.00872803, 0.017334,\n",
       "             0.00245667],\n",
       "            ...,\n",
       "            [0.00588989, -0.00909424, 0.00082016, ..., 0.00543213,\n",
       "             -0.0039978, 0.0119629],\n",
       "            [-0.00692749, 0.000991821, -0.0174561, ..., -0.00558472,\n",
       "             -0.00418091, -0.0111084],\n",
       "            [0.00187683, -0.00897217, 0.00866699, ..., 0.00878906,\n",
       "             -0.0108643, 0.0150146]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.0045166, -0.00686646, -0.00793457, ..., -0.012207,\n",
       "             -0.012085, -0.00424194],\n",
       "            [-0.0144653, -0.0111084, -0.0123291, ..., 0.00799561,\n",
       "             -0.00811768, 0.0145874],\n",
       "            [0.0134277, -0.0249023, -0.00765991, ..., 0.000235558,\n",
       "             -0.00396729, -0.0125122],\n",
       "            ...,\n",
       "            [0.00209045, -0.0123291, -0.0098877, ..., 0.00823975, 0.0032196,\n",
       "             -0.000782013],\n",
       "            [-0.00695801, -0.0407715, -0.00469971, ..., -0.00811768,\n",
       "             -0.00195312, -0.000499725],\n",
       "            [0.00265503, 0.0014801, 0.00878906, ..., -0.00300598,\n",
       "             0.00418091, 0.0114746]],\n",
       "    \n",
       "           [[-0.00332642, -6.38962e-05, -0.0088501, ..., -0.0170898,\n",
       "             0.0112915, 0.0114746],\n",
       "            [-0.000312805, -0.00189209, 0.00439453, ..., -0.00515747,\n",
       "             -0.0018158, -0.0166016],\n",
       "            [-0.00848389, -0.0013504, 0.00717163, ..., 0.00276184,\n",
       "             -0.00337219, 0.00521851],\n",
       "            ...,\n",
       "            [-0.0111084, -0.0101929, 0.00671387, ..., 0.024292, 0.0230713,\n",
       "             -0.0166016],\n",
       "            [0.00497437, 0.00744629, 0.0045166, ..., -0.00564575, 0.010376,\n",
       "             -0.00650024],\n",
       "            [0.00744629, -0.00241089, 0.00848389, ..., 0.0151978,\n",
       "             -0.00622559, -0.00747681]],\n",
       "    \n",
       "           [[-0.00454712, 0.00248718, -0.0071106, ..., -0.0291748,\n",
       "             -0.00442505, 0.00436401],\n",
       "            [-0.00775146, 0.00442505, -0.00628662, ..., 9.58443e-05,\n",
       "             -0.00512695, -0.00512695],\n",
       "            [-0.00546265, -0.00830078, -0.000976562, ..., -0.00132751,\n",
       "             0.0251465, -0.00976562],\n",
       "            ...,\n",
       "            [0.00156403, -0.0123901, -0.00579834, ..., 0.010498, 0.0177002,\n",
       "             -0.00415039],\n",
       "            [-0.00668335, -0.00897217, -0.00811768, ..., -0.0115356,\n",
       "             -0.00331116, -0.017334],\n",
       "            [-0.00279236, 0.000486374, -0.0155029, ..., 0.0157471,\n",
       "             0.00500488, 0.00619507]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00686646, -0.00628662, 0.00628662, ..., 0.00848389,\n",
       "            -0.00756836, 0.010437],\n",
       "           [-0.00315857, -0.00463867, 0.000448227, ..., 0.00482178,\n",
       "            0.00245667, 0.00927734],\n",
       "           [-0.00408936, -0.0167236, -0.00994873, ..., 0.00382996,\n",
       "            -0.000411987, 0.00799561],\n",
       "           ...,\n",
       "           [0.00136566, 0.000133514, 0.00891113, ..., -0.00331116,\n",
       "            0.0016098, 0.00376892],\n",
       "           [0.00485229, 0.0161133, 0.00567627, ..., 0.000400543,\n",
       "            -0.00130463, 0.0108643],\n",
       "           [-2.32458e-05, 0.00163269, -0.00280762, ..., 0.0102539,\n",
       "            -0.00695801, -0.0032959]],\n",
       "   \n",
       "          [[0.00744629, 0.00872803, 0.0055542, ..., 0.00276184, -0.0142212,\n",
       "            -0.00976562],\n",
       "           [-0.00102997, 0.00312805, 0.000511169, ..., 0.00805664,\n",
       "            0.00634766, -0.00811768],\n",
       "           [-0.00787354, -0.000740051, -0.00221252, ..., 0.024292,\n",
       "            0.00418091, -0.0035553],\n",
       "           ...,\n",
       "           [-0.010498, 0.000972748, -0.00540161, ..., -0.000459671,\n",
       "            -0.00294495, -0.0112305],\n",
       "           [-0.00305176, 0.000495911, 0.00708008, ..., -0.0113525,\n",
       "            -0.00866699, 0.00848389],\n",
       "           [0.0144653, -0.00479126, -0.0032196, ..., 0.0043335, 0.00506592,\n",
       "            0.00811768]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00891113, 0.00970459, -0.00151062, ..., -0.0108032,\n",
       "           -0.00360107, 0.00717163],\n",
       "          [-0.000900269, 0.00148773, -0.00619507, ..., -0.00320435,\n",
       "           -0.00695801, -0.00671387],\n",
       "          [0.00463867, -0.0111084, 0.00196838, ..., 0.0101318, 0.0045166,\n",
       "           -0.000709534],\n",
       "          ...,\n",
       "          [0.000488281, 0.00909424, 0.0111694, ..., 0.015625, -0.00994873,\n",
       "           0.0118408],\n",
       "          [6.19888e-05, 0.00524902, -0.00720215, ..., -0.00184631,\n",
       "           -0.00628662, 0.0113525],\n",
       "          [-0.0112915, -0.00358582, 0.00182343, ..., -0.0201416,\n",
       "           -0.00463867, 0.00230408]], dtype=bfloat16), a=Array([[ 0.00232868,  0.00122111, -0.02715557, ...,  0.00275968,\n",
       "            0.0063306 ,  0.00120457],\n",
       "          [ 0.01015269, -0.00104287, -0.01713954, ...,  0.01712951,\n",
       "           -0.02799168, -0.01150994]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([-0.193359, -0.28125, -0.21582, ..., -0.378906, -0.0407715,\n",
       "          -0.332031], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.285156, 0.245117, 0.246094, ..., 0.0476074, 0.613281, 0.271484],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.652344, 0.507812, 0.613281, ..., 0.824219, -0.0534668, 0.363281],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.554688, 0.570312, 0.554688, ..., 0.851562, 0.124512, 0.453125],      dtype=bfloat16)}},\n",
       " 'layer_5': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00173187, 0.00221252, -0.00119781, ..., -0.00017643,\n",
       "             -0.00933838, 0.00221252],\n",
       "            [-0.00540161, -0.00692749, -0.0183105, ..., -0.00308228,\n",
       "             -0.0032959, -0.00570679],\n",
       "            [-0.00933838, 0.00866699, -0.000465393, ..., -0.00982666,\n",
       "             -0.00107574, 0.00363159],\n",
       "            ...,\n",
       "            [0.00193787, -0.00178528, 0.0117188, ..., 0.00375366,\n",
       "             -0.00518799, -0.00415039],\n",
       "            [-0.00576782, -0.00338745, -0.0158691, ..., -0.0135498,\n",
       "             0.00976562, -0.00182343],\n",
       "            [0.000747681, -0.00860596, 0.000545502, ..., -0.00326538,\n",
       "             -0.0212402, -0.00579834]],\n",
       "    \n",
       "           [[-0.00534058, -0.00289917, -0.0189209, ..., 0.0020752,\n",
       "             0.0131836, 0.00976562],\n",
       "            [-0.00469971, -0.0137939, -0.0229492, ..., 0.00193787,\n",
       "             0.00415039, 0.00671387],\n",
       "            [0.0344238, -0.000243187, 0.0314941, ..., -0.0183105, 0.0134888,\n",
       "             0.0180664],\n",
       "            ...,\n",
       "            [0.0354004, -0.00952148, 0.00732422, ..., -0.0162354,\n",
       "             0.00183105, -0.00830078],\n",
       "            [-0.00174713, -0.000307083, -0.0013504, ..., 0.0179443,\n",
       "             0.000797272, 0.000595093],\n",
       "            [-0.000766754, 0.0057373, -0.0108643, ..., -0.000553131,\n",
       "             -0.0149536, 0.00376892]],\n",
       "    \n",
       "           [[0.00842285, -0.0273438, 0.00836182, ..., -0.00683594,\n",
       "             -0.00805664, 0.0151978],\n",
       "            [-0.0118408, 0.0202637, -0.0159912, ..., -0.00872803,\n",
       "             -0.0179443, -0.00364685],\n",
       "            [-0.0184326, 0.0144043, -0.00927734, ..., -0.00448608,\n",
       "             0.00346375, -0.0117188],\n",
       "            ...,\n",
       "            [0.0155029, 0.00393677, 0.0115967, ..., -0.0118408, -0.00692749,\n",
       "             0.00178528],\n",
       "            [-0.00439453, 0.00367737, 0.0088501, ..., 0.0140381,\n",
       "             -0.00148773, -0.000299454],\n",
       "            [0.0133667, 0.00762939, -0.00396729, ..., -0.0166016,\n",
       "             0.00270081, -0.00576782]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00759888, 0.0351562, -0.0119019, ..., -0.0136108,\n",
       "             -0.0115967, 0.0172119],\n",
       "            [-0.0022583, -0.00366211, -0.00610352, ..., 0.0100708,\n",
       "             0.0134888, -0.0179443],\n",
       "            [0.0129395, -0.00616455, -0.0150146, ..., 0.012207,\n",
       "             -0.000759125, 0.019165],\n",
       "            ...,\n",
       "            [-0.00104523, 0.0145264, 0.0146484, ..., 0.00897217,\n",
       "             -0.00576782, -0.000854492],\n",
       "            [0.0246582, -0.00204468, -0.00952148, ..., -0.00546265,\n",
       "             0.00274658, 0.0162354],\n",
       "            [-0.00476074, -0.0153198, -0.0137329, ..., 0.00160217,\n",
       "             0.00506592, -0.015564]],\n",
       "    \n",
       "           [[0.0114746, 0.00726318, 0.0198975, ..., -0.0184326, -0.0179443,\n",
       "             -0.00289917],\n",
       "            [-0.017334, -0.00231934, -0.0245361, ..., -0.0219727,\n",
       "             0.00616455, 0.0105591],\n",
       "            [0.00280762, -0.00765991, -0.00469971, ..., 0.00756836,\n",
       "             -0.0167236, -0.0198975],\n",
       "            ...,\n",
       "            [0.00130463, 0.0314941, -0.000253677, ..., -0.00160217,\n",
       "             -0.00866699, 0.0194092],\n",
       "            [0.0158691, 0.00723267, -0.00616455, ..., 0.0130005, -0.0115356,\n",
       "             -0.00167847],\n",
       "            [0.00112915, 0.0167236, -0.0144653, ..., 0.0212402, 0.0101929,\n",
       "             0.0108643]],\n",
       "    \n",
       "           [[-0.0135498, -0.0130615, -0.0126953, ..., 0.013855, 0.00866699,\n",
       "             -0.00372314],\n",
       "            [0.0172119, 1.29342e-05, 0.0118408, ..., -0.0122681, -0.0240479,\n",
       "             0.00686646],\n",
       "            [0.0140991, 0.0159912, 0.00491333, ..., 0.00604248, -0.00994873,\n",
       "             0.00236511],\n",
       "            ...,\n",
       "            [-0.00335693, 0.0145874, -0.0151367, ..., 0.0286865, -0.0229492,\n",
       "             -0.0251465],\n",
       "            [-0.00512695, 0.0109253, 0.0216064, ..., -0.00128174,\n",
       "             0.00283813, -0.00165558],\n",
       "            [0.0284424, -0.0157471, 0.00872803, ..., 0.0169678, 0.00369263,\n",
       "             0.00970459]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00860596, -0.0126343, 0.00297546, ..., 0.00340271,\n",
       "              -0.00137329, 0.00334167],\n",
       "             [-0.00430298, -0.00567627, -0.00491333, ..., -0.0122681,\n",
       "              0.00337219, 0.000347137],\n",
       "             [-0.0140991, -0.00665283, -0.00198364, ..., 0.0109253,\n",
       "              -0.00714111, 0.006073],\n",
       "             ...,\n",
       "             [-0.0101318, -0.00671387, -0.00842285, ..., 0.000900269,\n",
       "              0.00418091, -0.00418091],\n",
       "             [0.022583, 0.0211182, -0.0140991, ..., 0.00358582, 0.0268555,\n",
       "              0.00138855],\n",
       "             [-0.0133667, -0.0012207, 0.00952148, ..., -0.0161133,\n",
       "              -0.00601196, 0.00357056]],\n",
       "    \n",
       "            [[0.0012207, 0.00227356, 0.00137329, ..., -0.0351562,\n",
       "              0.0255127, -0.0220947],\n",
       "             [-0.000549316, -0.000705719, 0.00117493, ..., -0.0100098,\n",
       "              -0.0155029, 0.0195312],\n",
       "             [0.00415039, 0.00106049, 0.00126648, ..., -0.00640869,\n",
       "              0.0039978, -0.00793457],\n",
       "             ...,\n",
       "             [0.00294495, 0.00805664, -0.0062561, ..., -0.0118408,\n",
       "              0.00241089, -0.0131226],\n",
       "             [0.0167236, 0.00270081, 0.0108032, ..., 0.0128174, -0.0252686,\n",
       "              0.0184326],\n",
       "             [-0.00753784, 0.00411987, 0.000591278, ..., -0.0170898,\n",
       "              0.00872803, 0.0187988]],\n",
       "    \n",
       "            [[0.012085, 0.00817871, -0.00866699, ..., 0.00170135,\n",
       "              0.0213623, -0.0035553],\n",
       "             [-0.00878906, -0.0043335, 0.00552368, ..., -0.00405884,\n",
       "              -8.29697e-05, 0.00695801],\n",
       "             [-0.00811768, -0.0101318, 0.00128174, ..., -0.0178223,\n",
       "              -0.00112915, 0.00294495],\n",
       "             ...,\n",
       "             [0.0244141, -0.00762939, -0.0011673, ..., 0.00759888,\n",
       "              -0.0016098, 0.00430298],\n",
       "             [-0.0162354, 0.00500488, -0.0218506, ..., 0.0201416,\n",
       "              0.0267334, 0.0219727],\n",
       "             [-0.00427246, -0.00296021, -0.0103149, ..., -0.019043,\n",
       "              0.00570679, -0.00375366]],\n",
       "    \n",
       "            [[0.00288391, -0.00592041, -0.000976562, ..., -0.0136108,\n",
       "              0.000167847, 0.00439453],\n",
       "             [-0.000230789, -0.000923157, -0.0151978, ..., 0.00294495,\n",
       "              0.0174561, 0.00656128],\n",
       "             [0.0146484, -0.00610352, 0.00289917, ..., -0.000808716,\n",
       "              0.00411987, 0.02771],\n",
       "             ...,\n",
       "             [0.0115356, 0.00735474, 0.00369263, ..., 0.0088501, 0.0107422,\n",
       "              -0.0264893],\n",
       "             [0.00202942, 0.00195312, 0.00970459, ..., 0.0236816,\n",
       "              0.0164795, -0.00193024],\n",
       "             [0.017334, 0.00323486, 0.00567627, ..., -0.0324707, 0.0336914,\n",
       "              -0.0115356]]],\n",
       "    \n",
       "    \n",
       "           [[[0.00292969, 0.000740051, -0.0045166, ..., -0.0185547,\n",
       "              0.010437, -0.0174561],\n",
       "             [-0.00598145, 0.00741577, 0.00927734, ..., -0.00396729,\n",
       "              0.00491333, -0.00479126],\n",
       "             [0.0098877, -0.00224304, 0.00445557, ..., 0.00259399,\n",
       "              -0.0125732, 0.00830078],\n",
       "             ...,\n",
       "             [-0.00650024, -0.012085, -0.00346375, ..., 0.0240479,\n",
       "              -0.00349426, 0.0234375],\n",
       "             [-0.0187988, -0.00323486, -0.00285339, ..., -0.00457764,\n",
       "              0.00799561, 0.00228882],\n",
       "             [-0.00872803, 0.00909424, -0.0050354, ..., -9.25064e-05,\n",
       "              0.0194092, 0.0128784]],\n",
       "    \n",
       "            [[0.0167236, -0.0213623, -0.00457764, ..., 0.013916,\n",
       "              -0.00582886, -0.00069046],\n",
       "             [-0.00405884, -0.00823975, -0.00268555, ..., 0.0290527,\n",
       "              0.00854492, -0.00393677],\n",
       "             [-0.0136108, 0.000314713, 0.0187988, ..., -0.00323486,\n",
       "              -0.0119629, -0.027832],\n",
       "             ...,\n",
       "             [0.0179443, -0.0113525, 0.00358582, ..., -0.010437,\n",
       "              -0.00836182, -0.010437],\n",
       "             [-0.0130005, 0.003479, 0.0109863, ..., 0.0111084, 0.000774384,\n",
       "              -0.00424194],\n",
       "             [0.00140381, 0.00811768, -0.00088501, ..., 0.00723267,\n",
       "              -0.0134277, 0.00144958]],\n",
       "    \n",
       "            [[-0.0235596, -0.0134888, 0.020874, ..., 0.0102539, 0.0120239,\n",
       "              -0.0088501],\n",
       "             [0.0290527, 0.0025177, -0.00473022, ..., -0.00842285,\n",
       "              -0.00817871, -0.00637817],\n",
       "             [-0.00328064, -0.00946045, -0.0269775, ..., 0.00204468,\n",
       "              0.0057373, -0.00421143],\n",
       "             ...,\n",
       "             [-0.0308838, 0.00473022, -0.012146, ..., 0.013916, 0.00201416,\n",
       "              0.00842285],\n",
       "             [-0.00043869, 0.00289917, 0.000801086, ..., -0.00311279,\n",
       "              -0.00540161, -0.010437],\n",
       "             [0.00063324, -0.010498, -0.000637054, ..., 0.00488281,\n",
       "              -0.00823975, 0.0158691]],\n",
       "    \n",
       "            [[0.0120239, -0.00735474, 0.0050354, ..., -0.00439453,\n",
       "              0.0111084, -0.000492096],\n",
       "             [0.0117798, 0.010498, 0.00192261, ..., -0.0230713, -0.019165,\n",
       "              -0.0107422],\n",
       "             [-0.00994873, 0.0102539, 0.0114746, ..., 0.0283203, 0.0162354,\n",
       "              -0.00262451],\n",
       "             ...,\n",
       "             [-0.000835419, 0.0152588, 0.0167236, ..., 0.00222778,\n",
       "              0.0101318, -0.00183105],\n",
       "             [0.00762939, 0.00259399, -0.00683594, ..., -0.0123901,\n",
       "              0.00756836, -0.00622559],\n",
       "             [0.0195312, 0.0118408, 0.0289307, ..., -0.0236816, -0.010376,\n",
       "              -0.0157471]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.0055542, -0.00805664, 0.000514984, ..., 0.00656128,\n",
       "             0.00552368, 0.00491333],\n",
       "            [0.0116577, 0.000495911, 0.0125122, ..., -0.00646973,\n",
       "             0.00325012, -0.00114441],\n",
       "            [-0.0297852, -0.0129395, 0.00775146, ..., 0.0032196, 0.0133057,\n",
       "             0.00811768],\n",
       "            ...,\n",
       "            [-0.0107422, -0.00308228, 0.0147095, ..., 0.000801086,\n",
       "             0.000576019, -0.00631714],\n",
       "            [0.00799561, 0.0065918, -0.00473022, ..., 0.00570679,\n",
       "             -0.0192871, 0.00202942],\n",
       "            [-0.0062561, 0.00427246, 0.00332642, ..., -0.0118408,\n",
       "             0.00765991, 0.00872803]],\n",
       "    \n",
       "           [[-0.00357056, 0.00469971, -0.00646973, ..., 0.012085,\n",
       "             0.00153351, 0.0211182],\n",
       "            [-0.00518799, 0.00328064, 0.0220947, ..., 0.00732422,\n",
       "             0.000648499, -0.0126343],\n",
       "            [-0.00137329, -0.00276184, 0.00735474, ..., -0.0112305,\n",
       "             0.00178528, -0.00915527],\n",
       "            ...,\n",
       "            [-0.0233154, 0.00933838, 0.0290527, ..., -0.0140991, 0.00222778,\n",
       "             -0.0236816],\n",
       "            [-0.00177765, 0.00328064, -0.0062561, ..., 0.00427246,\n",
       "             -0.0168457, 0.00653076],\n",
       "            [-0.00212097, -0.0100708, -0.0134277, ..., -0.00500488,\n",
       "             0.00741577, -0.000255585]],\n",
       "    \n",
       "           [[0.00177765, 0.00735474, 0.00424194, ..., -0.012207, 0.022583,\n",
       "             -0.0253906],\n",
       "            [-0.00720215, -0.0100098, -0.0150757, ..., -0.0375977,\n",
       "             -0.0050354, 0.0361328],\n",
       "            [-0.00714111, -0.0100708, 0.000379562, ..., -0.013916,\n",
       "             -0.00753784, -0.0101929],\n",
       "            ...,\n",
       "            [0.00927734, 0.0134888, 0.0196533, ..., 0.00512695, -0.00296021,\n",
       "             -0.0109863],\n",
       "            [-0.00405884, -0.00479126, -0.00147247, ..., -0.00363159,\n",
       "             0.00122833, 0.0177002],\n",
       "            [-0.00430298, 0.000303268, -0.00799561, ..., -0.0166016,\n",
       "             0.0250244, 0.0133667]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00171661, 0.00564575, 0.00317383, ..., -0.0098877,\n",
       "             -0.0019989, -0.00119019],\n",
       "            [-0.012146, -0.00265503, -0.0108643, ..., -0.003479,\n",
       "             -0.00534058, -0.00561523],\n",
       "            [0.0170898, -0.0218506, 0.0147095, ..., -0.00390625,\n",
       "             -0.00216675, 0.00521851],\n",
       "            ...,\n",
       "            [-0.00567627, 0.00378418, -0.00408936, ..., -0.00982666,\n",
       "             -0.0147705, -0.000123024],\n",
       "            [-0.00126648, -0.00174713, 0.00787354, ..., 0.00285339,\n",
       "             0.00145721, -0.00379944],\n",
       "            [0.00720215, 0.00585938, -0.000553131, ..., 0.00549316,\n",
       "             0.00799561, 0.00753784]],\n",
       "    \n",
       "           [[-0.00219727, 0.00297546, 0.000383377, ..., -0.00288391,\n",
       "             -0.00552368, -0.00463867],\n",
       "            [0.00909424, -0.0147095, 0.00230408, ..., -0.00222778,\n",
       "             0.00384521, -0.00613403],\n",
       "            [0.00328064, -0.00509644, 0.00169373, ..., -0.00756836,\n",
       "             0.0108643, -0.0163574],\n",
       "            ...,\n",
       "            [-0.00186157, 0.000797272, 0.0109253, ..., -0.00946045,\n",
       "             -0.0292969, 0.0361328],\n",
       "            [-0.0198975, 0.00466919, -0.00646973, ..., 0.0102539,\n",
       "             -0.00878906, -0.000865936],\n",
       "            [0.00254822, 9.9659e-05, 0.000142097, ..., -0.00396729,\n",
       "             -0.02771, 0.0216064]],\n",
       "    \n",
       "           [[-0.00662231, 0.00915527, 0.00976562, ..., -0.00753784,\n",
       "             -0.00247192, -0.00189972],\n",
       "            [0.00457764, 0.0137939, 0.0172119, ..., -0.00114441,\n",
       "             -0.000972748, 0.000953674],\n",
       "            [-0.00309753, -0.0206299, -0.00161743, ..., -0.0111084,\n",
       "             0.00375366, 0.00372314],\n",
       "            ...,\n",
       "            [0.00430298, -0.00370789, 0.00183868, ..., 0.000461578,\n",
       "             0.00300598, -0.00708008],\n",
       "            [0.00195312, 0.00753784, -0.0101318, ..., 0.00787354,\n",
       "             0.00823975, 0.00479126],\n",
       "            [-0.00878906, 0.00364685, 0.00169373, ..., 0.000904083,\n",
       "             7.00951e-05, -0.00482178]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00107574, 0.00662231, -0.00872803, ..., 0.00561523,\n",
       "            0.00909424, 0.00312805],\n",
       "           [0.00601196, 0.00418091, 0.0105591, ..., 0.00534058, 0.013855,\n",
       "            0.00239563],\n",
       "           [0.00866699, -0.00952148, 0.000545502, ..., -0.00732422,\n",
       "            0.0146484, 0.00436401],\n",
       "           ...,\n",
       "           [-0.00112152, -0.00421143, 0.00994873, ..., -0.00723267,\n",
       "            -0.0111694, -0.00160217],\n",
       "           [0.0150146, 0.00436401, -0.0100098, ..., -0.00787354,\n",
       "            -0.00469971, 0.0131836],\n",
       "           [-0.000587463, 0.00497437, 0.0137329, ..., 0.00494385,\n",
       "            -0.000392914, -0.0118408]],\n",
       "   \n",
       "          [[0.000370026, -0.0118408, 0.0289307, ..., -0.0141602,\n",
       "            -0.00805664, 0.00604248],\n",
       "           [-0.001297, 0.000196457, -0.0127563, ..., 0.00222778, -0.013916,\n",
       "            -0.000614166],\n",
       "           [-0.00506592, 0.0108032, 0.00958252, ..., -0.00375366,\n",
       "            -0.00933838, -0.00294495],\n",
       "           ...,\n",
       "           [-0.0038147, -0.010376, -0.0035553, ..., 0.0106812, 0.00361633,\n",
       "            0.00717163],\n",
       "           [0.0043335, -0.000686646, 0.0147095, ..., -0.000180244,\n",
       "            0.0072937, 0.00282288],\n",
       "           [0.0012207, 0.0111694, -0.00491333, ..., -0.00860596,\n",
       "            -0.00909424, 0.00283813]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.00415039, -0.00134277, -0.00189972, ..., -0.00366211,\n",
       "           -0.00107574, 0.0043335],\n",
       "          [-0.00744629, 0.00726318, 0.00897217, ..., -0.00308228,\n",
       "           0.000663757, 0.00537109],\n",
       "          [0.0150757, -0.0078125, -0.00244141, ..., -0.00817871,\n",
       "           -0.00775146, -0.00631714],\n",
       "          ...,\n",
       "          [-0.00402832, -0.0148926, -0.0030365, ..., 0.00756836, -0.0161133,\n",
       "           -0.00457764],\n",
       "          [-0.00692749, -0.00289917, -0.0108032, ..., 0.00891113,\n",
       "           -0.00732422, -0.00613403],\n",
       "          [0.0161133, -0.00332642, 0.00631714, ..., 0.00497437, 0.00384521,\n",
       "           -0.00491333]], dtype=bfloat16), a=Array([[-0.00584595, -0.00180545, -0.00662199, ..., -0.0220709 ,\n",
       "           -0.00569964, -0.00861686],\n",
       "          [ 0.00151854, -0.00964406,  0.00366633, ...,  0.00940564,\n",
       "           -0.00930284,  0.00364371]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.0136108, -0.150391, -0.020874, ..., -0.355469, -0.0186768,\n",
       "          -0.425781], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.0888672, 0.0622559, 0.12793, ..., -0.00866699, 0.337891,\n",
       "          0.0756836], dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.490234, 0.255859, 0.330078, ..., 0.367188, -0.0544434, 0.046875],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.388672, 0.382812, 0.402344, ..., 0.597656, -0.0415039, 0.236328],      dtype=bfloat16)}},\n",
       " 'layer_6': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.0103149, 0.000452042, -0.0153809, ..., -0.00915527,\n",
       "             0.0106201, 0.00836182],\n",
       "            [-0.00848389, 0.0072937, 0.000648499, ..., -0.00823975,\n",
       "             0.010437, 0.0090332],\n",
       "            [0.00927734, -0.00402832, -0.00141907, ..., -0.00317383,\n",
       "             0.0161133, 0.00418091],\n",
       "            ...,\n",
       "            [0.0145874, 0.0222168, 0.00640869, ..., 0.00817871, -0.0137329,\n",
       "             -0.0114746],\n",
       "            [-0.00668335, 0.00195312, 0.00424194, ..., -0.00133514,\n",
       "             0.000226974, 0.0030365],\n",
       "            [-0.00195312, 0.00558472, -0.020752, ..., 0.00830078,\n",
       "             -0.0014801, 0.00341797]],\n",
       "    \n",
       "           [[-0.00139618, 0.000881195, -0.0119019, ..., 0.0112305,\n",
       "             -0.00799561, -0.0140381],\n",
       "            [0.0164795, -0.0131226, 0.00582886, ..., 0.000228882,\n",
       "             -0.00772095, -0.00708008],\n",
       "            [0.00170135, 0.00753784, -0.00842285, ..., 0.00558472,\n",
       "             0.00601196, -0.00221252],\n",
       "            ...,\n",
       "            [-0.00509644, 0.00665283, 0.0127563, ..., -0.00933838,\n",
       "             0.0127563, -0.000141144],\n",
       "            [-0.0123901, -0.0179443, 0.0045166, ..., -0.00765991,\n",
       "             0.00133514, 0.00390625],\n",
       "            [0.00202942, -0.00221252, 0.00424194, ..., 0.00567627,\n",
       "             -0.00515747, 0.0050354]],\n",
       "    \n",
       "           [[0.000213623, 0.000831604, -0.00720215, ..., -0.00933838,\n",
       "             0.00186157, -0.00527954],\n",
       "            [0.0113525, 0.00405884, -0.00585938, ..., -0.00253296,\n",
       "             0.00497437, 0.0174561],\n",
       "            [0.00136566, 0.00189972, 0.00570679, ..., -0.00704956,\n",
       "             0.00174713, -0.00358582],\n",
       "            ...,\n",
       "            [0.0130005, 3.40939e-05, 0.0153198, ..., 0.00112915,\n",
       "             -0.00247192, -0.0131226],\n",
       "            [-0.00646973, -0.0108643, 0.00628662, ..., 0.00312805,\n",
       "             0.00244141, -0.00848389],\n",
       "            [-0.00915527, 0.00836182, 0.000206947, ..., -0.013916,\n",
       "             -0.0111694, -0.00512695]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.000766754, 0.00285339, -0.0065918, ..., -0.0184326,\n",
       "             -0.00286865, 0.00170898],\n",
       "            [-0.000185966, -0.0106201, 0.0113525, ..., 0.00747681,\n",
       "             -0.0127563, 0.0106812],\n",
       "            [0.0137329, -0.00848389, -0.00120544, ..., 0.00320435,\n",
       "             0.00723267, 0.00897217],\n",
       "            ...,\n",
       "            [0.00897217, -0.00102997, -0.0257568, ..., -0.00686646,\n",
       "             -0.00753784, 0.0133057],\n",
       "            [0.00848389, -0.00141907, 0.0270996, ..., 0.00219727, 0.0145874,\n",
       "             0.000261307],\n",
       "            [0.000204086, -0.00363159, -0.0090332, ..., -0.00198364,\n",
       "             0.00509644, -0.0154419]],\n",
       "    \n",
       "           [[0.00147247, -0.00531006, -0.00402832, ..., -0.00970459,\n",
       "             -0.00613403, 0.0113525],\n",
       "            [-0.000453949, 0.026001, -0.00872803, ..., -0.00136566,\n",
       "             -0.000320435, -0.000239372],\n",
       "            [-0.0256348, 0.00075531, -0.017334, ..., 0.00897217, -0.0238037,\n",
       "             0.0200195],\n",
       "            ...,\n",
       "            [-0.00592041, -0.00314331, -0.00317383, ..., -0.0189209,\n",
       "             -0.00540161, -0.0119629],\n",
       "            [-0.0131226, 0.0118408, -0.0125122, ..., 0.00273132, 0.00506592,\n",
       "             -0.00811768],\n",
       "            [0.0192871, 0.00479126, -0.0145874, ..., 0.0119629, 0.00408936,\n",
       "             0.0240479]],\n",
       "    \n",
       "           [[0.0143433, 0.0111084, 0.0145874, ..., 0.0169678, 0.00964355,\n",
       "             -0.0144653],\n",
       "            [-0.00552368, -0.020752, -0.00296021, ..., 0.000173569,\n",
       "             0.00692749, -0.00939941],\n",
       "            [0.00643921, 0.00335693, 0.0230713, ..., 0.00567627, 0.00473022,\n",
       "             -0.0140381],\n",
       "            ...,\n",
       "            [0.0194092, -0.0213623, -0.00799561, ..., -0.00506592,\n",
       "             -0.0227051, 0.0147705],\n",
       "            [0.00509644, 0.000545502, 0.00180054, ..., -0.000682831,\n",
       "             -0.0162354, 0.00823975],\n",
       "            [-0.0132446, -0.0142212, 0.00799561, ..., -0.0128784,\n",
       "             -0.00352478, 0.00427246]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.000455856, 0.0103149, 0.00732422, ..., -0.000148773,\n",
       "              0.00927734, -0.00491333],\n",
       "             [0.00102997, 0.0098877, -0.00289917, ..., -0.0123901,\n",
       "              0.0214844, -0.0014801],\n",
       "             [-0.00241089, -0.00753784, 0.00866699, ..., -0.0126953,\n",
       "              -0.00445557, -0.00531006],\n",
       "             ...,\n",
       "             [-0.0113525, -0.00476074, 0.00805664, ..., -0.00701904,\n",
       "              0.00149536, -0.0150757],\n",
       "             [0.00291443, -0.00144196, -0.00248718, ..., -0.0127563,\n",
       "              0.00787354, 0.00860596],\n",
       "             [-0.00491333, -0.0284424, -0.00473022, ..., -0.0027771,\n",
       "              0.0148926, -0.036377]],\n",
       "    \n",
       "            [[-0.000293732, 0.0032959, -0.00772095, ..., 0.00653076,\n",
       "              0.0252686, -0.0090332],\n",
       "             [0.00537109, -0.00390625, -0.0071106, ..., -0.0101318,\n",
       "              0.0175781, 0.0109253],\n",
       "             [0.00364685, -0.00331116, -0.00143433, ..., 0.00521851,\n",
       "              -0.0212402, 0.0103149],\n",
       "             ...,\n",
       "             [-0.00209045, -0.000530243, -0.00294495, ..., -2.36034e-05,\n",
       "              0.0162354, -0.019043],\n",
       "             [-0.00506592, -0.00823975, 0.00640869, ..., -0.0103149,\n",
       "              -0.00860596, 0.0249023],\n",
       "             [-0.00546265, 0.00424194, 0.0067749, ..., -0.00125885,\n",
       "              0.00708008, -0.0262451]],\n",
       "    \n",
       "            [[0.0105591, 0.00686646, -0.00466919, ..., 0.00305176,\n",
       "              0.00189972, -0.0249023],\n",
       "             [-0.0205078, 0.00360107, -0.00245667, ..., -0.00592041,\n",
       "              -0.00291443, -0.0115356],\n",
       "             [0.00370789, 0.00735474, -0.001297, ..., -0.0100098,\n",
       "              -0.0131226, 0.0205078],\n",
       "             ...,\n",
       "             [-0.00982666, -0.0019455, -0.010437, ..., 0.0102539,\n",
       "              -0.00343323, 0.00436401],\n",
       "             [0.00732422, 0.00485229, -0.00686646, ..., -0.0137939,\n",
       "              -0.0257568, 0.0151978],\n",
       "             [0.0071106, -1.80006e-05, 0.00952148, ..., -0.012085,\n",
       "              -0.0131836, 0.0078125]],\n",
       "    \n",
       "            [[-0.0126343, 0.00325012, 0.0142212, ..., 0.00141144,\n",
       "              0.00305176, -0.00305176],\n",
       "             [0.00169373, 0.00543213, -0.00280762, ..., -0.00227356,\n",
       "              0.0112915, -0.0206299],\n",
       "             [0.000404358, 0.00021553, -0.0057373, ..., -0.0122681,\n",
       "              -0.00689697, 0.00460815],\n",
       "             ...,\n",
       "             [0.0126953, -0.00762939, -0.00289917, ..., 0.0013504,\n",
       "              0.00952148, 0.00028801],\n",
       "             [-0.00933838, 0.000434875, 0.00897217, ..., -0.0016861,\n",
       "              -0.00872803, -0.00689697],\n",
       "             [-0.00769043, 0.00216675, 0.0039978, ..., -0.00732422,\n",
       "              0.0101929, -0.00488281]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0169678, 0.0133057, -0.00382996, ..., -0.0045166,\n",
       "              0.00396729, -0.00375366],\n",
       "             [0.00306702, -0.0106201, 0.00506592, ..., -0.0151978,\n",
       "              -0.0195312, -0.0144043],\n",
       "             [0.00933838, -0.00732422, 0.00561523, ..., -0.00769043,\n",
       "              0.00219727, 0.0233154],\n",
       "             ...,\n",
       "             [0.00150299, 0.00390625, 0.00485229, ..., -0.0098877,\n",
       "              -0.0010376, -0.00692749],\n",
       "             [-0.00137329, -0.00047493, -0.00680542, ..., 0.0151367,\n",
       "              -0.0136719, -0.00270081],\n",
       "             [-7.43866e-05, -0.0111084, -0.00136566, ..., 0.0130005,\n",
       "              -0.0016861, -0.00521851]],\n",
       "    \n",
       "            [[0.000530243, -0.00982666, -0.00209045, ..., 0.0055542,\n",
       "              0.00958252, -0.0108643],\n",
       "             [0.00952148, -4.86374e-05, 0.0100098, ..., 0.0111084,\n",
       "              -0.012085, 0.0124512],\n",
       "             [0.00178528, 0.00854492, -0.00309753, ..., 0.00680542,\n",
       "              -0.00193787, 0.000576019],\n",
       "             ...,\n",
       "             [-0.0231934, 0.0222168, -0.0140991, ..., -0.0112915,\n",
       "              0.0137329, -0.0142212],\n",
       "             [0.00014782, 0.00350952, 0.0011673, ..., 0.000656128,\n",
       "              -0.00540161, -0.00939941],\n",
       "             [0.0119019, -0.00411987, -0.0139771, ..., 0.00338745,\n",
       "              0.00595093, 0.00124359]],\n",
       "    \n",
       "            [[-0.00436401, 0.00735474, -0.00476074, ..., 0.0153198,\n",
       "              0.00787354, -0.00982666],\n",
       "             [-0.000188828, -0.0385742, 0.00534058, ..., -0.010498,\n",
       "              -0.00671387, 0.00643921],\n",
       "             [-0.00759888, 0.0118408, 0.0224609, ..., 0.0130005,\n",
       "              -0.0131226, -0.00038147],\n",
       "             ...,\n",
       "             [0.0158691, 0.0115967, 0.0100098, ..., 0.0170898, -0.00476074,\n",
       "              -0.00415039],\n",
       "             [0.0122681, 0.00233459, -0.0057373, ..., 0.00326538,\n",
       "              -0.0027771, -0.0107422],\n",
       "             [-0.0118408, 0.00346375, 0.000219345, ..., 0.0126953,\n",
       "              -0.00338745, 0.0299072]],\n",
       "    \n",
       "            [[0.00305176, 0.00279236, 0.0185547, ..., 0.0025177,\n",
       "              0.00601196, -0.020752],\n",
       "             [0.00424194, -0.0354004, 0.0198975, ..., 0.00689697,\n",
       "              -0.00350952, 0.00238037],\n",
       "             [0.0114746, -0.0184326, 0.034668, ..., 0.00744629, 0.0227051,\n",
       "              0.0137329],\n",
       "             ...,\n",
       "             [0.00567627, 0.010437, 0.00114441, ..., 0.0100098, 0.0133057,\n",
       "              -0.0177002],\n",
       "             [0.00537109, -0.000709534, 0.0102539, ..., 0.00421143,\n",
       "              -0.00830078, -0.0122681],\n",
       "             [-0.0134888, 0.0140381, -0.0150146, ..., 0.00601196,\n",
       "              0.0192871, -0.0090332]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.0222168, -0.0038147, -0.00323486, ..., 0.00360107,\n",
       "             0.0177002, 0.00436401],\n",
       "            [-0.0290527, -0.00921631, 0.0100708, ..., -0.0203857,\n",
       "             0.00300598, -0.00132751],\n",
       "            [0.00343323, 0.00311279, 0.000858307, ..., -0.0071106,\n",
       "             -0.00448608, 0.00787354],\n",
       "            ...,\n",
       "            [0.00173187, -0.0106201, -0.00485229, ..., 0.00546265,\n",
       "             0.0050354, -0.000135422],\n",
       "            [0.00382996, 0.0151978, 0.00439453, ..., -0.00369263,\n",
       "             -0.00946045, -0.0043335],\n",
       "            [-0.0130615, -0.00692749, -0.00402832, ..., -0.00271606,\n",
       "             0.0134888, -0.013855]],\n",
       "    \n",
       "           [[-0.00326538, -0.00286865, -0.0071106, ..., 0.00704956,\n",
       "             0.0125732, 0.00878906],\n",
       "            [-0.00976562, -0.00282288, -0.00113678, ..., 0.00485229,\n",
       "             0.000238419, 0.00750732],\n",
       "            [0.00150299, -0.00927734, -0.0057373, ..., -0.022583,\n",
       "             -0.000999451, -0.0102539],\n",
       "            ...,\n",
       "            [0.00182343, -0.00138855, -0.00921631, ..., -0.00469971,\n",
       "             0.00531006, 0.0137939],\n",
       "            [-0.00933838, 0.00244141, 0.00227356, ..., 0.000919342,\n",
       "             -0.0133057, -0.0200195],\n",
       "            [-0.0038147, 0.0150757, -0.00109863, ..., -0.03125, -0.022583,\n",
       "             -0.029541]],\n",
       "    \n",
       "           [[0.00747681, -0.00485229, -0.00646973, ..., 0.00224304,\n",
       "             0.010376, -0.00799561],\n",
       "            [0.000141144, 0.00921631, -0.000892639, ..., 0.000322342,\n",
       "             -0.00308228, 0.00210571],\n",
       "            [-0.00686646, 0.00305176, 0.00552368, ..., 0.000675201,\n",
       "             0.00379944, -0.00427246],\n",
       "            ...,\n",
       "            [-0.00643921, 0.00442505, 0.00175476, ..., 0.000134468,\n",
       "             0.0045166, -0.00793457],\n",
       "            [0.00300598, -0.00616455, 0.00460815, ..., 0.000312805,\n",
       "             0.00302124, -0.0101318],\n",
       "            [0.00976562, 0.00756836, -0.00260925, ..., -0.00376892,\n",
       "             -0.00364685, 0.00260925]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00341797, -0.0178223, -0.00263977, ..., -0.0050354,\n",
       "             -0.00256348, -0.00253296],\n",
       "            [0.00524902, 0.0103149, 0.0269775, ..., 0.00267029, -0.00753784,\n",
       "             -0.00415039],\n",
       "            [-0.0119019, -0.00469971, -0.00793457, ..., 0.00915527,\n",
       "             0.00854492, 0.00762939],\n",
       "            ...,\n",
       "            [-0.00439453, 0.0129395, -0.00427246, ..., -0.00674438,\n",
       "             0.00775146, 0.00909424],\n",
       "            [0.00515747, 0.0032196, 0.0117798, ..., 0.0170898, -0.00352478,\n",
       "             -0.0050354],\n",
       "            [-0.00500488, -0.00717163, -0.00297546, ..., -0.0203857,\n",
       "             -0.0115967, 0.0153198]],\n",
       "    \n",
       "           [[0.0142212, -0.00180817, 0.0267334, ..., 0.00585938,\n",
       "             3.86238e-05, -0.00527954],\n",
       "            [0.0144043, 0.00242615, -0.0022583, ..., -0.0164795, 0.00509644,\n",
       "             -0.000171661],\n",
       "            [0.0071106, -0.00224304, 0.00415039, ..., -0.019165, -0.0152588,\n",
       "             0.0122681],\n",
       "            ...,\n",
       "            [0.0212402, 0.0167236, -0.0139771, ..., 0.00204468, 0.00564575,\n",
       "             -0.012207],\n",
       "            [-0.00286865, 0.00202942, 0.00476074, ..., -0.0131836,\n",
       "             8.53539e-05, -0.00136566],\n",
       "            [-0.0130005, 0.00653076, -0.00497437, ..., -0.0153809,\n",
       "             -0.0105591, -0.000511169]],\n",
       "    \n",
       "           [[0.00946045, 0.0224609, 0.00149536, ..., 0.00680542,\n",
       "             -0.00233459, -0.000579834],\n",
       "            [0.00564575, -0.00680542, 0.0214844, ..., -0.00314331,\n",
       "             0.0267334, 0.00921631],\n",
       "            [-0.00897217, 0.00701904, 0.00325012, ..., 0.0114746, 0.0117188,\n",
       "             0.0281982],\n",
       "            ...,\n",
       "            [-0.0103149, 0.00854492, -0.0134277, ..., 0.00439453,\n",
       "             -0.0151978, -0.000740051],\n",
       "            [0.0101929, 0.000904083, 0.00921631, ..., 0.00299072,\n",
       "             -0.0177002, -0.0187988],\n",
       "            [0.000965118, -8.39233e-05, -0.00202942, ..., 5.50747e-05,\n",
       "             0.0045166, -0.00463867]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00227356, -0.00634766, 0.00634766, ..., 0.00701904,\n",
       "            -0.00534058, -0.010437],\n",
       "           [-0.00436401, 0.00524902, 0.010498, ..., -0.0154419, 0.00756836,\n",
       "            8.34465e-05],\n",
       "           [0.0131836, 0.00268555, -0.00683594, ..., -0.0106201, 0.0062561,\n",
       "            0.0111694],\n",
       "           ...,\n",
       "           [0.00276184, -0.00314331, 0.00430298, ..., 0.00805664,\n",
       "            0.00512695, -0.00231934],\n",
       "           [-0.00445557, -0.00280762, 0.00332642, ..., -0.000785828,\n",
       "            0.0057373, -0.00325012],\n",
       "           [0.00164795, -0.00454712, 0.00165558, ..., 0.00631714,\n",
       "            -0.015564, 0.00375366]],\n",
       "   \n",
       "          [[-0.012207, -0.00622559, 0.00708008, ..., -0.00509644,\n",
       "            -0.00747681, 0.00708008],\n",
       "           [0.000263214, 0.00325012, 0.0228271, ..., -0.00393677,\n",
       "            0.00662231, -0.00650024],\n",
       "           [-0.0136108, 0.0100098, 0.00157928, ..., -0.00756836,\n",
       "            0.00402832, 0.00125122],\n",
       "           ...,\n",
       "           [0.0112915, 0.00143433, 0.00512695, ..., 0.00671387, 0.00279236,\n",
       "            0.0142212],\n",
       "           [-0.00765991, -0.00976562, -0.00114441, ..., -0.00665283,\n",
       "            -0.003479, -0.0107422],\n",
       "           [0.00534058, -0.013916, 0.00494385, ..., -0.00126648,\n",
       "            0.00259399, 0.00302124]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.0153198, -0.00793457, -0.0203857, ..., 0.0152588, -0.00891113,\n",
       "           0.00259399],\n",
       "          [-0.0142212, 0.0132446, 0.00976562, ..., 0.0123291, 0.00534058,\n",
       "           -0.00445557],\n",
       "          [0.00244141, 0.00318909, -0.0145264, ..., -0.000740051,\n",
       "           -0.00265503, -0.00405884],\n",
       "          ...,\n",
       "          [-0.0153198, 0.00187683, -0.00402832, ..., 0.00842285, -0.0174561,\n",
       "           0.00157928],\n",
       "          [0.0014801, 0.0045166, -0.00524902, ..., -0.0020752, -0.0114136,\n",
       "           -0.00146484],\n",
       "          [0.00230408, -0.0117188, -0.00201416, ..., 0.00970459, -0.019043,\n",
       "           -0.00352478]], dtype=bfloat16), a=Array([[-0.0155806 , -0.01371003, -0.01509875, ...,  0.01296713,\n",
       "            0.00798594,  0.00760426],\n",
       "          [-0.00061655,  0.01749108, -0.01459254, ...,  0.01223726,\n",
       "           -0.01537374,  0.00116413]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.0039978, -0.124512, -0.0678711, ..., -0.241211, 0.00665283,\n",
       "          -0.359375], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.106934, 0.0874023, 0.219727, ..., 0.0168457, 0.365234, 0.10498],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([1.10156, 0.796875, 0.84375, ..., 0.988281, 0.0463867, 0.369141],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.435547, 0.447266, 0.443359, ..., 0.636719, -0.0673828, 0.363281],      dtype=bfloat16)}},\n",
       " 'layer_7': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.0178223, 0.00132751, -0.00531006, ..., 0.00689697,\n",
       "             -0.00561523, -0.00982666],\n",
       "            [-0.00958252, 0.0183105, -0.00515747, ..., 0.00263977,\n",
       "             -0.0137329, 0.00741577],\n",
       "            [0.000368118, -0.0192871, -0.0109253, ..., -0.0161133,\n",
       "             -0.0101318, -0.00698853],\n",
       "            ...,\n",
       "            [-0.013916, 0.00430298, -0.0222168, ..., 0.012207, -0.0014267,\n",
       "             -0.0120239],\n",
       "            [0.0148926, 0.0256348, 0.00123596, ..., 0.00317383, 0.00466919,\n",
       "             -0.00753784],\n",
       "            [0.0072937, -0.00842285, 0.0294189, ..., -0.0128784,\n",
       "             -0.00473022, -0.0011673]],\n",
       "    \n",
       "           [[-0.003479, 0.0122681, 0.00640869, ..., 0.00193787, -0.0123291,\n",
       "             0.00357056],\n",
       "            [0.00473022, 0.00558472, -0.00219727, ..., -0.00323486,\n",
       "             0.006073, 0.0209961],\n",
       "            [0.00512695, 0.0111694, 0.0202637, ..., 0.0144653, 0.00309753,\n",
       "             -0.012146],\n",
       "            ...,\n",
       "            [0.00119781, 0.00276184, -0.0175781, ..., 0.00291443,\n",
       "             0.00485229, 0.00222778],\n",
       "            [0.00202942, -0.00506592, 0.000371933, ..., 0.00122833,\n",
       "             0.00982666, 0.000289917],\n",
       "            [0.00482178, -0.00283813, 0.0124512, ..., -0.000366211,\n",
       "             -0.000431061, 0.000459671]],\n",
       "    \n",
       "           [[0.00561523, 0.00195312, 0.00946045, ..., -0.017334, -0.0109253,\n",
       "             0.00720215],\n",
       "            [-0.00279236, 0.0131836, 0.0019989, ..., -0.0088501,\n",
       "             -0.00515747, -0.000488281],\n",
       "            [-0.0145874, 0.0166016, -0.00340271, ..., 0.0134277, 0.00668335,\n",
       "             0.0136108],\n",
       "            ...,\n",
       "            [0.00939941, 0.0111084, -0.0119019, ..., 0.0152588, 0.00708008,\n",
       "             0.00460815],\n",
       "            [-0.0251465, 0.00286865, -0.0132446, ..., -0.0241699,\n",
       "             -0.00201416, 0.0144043],\n",
       "            [-0.00271606, 0.0169678, -0.0164795, ..., -0.00570679,\n",
       "             0.00230408, 0.00202942]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0133667, -0.00288391, 0.00558472, ..., -0.0107422,\n",
       "             -0.0145264, -0.017334],\n",
       "            [-0.00236511, 0.00396729, 0.00756836, ..., 0.00177765,\n",
       "             -0.00209045, -0.00915527],\n",
       "            [-0.0120239, 0.0245361, 0.0170898, ..., -0.00430298,\n",
       "             -0.00759888, -0.00427246],\n",
       "            ...,\n",
       "            [-0.0170898, -0.0217285, -0.00692749, ..., -0.0114746,\n",
       "             -0.0246582, 0.00576782],\n",
       "            [0.0158691, 0.0055542, -0.00793457, ..., 0.0162354, -0.0145874,\n",
       "             -0.00698853],\n",
       "            [0.0062561, -0.00585938, -0.00787354, ..., 0.00933838,\n",
       "             -0.026123, 0.0288086]],\n",
       "    \n",
       "           [[-0.00793457, -0.00921631, -0.00382996, ..., -2.03848e-05,\n",
       "             0.00524902, -0.00964355],\n",
       "            [-0.0197754, 0.00185394, -0.00558472, ..., 0.0071106,\n",
       "             -0.0187988, 0.00512695],\n",
       "            [0.00952148, -0.0161133, 0.00842285, ..., -0.0150146,\n",
       "             -0.00309753, -0.00830078],\n",
       "            ...,\n",
       "            [-0.0014801, 0.0142822, 0.0101929, ..., -0.0032196, 0.0327148,\n",
       "             0.00595093],\n",
       "            [-0.00427246, 0.00915527, -0.0161133, ..., -0.00692749,\n",
       "             0.0125732, 0.0112305],\n",
       "            [0.0132446, -0.00823975, 0.012146, ..., -0.0247803, -0.00909424,\n",
       "             -0.00604248]],\n",
       "    \n",
       "           [[-0.00842285, 0.00579834, -0.00121307, ..., 0.00442505,\n",
       "             -0.0157471, 0.00104523],\n",
       "            [-0.0142822, -0.00132751, -0.0123901, ..., -0.010437,\n",
       "             0.00576782, -0.0144043],\n",
       "            [-0.0144653, -0.00260925, 0.00946045, ..., -0.00643921,\n",
       "             -0.00224304, 0.00402832],\n",
       "            ...,\n",
       "            [0.00567627, -0.00145721, 0.00469971, ..., -0.0062561, 0.001297,\n",
       "             -0.00291443],\n",
       "            [-0.00188446, -0.00259399, 0.00184631, ..., -0.0174561,\n",
       "             -0.0153198, -0.00958252],\n",
       "            [-0.00582886, -0.00753784, -0.0124512, ..., 0.00793457,\n",
       "             0.0148926, -0.0220947]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.0001688, -0.00723267, 0.00915527, ..., 0.0118408,\n",
       "              0.00854492, -0.00842285],\n",
       "             [0.00793457, 0.00396729, 0.0098877, ..., 0.00653076,\n",
       "              -0.00101471, -0.0290527],\n",
       "             [0.00491333, 0.00127411, 0.00561523, ..., 0.0136108,\n",
       "              -0.00494385, 0.00482178],\n",
       "             ...,\n",
       "             [6.38962e-05, 0.0155029, 0.00897217, ..., 0.00698853,\n",
       "              -0.00363159, 0.0078125],\n",
       "             [-0.0123291, 0.00317383, 0.00384521, ..., -0.0145874,\n",
       "              -0.00386047, 0.000656128],\n",
       "             [0.00180054, 0.0011673, 0.00720215, ..., 3.86238e-05,\n",
       "              0.00248718, -0.00424194]],\n",
       "    \n",
       "            [[0.00546265, -0.00854492, -0.000201225, ..., -0.00534058,\n",
       "              -0.0192871, 0.0155029],\n",
       "             [-0.00491333, 0.00897217, -0.00315857, ..., -0.0067749,\n",
       "              -0.0163574, -0.00817871],\n",
       "             [-0.0130005, 0.00167084, 0.000907898, ..., 0.000413895,\n",
       "              -0.00323486, 0.0116577],\n",
       "             ...,\n",
       "             [-0.0195312, 0.0022583, 0.000411987, ..., 0.0147095,\n",
       "              -0.0126953, -0.0368652],\n",
       "             [-0.00601196, -0.00367737, 0.0067749, ..., 0.00488281,\n",
       "              0.0118408, 0.0203857],\n",
       "             [0.00292969, -0.0130005, -0.00488281, ..., -0.027832,\n",
       "              -0.010376, -0.0134888]],\n",
       "    \n",
       "            [[-0.00811768, -0.00448608, 0.0113525, ..., 0.00427246,\n",
       "              -0.022583, 0.0140381],\n",
       "             [-0.00191498, -0.00256348, -0.00267029, ..., -0.0136108,\n",
       "              0.00332642, -0.00439453],\n",
       "             [-0.00582886, 0.00601196, 0.00448608, ..., -0.000675201,\n",
       "              -0.00311279, 0.00260925],\n",
       "             ...,\n",
       "             [0.00616455, 0.00836182, -0.0127563, ..., -0.00306702,\n",
       "              0.0101929, -0.00421143],\n",
       "             [0.000278473, -0.00201416, -0.0216064, ..., 0.0090332,\n",
       "              -0.0306396, 0.00714111],\n",
       "             [-0.00473022, -0.0027771, 0.0106812, ..., -0.00552368,\n",
       "              -0.00297546, -0.0123291]],\n",
       "    \n",
       "            [[0.0050354, -0.00952148, -0.0114136, ..., 0.0119629,\n",
       "              -0.0288086, 0.012146],\n",
       "             [-0.0123291, -0.0145874, 0.000686646, ..., 0.00921631,\n",
       "              -0.00842285, 0.012085],\n",
       "             [0.00234985, 0.00375366, -0.00476074, ..., -0.0288086,\n",
       "              0.010498, -0.00350952],\n",
       "             ...,\n",
       "             [-0.00146484, -0.00390625, -0.0115967, ..., 0.0349121,\n",
       "              -0.0336914, -0.00582886],\n",
       "             [-0.00897217, 0.00177002, -0.00537109, ..., 0.00500488,\n",
       "              0.0098877, 0.0378418],\n",
       "             [0.00793457, -0.0043335, -0.00720215, ..., 0.0371094,\n",
       "              0.0180664, -0.0177002]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0020752, -0.00927734, -0.00436401, ..., -0.00244141,\n",
       "              0.00537109, 0.0120239],\n",
       "             [0.00765991, 0.0172119, 0.00952148, ..., 0.00408936,\n",
       "              0.0158691, 0.00360107],\n",
       "             [0.00178528, -0.00454712, -0.00445557, ..., -0.0126953,\n",
       "              -0.00411987, 0.0106812],\n",
       "             ...,\n",
       "             [0.00314331, 0.00588989, -0.00238037, ..., 0.00331116,\n",
       "              -0.0128174, -0.0114746],\n",
       "             [-0.00173187, -0.00939941, -0.00854492, ..., -0.00369263,\n",
       "              0.0145874, 0.00393677],\n",
       "             [-0.0126343, 0.00424194, 0.000432968, ..., -0.00842285,\n",
       "              -0.0103149, -0.00106049]],\n",
       "    \n",
       "            [[0.0163574, 0.00860596, 0.0072937, ..., -0.0289307,\n",
       "              -0.0279541, 0.0181885],\n",
       "             [-0.0151367, 0.0234375, -0.0128784, ..., 0.0186768,\n",
       "              -0.00576782, -0.0196533],\n",
       "             [0.00811768, 0.00567627, 0.00224304, ..., -6.00815e-05,\n",
       "              -0.0194092, -0.0139771],\n",
       "             ...,\n",
       "             [-0.00946045, -0.00717163, 0.00753784, ..., 0.0230713,\n",
       "              0.00196838, -0.00136566],\n",
       "             [0.0122681, -0.00872803, -0.00653076, ..., 0.00613403,\n",
       "              0.00836182, -0.00442505],\n",
       "             [-0.0157471, -0.00387573, 0.00354004, ..., 0.0088501,\n",
       "              0.0236816, 0.0134888]],\n",
       "    \n",
       "            [[0.00396729, -0.000349045, -0.00476074, ..., -0.00393677,\n",
       "              0.00811768, 0.00695801],\n",
       "             [-0.0114136, -0.0170898, 0.00518799, ..., -0.0115967,\n",
       "              0.0140991, 0.0105591],\n",
       "             [-0.00482178, 0.0183105, -0.0105591, ..., -0.00588989,\n",
       "              -0.00619507, 0.00488281],\n",
       "             ...,\n",
       "             [-0.0192871, -0.0130005, 0.00369263, ..., -0.00311279,\n",
       "              0.00723267, 0.00354004],\n",
       "             [0.00524902, 0.0110474, -0.00793457, ..., -0.0134277,\n",
       "              -0.00236511, -0.00292969],\n",
       "             [-0.0119629, 0.00069809, 0.00537109, ..., 0.0212402,\n",
       "              0.0185547, 0.0065918]],\n",
       "    \n",
       "            [[-0.0178223, 0.0233154, -0.00238037, ..., -0.00198364,\n",
       "              -0.0149536, -0.00576782],\n",
       "             [0.0174561, -0.0127563, 0.000299454, ..., -0.0169678,\n",
       "              -0.0110474, 0.00114441],\n",
       "             [0.0178223, -0.00552368, -0.00069809, ..., 0.0231934,\n",
       "              0.0013504, 0.0145874],\n",
       "             ...,\n",
       "             [-0.00305176, -0.0172119, -0.0043335, ..., -0.00546265,\n",
       "              -0.00704956, 0.0155029],\n",
       "             [-0.00674438, -0.00576782, 0.00120544, ..., -0.010376,\n",
       "              0.00193024, -0.00854492],\n",
       "             [0.00598145, 0.0127563, 0.000957489, ..., 0.00494385,\n",
       "              -0.0045166, -0.00506592]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[-0.00174713, 0.00315857, 0.00646973, ..., -0.00830078,\n",
       "             -0.0164795, -0.0107422],\n",
       "            [0.0146484, -0.00439453, 0.00212097, ..., -0.00793457,\n",
       "             -0.00891113, -0.0119629],\n",
       "            [-0.00915527, 0.00119781, 0.0194092, ..., 0.0167236, 0.0203857,\n",
       "             0.00135803],\n",
       "            ...,\n",
       "            [-0.0217285, -0.0108032, 0.0167236, ..., 0.010498, -0.00069046,\n",
       "             -0.0217285],\n",
       "            [0.0213623, 0.00952148, -0.0233154, ..., -0.00598145, 0.0192871,\n",
       "             0.00436401],\n",
       "            [0.00187683, -0.00317383, -0.0197754, ..., 0.0112305,\n",
       "             0.00212097, 0.0142212]],\n",
       "    \n",
       "           [[0.000545502, 0.00564575, 0.0067749, ..., 0.0100708,\n",
       "             -0.00154114, -0.00958252],\n",
       "            [0.0158691, 0.00221252, -0.00805664, ..., 0.0137329, 0.0072937,\n",
       "             0.0336914],\n",
       "            [0.00047493, 0.00346375, 0.00115204, ..., 0.00105286, 0.0245361,\n",
       "             0.00285339],\n",
       "            ...,\n",
       "            [-0.00195312, 0.00248718, 0.00488281, ..., 0.00866699,\n",
       "             0.0241699, 0.015625],\n",
       "            [0.0111694, 0.000534058, -0.013916, ..., 0.0050354, 0.00463867,\n",
       "             -0.0150757],\n",
       "            [-0.00439453, -0.0134888, 0.0211182, ..., -0.0169678,\n",
       "             -0.0105591, 0.00343323]],\n",
       "    \n",
       "           [[0.0050354, 0.0065918, -0.00352478, ..., 0.0112305, -0.013916,\n",
       "             0.0272217],\n",
       "            [0.00296021, 0.00805664, -0.00842285, ..., -0.0118408,\n",
       "             0.00491333, -0.0422363],\n",
       "            [0.00291443, -0.000136375, 0.00793457, ..., 0.0269775,\n",
       "             0.00939941, -0.00124359],\n",
       "            ...,\n",
       "            [0.00106812, -0.000511169, -0.00245667, ..., -0.00300598,\n",
       "             0.024292, -0.0159912],\n",
       "            [0.00387573, -0.0111084, 0.00549316, ..., 0.00242615, 0.0148315,\n",
       "             -0.0016098],\n",
       "            [-0.00570679, -0.00634766, 0.00836182, ..., -0.00640869,\n",
       "             0.00582886, 0.000598907]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00158691, -0.000705719, -0.0133057, ..., -0.00518799,\n",
       "             -0.0145874, -0.0263672],\n",
       "            [-0.000762939, 0.00439453, -0.00686646, ..., -0.0213623,\n",
       "             -0.0270996, -0.0227051],\n",
       "            [0.000392914, -0.000177383, 0.00216675, ..., -0.0124512,\n",
       "             -0.00254822, -0.0137939],\n",
       "            ...,\n",
       "            [-0.00139618, -0.000862122, 0.00604248, ..., -0.0290527,\n",
       "             -0.0134277, -0.0127563],\n",
       "            [-0.00405884, 0.00141144, 0.0148315, ..., -0.00263977,\n",
       "             -0.00628662, 0.0319824],\n",
       "            [-0.00320435, 0.000419617, -0.00357056, ..., -0.00227356,\n",
       "             -0.0109863, -0.0200195]],\n",
       "    \n",
       "           [[0.000257492, -0.0015564, 0.00631714, ..., 0.0147095, -0.003479,\n",
       "             -0.00418091],\n",
       "            [-0.0108643, 0.00343323, -0.00616455, ..., 0.00466919,\n",
       "             -0.0219727, 0.00236511],\n",
       "            [-0.000459671, 0.00113678, 0.0111084, ..., -0.0289307,\n",
       "             0.00714111, -0.000705719],\n",
       "            ...,\n",
       "            [0.00213623, 0.00415039, 0.00488281, ..., 0.0145264, 0.0186768,\n",
       "             -0.0133057],\n",
       "            [-0.000167847, -0.00274658, -0.00288391, ..., -0.0189209,\n",
       "             0.00485229, -0.0247803],\n",
       "            [-0.00113678, 0.000400543, -0.00366211, ..., 0.0371094,\n",
       "             -0.00878906, 0.00610352]],\n",
       "    \n",
       "           [[-7.62939e-05, -0.00531006, -0.0117798, ..., -0.00151825,\n",
       "             0.000682831, 0.00793457],\n",
       "            [-0.0147705, -0.00390625, 0.000541687, ..., 0.00346375,\n",
       "             0.000907898, 0.00665283],\n",
       "            [-0.0134277, 0.00386047, -0.00909424, ..., -0.00126648,\n",
       "             0.000114918, 0.00186157],\n",
       "            ...,\n",
       "            [0.000930786, 0.00354004, 0.00370789, ..., -0.000839233,\n",
       "             0.00378418, -0.00411987],\n",
       "            [-0.00143433, 0.00212097, 0.0139771, ..., 0.00151062,\n",
       "             -0.00352478, -0.00842285],\n",
       "            [-0.0100098, -0.00332642, -0.010498, ..., 0.00121307,\n",
       "             0.00488281, 0.00579834]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[0.00805664, 0.00595093, -0.00527954, ..., -0.00494385,\n",
       "            0.00338745, -0.00314331],\n",
       "           [0.00177002, 0.00775146, 0.00445557, ..., 0.00582886,\n",
       "            -0.0100098, 0.00274658],\n",
       "           [-0.00442505, -0.001297, 0.00769043, ..., -0.0072937,\n",
       "            -0.0119629, -0.000591278],\n",
       "           ...,\n",
       "           [0.000999451, 0.00866699, 0.00552368, ..., 0.00622559,\n",
       "            0.000141144, -0.00296021],\n",
       "           [0.00265503, 0.000149727, 0.00063324, ..., -0.00588989,\n",
       "            0.0106812, -0.00585938],\n",
       "           [-0.00172424, 0.00872803, -0.0126953, ..., -0.0145874,\n",
       "            -0.00393677, -0.000652313]],\n",
       "   \n",
       "          [[-0.00756836, -0.00750732, -0.00772095, ..., -0.00387573,\n",
       "            -0.00213623, 0.013916],\n",
       "           [-0.000450134, 0.00109863, 0.00282288, ..., 0.00189972,\n",
       "            -0.00436401, -0.00375366],\n",
       "           [0.0110474, -0.00592041, 0.00268555, ..., 0.00318909,\n",
       "            0.00285339, -0.012146],\n",
       "           ...,\n",
       "           [-0.0153198, -0.00494385, 0.00482178, ..., 0.00288391,\n",
       "            -0.00509644, -0.000701904],\n",
       "           [-0.000358582, 0.00527954, -0.00610352, ..., 0.0111084,\n",
       "            -0.0110474, -0.00509644],\n",
       "           [0.000164986, -0.00830078, -0.000337601, ..., -0.00151062,\n",
       "            -0.00337219, -0.015625]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00817871, 0.00157166, -0.00389099, ..., 0.00769043,\n",
       "           -0.00836182, -0.00286865],\n",
       "          [-0.0159912, -0.00500488, 0.0167236, ..., -0.00582886, -0.0011673,\n",
       "           0.0090332],\n",
       "          [-0.00311279, 0.00689697, -0.00259399, ..., 0.00604248,\n",
       "           -0.000442505, -0.0050354],\n",
       "          ...,\n",
       "          [-0.00227356, -0.00193787, 0.00653076, ..., 0.00244141,\n",
       "           -0.00352478, -0.00579834],\n",
       "          [0.00427246, 0.00866699, -0.0050354, ..., 0.00952148,\n",
       "           -0.000450134, -0.00107574],\n",
       "          [0.015564, 0.000236511, -0.00159454, ..., 0.00164795, 0.00415039,\n",
       "           -0.00570679]], dtype=bfloat16), a=Array([[-0.00536764,  0.01348992, -0.00598283, ..., -0.01268126,\n",
       "           -0.01520117, -0.01440818],\n",
       "          [ 0.00239141,  0.01290342,  0.00408962, ...,  0.00013094,\n",
       "            0.00600098, -0.00192806]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.0143433, -0.0620117, 0.0375977, ..., -0.0898438, 0.110352,\n",
       "          -0.135742], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.191406, 0.195312, 0.308594, ..., 0.118164, 0.625, 0.196289],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.726562, 0.589844, 0.59375, ..., 0.789062, -0.155273, 0.455078],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.542969, 0.582031, 0.550781, ..., 0.742188, -0.00248718, 0.455078],      dtype=bfloat16)}},\n",
       " 'layer_8': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[-0.0039978, 0.0115967, 0.000343323, ..., 0.032959, 0.00454712,\n",
       "             0.00701904],\n",
       "            [-0.00799561, 0.0169678, 0.0223389, ..., -0.0151367, 0.00018692,\n",
       "             1.24574e-05],\n",
       "            [0.00411987, 0.00619507, 0.000823975, ..., -0.000961304,\n",
       "             -0.00460815, 0.0205078],\n",
       "            ...,\n",
       "            [0.00159454, 0.0268555, -0.0100098, ..., 0.00210571, 0.0189209,\n",
       "             -0.0238037],\n",
       "            [-0.00306702, -0.0134277, -0.0220947, ..., -0.0272217,\n",
       "             0.00585938, -0.00421143],\n",
       "            [-0.027832, -0.0111694, 0.0055542, ..., -0.012146, 0.0239258,\n",
       "             0.00747681]],\n",
       "    \n",
       "           [[0.00227356, -0.00762939, -0.00976562, ..., -0.0174561,\n",
       "             -0.0130005, -0.00497437],\n",
       "            [-0.00212097, -0.0150146, -0.00482178, ..., 0.00964355,\n",
       "             0.0027771, 0.000915527],\n",
       "            [-0.000471115, -0.0122681, -0.0101318, ..., -0.00976562,\n",
       "             0.00234985, -0.0035553],\n",
       "            ...,\n",
       "            [-0.00276184, -0.0177002, 0.000115395, ..., -0.00191498,\n",
       "             -0.013916, 0.0118408],\n",
       "            [0.0016861, 0.00946045, 0.015625, ..., 0.0178223, -0.00921631,\n",
       "             0.00778198],\n",
       "            [0.0134888, 0.00915527, -0.00427246, ..., 0.0078125, -0.0249023,\n",
       "             -0.0109253]],\n",
       "    \n",
       "           [[-0.0118408, 0.0203857, -0.00166321, ..., 0.0174561, 0.00144196,\n",
       "             0.00201416],\n",
       "            [-0.000522614, 0.0187988, 0.0147095, ..., -0.00497437,\n",
       "             0.00469971, 0.00106049],\n",
       "            [0.0192871, 0.0177002, 0.00543213, ..., -0.00878906,\n",
       "             0.000545502, 0.00245667],\n",
       "            ...,\n",
       "            [0.00613403, -0.0112305, 0.000965118, ..., -0.0203857,\n",
       "             -0.00186157, 0.0011673],\n",
       "            [0.00805664, -0.00479126, 0.00860596, ..., -0.00263977,\n",
       "             0.0184326, 0.000270844],\n",
       "            [-0.00631714, -0.00747681, -3.21865e-05, ..., 0.00421143,\n",
       "             -0.00323486, -0.00665283]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.0168457, 0.0106201, -0.00738525, ..., -0.0168457, 0.00921631,\n",
       "             -0.0118408],\n",
       "            [0.00927734, -0.0168457, -0.00753784, ..., -0.000354767,\n",
       "             -0.0227051, -0.0039978],\n",
       "            [0.0111694, 0.00021553, 0.00337219, ..., 0.00946045, 0.0236816,\n",
       "             0.0179443],\n",
       "            ...,\n",
       "            [-0.0229492, -0.00436401, 0.0131836, ..., -0.0101929,\n",
       "             0.00842285, 0.0371094],\n",
       "            [-0.00842285, 0.0107422, 0.00994873, ..., -0.00148773,\n",
       "             -0.0290527, -0.00157928],\n",
       "            [-0.00343323, 0.0148315, 0.0015564, ..., -0.0118408,\n",
       "             -0.00112915, -0.0336914]],\n",
       "    \n",
       "           [[0.00340271, 0.00576782, 0.00671387, ..., -0.00457764,\n",
       "             -0.00242615, -0.00259399],\n",
       "            [0.0172119, -0.00115204, 0.0020752, ..., -0.0016098, 0.00430298,\n",
       "             -0.00619507],\n",
       "            [0.00332642, 0.00537109, 0.00174713, ..., -0.00521851,\n",
       "             -0.00121307, -0.00159454],\n",
       "            ...,\n",
       "            [-0.00136566, 0.00527954, 0.000740051, ..., 0.00720215,\n",
       "             -0.0118408, 0.000572205],\n",
       "            [-0.00364685, 0.000272751, 0.00279236, ..., -0.000202179,\n",
       "             -0.00133514, 0.00239563],\n",
       "            [0.00149536, -0.0119019, 0.00582886, ..., 0.00674438,\n",
       "             -0.00848389, 0.0103149]],\n",
       "    \n",
       "           [[-0.0153198, -0.0013504, -0.0130005, ..., -0.00622559,\n",
       "             0.0130615, -0.0212402],\n",
       "            [-0.00408936, 0.0112915, 0.00650024, ..., -0.00352478,\n",
       "             0.0192871, -0.0142212],\n",
       "            [0.00248718, 0.0168457, -0.0234375, ..., 0.00276184, 0.00744629,\n",
       "             0.00854492],\n",
       "            ...,\n",
       "            [0.00946045, -0.006073, -6.67572e-05, ..., 0.0043335,\n",
       "             -0.00110626, -0.0205078],\n",
       "            [-0.0178223, -0.0134277, -0.012085, ..., 0.00830078, 0.0108032,\n",
       "             -0.010437],\n",
       "            [-0.00393677, -0.017334, 0.000652313, ..., 0.00585938,\n",
       "             -0.00531006, 0.0153809]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[0.00772095, -0.00479126, 0.000606537, ..., -0.00552368,\n",
       "              0.0109863, -0.0022583],\n",
       "             [0.00195312, -0.000682831, 0.00379944, ..., 0.00402832,\n",
       "              -0.0111084, 0.0125732],\n",
       "             [0.00717163, -0.00939941, -0.0151978, ..., -0.00143433,\n",
       "              -0.00665283, -0.0167236],\n",
       "             ...,\n",
       "             [5.81741e-05, -0.00564575, -0.00312805, ..., 0.00579834,\n",
       "              0.0123291, 0.00112915],\n",
       "             [-0.00101471, 0.00698853, -0.00115967, ..., -0.0216064,\n",
       "              -0.00531006, 0.0292969],\n",
       "             [-0.0050354, 0.0088501, -0.000732422, ..., -0.00396729,\n",
       "              -0.0078125, -0.00463867]],\n",
       "    \n",
       "            [[-0.00500488, 0.00384521, -0.00088501, ..., 0.00294495,\n",
       "              -0.0263672, -0.0167236],\n",
       "             [-0.00778198, 0.00393677, -0.0137939, ..., 0.00805664,\n",
       "              -0.00138855, 0.0197754],\n",
       "             [-0.00357056, -0.00695801, 0.00460815, ..., -0.00479126,\n",
       "              0.00860596, -0.00488281],\n",
       "             ...,\n",
       "             [0.0161133, -0.00126648, -0.00047493, ..., 0.00151062,\n",
       "              0.00646973, 0.00265503],\n",
       "             [-0.0100098, 0.00595093, -0.0035553, ..., 0.0332031,\n",
       "              -0.00126648, -0.0236816],\n",
       "             [0.00224304, 0.0126953, 0.000984192, ..., 0.0166016,\n",
       "              -0.000965118, -0.00364685]],\n",
       "    \n",
       "            [[0.0119019, -0.00125885, -0.00201416, ..., 0.0159912,\n",
       "              -0.00897217, -0.0113525],\n",
       "             [-0.00162506, -0.00141144, 0.00534058, ..., 0.000530243,\n",
       "              -0.000436783, -0.00247192],\n",
       "             [-0.00344849, 0.0018692, 0.00158691, ..., 0.00537109,\n",
       "              -0.00427246, 0.00891113],\n",
       "             ...,\n",
       "             [-0.00408936, -0.00296021, -0.000188828, ..., 0.0013504,\n",
       "              0.00958252, -0.0149536],\n",
       "             [0.00250244, 0.00271606, -0.00265503, ..., -0.00772095,\n",
       "              -0.0147705, 0.0098877],\n",
       "             [-0.0100098, 0.00442505, 0.0045166, ..., -0.00436401,\n",
       "              -0.00653076, -0.0137329]],\n",
       "    \n",
       "            [[0.00872803, 0.00427246, 0.000448227, ..., -0.0167236,\n",
       "              -0.0133057, -0.00656128],\n",
       "             [-0.010437, 0.000720978, -0.00421143, ..., 0.00485229,\n",
       "              -0.019043, -0.00561523],\n",
       "             [0.00619507, 0.00135803, 0.00346375, ..., 0.000453949,\n",
       "              0.00260925, 0.0108032],\n",
       "             ...,\n",
       "             [-0.00113678, 3.12328e-05, -0.012085, ..., -0.000165939,\n",
       "              0.00415039, 0.00842285],\n",
       "             [0.00326538, -0.000976562, 0.00689697, ..., -0.0324707,\n",
       "              -0.00964355, -0.00221252],\n",
       "             [0.00430298, -0.00119019, -0.00317383, ..., 0.00427246,\n",
       "              -0.0145874, 0.0212402]]],\n",
       "    \n",
       "    \n",
       "           [[[-0.00650024, 0.000227928, -0.00245667, ..., -0.00939941,\n",
       "              0.00540161, 0.0280762],\n",
       "             [-0.000564575, 0.0131836, -0.0197754, ..., 0.00854492,\n",
       "              0.0153809, 0.0108032],\n",
       "             [-0.00107574, -0.000900269, -0.0216064, ..., 0.00753784,\n",
       "              -0.00326538, 0.000482559],\n",
       "             ...,\n",
       "             [-0.0125732, -0.0114746, -0.00160217, ..., 0.000221252,\n",
       "              0.00297546, 0.0131226],\n",
       "             [-0.00485229, -0.0145874, 9.53674e-05, ..., -0.00241089,\n",
       "              0.00320435, 0.001091],\n",
       "             [-0.000888824, -0.0062561, 0.00244141, ..., 0.00216675,\n",
       "              0.00415039, -0.00140381]],\n",
       "    \n",
       "            [[0.0125732, -0.0157471, 0.00494385, ..., 0.0147095,\n",
       "              0.00982666, 0.00300598],\n",
       "             [-0.00159454, -0.00479126, 0.00210571, ..., -0.0117798,\n",
       "              0.00491333, -0.00909424],\n",
       "             [-0.0106201, 0.00231934, 0.0229492, ..., -0.0115967,\n",
       "              0.000709534, 0.0301514],\n",
       "             ...,\n",
       "             [-0.00386047, -0.00579834, -0.00408936, ..., -0.0175781,\n",
       "              -0.013916, 0.019165],\n",
       "             [0.00193787, -0.00236511, -0.000328064, ..., -0.006073,\n",
       "              0.012085, -0.00170135],\n",
       "             [-0.0131226, -0.0133667, 0.0175781, ..., 0.0155029,\n",
       "              -0.0113525, -0.00576782]],\n",
       "    \n",
       "            [[-0.0179443, -0.0240479, 0.0108643, ..., 0.0267334, 0.0205078,\n",
       "              -0.00686646],\n",
       "             [-0.003479, 0.0145264, -0.0109863, ..., 0.0238037, -0.0158691,\n",
       "              -0.0174561],\n",
       "             [0.0151978, 0.00726318, 0.00860596, ..., -0.00263977,\n",
       "              0.00360107, 0.00442505],\n",
       "             ...,\n",
       "             [0.00704956, -0.00970459, -0.000255585, ..., 0.0175781,\n",
       "              -0.00738525, 0.00537109],\n",
       "             [-0.00872803, 0.0253906, -0.0117188, ..., -0.00744629,\n",
       "              0.0283203, -0.00233459],\n",
       "             [0.0167236, -0.00842285, -0.0105591, ..., -0.0427246,\n",
       "              -0.00205994, 0.0385742]],\n",
       "    \n",
       "            [[0.0100098, 0.00891113, 0.00610352, ..., -0.0170898,\n",
       "              -0.000328064, 0.00897217],\n",
       "             [-0.00582886, 0.00747681, 0.0194092, ..., 0.00263977,\n",
       "              -0.000919342, -0.0157471],\n",
       "             [-0.0050354, 0.00518799, -0.0324707, ..., 0.00215149,\n",
       "              0.00314331, -0.00463867],\n",
       "             ...,\n",
       "             [-0.0201416, -0.00939941, -0.0119629, ..., 0.0234375,\n",
       "              -0.00897217, 0.0109253],\n",
       "             [0.000170708, 0.000854492, 0.00216675, ..., -0.0217285,\n",
       "              0.0108032, -0.000938416],\n",
       "             [-0.019165, -0.00476074, -0.00259399, ..., -0.00518799,\n",
       "              0.0126343, 0.010376]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00328064, -0.00860596, -0.00848389, ..., -0.00259399,\n",
       "             0.00836182, 0.00817871],\n",
       "            [0.00982666, -0.00631714, -0.00151062, ..., 0.00141144,\n",
       "             -0.012085, -0.00430298],\n",
       "            [0.00411987, 0.00248718, -0.00257874, ..., -0.00378418,\n",
       "             0.00793457, -0.0067749],\n",
       "            ...,\n",
       "            [0.00543213, 0.00382996, 0.00506592, ..., -0.00292969,\n",
       "             0.00698853, -0.00379944],\n",
       "            [0.0136108, 0.00276184, -0.0161133, ..., 0.00180054,\n",
       "             0.000492096, 0.00247192],\n",
       "            [0.00582886, -0.0014801, -0.0114136, ..., -0.00204468,\n",
       "             0.00445557, -0.00650024]],\n",
       "    \n",
       "           [[0.0131226, -0.0124512, -0.0112915, ..., 0.00180817, 0.010376,\n",
       "             0.00473022],\n",
       "            [0.00817871, -0.00549316, -0.00622559, ..., -0.00622559,\n",
       "             -0.0209961, -0.0211182],\n",
       "            [-0.00166321, 0.00946045, 0.0112915, ..., 0.00143433,\n",
       "             -0.00564575, -0.00131226],\n",
       "            ...,\n",
       "            [-0.000720978, 0.00604248, 0.00326538, ..., 0.0240479,\n",
       "             0.0088501, 0.000188828],\n",
       "            [0.00186157, 0.00454712, -0.00262451, ..., 0.010376,\n",
       "             0.000172615, -0.00222778],\n",
       "            [-0.0035553, -0.00233459, -0.00183105, ..., -0.00854492,\n",
       "             -0.0197754, -0.0186768]],\n",
       "    \n",
       "           [[-0.00228882, 0.00122833, 0.00186157, ..., -0.00448608,\n",
       "             -0.0238037, -0.0117798],\n",
       "            [-0.00695801, 0.00582886, 0.00138092, ..., 0.0184326,\n",
       "             -0.00405884, 0.00848389],\n",
       "            [-0.00270081, -0.00396729, 0.000946045, ..., -0.00263977,\n",
       "             0.00946045, 0.0162354],\n",
       "            ...,\n",
       "            [-0.00958252, -0.0144653, -0.015625, ..., 0.0166016, -0.0175781,\n",
       "             0.00159454],\n",
       "            [0.00360107, -0.00105286, 0.0098877, ..., 0.0202637, 0.0205078,\n",
       "             -0.00271606],\n",
       "            [0.00518799, -0.0111694, 0.0039978, ..., -0.0183105, -0.0167236,\n",
       "             0.00369263]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00366211, 0.00939941, 0.0135498, ..., -0.00196838,\n",
       "             -0.000793457, -0.00646973],\n",
       "            [-0.0105591, 0.006073, 0.00866699, ..., -0.00671387, 0.00970459,\n",
       "             0.00891113],\n",
       "            [-0.00811768, 0.0170898, -0.00750732, ..., -0.000808716,\n",
       "             -0.0220947, 0.00836182],\n",
       "            ...,\n",
       "            [-0.0109253, 0.00576782, -0.00111389, ..., -0.00775146,\n",
       "             -0.0179443, 0.00497437],\n",
       "            [0.000591278, -0.00460815, -0.0039978, ..., 0.00619507,\n",
       "             -0.0022583, -0.00019455],\n",
       "            [-0.0127563, 0.00139618, 0.00187683, ..., 0.00245667, 0.013855,\n",
       "             -0.00205994]],\n",
       "    \n",
       "           [[-0.003479, 0.00379944, -0.0145874, ..., 0.0244141, -0.036377,\n",
       "             -0.00408936],\n",
       "            [0.00872803, 0.0189209, -0.00141144, ..., -0.00692749,\n",
       "             0.0368652, -0.00970459],\n",
       "            [-0.0105591, -0.0150757, -0.00643921, ..., -0.0324707,\n",
       "             -0.0123901, -0.0272217],\n",
       "            ...,\n",
       "            [-0.00970459, 0.00469971, -0.00695801, ..., -0.00878906,\n",
       "             -0.0135498, 0.0354004],\n",
       "            [-0.00506592, 0.0150757, 0.00982666, ..., -0.00946045,\n",
       "             0.0186768, 0.000396729],\n",
       "            [0.00939941, 0.00521851, 0.0090332, ..., -0.00921631,\n",
       "             0.00717163, -0.0227051]],\n",
       "    \n",
       "           [[0.015564, 0.00759888, 0.00056076, ..., 0.0317383, 0.0109253,\n",
       "             0.00927734],\n",
       "            [0.00344849, -0.00799561, 0.00897217, ..., 0.00289917,\n",
       "             0.0272217, -0.0439453],\n",
       "            [0.0137329, 0.0167236, 0.0167236, ..., -0.015625, 0.00063324,\n",
       "             0.00799561],\n",
       "            ...,\n",
       "            [-0.00231934, -0.00139618, 0.00411987, ..., -0.0153198,\n",
       "             -6.24657e-05, 0.0228271],\n",
       "            [0.00149536, 0.00753784, -0.00262451, ..., -0.000463486,\n",
       "             0.0214844, -0.00126648],\n",
       "            [0.0016861, 0.00708008, 0.0144043, ..., -0.00521851, 0.0132446,\n",
       "             -0.000434875]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.0115967, 0.00300598, -0.000114441, ..., 0.0032196,\n",
       "            0.0067749, -0.00665283],\n",
       "           [0.00396729, 0.00364685, -0.00799561, ..., 0.000915527,\n",
       "            0.00762939, 0.00891113],\n",
       "           [-0.00136566, 0.0105591, 0.0177002, ..., 0.00242615,\n",
       "            -0.000865936, -0.00848389],\n",
       "           ...,\n",
       "           [0.0101318, -0.00512695, -0.00218201, ..., -0.0123901,\n",
       "            -0.00106049, 0.000450134],\n",
       "           [-0.00466919, 0.00762939, 0.0110474, ..., 0.0100098,\n",
       "            -0.000679016, -0.0228271],\n",
       "           [0.00357056, 0.00445557, -0.00291443, ..., -0.00239563,\n",
       "            -0.00408936, -0.00921631]],\n",
       "   \n",
       "          [[0.0065918, 0.00747681, 0.0105591, ..., -0.0106201, 0.000743866,\n",
       "            0.00512695],\n",
       "           [0.0100708, -0.00637817, -0.00141907, ..., -0.00424194,\n",
       "            0.00427246, -0.00408936],\n",
       "           [-0.00982666, 0.00549316, -0.00830078, ..., -0.00619507,\n",
       "            0.00637817, 0.00415039],\n",
       "           ...,\n",
       "           [0.00909424, -0.00952148, -0.0107422, ..., -0.00631714,\n",
       "            0.00280762, 0.00063324],\n",
       "           [-0.00836182, 0.00854492, 0.00604248, ..., -0.0105591,\n",
       "            -0.0153809, -0.00280762],\n",
       "           [-0.0120239, 0.00305176, -0.00811768, ..., 0.0147095,\n",
       "            0.00921631, 0.00668335]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[-0.010376, -0.00247192, 0.00189972, ..., 0.0128174, -0.00787354,\n",
       "           -0.00527954],\n",
       "          [0.00102997, -0.010498, 0.00263977, ..., 0.000743866, -0.00367737,\n",
       "           -0.000455856],\n",
       "          [0.0102539, -0.0137329, -0.0224609, ..., -0.00289917, 0.00334167,\n",
       "           -0.0108643],\n",
       "          ...,\n",
       "          [-0.0017395, -0.00028038, -0.00494385, ..., 0.000900269,\n",
       "           -0.0107422, -0.00817871],\n",
       "          [-0.00396729, -0.00650024, 0.00276184, ..., -0.00747681,\n",
       "           0.0062561, 0.00360107],\n",
       "          [0.00616455, 0.00631714, 0.0216064, ..., -0.00488281, 0.0030365,\n",
       "           0.00160217]], dtype=bfloat16), a=Array([[-0.00295627, -0.00559398, -0.00677068, ...,  0.01155958,\n",
       "           -0.01056946, -0.01427677],\n",
       "          [ 0.02465803,  0.01395147, -0.01297336, ..., -0.0011971 ,\n",
       "           -0.00226062, -0.00428502]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.120117, 0.132812, 0.211914, ..., 0.0247803, 0.125977, 0.0432129],      dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.277344, 0.273438, 0.369141, ..., 0.199219, 0.644531, 0.271484],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([1.14062, 1.02344, 1.03906, ..., 1.14062, 0.0703125, 0.894531],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.601562, 0.675781, 0.648438, ..., 0.785156, 0.0917969, 0.589844],      dtype=bfloat16)}},\n",
       " 'layer_9': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=Array([[[0.00379944, 0.000249863, -0.0267334, ..., -0.0148315,\n",
       "             0.000656128, -0.00650024],\n",
       "            [-0.0100708, 0.00460815, 0.0133057, ..., 0.0071106, 0.00482178,\n",
       "             -0.00735474],\n",
       "            [-0.00534058, -0.00628662, -0.00349426, ..., -0.00195312,\n",
       "             0.0115356, 0.015625],\n",
       "            ...,\n",
       "            [0.000203133, 0.00854492, -0.00823975, ..., -0.00686646,\n",
       "             -0.0103149, 0.00723267],\n",
       "            [0.0241699, 0.00389099, 0.00860596, ..., 0.000999451,\n",
       "             -0.00227356, -0.00500488],\n",
       "            [0.0216064, 0.015564, -0.00817871, ..., -0.00125122, 0.00671387,\n",
       "             -0.0212402]],\n",
       "    \n",
       "           [[0.00805664, 0.0144653, -0.0108032, ..., 0.00384521,\n",
       "             0.000621796, -0.012146],\n",
       "            [-0.0140991, -0.0016098, -0.0175781, ..., -0.015564,\n",
       "             -0.00720215, -0.00210571],\n",
       "            [4.36306e-05, -0.0111084, -0.0101929, ..., 0.000413895,\n",
       "             0.0130615, -0.0154419],\n",
       "            ...,\n",
       "            [-0.0161133, -0.00215149, -0.00848389, ..., 0.00817871,\n",
       "             -0.00494385, -0.00405884],\n",
       "            [0.0166016, -0.00112152, 0.00546265, ..., 0.00872803,\n",
       "             0.00193787, 0.00817871],\n",
       "            [-0.0122681, -0.034668, -0.00473022, ..., 0.0169678, 0.00738525,\n",
       "             -0.0187988]],\n",
       "    \n",
       "           [[0.00823975, -0.0101929, 0.0102539, ..., -0.00222778,\n",
       "             -0.00335693, -0.0169678],\n",
       "            [0.0146484, -0.00933838, -0.00570679, ..., 0.00291443,\n",
       "             -0.00144958, 0.00177002],\n",
       "            [0.00309753, 0.0238037, -0.0341797, ..., 0.00473022, 0.0109863,\n",
       "             -0.00138092],\n",
       "            ...,\n",
       "            [-0.00178528, 0.00396729, -0.00228882, ..., 0.00144196,\n",
       "             -0.012207, -0.00738525],\n",
       "            [0.0327148, 0.00921631, -0.0015564, ..., 0.00179291,\n",
       "             -0.00540161, 0.0132446],\n",
       "            [-0.00891113, 0.00866699, 0.00387573, ..., 0.000190735,\n",
       "             -0.0144653, 0.0102539]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00497437, 0.00274658, -0.00170135, ..., 0.00485229,\n",
       "             -0.00726318, 0.0164795],\n",
       "            [0.019043, -0.00778198, 0.00921631, ..., -0.00335693, 0.0133057,\n",
       "             -0.00970459],\n",
       "            [-0.0267334, -0.0194092, -0.0022583, ..., 0.0157471, -0.0108643,\n",
       "             0.0109253],\n",
       "            ...,\n",
       "            [-0.00653076, 0.0144653, 0.0100708, ..., -0.0349121, 0.00209045,\n",
       "             -0.000991821],\n",
       "            [-0.0140381, 0.00239563, -0.00113678, ..., -0.00172424,\n",
       "             -0.0174561, 0.0112305],\n",
       "            [-0.0145874, 0.0192871, 0.00982666, ..., 0.00466919,\n",
       "             -0.00592041, -0.00689697]],\n",
       "    \n",
       "           [[0.0185547, 0.00283813, 0.00619507, ..., -0.00308228, 0.0142212,\n",
       "             0.00427246],\n",
       "            [-0.00341797, -0.0163574, 0.00723267, ..., -0.00500488,\n",
       "             -0.00177765, -0.00552368],\n",
       "            [-0.012207, 0.00280762, 0.0198975, ..., -0.0178223, -0.00479126,\n",
       "             -0.0088501],\n",
       "            ...,\n",
       "            [0.00387573, -0.0209961, -0.0120239, ..., 0.00402832,\n",
       "             0.00306702, 0.0139771],\n",
       "            [-3.48091e-05, -0.00224304, 0.00915527, ..., 0.0144043, 0.03125,\n",
       "             -0.0161133],\n",
       "            [-0.0105591, -0.00286865, 0.001091, ..., -0.0187988, 0.00860596,\n",
       "             -0.0212402]],\n",
       "    \n",
       "           [[-0.0177002, -0.00231934, 0.0050354, ..., 0.0108643,\n",
       "             -0.00698853, -0.000463486],\n",
       "            [0.0115967, 0.0019989, -0.000238419, ..., -0.00317383,\n",
       "             3.60608e-06, 0.00750732],\n",
       "            [-0.0131226, 0.00411987, 0.0119019, ..., -0.00848389,\n",
       "             0.00720215, -0.0118408],\n",
       "            ...,\n",
       "            [-0.0128174, 0.0185547, 0.0213623, ..., 0.0168457, -0.015625,\n",
       "             -0.0103149],\n",
       "            [-0.0238037, 0.00274658, 0.00598145, ..., 0.00866699,\n",
       "             -0.00878906, 0.00349426],\n",
       "            [0.00473022, -0.0055542, -0.00610352, ..., 0.00500488,\n",
       "             -0.00805664, 0.00732422]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "            [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n",
       "            [-0.00643921, -0.0130615],\n",
       "            [-0.00396729, -0.000341415],\n",
       "            ...,\n",
       "            [-0.0174561, 0.0014267],\n",
       "            [-0.00152588, -0.00854492],\n",
       "            [0.0148315, 0.00283813]],\n",
       "    \n",
       "           [[-0.0050354, 0.00366211],\n",
       "            [0.00344849, -0.0195312],\n",
       "            [0.00680542, 0.000835419],\n",
       "            ...,\n",
       "            [-0.00692749, -0.0195312],\n",
       "            [-0.00375366, -0.00375366],\n",
       "            [0.000246048, 0.0101929]],\n",
       "    \n",
       "           [[0.00732422, -0.0130615],\n",
       "            [0.0251465, 0.0119629],\n",
       "            [-0.000341415, 0.00325012],\n",
       "            ...,\n",
       "            [-0.000146866, -0.00598145],\n",
       "            [-0.0125732, -0.00273132],\n",
       "            [-0.00375366, -0.000341415]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[0.00897217, -0.00741577],\n",
       "            [-0.00312805, -0.00460815],\n",
       "            [-0.00482178, 0.00325012],\n",
       "            ...,\n",
       "            [0.00897217, -0.00273132],\n",
       "            [0.0115967, -0.00334167],\n",
       "            [-0.0114136, 0.00515747]],\n",
       "    \n",
       "           [[0.0162354, -0.0166016],\n",
       "            [0.00408936, 0.0018158],\n",
       "            [-0.0166016, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00668335, -0.00769043],\n",
       "            [0.0119629, -0.00878906],\n",
       "            [0.0124512, -0.0100098]],\n",
       "    \n",
       "           [[-0.00668335, -0.00854492],\n",
       "            [0.0078125, -0.0211182],\n",
       "            [-0.00692749, 0.0078125],\n",
       "            ...,\n",
       "            [-0.00460815, 0.000246048],\n",
       "            [0.00122833, 0.00610352],\n",
       "            [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=Array([[[[-0.00346375, -0.00686646, -0.00793457, ..., 0.00878906,\n",
       "              -0.00860596, 0.0113525],\n",
       "             [0.0146484, 0.00338745, -0.00762939, ..., -0.000379562,\n",
       "              0.0167236, -0.0162354],\n",
       "             [-0.0102539, 0.00476074, 0.0116577, ..., -0.0111694,\n",
       "              0.0134277, 0.00113678],\n",
       "             ...,\n",
       "             [-0.00167847, 0.00823975, 0.00778198, ..., -0.00939941,\n",
       "              0.0004673, 0.0246582],\n",
       "             [-0.00994873, 0.00650024, -0.00570679, ..., 0.00378418,\n",
       "              -0.00897217, 0.00671387],\n",
       "             [-0.00164795, 0.00976562, 0.0045166, ..., -0.010498,\n",
       "              0.0180664, 0.00411987]],\n",
       "    \n",
       "            [[0.00167847, -0.00337219, -0.00744629, ..., 0.00637817,\n",
       "              -0.00982666, 0.00180817],\n",
       "             [0.00479126, 0.00427246, 0.00175476, ..., 0.00634766,\n",
       "              -0.000831604, -0.0201416],\n",
       "             [0.000705719, 0.00408936, 0.00515747, ..., -0.00184631,\n",
       "              -0.00933838, -0.0123901],\n",
       "             ...,\n",
       "             [-0.00144196, 0.00927734, -0.00102997, ..., 0.0149536,\n",
       "              0.0268555, 0.00878906],\n",
       "             [-0.00253296, 0.00219727, 0.0111694, ..., 0.0233154,\n",
       "              -0.0144653, 0.00257874],\n",
       "             [-0.00579834, 0.0016861, 0.00163269, ..., -0.0148926,\n",
       "              0.00230408, 0.0158691]],\n",
       "    \n",
       "            [[0.015625, -0.000459671, 0.00101471, ..., 0.0131836,\n",
       "              -0.060791, -0.0124512],\n",
       "             [-0.00866699, 0.0184326, 0.00570679, ..., 0.0158691,\n",
       "              -0.0158691, 0.00769043],\n",
       "             [0.00331116, 0.00628662, -0.00534058, ..., 0.00250244,\n",
       "              -0.019043, 0.000896454],\n",
       "             ...,\n",
       "             [-0.000339508, -0.000663757, -0.0115356, ..., 0.00306702,\n",
       "              -0.00311279, 0.0148926],\n",
       "             [-0.00714111, -0.00179291, -0.00958252, ..., -0.00567627,\n",
       "              0.00860596, 0.0402832],\n",
       "             [-0.00982666, 0.00439453, -0.00216675, ..., -0.0117188,\n",
       "              0.0220947, -0.000514984]],\n",
       "    \n",
       "            [[0.00561523, 0.000648499, -0.00866699, ..., 0.00927734,\n",
       "              -0.00897217, -0.0117188],\n",
       "             [0.00585938, 0.00411987, 0.00147247, ..., 0.00610352,\n",
       "              0.00488281, 0.00402832],\n",
       "             [0.00107574, -0.00370789, -0.00515747, ..., 0.0139771,\n",
       "              0.0106201, -0.000747681],\n",
       "             ...,\n",
       "             [0.0043335, 0.00686646, 0.0088501, ..., -0.0043335, 0.0166016,\n",
       "              -0.0126343],\n",
       "             [-0.00479126, -0.00436401, -0.00069809, ..., 0.0301514,\n",
       "              -0.0154419, 0.00540161],\n",
       "             [0.00156403, 3.33786e-05, -0.00187683, ..., 0.00619507,\n",
       "              -0.00427246, 0.0664062]]],\n",
       "    \n",
       "    \n",
       "           [[[0.00915527, -0.0126343, 0.0205078, ..., -0.00701904,\n",
       "              0.0142212, -0.000843048],\n",
       "             [0.0256348, -0.0114136, -0.0196533, ..., 0.0196533,\n",
       "              0.00231934, -0.0131836],\n",
       "             [-0.00094223, -0.012085, -0.00390625, ..., -0.00317383,\n",
       "              -0.00463867, -0.00352478],\n",
       "             ...,\n",
       "             [0.0043335, -0.0112915, 0.00476074, ..., -0.0012207,\n",
       "              -0.00497437, 0.0236816],\n",
       "             [0.00366211, -0.00212097, -0.00476074, ..., 0.00628662,\n",
       "              -0.00958252, -0.00561523],\n",
       "             [-0.00543213, -0.0032959, -0.00134277, ..., -0.00915527,\n",
       "              -0.0238037, 0.00509644]],\n",
       "    \n",
       "            [[0.00680542, -0.00415039, 0.0222168, ..., 0.0106812,\n",
       "              0.0150757, -0.0067749],\n",
       "             [-0.0187988, -0.0115356, 0.0307617, ..., 0.0183105,\n",
       "              0.00567627, 0.00891113],\n",
       "             [0.00982666, -0.000425339, -0.0150146, ..., 0.00750732,\n",
       "              -0.00726318, -0.0130615],\n",
       "             ...,\n",
       "             [0.0110474, 0.0145874, 0.0262451, ..., -0.00102234, 0.001297,\n",
       "              -0.0140991],\n",
       "             [0.0142212, -0.00135803, 0.00228882, ..., -0.00154114,\n",
       "              0.00665283, -0.00778198],\n",
       "             [0.0090332, 0.00848389, -0.0390625, ..., -0.0154419,\n",
       "              0.000375748, 0.0164795]],\n",
       "    \n",
       "            [[0.00653076, 0.0147095, -0.00524902, ..., 0.00866699,\n",
       "              -0.00552368, 0.0022583],\n",
       "             [0.0062561, -0.00128937, -0.00637817, ..., 0.019043,\n",
       "              -0.0116577, 0.0157471],\n",
       "             [0.000137329, 0.0125732, -0.00708008, ..., 0.0286865,\n",
       "              0.00213623, -0.00866699],\n",
       "             ...,\n",
       "             [0.0163574, 0.0148315, -0.0143433, ..., -0.0217285, 0.0110474,\n",
       "              -0.00933838],\n",
       "             [0.0111084, -0.00701904, -0.00176239, ..., -0.00238037,\n",
       "              0.00769043, 0.00616455],\n",
       "             [0.00714111, -0.000247955, 0.00166321, ..., -0.00216675,\n",
       "              0.00933838, -0.00209045]],\n",
       "    \n",
       "            [[4.95911e-05, -0.00897217, -0.00141144, ..., 0.00296021,\n",
       "              -0.00328064, -0.0322266],\n",
       "             [0.0115356, 0.00466919, 0.00769043, ..., -0.00537109,\n",
       "              -0.00970459, -0.0119629],\n",
       "             [0.0111694, 0.000385284, -0.00494385, ..., 0.00830078,\n",
       "              0.0124512, 0.000198364],\n",
       "             ...,\n",
       "             [0.00518799, -0.0222168, -0.000595093, ..., 0.0250244,\n",
       "              -0.00430298, 0.0114136],\n",
       "             [-0.00195312, -0.00306702, -0.00747681, ..., -0.00291443,\n",
       "              -0.019165, 0.0108643],\n",
       "             [-0.00970459, 0.0263672, -0.000204086, ..., -0.0078125,\n",
       "              -0.0103149, 0.010437]]]], dtype=bfloat16), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "              0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n",
       "             [0.00866699, 0.0045166],\n",
       "             [-0.0289307, 0.0133057],\n",
       "             ...,\n",
       "             [0.00262451, -0.00439453],\n",
       "             [-0.00622559, 0.0119629],\n",
       "             [0.0203857, -0.00273132]],\n",
       "    \n",
       "            [[-0.00334167, 0.00202942],\n",
       "             [-0.0117798, 0.00122833],\n",
       "             [0.0045166, -0.00823975],\n",
       "             ...,\n",
       "             [0.0124512, 0.0108643],\n",
       "             [-0.000934601, -0.00909424],\n",
       "             [0.00387573, 0.00366211]],\n",
       "    \n",
       "            [[0.00430298, -0.00231934],\n",
       "             [0.00162506, 0.00262451],\n",
       "             [0.0178223, -0.000146866],\n",
       "             ...,\n",
       "             [0.00897217, -0.00552368],\n",
       "             [0.0128174, -0.00970459],\n",
       "             [-0.00132751, -0.00172424]],\n",
       "    \n",
       "            [[-0.0050354, 0.0155029],\n",
       "             [0.00585938, -0.00552368],\n",
       "             [-0.000341415, -0.000541687],\n",
       "             ...,\n",
       "             [0.00634766, -0.00622559],\n",
       "             [0.00561523, -0.00396729],\n",
       "             [-0.00692749, -0.0140991]]],\n",
       "    \n",
       "    \n",
       "           [[[0.0133057, 0.0119629],\n",
       "             [0.000246048, -0.0211182],\n",
       "             [-0.00112915, 0.0115967],\n",
       "             ...,\n",
       "             [0.0189209, 0.000835419],\n",
       "             [0.00430298, 0.00515747],\n",
       "             [-0.00769043, 0.0148315]],\n",
       "    \n",
       "            [[-0.00823975, -0.0146484],\n",
       "             [-0.00334167, 0.00344849],\n",
       "             [0.00732422, -0.0025177],\n",
       "             ...,\n",
       "             [0.00610352, -0.0117798],\n",
       "             [0.00387573, -0.00439453],\n",
       "             [0.00473022, -0.00172424]],\n",
       "    \n",
       "            [[-0.00292969, -0.00799561],\n",
       "             [-0.0107422, -0.00552368],\n",
       "             [-0.00273132, -0.0233154],\n",
       "             ...,\n",
       "             [-0.00396729, -0.00854492],\n",
       "             [-0.00769043, -0.00482178],\n",
       "             [0.00325012, -0.0050354]],\n",
       "    \n",
       "            [[0.000246048, 0.000637054],\n",
       "             [-0.00334167, 0.000637054],\n",
       "             [0.0112305, -0.00439453],\n",
       "             ...,\n",
       "             [0.0128174, 0.00927734],\n",
       "             [0.0030365, -0.00643921],\n",
       "             [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)},\n",
       "   'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=Array([[[0.00595093, 0.00854492, 0.00390625, ..., 0.00741577, 0.0112305,\n",
       "             -0.0043335],\n",
       "            [-0.00534058, 0.00878906, -0.0113525, ..., 0.00202942,\n",
       "             -0.00604248, -0.00248718],\n",
       "            [-0.00897217, 0.00241089, -0.0128174, ..., -0.00860596,\n",
       "             -0.00683594, 0.010498],\n",
       "            ...,\n",
       "            [0.0162354, 0.00823975, 0.00872803, ..., -0.00610352, 0.0126953,\n",
       "             -0.0057373],\n",
       "            [0.0183105, 0.00030899, 0.0125122, ..., 0.00860596, -0.0123291,\n",
       "             0.000785828],\n",
       "            [0.000976562, 0.00390625, -0.00994873, ..., 0.0205078,\n",
       "             0.00418091, -0.0131836]],\n",
       "    \n",
       "           [[-0.00153351, 0.0202637, 0.0187988, ..., -0.000274658,\n",
       "             0.0125732, -0.000457764],\n",
       "            [-0.00521851, -0.00872803, -0.00138092, ..., -0.0140991,\n",
       "             0.012146, -0.00331116],\n",
       "            [-0.00738525, -0.00127411, -0.0126953, ..., -0.0349121,\n",
       "             -0.0050354, -0.0065918],\n",
       "            ...,\n",
       "            [0.00317383, -0.00714111, -0.0149536, ..., 0.0130615,\n",
       "             0.00793457, -0.0246582],\n",
       "            [0.010437, -0.0167236, 0.00335693, ..., 0.00854492, -0.0366211,\n",
       "             -0.0220947],\n",
       "            [0.0118408, -0.00708008, 0.00241089, ..., -0.00375366,\n",
       "             -0.0184326, 0.00787354]],\n",
       "    \n",
       "           [[0.00842285, -0.00119781, 0.00170135, ..., -0.0133667,\n",
       "             -0.00640869, -0.0143433],\n",
       "            [-0.0164795, -0.00637817, -0.0172119, ..., -0.00340271,\n",
       "             0.00309753, 0.000778198],\n",
       "            [0.000411987, -3.40939e-05, -0.00186157, ..., -0.0147705,\n",
       "             0.0155029, -0.0235596],\n",
       "            ...,\n",
       "            [-0.00524902, 0.00662231, 0.00393677, ..., -0.00256348,\n",
       "             0.000732422, -0.00799561],\n",
       "            [-0.00112152, -0.0200195, -0.0057373, ..., -0.00521851,\n",
       "             0.0214844, -0.0148926],\n",
       "            [0.00994873, -0.0135498, -0.00177002, ..., -0.0217285,\n",
       "             -0.015625, 0.00616455]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00765991, 0.00340271, -0.00738525, ..., -0.00360107,\n",
       "             -0.0130615, -0.0103149],\n",
       "            [0.00515747, -0.0134888, 0.00479126, ..., -0.00106049,\n",
       "             -0.00320435, -0.00598145],\n",
       "            [-0.00982666, 0.0217285, -0.00778198, ..., 0.00689697,\n",
       "             -0.0213623, 0.00527954],\n",
       "            ...,\n",
       "            [-0.00518799, 0.00315857, 0.00683594, ..., -0.0142212,\n",
       "             0.00300598, -0.00872803],\n",
       "            [-0.0141602, 0.00549316, 0.0101929, ..., 0.0109863, 0.0170898,\n",
       "             0.00233459],\n",
       "            [0.00964355, 0.00671387, -0.000545502, ..., 0.000333786,\n",
       "             0.00389099, -0.00457764]],\n",
       "    \n",
       "           [[-0.00772095, 0.00564575, -0.0105591, ..., -0.00970459,\n",
       "             -4.8399e-05, -0.0098877],\n",
       "            [-0.0108032, 0.000499725, 0.000667572, ..., 0.00640869,\n",
       "             0.0109253, 0.00430298],\n",
       "            [-0.00218201, -0.0114746, 0.0126953, ..., 0.0168457,\n",
       "             -0.00866699, 0.0185547],\n",
       "            ...,\n",
       "            [-0.00274658, -0.00285339, -0.00427246, ..., 0.006073,\n",
       "             0.0098877, 0.0120239],\n",
       "            [0.0098877, 0.0196533, -0.0186768, ..., 0.0109253, 0.00509644,\n",
       "             0.0187988],\n",
       "            [0.0118408, 0.00634766, -0.00854492, ..., -0.00408936,\n",
       "             0.000398636, 0.0195312]],\n",
       "    \n",
       "           [[-0.00549316, 0.00436401, 0.00848389, ..., 0.00312805,\n",
       "             0.0113525, 0.00445557],\n",
       "            [-0.00512695, -0.00732422, 0.00772095, ..., 0.0194092,\n",
       "             0.0108032, -0.00341797],\n",
       "            [0.00546265, -0.00241089, 0.000572205, ..., -0.00256348,\n",
       "             0.000213623, 0.012085],\n",
       "            ...,\n",
       "            [-0.00479126, -0.00382996, -0.00262451, ..., -0.00662231,\n",
       "             0.0201416, -0.00418091],\n",
       "            [0.00613403, 0.0125122, -0.00558472, ..., -0.00637817,\n",
       "             -0.0192871, -0.00769043],\n",
       "            [0.000234604, 0.00280762, -0.00567627, ..., -0.0136719,\n",
       "             -0.00457764, 0.026123]]], dtype=bfloat16), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0],\n",
       "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "             0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n",
       "            [0.00866699, 0.0045166],\n",
       "            [-0.0289307, 0.0133057],\n",
       "            ...,\n",
       "            [0.00262451, -0.00439453],\n",
       "            [-0.00622559, 0.0119629],\n",
       "            [0.0203857, -0.00273132]],\n",
       "    \n",
       "           [[-0.00334167, 0.00202942],\n",
       "            [-0.0117798, 0.00122833],\n",
       "            [0.0045166, -0.00823975],\n",
       "            ...,\n",
       "            [0.0124512, 0.0108643],\n",
       "            [-0.000934601, -0.00909424],\n",
       "            [0.00387573, 0.00366211]],\n",
       "    \n",
       "           [[0.00430298, -0.00231934],\n",
       "            [0.00162506, 0.00262451],\n",
       "            [0.0178223, -0.000146866],\n",
       "            ...,\n",
       "            [0.00897217, -0.00552368],\n",
       "            [0.0128174, -0.00970459],\n",
       "            [-0.00132751, -0.00172424]],\n",
       "    \n",
       "           ...,\n",
       "    \n",
       "           [[-0.00823975, -0.0146484],\n",
       "            [-0.00334167, 0.00344849],\n",
       "            [0.00732422, -0.0025177],\n",
       "            ...,\n",
       "            [0.00610352, -0.0117798],\n",
       "            [0.00387573, -0.00439453],\n",
       "            [0.00473022, -0.00172424]],\n",
       "    \n",
       "           [[-0.00292969, -0.00799561],\n",
       "            [-0.0107422, -0.00552368],\n",
       "            [-0.00273132, -0.0233154],\n",
       "            ...,\n",
       "            [-0.00396729, -0.00854492],\n",
       "            [-0.00769043, -0.00482178],\n",
       "            [0.00325012, -0.0050354]],\n",
       "    \n",
       "           [[0.000246048, 0.000637054],\n",
       "            [-0.00334167, 0.000637054],\n",
       "            [0.0112305, -0.00439453],\n",
       "            ...,\n",
       "            [0.0128174, 0.00927734],\n",
       "            [0.0030365, -0.00643921],\n",
       "            [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}},\n",
       "  'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=Array([[[-0.00107574, -0.0137939, 0.013916, ..., 0.0205078, 0.000705719,\n",
       "            -0.000926971],\n",
       "           [0.000843048, 0.0109863, -0.00476074, ..., -0.00411987,\n",
       "            -0.00427246, 0.00138855],\n",
       "           [-0.00469971, 0.0162354, 0.00312805, ..., 0.000133514,\n",
       "            0.00408936, -0.00280762],\n",
       "           ...,\n",
       "           [-0.00196838, 0.000606537, 0.00445557, ..., -0.0109253,\n",
       "            -0.0115356, 0.00113678],\n",
       "           [0.00799561, 0.00598145, -0.00436401, ..., 0.00543213,\n",
       "            0.00390625, -0.0150146],\n",
       "           [-0.0100098, 0.012207, -0.00418091, ..., -3.71933e-05,\n",
       "            0.00317383, -0.00762939]],\n",
       "   \n",
       "          [[0.0131226, 0.00756836, 0.00860596, ..., 0.00970459, -0.0107422,\n",
       "            -0.000591278],\n",
       "           [-0.00762939, -0.00680542, 0.00692749, ..., -0.00337219,\n",
       "            0.00616455, 0.00830078],\n",
       "           [6.07967e-05, -0.00848389, 0.00683594, ..., 0.0144043,\n",
       "            0.00964355, 0.00494385],\n",
       "           ...,\n",
       "           [0.00427246, -0.012146, 0.0186768, ..., 0.00158691, -0.00759888,\n",
       "            0.000240326],\n",
       "           [0.00218201, 0.0078125, 0.0145874, ..., -0.00799561, 0.00384521,\n",
       "            0.00933838],\n",
       "           [0.00811768, -0.00424194, -0.00317383, ..., 0.003479,\n",
       "            -0.00289917, 0.00296021]]], dtype=bfloat16), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n",
       "           [0.0014267, -0.00720215],\n",
       "           [0.00708008, 0.0142822],\n",
       "           ...,\n",
       "           [-0.000341415, 0.00408936],\n",
       "           [-0.00439453, 0.0108643],\n",
       "           [0.0220947, 0.0203857]],\n",
       "   \n",
       "          [[-0.00527954, 0.00283813],\n",
       "           [0.0101929, 0.00927734],\n",
       "           [0.00836182, -0.0211182],\n",
       "           ...,\n",
       "           [-0.000341415, -0.000341415],\n",
       "           [0.00221252, 0.0078125],\n",
       "           [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0),\n",
       "   'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=Array([[0.00128937, -0.0125732, -0.0032196, ..., 0.00576782, 0.00156403,\n",
       "           0.00473022],\n",
       "          [0.0037384, 0.000239372, 0.00402832, ..., 0.000394821,\n",
       "           -0.000530243, 0.010376],\n",
       "          [0.00817871, 0.00106812, 0.00132751, ..., 0.00848389, -0.00289917,\n",
       "           -0.00491333],\n",
       "          ...,\n",
       "          [-0.00891113, -0.00646973, 0.0057373, ..., -0.00320435,\n",
       "           -0.0106812, 0.00619507],\n",
       "          [-0.00558472, -0.00738525, -0.0100708, ..., 0.0043335, 0.00579834,\n",
       "           0.00738525],\n",
       "          [0.00341797, -0.0169678, -0.0038147, ..., 0.00439453, 0.00817871,\n",
       "           0.0125732]], dtype=bfloat16), a=Array([[-0.0046731 ,  0.00286664,  0.00511242, ...,  0.01160862,\n",
       "           -0.00942933, -0.01301723],\n",
       "          [ 0.0052865 ,  0.00223007, -0.01150817, ..., -0.00929926,\n",
       "           -0.01117802,  0.00230565]], dtype=float32), b=Array([[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]], dtype=float32), alpha=1.0)},\n",
       "  'post_attention_norm': {'scale': Array([0.107422, 0.113281, 0.164062, ..., 0.0292969, 0.0986328,\n",
       "          -0.0441895], dtype=bfloat16)},\n",
       "  'post_ffw_norm': {'scale': Array([0.484375, 0.488281, 0.539062, ..., 0.390625, 0.65625, 0.408203],      dtype=bfloat16)},\n",
       "  'pre_attention_norm': {'scale': Array([0.953125, 0.917969, 0.871094, ..., 1.10156, 0.15918, 0.871094],      dtype=bfloat16)},\n",
       "  'pre_ffw_norm': {'scale': Array([0.267578, 0.339844, 0.296875, ..., 0.400391, -0.120117, 0.251953],      dtype=bfloat16)}}}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_params['transformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer': {'embedder': {'input_embedding': 2},\n",
       "  'final_norm': {'scale': -1},\n",
       "  'layer_0': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_1': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_10': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_11': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_12': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_13': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_14': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_15': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_16': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_17': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_18': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_19': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_2': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_20': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_21': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_22': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_23': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_24': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_25': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_3': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_4': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_5': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_6': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_7': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_8': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}},\n",
       "  'layer_9': {'attn': {'attn_vec_einsum': {'w': 2},\n",
       "    'kv_einsum': {'w': 2},\n",
       "    'q_einsum': {'w': 2}},\n",
       "   'mlp': {'gating_einsum': 2, 'linear': 2},\n",
       "   'post_attention_norm': {'scale': -1},\n",
       "   'post_ffw_norm': {'scale': -1},\n",
       "   'pre_attention_norm': {'scale': -1},\n",
       "   'pre_ffw_norm': {'scale': -1}}}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cellView": "form",
    "id": "7SL2VAmVEcoa"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dict key mismatch; expected keys: ['embedder', 'final_norm', 'layer_0', 'layer_1', 'layer_10', 'layer_11', 'layer_12', 'layer_13', 'layer_14', 'layer_15', 'layer_16', 'layer_17', 'layer_18', 'layer_19', 'layer_2', 'layer_20', 'layer_21', 'layer_22', 'layer_23', 'layer_24', 'layer_25', 'layer_3', 'layer_4', 'layer_5', 'layer_6', 'layer_7', 'layer_8', 'layer_9']; dict: {'transformer': {'embedder': {'input_embedding': LoraWeight(shape=(256128, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.02199156,  0.0049439 , -0.01322838, ..., -0.01093095,\n         0.01156266,  0.01847863],\n       [ 0.01022545, -0.01507886, -0.0023296 , ...,  0.00661303,\n         0.02698121,  0.00401224]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'final_norm': {'scale': Array([2.32812, 2.34375, 2.28125, ..., 4.65625, 2.53125, 2.4375],      dtype=bfloat16)}, 'layer_0': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 1.3663782e-02, -6.0665291e-03,  1.4391938e-02, ...,\n        -7.4021826e-03, -2.7578839e-03, -8.8478941e-03],\n       [ 1.8342493e-02,  3.5765569e-03,  2.9392069e-05, ...,\n        -1.2318562e-02,  2.7163564e-03,  2.3088796e-02]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.53125, -0.515625, -0.490234, ..., -0.53125, 1.42188, -0.519531],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([-0.229492, -0.189453, -0.194336, ..., -0.361328, 0.441406,\n       -0.162109], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.116699, 0.134766, 0.192383, ..., 0.636719, 0.0402832, 0.243164],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.227539, 0.208008, 0.208008, ..., 0.992188, 2.15625, 0.197266],      dtype=bfloat16)}}, 'layer_1': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.01047093,  0.01922145, -0.01181239, ...,  0.0187807 ,\n        -0.002852  ,  0.01409159],\n       [-0.01944142,  0.00886716, -0.00052842, ..., -0.02301286,\n         0.00416193, -0.00264629]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.507812, -0.46875, -0.466797, ..., -0.503906, 0.102539,\n       -0.498047], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([-0.0354004, 0.0598145, 0.043457, ..., -0.202148, 0.308594,\n       0.113281], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.648438, 0.589844, 0.640625, ..., 1.27344, 0.229492, 0.5625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.498047, 0.570312, 0.535156, ..., 1.22656, 0.361328, 0.462891],      dtype=bfloat16)}}, 'layer_10': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00627691, -0.01385751, -0.00372067, ..., -0.01245145,\n        -0.01636037,  0.00584008],\n       [-0.01115024, -0.00439675,  0.00728602, ..., -0.01480319,\n         0.01306054,  0.00127973]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.244141, 0.330078, 0.421875, ..., 0.183594, 0.165039, 0.129883],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.496094, 0.535156, 0.570312, ..., 0.429688, 0.511719, 0.371094],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.699219, 0.773438, 0.65625, ..., 0.820312, 0.0186768, 0.671875],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.12793, 0.229492, 0.152344, ..., 0.227539, -0.212891, 0.125977],      dtype=bfloat16)}}, 'layer_11': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.01029943, -0.01047805,  0.00627802, ...,  0.00658243,\n         0.00416735, -0.00188006],\n       [-0.00780879, -0.00588758,  0.00545886, ...,  0.00931677,\n        -0.00922768,  0.00010113]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.417969, 0.449219, 0.496094, ..., 0.236328, 0.0996094, 0.226562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.570312, 0.636719, 0.699219, ..., 0.523438, 0.554688, 0.421875],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.648438, 0.875, 0.738281, ..., 0.773438, -0.0170898, 0.667969],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.074707, 0.15625, 0.0830078, ..., 0.185547, -0.205078, 0.0991211],      dtype=bfloat16)}}, 'layer_12': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00788363,  0.00197184,  0.00437608, ...,  0.01334583,\n         0.00926806,  0.01390658],\n       [ 0.00132567, -0.00222159, -0.00384167, ..., -0.02493023,\n         0.00545663, -0.00319182]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.416016, 0.648438, 0.589844, ..., 0.335938, 0.133789, 0.298828],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.644531, 0.695312, 0.757812, ..., 0.589844, 0.589844, 0.507812],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.933594, 1.07812, 0.972656, ..., 0.863281, 0.0952148, 0.957031],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.0192871, 0.0976562, 0.0195312, ..., 0.10498, -0.239258,\n       0.0118408], dtype=bfloat16)}}, 'layer_13': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.01005734,  0.01642189,  0.01510733, ...,  0.01328816,\n         0.00516436,  0.00271901],\n       [ 0.01016035, -0.00417797, -0.00903327, ..., -0.00616623,\n        -0.00244164, -0.01308654]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.742188, 0.71875, 0.671875, ..., 0.597656, 0.515625, 0.494141],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.875, 0.867188, 0.953125, ..., 0.859375, 0.839844, 0.679688],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.722656, 0.894531, 0.761719, ..., 0.726562, 0.0529785, 0.789062],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.126953, -0.0751953, -0.126953, ..., -0.0358887, -0.269531,\n       -0.0932617], dtype=bfloat16)}}, 'layer_14': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00014633,  0.00200139, -0.00434174, ..., -0.001957  ,\n        -0.01323679, -0.00078773],\n       [ 0.00267099, -0.01303148,  0.02141839, ..., -0.00115613,\n        -0.01118799, -0.00374962]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.882812, 0.957031, 0.742188, ..., 0.757812, 0.648438, 0.628906],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.14844, 1.125, 1.20312, ..., 1.07031, 1.04688, 0.898438],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.878906, 1.07812, 0.859375, ..., 0.964844, 0.373047, 0.929688],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.185547, -0.140625, -0.193359, ..., -0.111328, -0.271484,\n       -0.130859], dtype=bfloat16)}}, 'layer_15': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00193953,  0.00879681, -0.02188212, ...,  0.00268727,\n         0.00692501, -0.02095343],\n       [-0.01345678,  0.01583269,  0.00739929, ...,  0.00684354,\n        -0.01523105,  0.00528662]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.125, 1.09375, 1.17969, ..., 1.22656, 0.921875, 0.847656],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.42188, 1.45312, 1.50781, ..., 1.46094, 1.53125, 1.23438],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.589844, 0.570312, 0.498047, ..., 0.628906, 0.259766, 0.570312],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.176758, -0.133789, -0.176758, ..., -0.145508, -0.251953,\n       -0.133789], dtype=bfloat16)}}, 'layer_16': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00321405, -0.01531544,  0.01043977, ...,  0.01724594,\n        -0.00019943, -0.00515615],\n       [-0.00242979, -0.00892317, -0.00779914, ...,  0.01742655,\n         0.00521834,  0.00618159]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.25781, 1.17969, 1.125, ..., 0.96875, 1.0625, 0.910156], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.8125, 1.82812, 1.90625, ..., 1.71094, 1.84375, 1.57031],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.871094, 0.992188, 0.765625, ..., 0.648438, 0.5625, 0.960938],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.108398, -0.0561523, -0.0947266, ..., -0.074707, -0.150391,\n       -0.0505371], dtype=bfloat16)}}, 'layer_17': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00229674,  0.00096951,  0.00196753, ...,  0.00066601,\n         0.00454113, -0.01169481],\n       [-0.00571106, -0.00023862, -0.00663244, ...,  0.00123321,\n        -0.01802823,  0.00163148]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.17188, 1.17188, 1.03125, ..., 1.05469, 0.980469, 1.01562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.125, 2.04688, 2.1875, ..., 2, 2.15625, 1.875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.535156, 0.675781, 0.472656, ..., 0.484375, 0.423828, 0.667969],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.0554199, -0.00891113, -0.0585938, ..., -0.0483398, -0.0942383,\n       -0.000480652], dtype=bfloat16)}}, 'layer_18': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.01076485, -0.01254259,  0.00719575, ..., -0.01088936,\n         0.02172294,  0.00355693],\n       [-0.00358216, -0.01947643, -0.00234379, ..., -0.00571739,\n         0.02209909,  0.01588861]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.36719, 1.41406, 1.35938, ..., 1.39062, 1.60938, 1.26562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.46875, 2.42188, 2.48438, ..., 2.34375, 2.53125, 2.3125],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.443359, 0.570312, 0.347656, ..., 0.453125, 0.388672, 0.5625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.160156, 0.269531, 0.191406, ..., 0.158203, 0.11377, 0.259766],      dtype=bfloat16)}}, 'layer_19': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.01803358, -0.00303927,  0.00691553, ...,  0.00371117,\n         0.00372419,  0.00021878],\n       [ 0.00078573, -0.00061509, -0.0201269 , ...,  0.01225177,\n         0.00519481,  0.00182117]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.25, 1.07812, 1.29688, ..., 1.35156, 1.29688, 1.14062], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.64062, 2.625, 2.73438, ..., 2.51562, 2.625, 2.3125], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.414062, 0.59375, 0.5, ..., 0.451172, 0.375, 0.554688], dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.175781, 0.236328, 0.203125, ..., 0.168945, 0.128906, 0.248047],      dtype=bfloat16)}}, 'layer_2': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.01155356,  0.00352542, -0.00475057, ...,  0.00461095,\n         0.00289454, -0.0215128 ],\n       [ 0.00688512, -0.00726845, -0.00535207, ...,  0.00995815,\n         0.00537037,  0.00453264]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.232422, -0.229492, -0.160156, ..., -0.414062, 0.0179443,\n       -0.265625], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.131836, 0.105469, 0.139648, ..., -0.141602, 0.326172, 0.135742],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.714844, 0.667969, 0.71875, ..., 1.07812, 0.300781, 0.515625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.5, 0.511719, 0.53125, ..., 0.941406, 0.00320435, 0.40625],      dtype=bfloat16)}}, 'layer_20': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00383564, -0.00756023, -0.01255484, ...,  0.01498562,\n        -0.01903302,  0.02186585],\n       [-0.00933835,  0.0013327 ,  0.01779663, ..., -0.00167542,\n         0.00606556, -0.00059748]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.39062, 1.32031, 1.55469, ..., 1.32031, 1.50781, 1.29688],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.84375, 2.875, 2.90625, ..., 2.64062, 2.78125, 2.5625], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.359375, 0.330078, 0.347656, ..., 0.306641, 0.318359, 0.5],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.0220947, 0.0688477, 0.0303955, ..., 0.0279541, 0.0133057,\n       0.108887], dtype=bfloat16)}}, 'layer_21': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00473069, -0.01229254,  0.00118823, ...,  0.00760194,\n        -0.01410474, -0.00785806],\n       [-0.00138563, -0.00167912,  0.01098308, ...,  0.01268801,\n         0.0018889 , -0.00222404]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.34375, 1.36719, 1.53906, ..., 1.33594, 1.35156, 1.24219],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([3.1875, 3.34375, 3.375, ..., 3.04688, 3.32812, 3.03125], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.421875, 0.402344, 0.400391, ..., 0.457031, 0.480469, 0.53125],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.0605469, -0.0107422, -0.0512695, ..., -0.0512695, -0.0771484,\n       0.0262451], dtype=bfloat16)}}, 'layer_22': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00068823,  0.00820747,  0.00691753, ..., -0.01032871,\n         0.01214039, -0.01452747],\n       [-0.00807814, -0.00087587,  0.01156158, ..., -0.00500905,\n         0.0198493 ,  0.00917682]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.54688, 2.875, 2.70312, ..., 2.375, 2.73438, 2.35938], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([3.73438, 3.75, 3.84375, ..., 3.57812, 3.89062, 3.48438], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.232422, 0.261719, 0.180664, ..., 0.330078, 0.298828, 0.355469],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.090332, -0.0563965, -0.0976562, ..., -0.104004, -0.11084,\n       -0.0168457], dtype=bfloat16)}}, 'layer_23': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00148038,  0.0081275 ,  0.0149825 , ...,  0.00171928,\n        -0.0045339 ,  0.00112129],\n       [-0.01026383,  0.0025746 , -0.02289991, ..., -0.00131096,\n         0.00538384, -0.00893523]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.21875, 2.28125, 2.20312, ..., 2.07812, 2.29688, 2.03125],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.15625, 4.28125, 4.34375, ..., 4.25, 4.53125, 4], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.306641, 0.337891, 0.300781, ..., 0.367188, 0.396484, 0.429688],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.158203, -0.146484, -0.166016, ..., -0.147461, -0.173828,\n       -0.10791], dtype=bfloat16)}}, 'layer_24': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.0118248 ,  0.00209964,  0.00429165, ...,  0.00531876,\n         0.0007639 , -0.01389843],\n       [ 0.00161521,  0.01745081, -0.0089213 , ...,  0.01427022,\n        -0.00016093,  0.01795714]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.5625, 2.40625, 2.51562, ..., 2.625, 2.76562, 2.46875], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.75, 4.78125, 4.90625, ..., 5.59375, 5.34375, 4.6875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.248047, 0.223633, 0.21582, ..., 0.345703, 0.259766, 0.339844],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.188477, -0.169922, -0.19043, ..., -0.158203, -0.195312,\n       -0.142578], dtype=bfloat16)}}, 'layer_25': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.005503  , -0.00465591,  0.02688703, ...,  0.00167953,\n        -0.00383867,  0.01666052],\n       [ 0.00788943, -0.01279993, -0.01336973, ...,  0.00526251,\n        -0.00046879,  0.01022278]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.39062, 2.375, 2.32812, ..., 3.42188, 2.84375, 2.29688], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.6875, 4.84375, 4.9375, ..., 5.9375, 4.5625, 4.6875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.296875, 0.261719, 0.265625, ..., 0.380859, 0.296875, 0.373047],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.136719, -0.134766, -0.133789, ..., -0.0761719, -0.129883,\n       -0.105957], dtype=bfloat16)}}, 'layer_3': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00757848,  0.00208123, -0.0095167 , ...,  0.01346242,\n         0.01381325, -0.00154688],\n       [-0.01088316, -0.00166531, -0.02113895, ..., -0.00199354,\n         0.00065937,  0.00700611]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.166992, -0.209961, -0.139648, ..., -0.363281, -0.0634766,\n       -0.261719], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.361328, 0.380859, 0.306641, ..., 0.0698242, 0.480469, 0.386719],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.617188, 0.453125, 0.699219, ..., 0.785156, 0.363281, 0.527344],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.859375, 0.824219, 0.894531, ..., 1.19531, 0.0356445, 0.714844],      dtype=bfloat16)}}, 'layer_4': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00232868,  0.00122111, -0.02715557, ...,  0.00275968,\n         0.0063306 ,  0.00120457],\n       [ 0.01015269, -0.00104287, -0.01713954, ...,  0.01712951,\n        -0.02799168, -0.01150994]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.193359, -0.28125, -0.21582, ..., -0.378906, -0.0407715,\n       -0.332031], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.285156, 0.245117, 0.246094, ..., 0.0476074, 0.613281, 0.271484],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.652344, 0.507812, 0.613281, ..., 0.824219, -0.0534668, 0.363281],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.554688, 0.570312, 0.554688, ..., 0.851562, 0.124512, 0.453125],      dtype=bfloat16)}}, 'layer_5': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00584595, -0.00180545, -0.00662199, ..., -0.0220709 ,\n        -0.00569964, -0.00861686],\n       [ 0.00151854, -0.00964406,  0.00366633, ...,  0.00940564,\n        -0.00930284,  0.00364371]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0136108, -0.150391, -0.020874, ..., -0.355469, -0.0186768,\n       -0.425781], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.0888672, 0.0622559, 0.12793, ..., -0.00866699, 0.337891,\n       0.0756836], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.490234, 0.255859, 0.330078, ..., 0.367188, -0.0544434, 0.046875],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.388672, 0.382812, 0.402344, ..., 0.597656, -0.0415039, 0.236328],      dtype=bfloat16)}}, 'layer_6': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.0155806 , -0.01371003, -0.01509875, ...,  0.01296713,\n         0.00798594,  0.00760426],\n       [-0.00061655,  0.01749108, -0.01459254, ...,  0.01223726,\n        -0.01537374,  0.00116413]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0039978, -0.124512, -0.0678711, ..., -0.241211, 0.00665283,\n       -0.359375], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.106934, 0.0874023, 0.219727, ..., 0.0168457, 0.365234, 0.10498],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([1.10156, 0.796875, 0.84375, ..., 0.988281, 0.0463867, 0.369141],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.435547, 0.447266, 0.443359, ..., 0.636719, -0.0673828, 0.363281],      dtype=bfloat16)}}, 'layer_7': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00536764,  0.01348992, -0.00598283, ..., -0.01268126,\n        -0.01520117, -0.01440818],\n       [ 0.00239141,  0.01290342,  0.00408962, ...,  0.00013094,\n         0.00600098, -0.00192806]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0143433, -0.0620117, 0.0375977, ..., -0.0898438, 0.110352,\n       -0.135742], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.191406, 0.195312, 0.308594, ..., 0.118164, 0.625, 0.196289],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.726562, 0.589844, 0.59375, ..., 0.789062, -0.155273, 0.455078],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.542969, 0.582031, 0.550781, ..., 0.742188, -0.00248718, 0.455078],      dtype=bfloat16)}}, 'layer_8': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00295627, -0.00559398, -0.00677068, ...,  0.01155958,\n        -0.01056946, -0.01427677],\n       [ 0.02465803,  0.01395147, -0.01297336, ..., -0.0011971 ,\n        -0.00226062, -0.00428502]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.120117, 0.132812, 0.211914, ..., 0.0247803, 0.125977, 0.0432129],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.277344, 0.273438, 0.369141, ..., 0.199219, 0.644531, 0.271484],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([1.14062, 1.02344, 1.03906, ..., 1.14062, 0.0703125, 0.894531],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.601562, 0.675781, 0.648438, ..., 0.785156, 0.0917969, 0.589844],      dtype=bfloat16)}}, 'layer_9': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.0046731 ,  0.00286664,  0.00511242, ...,  0.01160862,\n        -0.00942933, -0.01301723],\n       [ 0.0052865 ,  0.00223007, -0.01150817, ..., -0.00929926,\n        -0.01117802,  0.00230565]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.107422, 0.113281, 0.164062, ..., 0.0292969, 0.0986328,\n       -0.0441895], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.484375, 0.488281, 0.539062, ..., 0.390625, 0.65625, 0.408203],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.953125, 0.917969, 0.871094, ..., 1.10156, 0.15918, 0.871094],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.267578, 0.339844, 0.296875, ..., 0.400391, -0.120117, 0.251953],      dtype=bfloat16)}}}}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m training_cfg \u001b[38;5;241m=\u001b[39m TrainingConfig(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m      2\u001b[0m                               num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m                               eval_every_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      4\u001b[0m                               batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m                               max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlora_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_params\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtraining_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlora_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 25\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(lora_model, params, train_dataloader, tokenizer, training_cfg, lora_spec)\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39msgd(training_cfg\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m     24\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m lorax\u001b[38;5;241m.\u001b[39mwrap_optimizer(optimizer, lora_spec)\n\u001b[0;32m---> 25\u001b[0m opt_state \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     28\u001b[0m avg_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optax/_src/combine.py:214\u001b[0m, in \u001b[0;36mmulti_transform.<locals>.init_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m label_set\u001b[38;5;241m.\u001b[39missubset(transforms\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSome parameters have no corresponding transformation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    211\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(label_set))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    212\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransforms keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(transforms\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 214\u001b[0m inner_states \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    215\u001b[0m     group: wrappers\u001b[38;5;241m.\u001b[39mmasked(\n\u001b[1;32m    216\u001b[0m         tx, make_mask(labels, group),\n\u001b[1;32m    217\u001b[0m         mask_compatible_extra_args\u001b[38;5;241m=\u001b[39mmask_compatible_extra_args)\u001b[38;5;241m.\u001b[39minit(params)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group, tx \u001b[38;5;129;01min\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    219\u001b[0m }\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MultiTransformState(inner_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optax/_src/combine.py:217\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m label_set\u001b[38;5;241m.\u001b[39missubset(transforms\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSome parameters have no corresponding transformation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    211\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(label_set))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    212\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransforms keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(transforms\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    214\u001b[0m inner_states \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    215\u001b[0m     group: \u001b[43mwrappers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_compatible_extra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_compatible_extra_args\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group, tx \u001b[38;5;129;01min\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    219\u001b[0m }\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MultiTransformState(inner_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optax/_src/wrappers.py:546\u001b[0m, in \u001b[0;36mmasked.<locals>.init_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    544\u001b[0m mask_tree \u001b[38;5;241m=\u001b[39m mask(params) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mask) \u001b[38;5;28;01melse\u001b[39;00m mask\n\u001b[1;32m    545\u001b[0m masked_params \u001b[38;5;241m=\u001b[39m mask_pytree(params, mask_tree)\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MaskedState(inner_state\u001b[38;5;241m=\u001b[39m\u001b[43minner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_params\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optax/_src/combine.py:214\u001b[0m, in \u001b[0;36mmulti_transform.<locals>.init_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m label_set\u001b[38;5;241m.\u001b[39missubset(transforms\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSome parameters have no corresponding transformation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    211\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(label_set))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    212\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransforms keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(transforms\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 214\u001b[0m inner_states \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    215\u001b[0m     group: wrappers\u001b[38;5;241m.\u001b[39mmasked(\n\u001b[1;32m    216\u001b[0m         tx, make_mask(labels, group),\n\u001b[1;32m    217\u001b[0m         mask_compatible_extra_args\u001b[38;5;241m=\u001b[39mmask_compatible_extra_args)\u001b[38;5;241m.\u001b[39minit(params)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group, tx \u001b[38;5;129;01min\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    219\u001b[0m }\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MultiTransformState(inner_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optax/_src/combine.py:217\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m label_set\u001b[38;5;241m.\u001b[39missubset(transforms\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSome parameters have no corresponding transformation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    211\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(label_set))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    212\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransforms keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28msorted\u001b[39m(transforms\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    214\u001b[0m inner_states \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    215\u001b[0m     group: \u001b[43mwrappers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_compatible_extra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_compatible_extra_args\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group, tx \u001b[38;5;129;01min\u001b[39;00m transforms\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    219\u001b[0m }\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MultiTransformState(inner_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optax/_src/wrappers.py:545\u001b[0m, in \u001b[0;36mmasked.<locals>.init_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    542\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MaskedState(inner_state\u001b[38;5;241m=\u001b[39minner\u001b[38;5;241m.\u001b[39minit(params))\n\u001b[1;32m    544\u001b[0m mask_tree \u001b[38;5;241m=\u001b[39m mask(params) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mask) \u001b[38;5;28;01melse\u001b[39;00m mask\n\u001b[0;32m--> 545\u001b[0m masked_params \u001b[38;5;241m=\u001b[39m \u001b[43mmask_pytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_tree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MaskedState(inner_state\u001b[38;5;241m=\u001b[39minner\u001b[38;5;241m.\u001b[39minit(masked_params))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/optax/_src/wrappers.py:509\u001b[0m, in \u001b[0;36mmasked.<locals>.mask_pytree\u001b[0;34m(pytree, mask_tree)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmask_pytree\u001b[39m(pytree, mask_tree):\n\u001b[0;32m--> 509\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mMaskedNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpytree\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/_src/tree_util.py:342\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Alias of :func:`jax.tree.map`.\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 342\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/_src/tree_util.py:342\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Alias of :func:`jax.tree.map`.\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 342\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [\u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "\u001b[0;31mValueError\u001b[0m: Dict key mismatch; expected keys: ['embedder', 'final_norm', 'layer_0', 'layer_1', 'layer_10', 'layer_11', 'layer_12', 'layer_13', 'layer_14', 'layer_15', 'layer_16', 'layer_17', 'layer_18', 'layer_19', 'layer_2', 'layer_20', 'layer_21', 'layer_22', 'layer_23', 'layer_24', 'layer_25', 'layer_3', 'layer_4', 'layer_5', 'layer_6', 'layer_7', 'layer_8', 'layer_9']; dict: {'transformer': {'embedder': {'input_embedding': LoraWeight(shape=(256128, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.02199156,  0.0049439 , -0.01322838, ..., -0.01093095,\n         0.01156266,  0.01847863],\n       [ 0.01022545, -0.01507886, -0.0023296 , ...,  0.00661303,\n         0.02698121,  0.00401224]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'final_norm': {'scale': Array([2.32812, 2.34375, 2.28125, ..., 4.65625, 2.53125, 2.4375],      dtype=bfloat16)}, 'layer_0': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 1.3663782e-02, -6.0665291e-03,  1.4391938e-02, ...,\n        -7.4021826e-03, -2.7578839e-03, -8.8478941e-03],\n       [ 1.8342493e-02,  3.5765569e-03,  2.9392069e-05, ...,\n        -1.2318562e-02,  2.7163564e-03,  2.3088796e-02]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.53125, -0.515625, -0.490234, ..., -0.53125, 1.42188, -0.519531],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([-0.229492, -0.189453, -0.194336, ..., -0.361328, 0.441406,\n       -0.162109], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.116699, 0.134766, 0.192383, ..., 0.636719, 0.0402832, 0.243164],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.227539, 0.208008, 0.208008, ..., 0.992188, 2.15625, 0.197266],      dtype=bfloat16)}}, 'layer_1': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.01047093,  0.01922145, -0.01181239, ...,  0.0187807 ,\n        -0.002852  ,  0.01409159],\n       [-0.01944142,  0.00886716, -0.00052842, ..., -0.02301286,\n         0.00416193, -0.00264629]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.507812, -0.46875, -0.466797, ..., -0.503906, 0.102539,\n       -0.498047], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([-0.0354004, 0.0598145, 0.043457, ..., -0.202148, 0.308594,\n       0.113281], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.648438, 0.589844, 0.640625, ..., 1.27344, 0.229492, 0.5625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.498047, 0.570312, 0.535156, ..., 1.22656, 0.361328, 0.462891],      dtype=bfloat16)}}, 'layer_10': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00627691, -0.01385751, -0.00372067, ..., -0.01245145,\n        -0.01636037,  0.00584008],\n       [-0.01115024, -0.00439675,  0.00728602, ..., -0.01480319,\n         0.01306054,  0.00127973]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.244141, 0.330078, 0.421875, ..., 0.183594, 0.165039, 0.129883],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.496094, 0.535156, 0.570312, ..., 0.429688, 0.511719, 0.371094],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.699219, 0.773438, 0.65625, ..., 0.820312, 0.0186768, 0.671875],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.12793, 0.229492, 0.152344, ..., 0.227539, -0.212891, 0.125977],      dtype=bfloat16)}}, 'layer_11': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.01029943, -0.01047805,  0.00627802, ...,  0.00658243,\n         0.00416735, -0.00188006],\n       [-0.00780879, -0.00588758,  0.00545886, ...,  0.00931677,\n        -0.00922768,  0.00010113]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.417969, 0.449219, 0.496094, ..., 0.236328, 0.0996094, 0.226562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.570312, 0.636719, 0.699219, ..., 0.523438, 0.554688, 0.421875],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.648438, 0.875, 0.738281, ..., 0.773438, -0.0170898, 0.667969],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.074707, 0.15625, 0.0830078, ..., 0.185547, -0.205078, 0.0991211],      dtype=bfloat16)}}, 'layer_12': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00788363,  0.00197184,  0.00437608, ...,  0.01334583,\n         0.00926806,  0.01390658],\n       [ 0.00132567, -0.00222159, -0.00384167, ..., -0.02493023,\n         0.00545663, -0.00319182]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.416016, 0.648438, 0.589844, ..., 0.335938, 0.133789, 0.298828],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.644531, 0.695312, 0.757812, ..., 0.589844, 0.589844, 0.507812],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.933594, 1.07812, 0.972656, ..., 0.863281, 0.0952148, 0.957031],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.0192871, 0.0976562, 0.0195312, ..., 0.10498, -0.239258,\n       0.0118408], dtype=bfloat16)}}, 'layer_13': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.01005734,  0.01642189,  0.01510733, ...,  0.01328816,\n         0.00516436,  0.00271901],\n       [ 0.01016035, -0.00417797, -0.00903327, ..., -0.00616623,\n        -0.00244164, -0.01308654]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.742188, 0.71875, 0.671875, ..., 0.597656, 0.515625, 0.494141],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.875, 0.867188, 0.953125, ..., 0.859375, 0.839844, 0.679688],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.722656, 0.894531, 0.761719, ..., 0.726562, 0.0529785, 0.789062],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.126953, -0.0751953, -0.126953, ..., -0.0358887, -0.269531,\n       -0.0932617], dtype=bfloat16)}}, 'layer_14': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00014633,  0.00200139, -0.00434174, ..., -0.001957  ,\n        -0.01323679, -0.00078773],\n       [ 0.00267099, -0.01303148,  0.02141839, ..., -0.00115613,\n        -0.01118799, -0.00374962]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.882812, 0.957031, 0.742188, ..., 0.757812, 0.648438, 0.628906],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.14844, 1.125, 1.20312, ..., 1.07031, 1.04688, 0.898438],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.878906, 1.07812, 0.859375, ..., 0.964844, 0.373047, 0.929688],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.185547, -0.140625, -0.193359, ..., -0.111328, -0.271484,\n       -0.130859], dtype=bfloat16)}}, 'layer_15': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00193953,  0.00879681, -0.02188212, ...,  0.00268727,\n         0.00692501, -0.02095343],\n       [-0.01345678,  0.01583269,  0.00739929, ...,  0.00684354,\n        -0.01523105,  0.00528662]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.125, 1.09375, 1.17969, ..., 1.22656, 0.921875, 0.847656],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.42188, 1.45312, 1.50781, ..., 1.46094, 1.53125, 1.23438],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.589844, 0.570312, 0.498047, ..., 0.628906, 0.259766, 0.570312],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.176758, -0.133789, -0.176758, ..., -0.145508, -0.251953,\n       -0.133789], dtype=bfloat16)}}, 'layer_16': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00321405, -0.01531544,  0.01043977, ...,  0.01724594,\n        -0.00019943, -0.00515615],\n       [-0.00242979, -0.00892317, -0.00779914, ...,  0.01742655,\n         0.00521834,  0.00618159]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.25781, 1.17969, 1.125, ..., 0.96875, 1.0625, 0.910156], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([1.8125, 1.82812, 1.90625, ..., 1.71094, 1.84375, 1.57031],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.871094, 0.992188, 0.765625, ..., 0.648438, 0.5625, 0.960938],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.108398, -0.0561523, -0.0947266, ..., -0.074707, -0.150391,\n       -0.0505371], dtype=bfloat16)}}, 'layer_17': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00229674,  0.00096951,  0.00196753, ...,  0.00066601,\n         0.00454113, -0.01169481],\n       [-0.00571106, -0.00023862, -0.00663244, ...,  0.00123321,\n        -0.01802823,  0.00163148]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.17188, 1.17188, 1.03125, ..., 1.05469, 0.980469, 1.01562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.125, 2.04688, 2.1875, ..., 2, 2.15625, 1.875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.535156, 0.675781, 0.472656, ..., 0.484375, 0.423828, 0.667969],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.0554199, -0.00891113, -0.0585938, ..., -0.0483398, -0.0942383,\n       -0.000480652], dtype=bfloat16)}}, 'layer_18': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.01076485, -0.01254259,  0.00719575, ..., -0.01088936,\n         0.02172294,  0.00355693],\n       [-0.00358216, -0.01947643, -0.00234379, ..., -0.00571739,\n         0.02209909,  0.01588861]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.36719, 1.41406, 1.35938, ..., 1.39062, 1.60938, 1.26562],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.46875, 2.42188, 2.48438, ..., 2.34375, 2.53125, 2.3125],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.443359, 0.570312, 0.347656, ..., 0.453125, 0.388672, 0.5625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.160156, 0.269531, 0.191406, ..., 0.158203, 0.11377, 0.259766],      dtype=bfloat16)}}, 'layer_19': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.01803358, -0.00303927,  0.00691553, ...,  0.00371117,\n         0.00372419,  0.00021878],\n       [ 0.00078573, -0.00061509, -0.0201269 , ...,  0.01225177,\n         0.00519481,  0.00182117]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.25, 1.07812, 1.29688, ..., 1.35156, 1.29688, 1.14062], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.64062, 2.625, 2.73438, ..., 2.51562, 2.625, 2.3125], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.414062, 0.59375, 0.5, ..., 0.451172, 0.375, 0.554688], dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.175781, 0.236328, 0.203125, ..., 0.168945, 0.128906, 0.248047],      dtype=bfloat16)}}, 'layer_2': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.01155356,  0.00352542, -0.00475057, ...,  0.00461095,\n         0.00289454, -0.0215128 ],\n       [ 0.00688512, -0.00726845, -0.00535207, ...,  0.00995815,\n         0.00537037,  0.00453264]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.232422, -0.229492, -0.160156, ..., -0.414062, 0.0179443,\n       -0.265625], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.131836, 0.105469, 0.139648, ..., -0.141602, 0.326172, 0.135742],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.714844, 0.667969, 0.71875, ..., 1.07812, 0.300781, 0.515625],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.5, 0.511719, 0.53125, ..., 0.941406, 0.00320435, 0.40625],      dtype=bfloat16)}}, 'layer_20': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00383564, -0.00756023, -0.01255484, ...,  0.01498562,\n        -0.01903302,  0.02186585],\n       [-0.00933835,  0.0013327 ,  0.01779663, ..., -0.00167542,\n         0.00606556, -0.00059748]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.39062, 1.32031, 1.55469, ..., 1.32031, 1.50781, 1.29688],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([2.84375, 2.875, 2.90625, ..., 2.64062, 2.78125, 2.5625], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.359375, 0.330078, 0.347656, ..., 0.306641, 0.318359, 0.5],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.0220947, 0.0688477, 0.0303955, ..., 0.0279541, 0.0133057,\n       0.108887], dtype=bfloat16)}}, 'layer_21': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00473069, -0.01229254,  0.00118823, ...,  0.00760194,\n        -0.01410474, -0.00785806],\n       [-0.00138563, -0.00167912,  0.01098308, ...,  0.01268801,\n         0.0018889 , -0.00222404]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([1.34375, 1.36719, 1.53906, ..., 1.33594, 1.35156, 1.24219],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([3.1875, 3.34375, 3.375, ..., 3.04688, 3.32812, 3.03125], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.421875, 0.402344, 0.400391, ..., 0.457031, 0.480469, 0.53125],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.0605469, -0.0107422, -0.0512695, ..., -0.0512695, -0.0771484,\n       0.0262451], dtype=bfloat16)}}, 'layer_22': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00068823,  0.00820747,  0.00691753, ..., -0.01032871,\n         0.01214039, -0.01452747],\n       [-0.00807814, -0.00087587,  0.01156158, ..., -0.00500905,\n         0.0198493 ,  0.00917682]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.54688, 2.875, 2.70312, ..., 2.375, 2.73438, 2.35938], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([3.73438, 3.75, 3.84375, ..., 3.57812, 3.89062, 3.48438], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.232422, 0.261719, 0.180664, ..., 0.330078, 0.298828, 0.355469],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.090332, -0.0563965, -0.0976562, ..., -0.104004, -0.11084,\n       -0.0168457], dtype=bfloat16)}}, 'layer_23': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00148038,  0.0081275 ,  0.0149825 , ...,  0.00171928,\n        -0.0045339 ,  0.00112129],\n       [-0.01026383,  0.0025746 , -0.02289991, ..., -0.00131096,\n         0.00538384, -0.00893523]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.21875, 2.28125, 2.20312, ..., 2.07812, 2.29688, 2.03125],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.15625, 4.28125, 4.34375, ..., 4.25, 4.53125, 4], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.306641, 0.337891, 0.300781, ..., 0.367188, 0.396484, 0.429688],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.158203, -0.146484, -0.166016, ..., -0.147461, -0.173828,\n       -0.10791], dtype=bfloat16)}}, 'layer_24': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.0118248 ,  0.00209964,  0.00429165, ...,  0.00531876,\n         0.0007639 , -0.01389843],\n       [ 0.00161521,  0.01745081, -0.0089213 , ...,  0.01427022,\n        -0.00016093,  0.01795714]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.5625, 2.40625, 2.51562, ..., 2.625, 2.76562, 2.46875], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.75, 4.78125, 4.90625, ..., 5.59375, 5.34375, 4.6875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.248047, 0.223633, 0.21582, ..., 0.345703, 0.259766, 0.339844],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.188477, -0.169922, -0.19043, ..., -0.158203, -0.195312,\n       -0.142578], dtype=bfloat16)}}, 'layer_25': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.005503  , -0.00465591,  0.02688703, ...,  0.00167953,\n        -0.00383867,  0.01666052],\n       [ 0.00788943, -0.01279993, -0.01336973, ...,  0.00526251,\n        -0.00046879,  0.01022278]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([2.39062, 2.375, 2.32812, ..., 3.42188, 2.84375, 2.29688], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([4.6875, 4.84375, 4.9375, ..., 5.9375, 4.5625, 4.6875], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.296875, 0.261719, 0.265625, ..., 0.380859, 0.296875, 0.373047],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([-0.136719, -0.134766, -0.133789, ..., -0.0761719, -0.129883,\n       -0.105957], dtype=bfloat16)}}, 'layer_3': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00757848,  0.00208123, -0.0095167 , ...,  0.01346242,\n         0.01381325, -0.00154688],\n       [-0.01088316, -0.00166531, -0.02113895, ..., -0.00199354,\n         0.00065937,  0.00700611]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.166992, -0.209961, -0.139648, ..., -0.363281, -0.0634766,\n       -0.261719], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.361328, 0.380859, 0.306641, ..., 0.0698242, 0.480469, 0.386719],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.617188, 0.453125, 0.699219, ..., 0.785156, 0.363281, 0.527344],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.859375, 0.824219, 0.894531, ..., 1.19531, 0.0356445, 0.714844],      dtype=bfloat16)}}, 'layer_4': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[ 0.00232868,  0.00122111, -0.02715557, ...,  0.00275968,\n         0.0063306 ,  0.00120457],\n       [ 0.01015269, -0.00104287, -0.01713954, ...,  0.01712951,\n        -0.02799168, -0.01150994]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([-0.193359, -0.28125, -0.21582, ..., -0.378906, -0.0407715,\n       -0.332031], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.285156, 0.245117, 0.246094, ..., 0.0476074, 0.613281, 0.271484],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.652344, 0.507812, 0.613281, ..., 0.824219, -0.0534668, 0.363281],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.554688, 0.570312, 0.554688, ..., 0.851562, 0.124512, 0.453125],      dtype=bfloat16)}}, 'layer_5': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00584595, -0.00180545, -0.00662199, ..., -0.0220709 ,\n        -0.00569964, -0.00861686],\n       [ 0.00151854, -0.00964406,  0.00366633, ...,  0.00940564,\n        -0.00930284,  0.00364371]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0136108, -0.150391, -0.020874, ..., -0.355469, -0.0186768,\n       -0.425781], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.0888672, 0.0622559, 0.12793, ..., -0.00866699, 0.337891,\n       0.0756836], dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.490234, 0.255859, 0.330078, ..., 0.367188, -0.0544434, 0.046875],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.388672, 0.382812, 0.402344, ..., 0.597656, -0.0415039, 0.236328],      dtype=bfloat16)}}, 'layer_6': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.0155806 , -0.01371003, -0.01509875, ...,  0.01296713,\n         0.00798594,  0.00760426],\n       [-0.00061655,  0.01749108, -0.01459254, ...,  0.01223726,\n        -0.01537374,  0.00116413]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0039978, -0.124512, -0.0678711, ..., -0.241211, 0.00665283,\n       -0.359375], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.106934, 0.0874023, 0.219727, ..., 0.0168457, 0.365234, 0.10498],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([1.10156, 0.796875, 0.84375, ..., 0.988281, 0.0463867, 0.369141],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.435547, 0.447266, 0.443359, ..., 0.636719, -0.0673828, 0.363281],      dtype=bfloat16)}}, 'layer_7': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00536764,  0.01348992, -0.00598283, ..., -0.01268126,\n        -0.01520117, -0.01440818],\n       [ 0.00239141,  0.01290342,  0.00408962, ...,  0.00013094,\n         0.00600098, -0.00192806]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.0143433, -0.0620117, 0.0375977, ..., -0.0898438, 0.110352,\n       -0.135742], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.191406, 0.195312, 0.308594, ..., 0.118164, 0.625, 0.196289],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.726562, 0.589844, 0.59375, ..., 0.789062, -0.155273, 0.455078],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.542969, 0.582031, 0.550781, ..., 0.742188, -0.00248718, 0.455078],      dtype=bfloat16)}}, 'layer_8': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.00295627, -0.00559398, -0.00677068, ...,  0.01155958,\n        -0.01056946, -0.01427677],\n       [ 0.02465803,  0.01395147, -0.01297336, ..., -0.0011971 ,\n        -0.00226062, -0.00428502]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.120117, 0.132812, 0.211914, ..., 0.0247803, 0.125977, 0.0432129],      dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.277344, 0.273438, 0.369141, ..., 0.199219, 0.644531, 0.271484],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([1.14062, 1.02344, 1.03906, ..., 1.14062, 0.0703125, 0.894531],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.601562, 0.675781, 0.648438, ..., 0.785156, 0.0917969, 0.589844],      dtype=bfloat16)}}, 'layer_9': {'attn': {'attn_vec_einsum': {'w': LoraWeight(shape=(8, 256, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[-0.00212097, -0.00132751],\n        [-0.00643921, -0.0130615],\n        [-0.00396729, -0.000341415],\n        ...,\n        [-0.0174561, 0.0014267],\n        [-0.00152588, -0.00854492],\n        [0.0148315, 0.00283813]],\n\n       [[-0.0050354, 0.00366211],\n        [0.00344849, -0.0195312],\n        [0.00680542, 0.000835419],\n        ...,\n        [-0.00692749, -0.0195312],\n        [-0.00375366, -0.00375366],\n        [0.000246048, 0.0101929]],\n\n       [[0.00732422, -0.0130615],\n        [0.0251465, 0.0119629],\n        [-0.000341415, 0.00325012],\n        ...,\n        [-0.000146866, -0.00598145],\n        [-0.0125732, -0.00273132],\n        [-0.00375366, -0.000341415]],\n\n       ...,\n\n       [[0.00897217, -0.00741577],\n        [-0.00312805, -0.00460815],\n        [-0.00482178, 0.00325012],\n        ...,\n        [0.00897217, -0.00273132],\n        [0.0115967, -0.00334167],\n        [-0.0114136, 0.00515747]],\n\n       [[0.0162354, -0.0166016],\n        [0.00408936, 0.0018158],\n        [-0.0166016, -0.0233154],\n        ...,\n        [-0.00668335, -0.00769043],\n        [0.0119629, -0.00878906],\n        [0.0124512, -0.0100098]],\n\n       [[-0.00668335, -0.00854492],\n        [0.0078125, -0.0211182],\n        [-0.00692749, 0.0078125],\n        ...,\n        [-0.00460815, 0.000246048],\n        [0.00122833, 0.00610352],\n        [0.00680542, 0.000835419]]], dtype=bfloat16), alpha=1.0)}, 'kv_einsum': {'w': LoraWeight(shape=(2, 4, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]],      dtype=bfloat16), b=Array([[[[0.00515747, 0.00585938],\n         [0.00866699, 0.0045166],\n         [-0.0289307, 0.0133057],\n         ...,\n         [0.00262451, -0.00439453],\n         [-0.00622559, 0.0119629],\n         [0.0203857, -0.00273132]],\n\n        [[-0.00334167, 0.00202942],\n         [-0.0117798, 0.00122833],\n         [0.0045166, -0.00823975],\n         ...,\n         [0.0124512, 0.0108643],\n         [-0.000934601, -0.00909424],\n         [0.00387573, 0.00366211]],\n\n        [[0.00430298, -0.00231934],\n         [0.00162506, 0.00262451],\n         [0.0178223, -0.000146866],\n         ...,\n         [0.00897217, -0.00552368],\n         [0.0128174, -0.00970459],\n         [-0.00132751, -0.00172424]],\n\n        [[-0.0050354, 0.0155029],\n         [0.00585938, -0.00552368],\n         [-0.000341415, -0.000541687],\n         ...,\n         [0.00634766, -0.00622559],\n         [0.00561523, -0.00396729],\n         [-0.00692749, -0.0140991]]],\n\n\n       [[[0.0133057, 0.0119629],\n         [0.000246048, -0.0211182],\n         [-0.00112915, 0.0115967],\n         ...,\n         [0.0189209, 0.000835419],\n         [0.00430298, 0.00515747],\n         [-0.00769043, 0.0148315]],\n\n        [[-0.00823975, -0.0146484],\n         [-0.00334167, 0.00344849],\n         [0.00732422, -0.0025177],\n         ...,\n         [0.00610352, -0.0117798],\n         [0.00387573, -0.00439453],\n         [0.00473022, -0.00172424]],\n\n        [[-0.00292969, -0.00799561],\n         [-0.0107422, -0.00552368],\n         [-0.00273132, -0.0233154],\n         ...,\n         [-0.00396729, -0.00854492],\n         [-0.00769043, -0.00482178],\n         [0.00325012, -0.0050354]],\n\n        [[0.000246048, 0.000637054],\n         [-0.00334167, 0.000637054],\n         [0.0112305, -0.00439453],\n         ...,\n         [0.0128174, 0.00927734],\n         [0.0030365, -0.00643921],\n         [0.00811768, -0.000934601]]]], dtype=bfloat16), alpha=1.0)}, 'q_einsum': {'w': LoraWeight(shape=(8, 2304, 256), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00515747, 0.00585938],\n        [0.00866699, 0.0045166],\n        [-0.0289307, 0.0133057],\n        ...,\n        [0.00262451, -0.00439453],\n        [-0.00622559, 0.0119629],\n        [0.0203857, -0.00273132]],\n\n       [[-0.00334167, 0.00202942],\n        [-0.0117798, 0.00122833],\n        [0.0045166, -0.00823975],\n        ...,\n        [0.0124512, 0.0108643],\n        [-0.000934601, -0.00909424],\n        [0.00387573, 0.00366211]],\n\n       [[0.00430298, -0.00231934],\n        [0.00162506, 0.00262451],\n        [0.0178223, -0.000146866],\n        ...,\n        [0.00897217, -0.00552368],\n        [0.0128174, -0.00970459],\n        [-0.00132751, -0.00172424]],\n\n       ...,\n\n       [[-0.00823975, -0.0146484],\n        [-0.00334167, 0.00344849],\n        [0.00732422, -0.0025177],\n        ...,\n        [0.00610352, -0.0117798],\n        [0.00387573, -0.00439453],\n        [0.00473022, -0.00172424]],\n\n       [[-0.00292969, -0.00799561],\n        [-0.0107422, -0.00552368],\n        [-0.00273132, -0.0233154],\n        ...,\n        [-0.00396729, -0.00854492],\n        [-0.00769043, -0.00482178],\n        [0.00325012, -0.0050354]],\n\n       [[0.000246048, 0.000637054],\n        [-0.00334167, 0.000637054],\n        [0.0112305, -0.00439453],\n        ...,\n        [0.0128174, 0.00927734],\n        [0.0030365, -0.00643921],\n        [0.00811768, -0.000934601]]], dtype=bfloat16), alpha=1.0)}}, 'mlp': {'gating_einsum': LoraWeight(shape=(2, 2304, 9216), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]]], dtype=bfloat16), b=Array([[[0.00262451, -0.00668335],\n        [0.0014267, -0.00720215],\n        [0.00708008, 0.0142822],\n        ...,\n        [-0.000341415, 0.00408936],\n        [-0.00439453, 0.0108643],\n        [0.0220947, 0.0203857]],\n\n       [[-0.00527954, 0.00283813],\n        [0.0101929, 0.00927734],\n        [0.00836182, -0.0211182],\n        ...,\n        [-0.000341415, -0.000341415],\n        [0.00221252, 0.0078125],\n        [-0.0050354, 0.0124512]]], dtype=bfloat16), alpha=1.0), 'linear': LoraWeight(shape=(9216, 2304), dtype=dtype(bfloat16), w=MaskedNode(), a=Array([[-0.0046731 ,  0.00286664,  0.00511242, ...,  0.01160862,\n        -0.00942933, -0.01301723],\n       [ 0.0052865 ,  0.00223007, -0.01150817, ..., -0.00929926,\n        -0.01117802,  0.00230565]], dtype=float32), b=Array([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       ...,\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32), alpha=1.0)}, 'post_attention_norm': {'scale': Array([0.107422, 0.113281, 0.164062, ..., 0.0292969, 0.0986328,\n       -0.0441895], dtype=bfloat16)}, 'post_ffw_norm': {'scale': Array([0.484375, 0.488281, 0.539062, ..., 0.390625, 0.65625, 0.408203],      dtype=bfloat16)}, 'pre_attention_norm': {'scale': Array([0.953125, 0.917969, 0.871094, ..., 1.10156, 0.15918, 0.871094],      dtype=bfloat16)}, 'pre_ffw_norm': {'scale': Array([0.267578, 0.339844, 0.296875, ..., 0.400391, -0.120117, 0.251953],      dtype=bfloat16)}}}}."
     ]
    }
   ],
   "source": [
    "training_cfg = TrainingConfig(learning_rate=1e-4,\n",
    "                              num_epochs=1,\n",
    "                              eval_every_n=20,\n",
    "                              batch_size=1,\n",
    "                              max_steps=10)\n",
    "\n",
    "params = train_loop(lora_model=lora_model,\n",
    "                    params={'transformer': lora_params},\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    tokenizer=tokenizer,\n",
    "                    training_cfg=training_cfg, \n",
    "                   lora_spec=lora_spec)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
